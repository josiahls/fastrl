# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02b_fastai.data.load.ipynb (unless otherwise specified).

__all__ = ['default_worker_f', 'MinimumDataLoader']

# Cell
# Python native modules
import os
# Third party libs
from fastcore.all import *
from fastai.torch_basics import *
# from torch.utils.data.dataloader import DataLoader as OrgDataLoader
from torchdata.datapipes.iter import HttpReader,IterDataPipe,IterableWrapper
from torch.utils.data import dataloader
from torch.utils.data.dataloader import _MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter,_DatasetKind
_loaders = (_MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter)
from torch.utils.data.dataloader_experimental import DataLoader2
# Local modules
from ..loop import *

from fastai.data.load import DataLoader as FastaiDataLoader

from torchdata.datapipes.iter import HttpReader,IterDataPipe

# Cell
def default_worker_f(worker_id):
    set_num_threads(1)
    info = get_worker_info()
    ds = info.dataset
    ds.offs = info.id
    set_seed(info.seed)
    if hasattr(ds,'wif'): ds.wif()

class MinimumDataLoader:
    def _fn_noops(self, x=None, *args, **kwargs): return x

    _IterableDataset_len_called,_auto_collation,collate_fn = None,False,_fn_noops
    _index_sampler,generator,prefetch_factor = Inf.count,None,2
    dataset_kind = _dataset_kind = _DatasetKind.Iterable
    drop_last = False

    def __init__(self,
                 datapipe:IterDataPipe,
                 pin_memory=False,
                 n_workers=0,
                 timeout=0,
                 persistent_workers=False
                ):
        #
        self.datapipe = datapipe
        self.worker_init_fn=default_worker_f
        self.num_workers = n_workers
        store_attr('pin_memory,timeout,persistent_workers')
    @property
    def dataset(self):
        "We also set self.dataset since torch~=1.11 still uses that field."
        return self.datapipe

    def __iter__(self):

        return _loaders[self.num_workers==0](self)

    @property
    def multiprocessing_context(self): return (None,multiprocessing)[self.num_workers>0]

    @contextmanager
    def no_multiproc(self):
        old_num_workers = self.num_workers
        try:
            self.num_workers = 0
            yield self.dataset
        finally: self.num_workers = old_num_workers

_collate_types = (ndarray, Tensor, typing.Mapping, str)