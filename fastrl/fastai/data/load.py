# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02d_fastai.data.load.ipynb (unless otherwise specified).

__all__ = ['TypeTransformLoop', 'ItemTransformLoop', 'BatchTransformLoop', 'default_loader_loop', 'GrandparentSplitter']

# Cell
# Python native modules
import os
from typing import Callable
# Third party libs
from fastcore.all import *
import torchdata.datapipes as dp
from torch.utils.data.dataloader_experimental import DataLoader2
from torch.utils.data.graph import traverse
# Local modules
from ...pipes.core import *
from ...pipes.map.mux import *
from ...pipes.map.demux import *

# Cell
class TypeTransformLoop(dp.map.MapDataPipe):
    def __init__(self,datapipe, type_tfms):
        self.type_tfms,self.datapipe = Pipeline(type_tfms),datapipe

    def __getitem__(self, index):
        data = self.datapipe[index]
        return self.type_tfms(data)

    def __len__(self): return len(self.datapipe)

class ItemTransformLoop(dp.iter.IterDataPipe):
    def __init__(self,source_datapipe, item_tfms:List[Callable]):
        self.item_tfms,self.source_datapipe = Pipeline(item_tfms),source_datapipe

    def __iter__(self):
        for data in self.source_datapipe:
            yield self.item_tfms(data)

class BatchTransformLoop(dp.iter.IterDataPipe):
    def __init__(self,source_datapipe, batch_tfms):
        self.batch_tfms,self.source_datapipe = Pipeline(batch_tfms),source_datapipe

    def __iter__(self):
        for data in self.source_datapipe:
            yield self.batch_tfms(data)

# Cell
def default_loader_loop(
    items:Iterable,
    splitter:Callable,
    cbs:Optional[List[Callback]]=None,
    type_tfms:Optional[Transform]=None,
    item_tfms:Optional[Transform]=None,
    batch_tfms:Optional[Transform]=None,
    bs:int=2,
    shuffler:Optional[Union[dp.iter.IterDataPipe,dp.map.MapDataPipe]]=None
):
    pipe = dp.map.SequenceWrapper(items) #
    train_vals = DemultiplexerMapDataPipe(
        pipe,
        num_instances=2,
        classifier_fn=splitter,
        drop_none=True
    )
    train_vals = L(train_vals).map(TypeTransformLoop,type_tfms=ifnone(type_tfms,L()))
    if shuffler:
        train_vals = train_vals.map(shuffler)
    else:
        train_vals = train_vals.map(Self.shuffle())
    train_vals = train_vals.map(dp.iter.MapToIterConverter)
    train_vals = L(train_vals).map(dp.iter.ShardingFilter)
    train_vals = train_vals.map(ItemTransformLoop, item_tfms=ifnone(item_tfms,L()))
    train_vals = train_vals.map(Self.batch(batch_size=bs))

    pipe = add_cbs_to_pipes(dp.iter.Zipper(*train_vals),cbs)

    return pipe.datapipes

# Cell
def GrandparentSplitter(train='train',valid='valid'):
    def splitter(item):
        if all(s not in item.parts for s in (train,valid)): return None
        if item.is_dir(): return None
        # valid=1, train=0
        return valid in item.parts
    return splitter