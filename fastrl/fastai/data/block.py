# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02e_fastai.data.block.ipynb (unless otherwise specified).

__all__ = ['TransformBlock', 'simple_iter_loader_loop', 'DataBlock', 'Flatten', 'NStepPipe', 'NSkipPipe',
           'NStepCallback', 'DictCollate', 'DictToTensor', 'make_step', 'GymTypeTransform', 'GymStepTransform',
           'GymTransformBlock']

# Cell
# Python native modules
import os
from typing import Any,Callable
from inspect import isfunction,ismethod
# Third party libs
from fastcore.all import *
from torch.utils.data.dataloader_experimental import DataLoader2
from fastai.torch_core import *
from fastai.data.transforms import *
import torchdata.datapipes as dp
from collections import deque
from fastai.imports import *
# Local modules
from .load import *
from .pipes.core import *
from ...core import *

# Cell
def _merge_grouper(o):
    if isinstance(o, LambdaType): return id(o)
    elif isinstance(o, type): return o
    elif (isfunction(o) or ismethod(o)): return o.__qualname__
    return o.__class__

def _merge_tfms(*tfms):
    "Group the `tfms` in a single list, removing duplicates (from the same class) and instantiating"
    g = groupby(concat(*tfms), _merge_grouper)
    return L(v[-1] for k,v in g.items()).map(instantiate)

def _zip(x): return L(x).zip()

# Cell
class TransformBlock():
    "A basic wrapper that links defaults transforms for the data block API"
    def __init__(self,
        type_tfms:list=None, # One or more `Transform`s for converting types. These will be re-called if workers!=0 for the dataloader.
        item_tfms:list=None, # `ItemTransform`s, applied on an item
        batch_tfms:list=None, # `Transform`s or `RandTransform`s, applied by batch
        cbs:list=None, # `Callback`s for use in dataloaders
        dl_type:DataLoader2=None, # Task specific `TfmdDL`, defaults to `TfmdDL`
        dls_kwargs:dict=None, # Additional arguments to be passed to `DataLoaders`
    ):
        self.type_tfms  =            L(type_tfms)
        self.item_tfms  =            L(item_tfms)
        self.batch_tfms =            L(batch_tfms)
        self.cbs        =            L(cbs)
        self.dl_type,self.dls_kwargs = dl_type,({} if dls_kwargs is None else dls_kwargs)

# Cell
def simple_iter_loader_loop(
    items:Iterable,
    cbs:Optional[List[Callback]]=None,
    type_tfms:Optional[Transform]=None,
    item_tfms:Optional[Transform]=None,
    batch_tfms:Optional[Transform]=None,
    bs:int=2,
    n:int=1
):
    pipe = dp.map.SequenceWrapper(items).add_cbs(cbs)
    pipe = TypeTransformLoop(pipe, type_tfms=ifnone(type_tfms,L())).add_cbs(cbs)
    pipe = dp.map.InMemoryCacheHolder(pipe).add_cbs(cbs)
    pipe = dp.iter.MapToIterConverter(pipe).add_cbs(cbs) # Will intialize the gym object, which will be an issue when doing multiproc
    pipe = dp.iter.ShardingFilter(pipe).add_cbs(cbs)
    pipe = pipe.cycle(count=n).add_cbs(cbs)
    pipe = ItemTransformLoop(pipe, item_tfms=ifnone(item_tfms,L())).add_cbs(cbs)
    pipe = pipe.batch(bs).add_cbs(cbs)
    pipe = BatchTransformLoop(pipe, batch_tfms=ifnone(batch_tfms,L())).add_cbs(cbs)

    return pipe

# Cell
class DataBlock(object):
    def __init__(
        self,
        blocks:List[TransformBlock]=None, # Transform blocks to use
        loader_loop:Callable=None,
        dl_type=None
    ):
        store_attr(but='loader_loop')
        self.loader_loop = ifnone(loader_loop,default_loader_loop)
        blocks = L(self.blocks if blocks is None else blocks)
        blocks = L(b() if callable(b) else b for b in blocks)
        self.type_tfms = blocks.attrgot('type_tfms', L())

        self.cbs = blocks.attrgot('cbs', L())
        self.item_tfms  = _merge_tfms(*blocks.attrgot('item_tfms',  L()))
        self.batch_tfms = _merge_tfms(*blocks.attrgot('batch_tfms', L()))
        for b in blocks:
            if getattr(b, 'dl_type', None) is not None: self.dl_type = b.dl_type
        if dl_type is not None: self.dl_type = dl_type
        self.dataloaders = delegates(self.dl_type.__init__)(self.dataloaders)
        self.dls_kwargs = merge(*blocks.attrgot('dls_kwargs', {}))

    def datapipes(
        self,
        source:Any,
        bs=2,
        n=1,
        **kwargs,
    ):
        return L(self.loader_loop(
            source,
            cbs=cbs,
            type_tfms=type_tfms,
            item_tfms=self.item_tfms,
            batch_tfms=self.batch_tfms,
            bs=bs,
            n=n,
            **kwargs
        ) for type_tfms,cbs in zip(self.type_tfms,self.cbs))

    def dataloaders(
        self,
        source:Any,
        n_workers=0,
        **kwargs
    ):
        pipes = self.datapipes(source,**kwargs)
        return L(pipes).map(DataLoader2,num_workers=n_workers,**self.dls_kwargs)

# Cell
import gym

class Flatten(dp.iter.IterDataPipe):

    def __init__(self, source_datapipe, **kwargs) -> None:
        self.source_datapipe = source_datapipe
        self.kwargs = kwargs

    def __iter__(self):
        for o in self.source_datapipe:
            if not is_listy(o):
                raise Exception(f'Expected listy object got {type(o)}\n{o}')
            for oo in o: yield oo

class NStepPipe(dp.iter.IterDataPipe):

    def __init__(self, source_datapipe, n=1, **kwargs) -> None:
        self.source_datapipe = source_datapipe
        self.n = n
        self.kwargs = kwargs

    def __iter__(self):
        buffer = []
        for o in self.source_datapipe:
            if not type(o)==dict:
                raise Exception(f'Expected dict object generated from `make_step` got {type(o)}\n{o}')

            buffer.append(o)
            if not o['done'] and len(buffer)<self.n: continue

            while o['done'] and len(buffer)!=0:
                yield tuple(buffer)
                buffer.pop(0)

            if not o['done']:
                yield tuple(buffer)
                buffer.pop(0)

class NSkipPipe(dp.iter.IterDataPipe):

    def __init__(self, source_datapipe, n=1, **kwargs) -> None:
        self.source_datapipe = source_datapipe
        self.n = n
        self.kwargs = kwargs

    def __iter__(self):
        skip_idx = 0
        for o in self.source_datapipe:
            if not type(o)==dict:
                raise Exception(f'Expected dict object generated from `make_step` got {type(o)}\n{o}')

            skip_idx += 1 # Be aware of the ordering here. we want to always show the first step when we can.
            if skip_idx%self.n==0 or o['done']:
                yield o
                if o['done']: skip_idx = 0

# Cell
class NStepCallback(Callback):
    "A list of data pipes that have an associated job."
    call_on=L(ItemTransformLoop)
    exclude_under=L()

    def __init__(self,nsteps=1,nskip=1):
        store_attr()
        self.pipes = L(partial(NSkipPipe,n=nskip),
                       partial(NStepPipe, n=nsteps),
                       Flatten
                       )

# Cell
class DictCollate(Transform):
    def encodes(self,o): return L(o).map(BD).sum()

class DictToTensor(Transform):
    def encodes(self,o:dict):
        for k,v in o.items():
            v = TensorBatch(v)
            if len(v.shape)==0: v = v.unsqueeze(0)
            o[k] = v
        return o

# Cell
def make_step(
    state,
    next_state,
    done,
    reward,
    action,
    env_id
):
    return dict(state=state,next_state=next_state,done=done,reward=reward,action=action,env_id=env_id)

class GymTypeTransform(Transform):
    def encodes(self,o): return gym.make(o)

class GymStepTransform(Transform):
    def encodes(self,o:gym.Env):

        action = 0

        if getattr(o,'is_done',True):
            state = o.reset(seed=getattr(self,'seed',0))
            o.is_done = False
        else:
            state = o.state
        next_state,reward,done,_ = o.step(action)

        if done: o.is_done = True
        o.state = next_state

        return make_step(state,next_state,done,reward,action,env_id=id(o))

GymTransformBlock = TransformBlock(
    type_tfms  = GymTypeTransform,
    item_tfms  = (GymStepTransform,DictToTensor),
    batch_tfms = DictCollate,
    cbs = NStepCallback(nsteps=3,nskip=2)
)