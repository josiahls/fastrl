# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02f_fastai.learner.ipynb (unless otherwise specified).

__all__ = ['XYSplit', 'ModelPredict', 'LossCalc', 'default_train_loop', 'only_train_loop', 'Learner', 'DQN']

# Cell
# Python native modules
import os
from typing import *
# Third party libs
from fastcore.all import *
from torch.utils.data.dataloader_experimental import DataLoader2
import torchdata.datapipes as dp
from torch.nn import *
from torch.optim import *
from fastai.torch_basics import *
from fastai.torch_core import *

# Local modules
from .data.block import *
from .data.pipes.core import *

# Cell
class XYSplit(dp.iter.IterDataPipe):
    def __init__(self,source_datapipe,learn,x_fld):
        self.source_datapipe = source_datapipe
        self.learn = learn
        self.x_fld = x_fld

    def __iter__(self):
        for batch in self.source_datapipe:
            yield (batch[self.x_fld],batch)

# Cell
class ModelPredict(dp.iter.IterDataPipe):
    def __init__(self,source_datapipe,learn):
        self.source_datapipe = source_datapipe
        self.learn = learn

    def __iter__(self):
        for xb,yb in self.source_datapipe:
            self.learn.xb = xb
            self.learn.yb = yb
            self.learn.preds = self.learn.model(xb)
            yield self.learn.preds

# Cell
class LossCalc(dp.iter.IterDataPipe):
    def __init__(self,source_datapipe,learn,y_target):
        self.source_datapipe = source_datapipe
        self.learn = learn
        self.y_target = y_target

    def __iter__(self):
        for batch in self.source_datapipe:
            self.loss_grad = self.learn.loss_func(self.learn.preds, *self.learn.yb[self.y_target])
            self.loss = self.loss_grad.clone()
            yield self.loss

# Cell
def default_train_loop(
    dls:List[DataLoader2],
    cbs:Optional[List[Callback]]=None,
):
    train_valid = L(dls).map(dp.iter.IterableWrapper).add_cbs(cbs)

    return train_vals

# Cell
def only_train_loop(
    dls:List[DataLoader2],
    cbs:Optional[List[Callback]]=None,
):
    train = dp.iter.IterableWrapper(dls,deepcopy=False).add_cbs(cbs)

    # train =

    return train

# Cell
class Learner(dp.iter.IterDataPipe):
    def __init__(self,model,dls,opt,loss_func,cbs,train_loop=None):
        store_attr('model,dls,opt,loss_func')
        self.cbs = L()
        self.add_cbs(cbs)
        self.train_loop = ifnone(train_loop,default_train_loop)

    def fit(self,epochs):
        self.it = iter(self.dls[0])
        train_pipe = only_train_loop(L(self.it),self.cbs) # Do not pass tuple, otherwise traverse will try to read the dl datapipes
        for res in train_pipe:
            print(res)

    def add_cbs(self, cbs):
        L(cbs).map(self.add_cb)
        return self

    def remove_cbs(self, cbs):
        L(cbs).map(self.remove_cb)
        return self

    def add_cb(self, cb):
        if isinstance(cb, type): cb = cb()
        cb.learn = self
        cb.init_pipes()
        setattr(self, cb.name, cb)
        self.cbs.append(cb)
        return self

# Cell
class DQN(Module):
    def __init__(self,state_sz:int,action_sz:int,hidden=512):
        self.layers=Sequential(
            Linear(state_sz,hidden),
            ReLU(),
            Linear(hidden,action_sz),
        )
    def forward(self,x): return self.layers(x)