# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02f_fastai.learner.ipynb (unless otherwise specified).

__all__ = ['XYSplit', 'ModelPredict', 'LossCalc', 'default_train_loop', 'find_pipes', 'Epocher', 'T_co',
           'only_train_loop', 'Learner', 'DQN', 'QCalc', 'ModelLearnCalc']

# Cell
# Python native modules
import os
from typing import *
# Third party libs
from fastcore.all import *
from torch.utils.data.dataloader_experimental import DataLoader2
import torchdata.datapipes as dp
from torch.nn import *
from torch.optim import *
from fastai.torch_basics import *
from fastai.torch_core import *
from torch.utils.data.graph import traverse

# Local modules
from .data.block import *
from .data.pipes.core import *

# Cell
class XYSplit(dp.iter.IterDataPipe):
    def __init__(self,source_datapipe,learn,x_fld):
        self.source_datapipe = source_datapipe
        self.learn = learn
        self.x_fld = x_fld

    def __iter__(self):
        for b in self.source_datapipe:

            for v in b.values():
                if v.shape[0]==1 and len(v.shape)!=2: v.squeeze_(0)

            yield (b[self.x_fld],b)

# Cell
class ModelPredict(dp.iter.IterDataPipe):
    def __init__(self,source_datapipe,learn):
        self.source_datapipe = source_datapipe
        self.learn = learn

    def __iter__(self):
        for xb,yb in self.source_datapipe:
            self.learn.xb = xb
            self.learn.yb = yb
            self.learn.preds = self.learn.model(xb)
            yield self.learn.preds

# Cell
class LossCalc(dp.iter.IterDataPipe):
    def __init__(self,source_datapipe,learn,y_target=None):
        self.source_datapipe = source_datapipe
        self.learn = learn
        self.y_target = y_target

    def __iter__(self):
        for batch in self.source_datapipe:
            if self.y_target is None:
                self.learn.loss_grad = self.learn.loss_func(self.learn.preds, *self.learn.yb)
            else:
                self.loss_grad = self.learn.loss_func(self.learn.preds, *self.learn.yb[self.y_target])
            self.learn.loss = self.learn.loss_grad.clone()
            yield self.learn.loss

# Cell
def default_train_loop(
    dls:List[DataLoader2],
    cbs:Optional[List[Callback]]=None,
):
    train_valid = L(dls).map(dp.iter.IterableWrapper).add_cbs(cbs)

    return train_vals

# Cell
def find_pipes(
    pipe:Union[dp.map.MapDataPipe,dp.iter.IterDataPipe],
    fn,
    pipe_list=None
):
    pipe_list = ifnone(pipe_list,[])
    if issubclass(pipe.__class__,(dp.map.MapDataPipe,dp.iter.IterDataPipe)) and fn(pipe): pipe_list.append(pipe)
    for v in traverse(pipe,only_datapipe=True).values(): # We dont want to traverse non-dp objects.
        for k,_ in v.items():
            cbs = find_pipes(k,fn,pipe_list)
    return pipe_list

# Cell
T_co = TypeVar("T_co", covariant=True)

class Epocher(dp.iter.IterDataPipe):
    def __init__(self,source_datapipe,epochs,learner):
        self.source_datapipe = source_datapipe
        self.learner = learner
        self.learner.epochs = epochs
        self.learner.epoch = 0
        self.learner.mbar = master_bar(list(range(self.learner.epochs)))

        self.metrics = None

    def __iter__(self) -> Iterator[T_co]:
        self.metrics = find_pipes(self.source_datapipe,lambda o:getattr(o,'is_metric',False))
        print('found: ',self.metrics)
        self.learner.mbar.write([o.name for o in self.metrics], table=True)
        for i in self.learner.mbar:
            yield from self.source_datapipe
            self.learner.epoch = i
            logs = [o.value for o in self.metrics]
            self.learner.mbar.write([f'{l:.6f}' if isinstance(l, float) else str(l) for l in logs], table=True)


# Cell
def only_train_loop(
    dls:List[DataLoader2],
    epochs:int,
    learner,
    cbs:Optional[List[Callback]]=None,
):

    train = dp.iter.IterableWrapper(dls,deepcopy=False)
    train = Epocher(train,epochs,learner=learner)

    # for _pipe in reversed(find_pipes(train,lambda o:True)): train = _pipe.add_cbs_before(cbs)
    # for _pipe in reversed(find_pipes(train,lambda o:True)): train = _pipe.add_cbs_after(cbs)
    train = add_cbs_to_pipes(train,cbs)

    return train

# Cell
class Learner(): #(dp.iter.IterDataPipe):
    def __init__(self,model,dls,opt,loss_func,cbs,train_loop=None):
        store_attr('model,dls,opt,loss_func')
        self.cbs = L()
        self.add_cbs(cbs)
        self.train_loop = ifnone(train_loop,default_train_loop)

    def fit(self,epochs):
        self.it = iter(self.dls[0])
        self.train_pipe = only_train_loop(L(self.it),epochs,self,self.cbs) # Do not pass tuple, otherwise traverse will try to read the dl datapipes
        for res in self.train_pipe:pass
            # print(res)

    def add_cbs(self, cbs):
        L(cbs).map(self.add_cb)
        return self

    def remove_cbs(self, cbs):
        L(cbs).map(self.remove_cb)
        return self

    def add_cb(self, cb):
        if isinstance(cb, type): cb = cb()
        cb.learn = self
        # cb.init_pipes()
        setattr(self, cb.name, cb)
        self.cbs.append(cb)
        return self

# Cell
class DQN(Module):
    def __init__(self,state_sz:int,action_sz:int,hidden=512):
        self.layers=Sequential(
            Linear(state_sz,hidden),
            ReLU(),
            Linear(hidden,action_sz),
        )
    def forward(self,x): return self.layers(x)

# Cell
class QCalc(dp.iter.IterDataPipe):
    def __init__(self,source_datapipe,learn,discount,nsteps):
        self.source_datapipe = source_datapipe
        self.learn = learn
        self.discount = discount
        self.nsteps = nsteps

    def __iter__(self):
        for batch in self.source_datapipe:
            self.learn.done_mask = self.learn.yb['done'].reshape(-1,)
            self.learn.next_q = self.learn.model(self.learn.yb['next_state'])
            self.learn.next_q = self.learn.next_q.max(dim=1).values.reshape(-1,1)
            self.learn.next_q[self.learn.done_mask] = 0 #xb[done_mask]['reward']
            self.learn.targets = self.learn.yb['reward']+self.learn.next_q*(self.discount**self.nsteps)
            self.learn.pred = self.learn.model(self.learn.yb['state'])


            t_q=self.learn.pred.clone()
            t_q.scatter_(1,self.learn.yb['action'],self.learn.targets)
            # finalize the xb and yb
            self.learn.yb=(t_q,)
            yield batch

class ModelLearnCalc(dp.iter.IterDataPipe):
    def __init__(self,source_datapipe,learn):
        self.source_datapipe = source_datapipe
        self.learn = learn

    def __iter__(self):
        for batch in self.source_datapipe:
            self.learn.loss_grad.backward()
            self.learn.opt.step()
            self.learn.opt.zero_grad()
            yield self.learn.loss