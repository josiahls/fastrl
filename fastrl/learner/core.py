# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/10a_learner.core.ipynb.

# %% auto 0
__all__ = ['LearnerBase', 'LearnerHead']

# %% ../nbs/10a_learner.core.ipynb 3
# Python native modules
import os
# Third party libs
from fastcore.all import *
import torchdata.datapipes as dp
import torch
from fastai.torch_basics import *
from fastai.torch_core import *
from torch.utils.data.dataloader_experimental import DataLoader2
# Local modules
from ..core import *
from ..pipes.core import *
from ..loggers.core import *

# %% ../nbs/10a_learner.core.ipynb 5
class LearnerBase(dp.iter.IterDataPipe):
    def __init__(self,
            model:Module, # The base NN that we getting raw action values out of.
            dls:List[DataLoader2], # The dataloaders to read data from for training
            loss_func=None, # The loss function to use
            opt=None, # The optimizer to use
            # LearnerBase will yield each dl individually by default. If `zipwise=True`
            # next() will be called on `dls` and will `yield next(dl1),next(dl2),next(dl1)...`
            zipwise:bool=False
    ):
        self.loss_func = loss_func
        self.opt = opt
        self.model = model
        self.iterable = dls
        self.zipwise = zipwise
        self.learner_base = self
        self.batches = find_dp(dls[0].dataset,dp.iter.Header).limit

    def __iter__(self):
        dls = [iter(dl) for dl in self.iterable]
        exhausted = []
        if self.zipwise:
            yield from [next(dl) for i,dl in enumerate(dls) if i not in exhausted]
        else:
            while not exhausted:
                for i,dl in enumerate(dls): 
                    while i not in exhausted:
                        try:
                            yield next(dl)
                        except StopIteration:
                            exhausted.append(i)
                            
add_docs(
    LearnerBase,
    """
    """
) 

# %% ../nbs/10a_learner.core.ipynb 6
class LearnerHead(dp.iter.IterDataPipe):
    def __init__(self,source_datapipe):
        self.source_datapipe = source_datapipe
        self.learner_base = find_dp(self.source_datapipe,LearnerBase)

    def __iter__(self): yield from self.source_datapipe
    
    def fit(self,epochs):
        epocher = find_dp(self,EpocherCollector)
        epocher.epochs = epochs
        
        for iteration in self: 
            pass
        
add_docs(
    LearnerHead,
    """
    """,
    fit="Runs the `LearnerHead` pipeline for `epochs`"
)  
