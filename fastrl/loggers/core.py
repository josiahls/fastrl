# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/09a_loggers.core.ipynb.

# %% auto 0
__all__ = ['LoggerBase', 'LogCollector', 'Record', 'ProgressBarLogger', 'RewardCollector', 'EpocherCollector', 'BatchCollector']

# %% ../nbs/09a_loggers.core.ipynb 3
# Python native modules
import os,typing
# Third party libs
from fastcore.all import *
from torch.multiprocessing import Queue
import torchdata.datapipes as dp
from fastprogress.fastprogress import *
# Local modules
from ..pipes.core import *

# %% ../nbs/09a_loggers.core.ipynb 5
class LoggerBase(dp.iter.IterDataPipe):
    def __init__(self,source_datapipe=None):
        self.source_datapipe = source_datapipe
        self.main_queue = Queue()
        
    def connect_source_datapipe(self,pipe):
        self.source_datapipe = pipe
        return self
        

# %% ../nbs/09a_loggers.core.ipynb 7
class LogCollector(dp.iter.IterDataPipe):
    def __init__(self,
         source_datapipe, # The parent datapipe, likely the one to collect metrics from
         logger_bases:List[LoggerBase] # `LoggerBase`s that we want to send metrics to
        ):
        self.source_datapipe = source_datapipe
        self.main_queues = [o.main_queue for o in logger_bases]
        
    def __iter__(self): raise NotImplementedError

# %% ../nbs/09a_loggers.core.ipynb 9
class Record(typing.NamedTuple):
    name:str
    value:typing.Any

# %% ../nbs/09a_loggers.core.ipynb 10
class ProgressBarLogger(LoggerBase):
    def __init__(self,
                 # This does not need to be immediately set since we need the `LogCollectors` to 
                 # first be able to reference its queues.
                 source_datapipe=None, 
                 # For automatic pipe attaching, we can designate which pipe this should be
                 # referneced for information on which epoch we are on
                 epoch_on_pipe:dp.iter.IterDataPipe=None,
                 # For automatic pipe attaching, we can designate which pipe this should be
                 # referneced for information on which batch we are on
                 batch_on_pipe:dp.iter.IterDataPipe=None
                ):
        self.source_datapipe = source_datapipe
        self.main_queue = Queue()
        self.epoch_on_pipe = epoch_on_pipe
        self.batch_on_pipe = batch_on_pipe
        
        self.collector_keys = None
        self.attached_collectors = None
    
    def dequeue(self): 
        while not self.main_queue.empty(): yield self.main_queue.get()
        
    def __iter__(self):
        epocher = find_pipe_instance(self,self.epoch_on_pipe)
        batcher = find_pipe_instance(self,self.batch_on_pipe)
        mbar = master_bar(range(epocher.epochs)) 
        pbar = progress_bar(range(batcher.batches),parent=mbar,leave=False)

        mbar.update(0)
        for i,record in enumerate(self.source_datapipe):
            if i==0:
                self.attached_collectors = {o.name:o.value for o in self.dequeue()}
                mbar.write(self.attached_collectors, table=True)
                self.collector_keys = list(self.attached_collectors)
                    
            attached_collectors = {o.name:o.value for o in self.dequeue()}
            
            if attached_collectors:
                self.attached_collectors = merge(self.attached_collectors,attached_collectors)
            
            if 'batch' in attached_collectors:
                pbar.update(attached_collectors['batch'])
                
            if 'epoch' in attached_collectors:
                mbar.update(attached_collectors['epoch'])
                collector_values = {k:self.attached_collectors.get(k,None) for k in self.collector_keys}
                mbar.write([f'{l:.6f}' if isinstance(l, float) else str(l) for l in collector_values.values()], table=True)
            yield record

        attached_collectors = {o.name:o.value for o in self.dequeue()}
        if attached_collectors: self.attached_collectors = merge(self.attached_collectors,attached_collectors)

        collector_values = {k:self.attached_collectors.get(k,None) for k in self.collector_keys}
        mbar.write([f'{l:.6f}' if isinstance(l, float) else str(l) for l in collector_values.values()], table=True)

        pbar.on_iter_end()
        mbar.on_iter_end()
            

# %% ../nbs/09a_loggers.core.ipynb 11
class RewardCollector(LogCollector):
    def __iter__(self):
        for q in self.main_queues: q.put(Record('reward',None))
        for steps in self.source_datapipe:
            if isinstance(steps,dp.DataChunk):
                for step in steps:
                    for q in self.main_queues: q.put(Record('reward',step.reward.detach().numpy()))
            else:
                for q in self.main_queues: q.put(Record('reward',steps.reward.detach().numpy()))
            yield steps

# %% ../nbs/09a_loggers.core.ipynb 12
class EpocherCollector(dp.iter.IterDataPipe):
    def __init__(self,
            source_datapipe,
            epochs:int=0,
            logger_bases:List[LoggerBase]=None # `LoggerBase`s that we want to send metrics to
        ):
        self.source_datapipe = source_datapipe
        self.main_queues = [o.main_queue for o in logger_bases] if logger_bases is not None else None
        self.iteration_started = False
        self.epochs = epochs
        self.epoch = 0

    def __iter__(self): 
        if self.main_queues is not None and not self.iteration_started:
            for q in self.main_queues: q.put(Record('epoch',None))
            self.iteration_started = True
            
        for i in range(self.epochs): 
            self.epoch = i
            if self.main_queues is not None:
                for q in self.main_queues: q.put(Record('epoch',self.epoch))
            yield from self.source_datapipe
            
add_docs(
    EpocherCollector,
    """Tracks the number of epochs that the pipeline is currently on."""
)

# %% ../nbs/09a_loggers.core.ipynb 13
class BatchCollector(dp.iter.IterDataPipe):
    def __init__(self,
            source_datapipe,
            logger_bases:List[LoggerBase], # `LoggerBase`s that we want to send metrics to
            batches:Optional[int]=None,
            # If `batches` is None, `BatchCollector` with try to find: `batch_on_pipe` instance
            # and try to grab a `batches` field from there.
            batch_on_pipe:dp.iter.IterDataPipe=None 
        ):
        self.source_datapipe = source_datapipe
        self.main_queues = [o.main_queue for o in logger_bases] if logger_bases is not None else None
        self.iteration_started = False
        self.batches = ifnone(
            batches,
            find_pipe_instance(self.source_datapipe,pipe_cls=batch_on_pipe).batches
        )
        self.batch = 0

    def __iter__(self): 
        if self.main_queues is not None and not self.iteration_started:
            for q in self.main_queues: q.put(Record('batch',None))
            self.iteration_started = True
            
        self.batch = 0
        for batch,record in enumerate(self.source_datapipe): 
            yield record
            self.batch = batch
            if self.main_queues is not None:
                for q in self.main_queues: q.put(Record('batch',batch))
                
add_docs(
    BatchCollector,
    """Tracks the number of batches that the pipeline is currently on."""
)
