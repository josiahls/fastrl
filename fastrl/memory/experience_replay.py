# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/04_Memory/06a_memory.experience_replay.ipynb.

# %% auto 0
__all__ = ['ExperienceReplay']

# %% ../../nbs/04_Memory/06a_memory.experience_replay.ipynb 3
# Python native modules
import os
from typing import *
from warnings import warn
from copy import copy
# Third party libs
from fastcore.all import *
from ..torch_core import *
import torchdata.datapipes as dp
import numpy as np
import torch
# Local modules
from ..core import *
from ..pipes.iter.transforms import *
from ..pipes.map.transforms import *

# %% ../../nbs/04_Memory/06a_memory.experience_replay.ipynb 5
class ExperienceReplay(dp.iter.IterDataPipe):
    debug=False
    def __init__(self,
            source_datapipe,
            learner=None,
            bs=1,
            max_sz=100,
            return_idxs=False,
            # If the `self.device` is not cpu, and `store_as_cpu=True`, then
            # calls to `sample()` will dynamically move them to `self.device`, and
            # next `sample()` will move them back to cpu before producing new samples.
            # This can be slower, but can save vram.
            # If `store_as_cpu=False`, then samples stay on `self.device`
            #
            # If being run with n_workers>0, shared_memory, and fork, this MUST be true. This is needed because
            # otherwise the tensors in the memory will remain shared with the tensors created in the 
            # dataloader.
            store_as_cpu:bool=True
        ):
        self.memory = np.array([None]*max_sz)
        self.source_datapipe = source_datapipe
        self.learner = learner
        if learner is not None:
            self.learner.experience_replay = self
        self.bs = bs
        self.max_sz = max_sz
        self._sz_tracker = 0
        self._idx_tracker = 0
        self._cycle_tracker = 0
        self.return_idxs = return_idxs
        self.store_as_cpu = store_as_cpu
        self._last_idx = None
        self.device = None

    def to(self,*args,**kwargs):
        self.device = kwargs.get('device',None)

    def sample(self,bs=None): 
        idxs = np.random.choice(range(self._sz_tracker),size=(ifnone(bs,self.bs),),replace=False)
        if self.return_idxs: return self.memory[idxs],idxs
        self._last_idx = idxs
        return [o.to(device=self.device) for o in self.memory[idxs]]
    
    def __repr__(self):
        return str({k:v if k!='memory' else f'{len(self)} elements' for k,v in self.__dict__.items()})

    def __len__(self): return self._sz_tracker
    
    def __iter__(self):
        for i,b in enumerate(self.source_datapipe):
            if self.debug: print('Experience Replay Adding: ',b)
            
            if not issubclass(b.__class__,(StepType,list,tuple)):
                raise Exception(f'Expected typing.NamedTuple,list,tuple object got {type(step)}\n{step}')
            
            if issubclass(b.__class__,StepType):   self.add(b)
            elif issubclass(b.__class__,(list,tuple)): 
                for step in b: self.add(step)
            else:
                raise Exception(f'This should not have occured: {self.__dict__}')
        
            if self._sz_tracker<self.bs: continue
            yield self.sample()

    def add(self,step:StepType): 
        if self.store_as_cpu: 
            step = step.clone().detach().to(device='cpu')
        
        if self._sz_tracker==0: 
            self.memory[self._idx_tracker] = step
            self._sz_tracker += 1
            self._idx_tracker = 1
        elif 0<self._sz_tracker<self.max_sz:
            self.memory[self._idx_tracker] = step
            self._sz_tracker += 1
            self._idx_tracker += 1
        elif self._sz_tracker>=self.max_sz:
            if self._idx_tracker>=self.max_sz:
                self._idx_tracker = 0
                self._cycle_tracker += 1
            self.memory[self._idx_tracker] = step
            self._idx_tracker += 1
        else:
            raise Exception(f'This should not have occured: {self.__dict__}')
            
add_docs(
ExperienceReplay,
"""Simplest form of memory. Takes steps from `source_datapipe` to stores them in `memory`. 
It outputs `bs` steps.""",
sample="Returns `bs` steps from `memory` in a uniform distribution.",
add="Adds new steps to `memory`. If `memory` reaches size `max_sz` then `step` will be added in earlier steps.",
to=torch.Tensor.to.__doc__
)
