---

title: DQN Basic


keywords: fastai
sidebar: home_sidebar

summary: "Core DQN modules, pipes, and tooling"
description: "Core DQN modules, pipes, and tooling"
nb_path: "nbs/10b_agents.dqn.basic.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/10b_agents.dqn.basic.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Agent">Agent<a class="anchor-link" href="#Agent"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DQN" class="doc_header"><code>class</code> <code>DQN</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L30" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DQN</code>(<strong><code>state_sz</code></strong>:<code>int</code>, <strong><code>action_sz</code></strong>:<code>int</code>, <strong><code>hidden</code></strong>=<em><code>512</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BasicModelForwarder" class="doc_header"><code>class</code> <code>BasicModelForwarder</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L41" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BasicModelForwarder</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>IterDataPipe</code></p>
</blockquote>
<p>Takes input from <code>source_datapipe</code> and pushes through the agent bases model assuming there is only one model field.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Check that the 1x4 tensor assuccessfully pushes through the model can get expected outputs...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># Setup the agent</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentBase</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">BasicModelForwarder</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentHead</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">agent</span><span class="p">([</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([-0.2909, -1.0357], grad_fn=&lt;AddBackward0&gt;)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="StepFieldSelector" class="doc_header"><code>class</code> <code>StepFieldSelector</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L51" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>StepFieldSelector</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>IterDataPipe</code></p>
</blockquote>
<p>Grabs <code>field</code> from <code>source_datapipe</code> to push to the rest of the pipeline.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>source_datapipe</code></strong></td>
<td></td>
<td></td>
<td>datapipe whose next(source_datapipe) -&gt; <a href="/fastrl/core.html#StepType"><code>StepType</code></a></td>
</tr>
<tr>
<td><strong><code>field</code></strong></td>
<td><code>str</code></td>
<td><code>state</code></td>
<td>A field in <a href="/fastrl/core.html#StepType"><code>StepType</code></a> to grab</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Check that using <a href="/fastrl/agents.dqn.basic.html#StepFieldSelector"><code>StepFieldSelector</code></a>, we can grab the <code>state</code> field from the <code>Simplestep</code> to push through the model...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">agent</span> <span class="o">=</span> <span class="n">AgentBase</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">StepFieldSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">field</span><span class="o">=</span><span class="s1">&#39;state&#39;</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">BasicModelForwarder</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentHead</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>

<span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">agent</span><span class="p">([</span><span class="n">SimpleStep</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mf">4.</span><span class="p">]))]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([-0.2909, -1.0357], grad_fn=&lt;AddBackward0&gt;)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ArgMaxer" class="doc_header"><code>class</code> <code>ArgMaxer</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L68" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ArgMaxer</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>IterDataPipe</code></p>
</blockquote>
<p>Iterable-style DataPipe.</p>
<p>All DataPipes that represent an iterable of data samples should subclass this.
This style of DataPipes is particularly useful when data come from a stream, or
when the number of samples is too large to fit them all in memory. <code>IterDataPipe</code> is lazily initialized and its
elements are computed only when <code>next()</code> is called on the iterator of an <code>IterDataPipe</code>.</p>
<p>All subclasses should overwrite :meth:<code>__iter__</code>, which would return an
iterator of samples in this DataPipe. Calling <code>__iter__</code> of an <code>IterDataPipe</code> automatically invokes its
method <code>reset()</code>, which by default performs no operation. When writing a custom <code>IterDataPipe</code>, users should
override <code>reset()</code> if necessary. The common usages include resetting buffers, pointers,
and various state variables within the custom <code>IterDataPipe</code>.</p>
<p>Note:
    Only <code>one</code> iterator can be valid for each <code>IterDataPipe</code> at a time,
    and the creation a second iterator will invalidate the first one. This constraint is necessary because
    some <code>IterDataPipe</code> have internal buffers, whose states can become invalid if there are multiple iterators.
    The code example below presents details on how this constraint looks in practice.
    If you have any feedback related to this constraint, please see <code>GitHub IterDataPipe Single Iterator Issue</code>_.</p>
<p>These DataPipes can be invoked in two ways, using the class constructor or applying their
functional form onto an existing <code>IterDataPipe</code> (recommended, available to most but not all DataPipes).
You can chain multiple <code>IterDataPipe</code> together to form a pipeline that will perform multiple
operations in succession.</p>
<p>.. _GitHub IterDataPipe Single Iterator Issue:
    <a href="https://github.com/pytorch/data/issues/45">https://github.com/pytorch/data/issues/45</a></p>
<p>Note:
    When a subclass is used with :class:<code>~torch.utils.data.DataLoader</code>, each
    item in the DataPipe will be yielded from the :class:<code>~torch.utils.data.DataLoader</code>
    iterator. When :attr:<code>num_workers &gt; 0</code>, each worker process will have a
    different copy of the DataPipe object, so it is often desired to configure
    each copy independently to avoid having duplicate data returned from the
    workers. :func:<code>~torch.utils.data.get_worker_info</code>, when called in a worker
    process, returns information about the worker. It can be used in either the
    dataset's :meth:<code>__iter__</code> method or the :class:<code>~torch.utils.data.DataLoader</code> 's
    :attr:<code>worker_init_fn</code> option to modify each copy's behavior.</p>
<p>Examples:
    General Usage:</p>

<pre><code>    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; map_dp_1 = Mapper(dp, lambda x: x + 1)  # Using class constructor
    &gt;&gt;&gt; map_dp_2 = dp.map(lambda x: x + 1)  # Using functional form (recommended)
    &gt;&gt;&gt; list(map_dp_1)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; list(map_dp_2)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; filter_dp = map_dp_1.filter(lambda x: x % 2 == 0)
    &gt;&gt;&gt; list(filter_dp)
    [2, 4, 6, 8, 10]
Single Iterator Constraint Example:
    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; list(it1)
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; it2 = iter(source_dp)  # The creation of a new iterator invalidates `it1`
    &gt;&gt;&gt; next(it2)
    0
    &gt;&gt;&gt; next(it1)  # Further usage of `it1` will raise a `RunTimeError`</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">agent</span> <span class="o">=</span> <span class="n">AgentBase</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">StepFieldSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">field</span><span class="o">=</span><span class="s1">&#39;state&#39;</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">BasicModelForwarder</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ArgMaxer</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentHead</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>

<span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">agent</span><span class="p">([</span><span class="n">SimpleStep</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mf">4.</span><span class="p">]]))]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[1, 0]])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="EpsilonSelector" class="doc_header"><code>class</code> <code>EpsilonSelector</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L92" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>EpsilonSelector</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>IterDataPipe</code></p>
</blockquote>
<p>Iterable-style DataPipe.</p>
<p>All DataPipes that represent an iterable of data samples should subclass this.
This style of DataPipes is particularly useful when data come from a stream, or
when the number of samples is too large to fit them all in memory. <code>IterDataPipe</code> is lazily initialized and its
elements are computed only when <code>next()</code> is called on the iterator of an <code>IterDataPipe</code>.</p>
<p>All subclasses should overwrite :meth:<code>__iter__</code>, which would return an
iterator of samples in this DataPipe. Calling <code>__iter__</code> of an <code>IterDataPipe</code> automatically invokes its
method <code>reset()</code>, which by default performs no operation. When writing a custom <code>IterDataPipe</code>, users should
override <code>reset()</code> if necessary. The common usages include resetting buffers, pointers,
and various state variables within the custom <code>IterDataPipe</code>.</p>
<p>Note:
    Only <code>one</code> iterator can be valid for each <code>IterDataPipe</code> at a time,
    and the creation a second iterator will invalidate the first one. This constraint is necessary because
    some <code>IterDataPipe</code> have internal buffers, whose states can become invalid if there are multiple iterators.
    The code example below presents details on how this constraint looks in practice.
    If you have any feedback related to this constraint, please see <code>GitHub IterDataPipe Single Iterator Issue</code>_.</p>
<p>These DataPipes can be invoked in two ways, using the class constructor or applying their
functional form onto an existing <code>IterDataPipe</code> (recommended, available to most but not all DataPipes).
You can chain multiple <code>IterDataPipe</code> together to form a pipeline that will perform multiple
operations in succession.</p>
<p>.. _GitHub IterDataPipe Single Iterator Issue:
    <a href="https://github.com/pytorch/data/issues/45">https://github.com/pytorch/data/issues/45</a></p>
<p>Note:
    When a subclass is used with :class:<code>~torch.utils.data.DataLoader</code>, each
    item in the DataPipe will be yielded from the :class:<code>~torch.utils.data.DataLoader</code>
    iterator. When :attr:<code>num_workers &gt; 0</code>, each worker process will have a
    different copy of the DataPipe object, so it is often desired to configure
    each copy independently to avoid having duplicate data returned from the
    workers. :func:<code>~torch.utils.data.get_worker_info</code>, when called in a worker
    process, returns information about the worker. It can be used in either the
    dataset's :meth:<code>__iter__</code> method or the :class:<code>~torch.utils.data.DataLoader</code> 's
    :attr:<code>worker_init_fn</code> option to modify each copy's behavior.</p>
<p>Examples:
    General Usage:</p>

<pre><code>    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; map_dp_1 = Mapper(dp, lambda x: x + 1)  # Using class constructor
    &gt;&gt;&gt; map_dp_2 = dp.map(lambda x: x + 1)  # Using functional form (recommended)
    &gt;&gt;&gt; list(map_dp_1)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; list(map_dp_2)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; filter_dp = map_dp_1.filter(lambda x: x % 2 == 0)
    &gt;&gt;&gt; list(filter_dp)
    [2, 4, 6, 8, 10]
Single Iterator Constraint Example:
    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; list(it1)
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; it2 = iter(source_dp)  # The creation of a new iterator invalidates `it1`
    &gt;&gt;&gt; next(it2)
    0
    &gt;&gt;&gt; next(it1)  # Further usage of `it1` will raise a `RunTimeError`

</code></pre>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>source_datapipe</code></strong></td>
<td></td>
<td></td>
<td>a datapipe whose next(source_datapipe) -&gt; <code>Tensor</code></td>
</tr>
<tr>
<td><strong><code>min_epsilon</code></strong></td>
<td><code>float</code></td>
<td><code>0.2</code></td>
<td>The minimum epsilon to drop to</td>
</tr>
<tr>
<td><strong><code>max_epsilon</code></strong></td>
<td><code>float</code></td>
<td><code>1</code></td>
<td>The max/starting epsilon if <code>epsilon</code> is None and used for calculating epislon decrease speed.</td>
</tr>
<tr>
<td><strong><code>max_steps</code></strong></td>
<td><code>int</code></td>
<td><code>100</code></td>
<td>Determines how fast the episilon should drop to <code>min_epsilon</code>. This should be the number<br />of steps that the agent was run through.</td>
</tr>
<tr>
<td><strong><code>epsilon</code></strong></td>
<td><code>float</code></td>
<td><code>None</code></td>
<td>The starting epsilon</td>
</tr>
<tr>
<td><strong><code>decrement_on_val</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Based on the <code>base_agent.model.training</code>, by default no decrement or step tracking will<br />occur during validation steps.</td>
</tr>
<tr>
<td><strong><code>select_on_val</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Based on the <code>base_agent.model.training</code>, by default random actions will not be attempted</td>
</tr>
<tr>
<td><strong><code>ret_mask</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Also return the mask that, where True, the action should be randomly selected.</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Check that when <code>min_epsilon=1</code>, that the actions have 100% likihood of randomness applied 
(even though some might not change due to the random action matching the chosen action). Check that this 
works on a large batch of <code>200 steps</code>...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">agent</span> <span class="o">=</span> <span class="n">AgentBase</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">StepFieldSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">field</span><span class="o">=</span><span class="s1">&#39;state&#39;</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">BasicModelForwarder</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ArgMaxer</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">EpsilonSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">min_epsilon</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ret_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentHead</span><span class="p">(</span><span class="n">selector</span><span class="p">)</span>

<span class="k">for</span> <span class="n">action</span><span class="p">,</span><span class="n">mask</span> <span class="ow">in</span> <span class="n">agent</span><span class="p">([</span><span class="n">SimpleStep</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mf">4.</span><span class="p">]]</span><span class="o">*</span><span class="mi">200</span><span class="p">))]):</span>
    <span class="n">test_eq</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">200</span><span class="p">)</span>
    <span class="n">test_ne</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">200</span><span class="p">)</span> <span class="c1"># Only some of the actions should 1</span>
    <span class="n">test_ne</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Only some of the actions should be 0</span>
    <span class="n">test_eq</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_eq</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">step</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Check that when <code>min_epsilon=1</code>, that the actions have 100% likihood of randomness applied 
(even though some might not change due to the random action matching the chosen action). Check that this 
works on single batches over <code>200 steps</code>...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ArgMaxer</span><span class="o">.</span><span class="n">debug</span><span class="o">=</span><span class="kc">False</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">agent</span> <span class="o">=</span> <span class="n">AgentBase</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">StepFieldSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">field</span><span class="o">=</span><span class="s1">&#39;state&#39;</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">BasicModelForwarder</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ArgMaxer</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">EpsilonSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">min_epsilon</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ret_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentHead</span><span class="p">(</span><span class="n">selector</span><span class="p">)</span>

<span class="n">actions</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">action</span><span class="p">,</span><span class="n">mask</span> <span class="ow">in</span> <span class="n">agent</span><span class="p">([</span><span class="n">SimpleStep</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mf">4.</span><span class="p">]]))]):</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">actions</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">actions</span> <span class="o">=</span> <span class="n">action</span>
        <span class="k">else</span><span class="p">:</span>               <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">actions</span><span class="p">,</span><span class="n">action</span><span class="p">))</span>
<span class="n">test_ne</span><span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">200</span><span class="p">)</span> <span class="c1"># Only some of the actions should 1</span>
<span class="n">test_ne</span><span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Only some of the actions should be 0</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">step</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Check that when <code>min_epsilon=0 and max_epsilon=0</code>, that the actions have 0% likihood of randomness applied. Check that this 
works on a large batch of <code>200 steps</code>...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">agent</span> <span class="o">=</span> <span class="n">AgentBase</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">StepFieldSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">field</span><span class="o">=</span><span class="s1">&#39;state&#39;</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">BasicModelForwarder</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ArgMaxer</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">EpsilonSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">min_epsilon</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">max_epsilon</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">ret_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentHead</span><span class="p">(</span><span class="n">selector</span><span class="p">)</span>

<span class="k">for</span> <span class="n">action</span><span class="p">,</span><span class="n">mask</span> <span class="ow">in</span> <span class="n">agent</span><span class="p">([</span><span class="n">SimpleStep</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mf">4.</span><span class="p">]]</span><span class="o">*</span><span class="mi">200</span><span class="p">))]):</span>
    <span class="n">test_eq</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">test_eq</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">200</span><span class="p">)</span> <span class="c1"># All the &quot;left&quot; actions should be 1</span>
    <span class="n">test_eq</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># All the &quot;right&quot; actions should be 0</span>
    <span class="n">test_eq</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">test_eq</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">step</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Check that when <code>min_epsilon=0 and max_epsilon=0</code>, that the actions have 0% likihood of randomness applied. Check that this 
works on single batches over <code>200 steps</code>...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">agent</span> <span class="o">=</span> <span class="n">AgentBase</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">StepFieldSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">field</span><span class="o">=</span><span class="s1">&#39;state&#39;</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">BasicModelForwarder</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ArgMaxer</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">EpsilonSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">min_epsilon</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">max_epsilon</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">ret_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentHead</span><span class="p">(</span><span class="n">selector</span><span class="p">)</span>

<span class="n">actions</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">action</span><span class="p">,</span><span class="n">mask</span> <span class="ow">in</span> <span class="n">agent</span><span class="p">([</span><span class="n">SimpleStep</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mf">4.</span><span class="p">]]))]):</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">actions</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">actions</span> <span class="o">=</span> <span class="n">action</span>
        <span class="k">else</span><span class="p">:</span>               <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">actions</span><span class="p">,</span><span class="n">action</span><span class="p">))</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">200</span><span class="p">)</span> <span class="c1"># All the &quot;left&quot; actions should be 1</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># All the &quot;right&quot; actions should be 0</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">step</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Check that when <code>min_epsilon=0 and max_epsilon=1</code>, the actions should become less random
as the steps go on. Check that this works on a large batch of <code>200 steps</code>...</p>
<p><code>epislon</code> should be 0 at the end of this...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">agent</span> <span class="o">=</span> <span class="n">AgentBase</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">StepFieldSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">field</span><span class="o">=</span><span class="s1">&#39;state&#39;</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">BasicModelForwarder</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ArgMaxer</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">EpsilonSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">min_epsilon</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">max_epsilon</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">ret_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentHead</span><span class="p">(</span><span class="n">selector</span><span class="p">)</span>

<span class="n">actions</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">masks</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">epsilons</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">action</span><span class="p">,</span><span class="n">mask</span> <span class="ow">in</span> <span class="n">agent</span><span class="p">([</span><span class="n">SimpleStep</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mf">4.</span><span class="p">]]</span><span class="o">*</span><span class="mi">200</span><span class="p">))]):</span>
        <span class="k">if</span> <span class="n">actions</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">actions</span> <span class="o">=</span> <span class="n">action</span>
        <span class="k">else</span><span class="p">:</span>               <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">actions</span><span class="p">,</span><span class="n">action</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">masks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">masks</span> <span class="o">=</span> <span class="n">mask</span>
        <span class="k">else</span><span class="p">:</span>             <span class="n">masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">masks</span><span class="p">,</span><span class="n">mask</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">epsilons</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">epsilons</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="n">selector</span><span class="o">.</span><span class="n">epsilon</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>                <span class="n">epsilons</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">epsilons</span><span class="p">,</span><span class="n">tensor</span><span class="p">([</span><span class="n">selector</span><span class="o">.</span><span class="n">epsilon</span><span class="p">])))</span>
        
<span class="n">test_ne</span><span class="p">(</span><span class="n">masks</span><span class="p">[:((</span><span class="mi">200</span><span class="o">*</span><span class="mi">200</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">)]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">200</span><span class="p">)</span> <span class="c1"># We do not expect this to equal a perfect 200...</span>
<span class="n">test_ne</span><span class="p">(</span><span class="n">masks</span><span class="p">[:((</span><span class="mi">200</span><span class="o">*</span><span class="mi">200</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">)]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">0</span><span class="p">)</span>   <span class="c1"># ... but we also dont expect it to be 0</span>
<span class="k">assert</span> <span class="mi">1000</span><span class="o">&lt;</span><span class="n">masks</span><span class="p">[:((</span><span class="mi">200</span><span class="o">*</span><span class="mi">200</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">)]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">&lt;</span><span class="mi">10_000</span><span class="p">,</span>\
        <span class="sd">&quot;&quot;&quot;We expect this to be somewhere between 1000 and 10,000, generally in the 9000 range since </span>
<span class="sd">           for 200 steps, we are running 200 inputs&quot;&quot;&quot;</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">masks</span><span class="p">[((</span><span class="mi">200</span><span class="o">*</span><span class="mi">200</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">):]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># We fully expect this to be 0 after the half way point</span>
<span class="n">test_ne</span><span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">200</span><span class="p">)</span> <span class="c1"># All the &quot;left&quot; generally shouldnt be 1</span>
<span class="n">test_ne</span><span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># All the &quot;right&quot;  generally shouldnt be 0</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">step</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span>
<span class="c1"># Since the max steps are 100, and we go for 200 steps, the first 100 epislon entries shouldnt be 0</span>
<span class="n">test_ne</span><span class="p">(</span><span class="n">epsilons</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">0</span><span class="p">)</span> 
<span class="c1"># In fact the first 100 should sum up to somewhere between 40 and 50. (expected 49.5)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="mi">40</span><span class="o">&lt;</span><span class="n">epsilons</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">&lt;</span><span class="mi">50</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span> 
<span class="c1"># Everything after 100 should be 0</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">epsilons</span><span class="p">[</span><span class="mi">100</span><span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Check that when <code>min_epsilon=0 and max_epsilon=0</code>, that the actions have 0% likihood of randomness applied. Check that this 
works on single batches over <code>200 steps</code>...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">agent</span> <span class="o">=</span> <span class="n">AgentBase</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">StepFieldSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">field</span><span class="o">=</span><span class="s1">&#39;state&#39;</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">BasicModelForwarder</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ArgMaxer</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">EpsilonSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">min_epsilon</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">max_epsilon</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">ret_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentHead</span><span class="p">(</span><span class="n">selector</span><span class="p">)</span>

<span class="n">actions</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">masks</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">epsilons</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">action</span><span class="p">,</span><span class="n">mask</span> <span class="ow">in</span> <span class="n">agent</span><span class="p">([</span><span class="n">SimpleStep</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mf">4.</span><span class="p">]]))]):</span>
        <span class="k">if</span> <span class="n">actions</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">actions</span> <span class="o">=</span> <span class="n">action</span>
        <span class="k">else</span><span class="p">:</span>               <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">actions</span><span class="p">,</span><span class="n">action</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">masks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">masks</span> <span class="o">=</span> <span class="n">mask</span>
        <span class="k">else</span><span class="p">:</span>             <span class="n">masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">masks</span><span class="p">,</span><span class="n">mask</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">epsilons</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">epsilons</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="n">selector</span><span class="o">.</span><span class="n">epsilon</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>                <span class="n">epsilons</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">epsilons</span><span class="p">,</span><span class="n">tensor</span><span class="p">([</span><span class="n">selector</span><span class="o">.</span><span class="n">epsilon</span><span class="p">])))</span>
        
<span class="n">test_ne</span><span class="p">(</span><span class="n">masks</span><span class="p">[:(</span><span class="mi">200</span><span class="o">//</span><span class="mi">2</span><span class="p">)]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">200</span><span class="p">)</span> <span class="c1"># We do not expect this to equal a perfect 200...</span>
<span class="n">test_ne</span><span class="p">(</span><span class="n">masks</span><span class="p">[:(</span><span class="mi">200</span><span class="o">//</span><span class="mi">2</span><span class="p">)]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">0</span><span class="p">)</span>   <span class="c1"># ... but we also dont expect it to be 0</span>
<span class="k">assert</span> <span class="mi">40</span><span class="o">&lt;</span><span class="n">masks</span><span class="p">[:(</span><span class="mi">200</span><span class="o">//</span><span class="mi">2</span><span class="p">)]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">&lt;</span><span class="mi">60</span><span class="p">,</span><span class="s1">&#39;We expect this to be somewhere between 60, generally in the ~50 range&#39;</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">masks</span><span class="p">[(</span><span class="mi">200</span><span class="o">//</span><span class="mi">2</span><span class="p">):]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># We fully expect this to be 0 after the half way point</span>
<span class="n">test_ne</span><span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">200</span><span class="p">)</span> <span class="c1"># All the &quot;left&quot; generally shouldnt be 1</span>
<span class="n">test_ne</span><span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># All the &quot;right&quot;  generally shouldnt be 0</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">step</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span>
<span class="c1"># Since the max steps are 100, and we go for 200 steps, the first 100 epislon entries shouldnt be 0</span>
<span class="n">test_ne</span><span class="p">(</span><span class="n">epsilons</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">0</span><span class="p">)</span> 
<span class="c1"># In fact the first 100 should sum up to somewhere between 40 and 50. (expected 49.5)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="mi">40</span><span class="o">&lt;</span><span class="n">epsilons</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">&lt;</span><span class="mi">50</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span> 
<span class="c1"># Everything after 100 should be 0</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">epsilons</span><span class="p">[</span><span class="mi">100</span><span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data">Data<a class="anchor-link" href="#Data"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastrl.envs.gym</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastrl.fastai.data.block</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentBase</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">StepFieldSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">field</span><span class="o">=</span><span class="s1">&#39;state&#39;</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">BasicModelForwarder</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ArgMaxer</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">EpsilonSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">min_epsilon</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">max_epsilon</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">ret_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentHead</span><span class="p">(</span><span class="n">selector</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="GymTransformBlock" class="doc_header"><code>GymTransformBlock</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L156" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>GymTransformBlock</code>(<strong><code>agent</code></strong>, <strong><code>seed</code></strong>=<em><code>None</code></em>, <strong><code>nsteps</code></strong>=<em><code>1</code></em>, <strong><code>nskips</code></strong>=<em><code>1</code></em>, <strong><code>dl_type</code></strong>=<em><code>DataLoader2</code></em>, <strong><code>pipe_fn_kwargs</code></strong>=<em><code>None</code></em>, <strong><code>type_tfms</code></strong>=<em><code>None</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastrl.pipes.core</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DataBlock" class="doc_header"><code>class</code> <code>DataBlock</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/fastai/data/block.py#L56" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DataBlock</code>(<strong><code>blocks</code></strong>:<code>List</code>[<a href="/fastrl/fastai.data.block.html#TransformBlock"><code>TransformBlock</code></a>]=<em><code>None</code></em>)</p>
</blockquote>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>blocks</code></strong></td>
<td><code>typing.List[fastrl.fastai.data.block.TransformBlock]</code></td>
<td><code>None</code></td>
<td>Each transform block will have its own dataloader.</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">block</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span> <span class="o">=</span> <span class="n">GymTransformBlock</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">pipes</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">datapipes</span><span class="p">([</span><span class="s1">&#39;CartPole-v1&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pipes</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[SimpleStep(state=tensor([-0.0387, -0.0470,  0.0055, -0.0448]), action=tensor([0.]), next_state=tensor([-0.0396, -0.2422,  0.0046,  0.2496]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([1.]), env_id=tensor([140406848874896]), proc_id=tensor([343]), step_n=tensor([1]), episode_n=tensor([1]))]
[SimpleStep(state=tensor([-0.0396, -0.2422,  0.0046,  0.2496]), action=tensor([0.]), next_state=tensor([-0.0445, -0.4373,  0.0095,  0.5437]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([2.]), env_id=tensor([140406848874896]), proc_id=tensor([343]), step_n=tensor([2]), episode_n=tensor([1]))]
[SimpleStep(state=tensor([-0.0445, -0.4373,  0.0095,  0.5437]), action=tensor([0.]), next_state=tensor([-0.0532, -0.6326,  0.0204,  0.8394]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([3.]), env_id=tensor([140406848874896]), proc_id=tensor([343]), step_n=tensor([3]), episode_n=tensor([1]))]
[SimpleStep(state=tensor([-0.0532, -0.6326,  0.0204,  0.8394]), action=tensor([0.]), next_state=tensor([-0.0658, -0.8280,  0.0372,  1.1384]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([4.]), env_id=tensor([140406848874896]), proc_id=tensor([343]), step_n=tensor([4]), episode_n=tensor([1]))]
[SimpleStep(state=tensor([-0.0658, -0.8280,  0.0372,  1.1384]), action=tensor([0.]), next_state=tensor([-0.0824, -1.0236,  0.0600,  1.4425]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([5.]), env_id=tensor([140406848874896]), proc_id=tensor([343]), step_n=tensor([5]), episode_n=tensor([1]))]
[SimpleStep(state=tensor([-0.0824, -1.0236,  0.0600,  1.4425]), action=tensor([0.]), next_state=tensor([-0.1029, -1.2194,  0.0888,  1.7533]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([6.]), env_id=tensor([140406848874896]), proc_id=tensor([343]), step_n=tensor([6]), episode_n=tensor([1]))]
[SimpleStep(state=tensor([-0.1029, -1.2194,  0.0888,  1.7533]), action=tensor([0.]), next_state=tensor([-0.1273, -1.4154,  0.1239,  2.0723]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([7.]), env_id=tensor([140406848874896]), proc_id=tensor([343]), step_n=tensor([7]), episode_n=tensor([1]))]
[SimpleStep(state=tensor([-0.1273, -1.4154,  0.1239,  2.0723]), action=tensor([0.]), next_state=tensor([-0.1556, -1.6115,  0.1653,  2.4006]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([8.]), env_id=tensor([140406848874896]), proc_id=tensor([343]), step_n=tensor([8]), episode_n=tensor([1]))]
[SimpleStep(state=tensor([-0.1556, -1.6115,  0.1653,  2.4006]), action=tensor([0.]), next_state=tensor([-0.1878, -1.8077,  0.2133,  2.7391]), terminated=tensor([True]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([9.]), env_id=tensor([140406848874896]), proc_id=tensor([343]), step_n=tensor([9]), episode_n=tensor([1]))]
[SimpleStep(state=tensor([0.0288, 0.0383, 0.0235, 0.0443]), action=tensor([0.]), next_state=tensor([ 0.0296, -0.1572,  0.0244,  0.3444]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([1.]), env_id=tensor([140406848874896]), proc_id=tensor([343]), step_n=tensor([1]), episode_n=tensor([2]))]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">block</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span> <span class="o">=</span> <span class="n">GymTransformBlock</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">pipes</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">([</span><span class="s1">&#39;CartPole-v1&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pipes</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[SimpleStep(state=tensor([[-0.0270,  0.0407, -0.0249, -0.0320]]), action=tensor([[0.]]), next_state=tensor([[-0.0262, -0.1540, -0.0255,  0.2528]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[1.]]), env_id=tensor([[140406848918032]]), proc_id=tensor([[343]]), step_n=tensor([[1]]), episode_n=tensor([[1]]))]
[SimpleStep(state=tensor([[-0.0262, -0.1540, -0.0255,  0.2528]]), action=tensor([[1.]]), next_state=tensor([[-0.0293,  0.0415, -0.0205, -0.0479]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[2.]]), env_id=tensor([[140406848918032]]), proc_id=tensor([[343]]), step_n=tensor([[2]]), episode_n=tensor([[1]]))]
[SimpleStep(state=tensor([[-0.0293,  0.0415, -0.0205, -0.0479]]), action=tensor([[1.]]), next_state=tensor([[-0.0285,  0.2369, -0.0214, -0.3469]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[3.]]), env_id=tensor([[140406848918032]]), proc_id=tensor([[343]]), step_n=tensor([[3]]), episode_n=tensor([[1]]))]
[SimpleStep(state=tensor([[-0.0285,  0.2369, -0.0214, -0.3469]]), action=tensor([[1.]]), next_state=tensor([[-0.0237,  0.4323, -0.0284, -0.6463]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[4.]]), env_id=tensor([[140406848918032]]), proc_id=tensor([[343]]), step_n=tensor([[4]]), episode_n=tensor([[1]]))]
[SimpleStep(state=tensor([[-0.0237,  0.4323, -0.0284, -0.6463]]), action=tensor([[0.]]), next_state=tensor([[-0.0151,  0.2376, -0.0413, -0.3627]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[5.]]), env_id=tensor([[140406848918032]]), proc_id=tensor([[343]]), step_n=tensor([[5]]), episode_n=tensor([[1]]))]
[SimpleStep(state=tensor([[-0.0151,  0.2376, -0.0413, -0.3627]]), action=tensor([[1.]]), next_state=tensor([[-0.0103,  0.4333, -0.0486, -0.6681]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[6.]]), env_id=tensor([[140406848918032]]), proc_id=tensor([[343]]), step_n=tensor([[6]]), episode_n=tensor([[1]]))]
[SimpleStep(state=tensor([[-0.0103,  0.4333, -0.0486, -0.6681]]), action=tensor([[1.]]), next_state=tensor([[-0.0017,  0.6290, -0.0619, -0.9757]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[7.]]), env_id=tensor([[140406848918032]]), proc_id=tensor([[343]]), step_n=tensor([[7]]), episode_n=tensor([[1]]))]
[SimpleStep(state=tensor([[-0.0017,  0.6290, -0.0619, -0.9757]]), action=tensor([[1.]]), next_state=tensor([[ 0.0109,  0.8249, -0.0814, -1.2872]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[8.]]), env_id=tensor([[140406848918032]]), proc_id=tensor([[343]]), step_n=tensor([[8]]), episode_n=tensor([[1]]))]
[SimpleStep(state=tensor([[ 0.0109,  0.8249, -0.0814, -1.2872]]), action=tensor([[0.]]), next_state=tensor([[ 0.0274,  0.6309, -0.1072, -1.0211]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[9.]]), env_id=tensor([[140406848918032]]), proc_id=tensor([[343]]), step_n=tensor([[9]]), episode_n=tensor([[1]]))]
[SimpleStep(state=tensor([[ 0.0274,  0.6309, -0.1072, -1.0211]]), action=tensor([[0.]]), next_state=tensor([[ 0.0400,  0.4374, -0.1276, -0.7639]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[10.]]), env_id=tensor([[140406848918032]]), proc_id=tensor([[343]]), step_n=tensor([[10]]), episode_n=tensor([[1]]))]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training">Training<a class="anchor-link" href="#Training"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LearnerBase" class="doc_header"><code>class</code> <code>LearnerBase</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L226" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LearnerBase</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>IterDataPipe</code></p>
</blockquote>
<p>Iterable-style DataPipe.</p>
<p>All DataPipes that represent an iterable of data samples should subclass this.
This style of DataPipes is particularly useful when data come from a stream, or
when the number of samples is too large to fit them all in memory. <code>IterDataPipe</code> is lazily initialized and its
elements are computed only when <code>next()</code> is called on the iterator of an <code>IterDataPipe</code>.</p>
<p>All subclasses should overwrite :meth:<code>__iter__</code>, which would return an
iterator of samples in this DataPipe. Calling <code>__iter__</code> of an <code>IterDataPipe</code> automatically invokes its
method <code>reset()</code>, which by default performs no operation. When writing a custom <code>IterDataPipe</code>, users should
override <code>reset()</code> if necessary. The common usages include resetting buffers, pointers,
and various state variables within the custom <code>IterDataPipe</code>.</p>
<p>Note:
    Only <code>one</code> iterator can be valid for each <code>IterDataPipe</code> at a time,
    and the creation a second iterator will invalidate the first one. This constraint is necessary because
    some <code>IterDataPipe</code> have internal buffers, whose states can become invalid if there are multiple iterators.
    The code example below presents details on how this constraint looks in practice.
    If you have any feedback related to this constraint, please see <code>GitHub IterDataPipe Single Iterator Issue</code>_.</p>
<p>These DataPipes can be invoked in two ways, using the class constructor or applying their
functional form onto an existing <code>IterDataPipe</code> (recommended, available to most but not all DataPipes).
You can chain multiple <code>IterDataPipe</code> together to form a pipeline that will perform multiple
operations in succession.</p>
<p>.. _GitHub IterDataPipe Single Iterator Issue:
    <a href="https://github.com/pytorch/data/issues/45">https://github.com/pytorch/data/issues/45</a></p>
<p>Note:
    When a subclass is used with :class:<code>~torch.utils.data.DataLoader</code>, each
    item in the DataPipe will be yielded from the :class:<code>~torch.utils.data.DataLoader</code>
    iterator. When :attr:<code>num_workers &gt; 0</code>, each worker process will have a
    different copy of the DataPipe object, so it is often desired to configure
    each copy independently to avoid having duplicate data returned from the
    workers. :func:<code>~torch.utils.data.get_worker_info</code>, when called in a worker
    process, returns information about the worker. It can be used in either the
    dataset's :meth:<code>__iter__</code> method or the :class:<code>~torch.utils.data.DataLoader</code> 's
    :attr:<code>worker_init_fn</code> option to modify each copy's behavior.</p>
<p>Examples:
    General Usage:</p>

<pre><code>    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; map_dp_1 = Mapper(dp, lambda x: x + 1)  # Using class constructor
    &gt;&gt;&gt; map_dp_2 = dp.map(lambda x: x + 1)  # Using functional form (recommended)
    &gt;&gt;&gt; list(map_dp_1)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; list(map_dp_2)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; filter_dp = map_dp_1.filter(lambda x: x % 2 == 0)
    &gt;&gt;&gt; list(filter_dp)
    [2, 4, 6, 8, 10]
Single Iterator Constraint Example:
    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; list(it1)
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; it2 = iter(source_dp)  # The creation of a new iterator invalidates `it1`
    &gt;&gt;&gt; next(it2)
    0
    &gt;&gt;&gt; next(it1)  # Further usage of `it1` will raise a `RunTimeError`

</code></pre>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>model</code></strong></td>
<td><code>Module</code></td>
<td></td>
<td>The base NN that we getting raw action values out of.</td>
</tr>
<tr>
<td><strong><code>dls</code></strong></td>
<td><code>typing.List[torch.utils.data.dataloader_experimental.DataLoader2]</code></td>
<td></td>
<td>The dataloaders to read data from for training</td>
</tr>
<tr>
<td><strong><code>loss_func</code></strong></td>
<td></td>
<td><code>None</code></td>
<td>The loss function to use</td>
</tr>
<tr>
<td><strong><code>opt</code></strong></td>
<td></td>
<td><code>None</code></td>
<td>The optimizer to use</td>
</tr>
<tr>
<td><strong><code>zipwise</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>LearnerBase will yield each dl individually by default. If <code>zipwise=True</code><br />next() will be called on <code>dls</code> and will <code>yield next(dl1),next(dl2),next(dl1)...</code></td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="is_epocher" class="doc_header"><code>is_epocher</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L259" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>is_epocher</code>(<strong><code>pipe</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Epocher" class="doc_header"><code>class</code> <code>Epocher</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L261" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Epocher</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>IterDataPipe</code></p>
</blockquote>
<p>Iterable-style DataPipe.</p>
<p>All DataPipes that represent an iterable of data samples should subclass this.
This style of DataPipes is particularly useful when data come from a stream, or
when the number of samples is too large to fit them all in memory. <code>IterDataPipe</code> is lazily initialized and its
elements are computed only when <code>next()</code> is called on the iterator of an <code>IterDataPipe</code>.</p>
<p>All subclasses should overwrite :meth:<code>__iter__</code>, which would return an
iterator of samples in this DataPipe. Calling <code>__iter__</code> of an <code>IterDataPipe</code> automatically invokes its
method <code>reset()</code>, which by default performs no operation. When writing a custom <code>IterDataPipe</code>, users should
override <code>reset()</code> if necessary. The common usages include resetting buffers, pointers,
and various state variables within the custom <code>IterDataPipe</code>.</p>
<p>Note:
    Only <code>one</code> iterator can be valid for each <code>IterDataPipe</code> at a time,
    and the creation a second iterator will invalidate the first one. This constraint is necessary because
    some <code>IterDataPipe</code> have internal buffers, whose states can become invalid if there are multiple iterators.
    The code example below presents details on how this constraint looks in practice.
    If you have any feedback related to this constraint, please see <code>GitHub IterDataPipe Single Iterator Issue</code>_.</p>
<p>These DataPipes can be invoked in two ways, using the class constructor or applying their
functional form onto an existing <code>IterDataPipe</code> (recommended, available to most but not all DataPipes).
You can chain multiple <code>IterDataPipe</code> together to form a pipeline that will perform multiple
operations in succession.</p>
<p>.. _GitHub IterDataPipe Single Iterator Issue:
    <a href="https://github.com/pytorch/data/issues/45">https://github.com/pytorch/data/issues/45</a></p>
<p>Note:
    When a subclass is used with :class:<code>~torch.utils.data.DataLoader</code>, each
    item in the DataPipe will be yielded from the :class:<code>~torch.utils.data.DataLoader</code>
    iterator. When :attr:<code>num_workers &gt; 0</code>, each worker process will have a
    different copy of the DataPipe object, so it is often desired to configure
    each copy independently to avoid having duplicate data returned from the
    workers. :func:<code>~torch.utils.data.get_worker_info</code>, when called in a worker
    process, returns information about the worker. It can be used in either the
    dataset's :meth:<code>__iter__</code> method or the :class:<code>~torch.utils.data.DataLoader</code> 's
    :attr:<code>worker_init_fn</code> option to modify each copy's behavior.</p>
<p>Examples:
    General Usage:</p>

<pre><code>    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; map_dp_1 = Mapper(dp, lambda x: x + 1)  # Using class constructor
    &gt;&gt;&gt; map_dp_2 = dp.map(lambda x: x + 1)  # Using functional form (recommended)
    &gt;&gt;&gt; list(map_dp_1)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; list(map_dp_2)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; filter_dp = map_dp_1.filter(lambda x: x % 2 == 0)
    &gt;&gt;&gt; list(filter_dp)
    [2, 4, 6, 8, 10]
Single Iterator Constraint Example:
    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; list(it1)
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; it2 = iter(source_dp)  # The creation of a new iterator invalidates `it1`
    &gt;&gt;&gt; next(it2)
    0
    &gt;&gt;&gt; next(it1)  # Further usage of `it1` will raise a `RunTimeError`</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="is_learner_base" class="doc_header"><code>is_learner_base</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L272" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>is_learner_base</code>(<strong><code>pipe</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="find_learner_base" class="doc_header"><code>find_learner_base</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L274" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>find_learner_base</code>(<strong><code>pipe</code></strong>)</p>
</blockquote>
<p>Basically just find_pipes+is_learner_base with exception handling</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LearnerHead" class="doc_header"><code>class</code> <code>LearnerHead</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L281" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LearnerHead</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>IterDataPipe</code></p>
</blockquote>
<p>Iterable-style DataPipe.</p>
<p>All DataPipes that represent an iterable of data samples should subclass this.
This style of DataPipes is particularly useful when data come from a stream, or
when the number of samples is too large to fit them all in memory. <code>IterDataPipe</code> is lazily initialized and its
elements are computed only when <code>next()</code> is called on the iterator of an <code>IterDataPipe</code>.</p>
<p>All subclasses should overwrite :meth:<code>__iter__</code>, which would return an
iterator of samples in this DataPipe. Calling <code>__iter__</code> of an <code>IterDataPipe</code> automatically invokes its
method <code>reset()</code>, which by default performs no operation. When writing a custom <code>IterDataPipe</code>, users should
override <code>reset()</code> if necessary. The common usages include resetting buffers, pointers,
and various state variables within the custom <code>IterDataPipe</code>.</p>
<p>Note:
    Only <code>one</code> iterator can be valid for each <code>IterDataPipe</code> at a time,
    and the creation a second iterator will invalidate the first one. This constraint is necessary because
    some <code>IterDataPipe</code> have internal buffers, whose states can become invalid if there are multiple iterators.
    The code example below presents details on how this constraint looks in practice.
    If you have any feedback related to this constraint, please see <code>GitHub IterDataPipe Single Iterator Issue</code>_.</p>
<p>These DataPipes can be invoked in two ways, using the class constructor or applying their
functional form onto an existing <code>IterDataPipe</code> (recommended, available to most but not all DataPipes).
You can chain multiple <code>IterDataPipe</code> together to form a pipeline that will perform multiple
operations in succession.</p>
<p>.. _GitHub IterDataPipe Single Iterator Issue:
    <a href="https://github.com/pytorch/data/issues/45">https://github.com/pytorch/data/issues/45</a></p>
<p>Note:
    When a subclass is used with :class:<code>~torch.utils.data.DataLoader</code>, each
    item in the DataPipe will be yielded from the :class:<code>~torch.utils.data.DataLoader</code>
    iterator. When :attr:<code>num_workers &gt; 0</code>, each worker process will have a
    different copy of the DataPipe object, so it is often desired to configure
    each copy independently to avoid having duplicate data returned from the
    workers. :func:<code>~torch.utils.data.get_worker_info</code>, when called in a worker
    process, returns information about the worker. It can be used in either the
    dataset's :meth:<code>__iter__</code> method or the :class:<code>~torch.utils.data.DataLoader</code> 's
    :attr:<code>worker_init_fn</code> option to modify each copy's behavior.</p>
<p>Examples:
    General Usage:</p>

<pre><code>    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; map_dp_1 = Mapper(dp, lambda x: x + 1)  # Using class constructor
    &gt;&gt;&gt; map_dp_2 = dp.map(lambda x: x + 1)  # Using functional form (recommended)
    &gt;&gt;&gt; list(map_dp_1)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; list(map_dp_2)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; filter_dp = map_dp_1.filter(lambda x: x % 2 == 0)
    &gt;&gt;&gt; list(filter_dp)
    [2, 4, 6, 8, 10]
Single Iterator Constraint Example:
    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; list(it1)
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; it2 = iter(source_dp)  # The creation of a new iterator invalidates `it1`
    &gt;&gt;&gt; next(it2)
    0
    &gt;&gt;&gt; next(it1)  # Further usage of `it1` will raise a `RunTimeError`</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastrl.loggers.core</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">logger_base</span> <span class="o">=</span> <span class="n">ProgressBarLogger</span><span class="p">(</span>
     <span class="n">epoch_on_pipe</span><span class="o">=</span><span class="n">Epocher</span><span class="p">,</span>
     <span class="n">batch_on_pipe</span><span class="o">=</span><span class="n">LearnerBase</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentBase</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">StepFieldSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">field</span><span class="o">=</span><span class="s1">&#39;state&#39;</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">BasicModelForwarder</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ArgMaxer</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">EpsilonSelector</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span><span class="n">min_epsilon</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">max_epsilon</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">ret_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentHead</span><span class="p">(</span><span class="n">selector</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">block</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span> <span class="o">=</span> <span class="n">GymTransformBlock</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">([</span><span class="s1">&#39;CartPole-v1&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="QCalc" class="doc_header"><code>class</code> <code>QCalc</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L296" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>QCalc</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>IterDataPipe</code></p>
</blockquote>
<p>Iterable-style DataPipe.</p>
<p>All DataPipes that represent an iterable of data samples should subclass this.
This style of DataPipes is particularly useful when data come from a stream, or
when the number of samples is too large to fit them all in memory. <code>IterDataPipe</code> is lazily initialized and its
elements are computed only when <code>next()</code> is called on the iterator of an <code>IterDataPipe</code>.</p>
<p>All subclasses should overwrite :meth:<code>__iter__</code>, which would return an
iterator of samples in this DataPipe. Calling <code>__iter__</code> of an <code>IterDataPipe</code> automatically invokes its
method <code>reset()</code>, which by default performs no operation. When writing a custom <code>IterDataPipe</code>, users should
override <code>reset()</code> if necessary. The common usages include resetting buffers, pointers,
and various state variables within the custom <code>IterDataPipe</code>.</p>
<p>Note:
    Only <code>one</code> iterator can be valid for each <code>IterDataPipe</code> at a time,
    and the creation a second iterator will invalidate the first one. This constraint is necessary because
    some <code>IterDataPipe</code> have internal buffers, whose states can become invalid if there are multiple iterators.
    The code example below presents details on how this constraint looks in practice.
    If you have any feedback related to this constraint, please see <code>GitHub IterDataPipe Single Iterator Issue</code>_.</p>
<p>These DataPipes can be invoked in two ways, using the class constructor or applying their
functional form onto an existing <code>IterDataPipe</code> (recommended, available to most but not all DataPipes).
You can chain multiple <code>IterDataPipe</code> together to form a pipeline that will perform multiple
operations in succession.</p>
<p>.. _GitHub IterDataPipe Single Iterator Issue:
    <a href="https://github.com/pytorch/data/issues/45">https://github.com/pytorch/data/issues/45</a></p>
<p>Note:
    When a subclass is used with :class:<code>~torch.utils.data.DataLoader</code>, each
    item in the DataPipe will be yielded from the :class:<code>~torch.utils.data.DataLoader</code>
    iterator. When :attr:<code>num_workers &gt; 0</code>, each worker process will have a
    different copy of the DataPipe object, so it is often desired to configure
    each copy independently to avoid having duplicate data returned from the
    workers. :func:<code>~torch.utils.data.get_worker_info</code>, when called in a worker
    process, returns information about the worker. It can be used in either the
    dataset's :meth:<code>__iter__</code> method or the :class:<code>~torch.utils.data.DataLoader</code> 's
    :attr:<code>worker_init_fn</code> option to modify each copy's behavior.</p>
<p>Examples:
    General Usage:</p>

<pre><code>    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; map_dp_1 = Mapper(dp, lambda x: x + 1)  # Using class constructor
    &gt;&gt;&gt; map_dp_2 = dp.map(lambda x: x + 1)  # Using functional form (recommended)
    &gt;&gt;&gt; list(map_dp_1)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; list(map_dp_2)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; filter_dp = map_dp_1.filter(lambda x: x % 2 == 0)
    &gt;&gt;&gt; list(filter_dp)
    [2, 4, 6, 8, 10]
Single Iterator Constraint Example:
    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; list(it1)
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; it2 = iter(source_dp)  # The creation of a new iterator invalidates `it1`
    &gt;&gt;&gt; next(it2)
    0
    &gt;&gt;&gt; next(it1)  # Further usage of `it1` will raise a `RunTimeError`</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ModelLearnCalc" class="doc_header"><code>class</code> <code>ModelLearnCalc</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L319" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ModelLearnCalc</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>IterDataPipe</code></p>
</blockquote>
<p>Iterable-style DataPipe.</p>
<p>All DataPipes that represent an iterable of data samples should subclass this.
This style of DataPipes is particularly useful when data come from a stream, or
when the number of samples is too large to fit them all in memory. <code>IterDataPipe</code> is lazily initialized and its
elements are computed only when <code>next()</code> is called on the iterator of an <code>IterDataPipe</code>.</p>
<p>All subclasses should overwrite :meth:<code>__iter__</code>, which would return an
iterator of samples in this DataPipe. Calling <code>__iter__</code> of an <code>IterDataPipe</code> automatically invokes its
method <code>reset()</code>, which by default performs no operation. When writing a custom <code>IterDataPipe</code>, users should
override <code>reset()</code> if necessary. The common usages include resetting buffers, pointers,
and various state variables within the custom <code>IterDataPipe</code>.</p>
<p>Note:
    Only <code>one</code> iterator can be valid for each <code>IterDataPipe</code> at a time,
    and the creation a second iterator will invalidate the first one. This constraint is necessary because
    some <code>IterDataPipe</code> have internal buffers, whose states can become invalid if there are multiple iterators.
    The code example below presents details on how this constraint looks in practice.
    If you have any feedback related to this constraint, please see <code>GitHub IterDataPipe Single Iterator Issue</code>_.</p>
<p>These DataPipes can be invoked in two ways, using the class constructor or applying their
functional form onto an existing <code>IterDataPipe</code> (recommended, available to most but not all DataPipes).
You can chain multiple <code>IterDataPipe</code> together to form a pipeline that will perform multiple
operations in succession.</p>
<p>.. _GitHub IterDataPipe Single Iterator Issue:
    <a href="https://github.com/pytorch/data/issues/45">https://github.com/pytorch/data/issues/45</a></p>
<p>Note:
    When a subclass is used with :class:<code>~torch.utils.data.DataLoader</code>, each
    item in the DataPipe will be yielded from the :class:<code>~torch.utils.data.DataLoader</code>
    iterator. When :attr:<code>num_workers &gt; 0</code>, each worker process will have a
    different copy of the DataPipe object, so it is often desired to configure
    each copy independently to avoid having duplicate data returned from the
    workers. :func:<code>~torch.utils.data.get_worker_info</code>, when called in a worker
    process, returns information about the worker. It can be used in either the
    dataset's :meth:<code>__iter__</code> method or the :class:<code>~torch.utils.data.DataLoader</code> 's
    :attr:<code>worker_init_fn</code> option to modify each copy's behavior.</p>
<p>Examples:
    General Usage:</p>

<pre><code>    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; map_dp_1 = Mapper(dp, lambda x: x + 1)  # Using class constructor
    &gt;&gt;&gt; map_dp_2 = dp.map(lambda x: x + 1)  # Using functional form (recommended)
    &gt;&gt;&gt; list(map_dp_1)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; list(map_dp_2)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; filter_dp = map_dp_1.filter(lambda x: x % 2 == 0)
    &gt;&gt;&gt; list(filter_dp)
    [2, 4, 6, 8, 10]
Single Iterator Constraint Example:
    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; list(it1)
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; it2 = iter(source_dp)  # The creation of a new iterator invalidates `it1`
    &gt;&gt;&gt; next(it2)
    0
    &gt;&gt;&gt; next(it1)  # Further usage of `it1` will raise a `RunTimeError`</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="StepBatcher" class="doc_header"><code>class</code> <code>StepBatcher</code><a href="https://github.com/josiahls/fastrl/tree/master/fastrl/agents/dqn/basic.py#L333" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>StepBatcher</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>IterDataPipe</code></p>
</blockquote>
<p>Iterable-style DataPipe.</p>
<p>All DataPipes that represent an iterable of data samples should subclass this.
This style of DataPipes is particularly useful when data come from a stream, or
when the number of samples is too large to fit them all in memory. <code>IterDataPipe</code> is lazily initialized and its
elements are computed only when <code>next()</code> is called on the iterator of an <code>IterDataPipe</code>.</p>
<p>All subclasses should overwrite :meth:<code>__iter__</code>, which would return an
iterator of samples in this DataPipe. Calling <code>__iter__</code> of an <code>IterDataPipe</code> automatically invokes its
method <code>reset()</code>, which by default performs no operation. When writing a custom <code>IterDataPipe</code>, users should
override <code>reset()</code> if necessary. The common usages include resetting buffers, pointers,
and various state variables within the custom <code>IterDataPipe</code>.</p>
<p>Note:
    Only <code>one</code> iterator can be valid for each <code>IterDataPipe</code> at a time,
    and the creation a second iterator will invalidate the first one. This constraint is necessary because
    some <code>IterDataPipe</code> have internal buffers, whose states can become invalid if there are multiple iterators.
    The code example below presents details on how this constraint looks in practice.
    If you have any feedback related to this constraint, please see <code>GitHub IterDataPipe Single Iterator Issue</code>_.</p>
<p>These DataPipes can be invoked in two ways, using the class constructor or applying their
functional form onto an existing <code>IterDataPipe</code> (recommended, available to most but not all DataPipes).
You can chain multiple <code>IterDataPipe</code> together to form a pipeline that will perform multiple
operations in succession.</p>
<p>.. _GitHub IterDataPipe Single Iterator Issue:
    <a href="https://github.com/pytorch/data/issues/45">https://github.com/pytorch/data/issues/45</a></p>
<p>Note:
    When a subclass is used with :class:<code>~torch.utils.data.DataLoader</code>, each
    item in the DataPipe will be yielded from the :class:<code>~torch.utils.data.DataLoader</code>
    iterator. When :attr:<code>num_workers &gt; 0</code>, each worker process will have a
    different copy of the DataPipe object, so it is often desired to configure
    each copy independently to avoid having duplicate data returned from the
    workers. :func:<code>~torch.utils.data.get_worker_info</code>, when called in a worker
    process, returns information about the worker. It can be used in either the
    dataset's :meth:<code>__iter__</code> method or the :class:<code>~torch.utils.data.DataLoader</code> 's
    :attr:<code>worker_init_fn</code> option to modify each copy's behavior.</p>
<p>Examples:
    General Usage:</p>

<pre><code>    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; map_dp_1 = Mapper(dp, lambda x: x + 1)  # Using class constructor
    &gt;&gt;&gt; map_dp_2 = dp.map(lambda x: x + 1)  # Using functional form (recommended)
    &gt;&gt;&gt; list(map_dp_1)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; list(map_dp_2)
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    &gt;&gt;&gt; filter_dp = map_dp_1.filter(lambda x: x % 2 == 0)
    &gt;&gt;&gt; list(filter_dp)
    [2, 4, 6, 8, 10]
Single Iterator Constraint Example:
    &gt;&gt;&gt; from torchdata.datapipes.iter import IterableWrapper, Mapper
    &gt;&gt;&gt; dp = IterableWrapper(range(10))
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; list(it1)
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
    &gt;&gt;&gt; it1 = iter(source_dp)
    &gt;&gt;&gt; it2 = iter(source_dp)  # The creation of a new iterator invalidates `it1`
    &gt;&gt;&gt; next(it2)
    0
    &gt;&gt;&gt; next(it1)  # Further usage of `it1` will raise a `RunTimeError`</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learner</span> <span class="o">=</span> <span class="n">LearnerBase</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">dls</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">MSELoss</span><span class="p">(),</span><span class="n">opt</span><span class="o">=</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">))</span>

<span class="n">learner</span> <span class="o">=</span> <span class="n">Epocher</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">RewardCollector</span><span class="p">(</span><span class="n">learner</span><span class="p">,[</span><span class="n">logger_base</span><span class="p">])</span>


<span class="n">learner</span> <span class="o">=</span> <span class="n">ExperienceReplay</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">StepBatcher</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">QCalc</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">ModelLearnCalc</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>

<span class="n">learner</span> <span class="o">=</span> <span class="n">logger_base</span><span class="o">.</span><span class="n">connect_source_datapipe</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>

<span class="n">learner</span> <span class="o">=</span> <span class="n">LearnerHead</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>

<span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>reward</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>[1.]</td>
    </tr>
    <tr>
      <td>[1.]</td>
    </tr>
    <tr>
      <td>[1.]</td>
    </tr>
  </tbody>
</table></div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>


