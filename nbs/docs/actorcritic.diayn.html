---

title: DIAYN


keywords: fastai
sidebar: home_sidebar

summary: "Diversity Is All You Need"
description: "Diversity Is All You Need"
nb_path: "nbs/14b_actorcritic.diayn.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/14b_actorcritic.diayn.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;CUDA_LAUNCH_BLOCKING&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/fast-reinforcement-learning-2/actorcritic.diayn.html#DIAYN"><code>DIAYN</code></a> extends SAC to create <em>Skills</em> that can be used for a single or multiple environments. 
<a href="https://arxiv.org/pdf/1802.06070.pdf">(Eysenbach et al. 2018) [DIAYN] Diversity Is All You Need</a> covers this in detail.</p>

<pre><code>The general idea is that Skills should each be as diverse as possible and should not be   tied to a reward function specific to an environment.

</code></pre>
<p>Their <a href="https://sites.google.com/view/diayn">project site</a> shows several <em>incredible</em> examples of <a href="/fast-reinforcement-learning-2/actorcritic.diayn.html#DIAYN"><code>DIAYN</code></a> finding <em>Skills</em> without any reward. The original implementation is in tensorflow and ca be found <a href="https://github.com/haarnoja/sac/blob/master/sac/algos/diayn.py">here</a></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Discriminator" class="doc_header"><code>class</code> <code>Discriminator</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/actorcritic/diayn.py#L35" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Discriminator</code>(<strong><code>num_inputs</code></strong>, <strong><code>num_actions</code></strong>, <strong><code>num_skills</code></strong>, <strong><code>hidden_dim</code></strong>) :: <code>Module</code></p>
</blockquote>
<p><code>Module</code> for storing skills. Receives input (<code>num_inputs</code>+<code>num_actions</code>) -&gt; <code>num_skills</code>.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">FastExplainer</span><span class="p">(</span><span class="n">tsensor</span><span class="o">.</span><span class="n">explain</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">once</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">store_attr</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">happened</span><span class="o">=</span><span class="kc">False</span>
        
    <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">happened</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">once</span><span class="p">:</span><span class="k">return</span> <span class="bp">self</span>
        <span class="c1"># print(&quot;ON trace&quot;, sys._getframe())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tracer</span> <span class="o">=</span> <span class="n">ExplainTensorTracer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">settrace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tracer</span><span class="o">.</span><span class="n">listener</span><span class="p">)</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">_getframe</span><span class="p">()</span>
        <span class="n">prev</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">f_back</span> <span class="c1"># get block wrapped in &quot;with&quot;</span>
        <span class="n">prev</span><span class="o">.</span><span class="n">f_trace</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tracer</span><span class="o">.</span><span class="n">listener</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tracer</span>

    <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_value</span><span class="p">,</span> <span class="n">exc_traceback</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">happened</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">once</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">happened</span><span class="p">:</span> <span class="k">return</span> <span class="kc">None</span>
        <span class="c1"># print(&quot;OFF trace&quot;)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">settrace</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="c1"># At this point we have already tried to visualize the statement</span>
        <span class="c1"># If there was no error, the visualization will look normal</span>
        <span class="c1"># but a matrix operation error will show the erroneous operator highlighted.</span>
        <span class="c1"># That was artificial execution of the code. Now the VM has executed</span>
        <span class="c1"># the statement for real and has found the same exception. Make sure to</span>
        <span class="c1"># augment the message with causal information.</span>
        <span class="k">if</span> <span class="n">exc_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="n">exc_frame</span><span class="p">,</span> <span class="n">lib_entry_frame</span> <span class="o">=</span> <span class="n">tensor_lib_entry_frame</span><span class="p">(</span><span class="n">exc_traceback</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">lib_entry_frame</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">is_interesting_exception</span><span class="p">(</span><span class="n">exc_value</span><span class="p">):</span>
            <span class="c1"># print(&quot;exception:&quot;, exc_value, exc_traceback)</span>
            <span class="c1"># traceback.print_tb(exc_traceback, limit=5, file=sys.stdout)</span>
            <span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">line</span><span class="p">,</span> <span class="n">code</span> <span class="o">=</span> <span class="n">info</span><span class="p">(</span><span class="n">exc_frame</span><span class="p">)</span>
            <span class="c1"># print(&#39;info&#39;, module, name, filename, line, code)</span>
            <span class="k">if</span> <span class="n">code</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># We&#39;ve already displayed picture so just augment message</span>
                <span class="n">root</span><span class="p">,</span> <span class="n">tokens</span> <span class="o">=</span> <span class="n">tsensor</span><span class="o">.</span><span class="n">parsing</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">code</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">root</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># Could be syntax error in statement or code I can&#39;t handle</span>
                    <span class="n">offending_expr</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">root</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">exc_frame</span><span class="p">)</span>
                    <span class="k">except</span> <span class="n">tsensor</span><span class="o">.</span><span class="n">ast</span><span class="o">.</span><span class="n">IncrEvalTrap</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="n">offending_expr</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">offending_expr</span>
                    <span class="n">augment_exception</span><span class="p">(</span><span class="n">exc_value</span><span class="p">,</span> <span class="n">offending_expr</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DIAYN" class="doc_header"><code>class</code> <code>DIAYN</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/actorcritic/diayn.py#L51" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DIAYN</code>(<strong><code>num_inputs</code></strong>, <strong><code>action_space</code></strong>, <strong><code>discriminator</code></strong>:<code>Module</code>=<em><code>None</code></em>, <strong><code>num_skills</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>find_best_skill_interval</code></strong>:<code>int</code>=<em><code>10</code></em>, <strong><code>scale_entropy</code></strong>:<code>float</code>=<em><code>1</code></em>, <strong><code>best_skill_n_rollouts</code></strong>:<code>int</code>=<em><code>10</code></em>, <strong><code>include_actions</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>learn_p_z</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>add_p_z</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>hidden_size</code></strong>=<em><code>100</code></em>, <strong><code>lr</code></strong>=<em><code>0.003</code></em>, <strong><code>gamma</code></strong>=<em><code>0.99</code></em>, <strong><code>tau</code></strong>=<em><code>0.005</code></em>, <strong><code>alpha</code></strong>=<em><code>0.2</code></em>, <strong><code>policy</code></strong>=<em><code>'gaussian'</code></em>, <strong><code>automatic_entropy_tuning</code></strong>=<em><code>True</code></em>, <strong><code>target_update_interval</code></strong>=<em><code>1</code></em>) :: <a href="/fast-reinforcement-learning-2/actorcritic.sac.html#SAC"><code>SAC</code></a></p>
</blockquote>
<p><code>discriminator</code> is an additional <code>Module</code> to calculate z.
<code>num_skills</code> is the number of skills/options to learn.
<code>find_best_skill_interval</code> is how often to recompute the best skill.
When finding the best skill, <code>best_skill_n_rollouts</code> determines how many rollouts to
do per skill.
<code>include_actions</code> determines whether to pass actions to the discriminator.
<code>add_p_z</code> determines whether to include $\log{p(z)}$ in the pseudo-reward.
<code>scale_entropy</code> is the scaling factor for entropy.</p>
<p>A few explainations of some of the internal fields:</p>
<p>We now have <code>num_inputs</code> and <code>original_num_inputs</code>. <code>num_inputs</code> has the <code>num_skills</code> being
added to it. This will then be used by the <a href="/fast-reinforcement-learning-2/actorcritic.sac.html#SAC"><code>SAC</code></a> parent in initializing the critic and actor.</p>
<p><code>original_num_inputs</code> will only be used by the <code>discriminator</code> now.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DiscriminatorTrainer" class="doc_header"><code>class</code> <code>DiscriminatorTrainer</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/actorcritic/diayn.py#L199" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DiscriminatorTrainer</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>) :: <a href="/fast-reinforcement-learning-2/qlearning.dqn.html#ExperienceReplay"><code>ExperienceReplay</code></a></p>
</blockquote>
<p>Subclasses ExperienceReplay for augmenting experience, and toggling the agent's skill thats,
being used, and also does training of the discriminator.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Some additional information about <code>DiscrimiatorTrainer</code>.</p>
<p>As noted in <a href="https://arxiv.org/pdf/1802.06070.pdf">(Eysenbach et al. 2018)</a> Algorithm 1, we need $log p(z)$. We accomplish this by getting the output from the discriminator $q_{\phi}(z|s)$, taking the softmax which will scale $z$ to $[0,1]$ which is when is needed to prepresent probability $p$. Next, we scale the distribution by $log$ which is critical for calculating entropy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Some important notes from <a href="https://arxiv.org/pdf/1802.06070.pdf">(Eysenbach et al. 2018)</a>:</p>
<ul>
<li>Hidden nn size is changed from 128 to 300 (pg 14)</li>
<li>Alpha is changed to 0.1 (pg 4)</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pybulletgym.envs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">env</span><span class="o">=</span><span class="s1">&#39;InvertedPendulumPyBulletEnv-v0&#39;</span>
<span class="n">agent</span><span class="o">=</span><span class="n">DIAYN</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env</span><span class="p">)</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span><span class="n">tau</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">hidden_size</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span><span class="n">num_skills</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">block</span><span class="o">=</span><span class="n">FirstLastExperienceBlock</span><span class="p">(</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">exclude_nones</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">dls_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;bs&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;num_workers&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;verbose&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;indexed&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;shuffle_train&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">})</span>
<span class="n">blk</span><span class="o">=</span><span class="n">IterableDataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">block</span><span class="p">),</span><span class="n">splitter</span><span class="o">=</span><span class="n">FuncSplitter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="kc">False</span><span class="p">))</span>
<span class="n">dls</span><span class="o">=</span><span class="n">blk</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">([</span><span class="n">env</span><span class="p">]</span><span class="o">*</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="n">default_device</span><span class="p">())</span>

<span class="n">learner</span><span class="o">=</span><span class="n">SACLearner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">DiscriminatorTrainer</span><span class="p">(</span><span class="n">sz</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span><span class="n">starting_els</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span><span class="n">max_steps</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env</span><span class="p">)</span><span class="o">.</span><span class="n">_max_episode_steps</span><span class="p">),</span>
                                        <span class="n">SACCriticTrainer</span><span class="p">],</span>
                   <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">AvgEpisodeRewardMetric</span><span class="p">(</span><span class="n">experience_cls</span><span class="o">=</span><span class="n">ExperienceFirstLast</span><span class="p">)])</span>
<span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.003</span><span class="p">,</span><span class="n">wd</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/conda/envs/fastrl/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: <span class="ansi-yellow-fg">WARN: Box bound precision lowered by casting to float32</span>
  warnings.warn(colorize(&#39;%s: %s&#39;%(&#39;WARN&#39;, msg % args), &#39;yellow&#39;))
/opt/conda/envs/fastrl/lib/python3.7/site-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_avg_episode_r</th>
      <th>valid_loss</th>
      <th>valid_avg_episode_r</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>-7.664313</td>
      <td>28.307692</td>
      <td>None</td>
      <td>28.307692</td>
      <td>00:30</td>
    </tr>
    <tr>
      <td>1</td>
      <td>-11.469699</td>
      <td>50.225806</td>
      <td>None</td>
      <td>50.225806</td>
      <td>00:30</td>
    </tr>
    <tr>
      <td>2</td>
      <td>-15.333174</td>
      <td>66.342857</td>
      <td>None</td>
      <td>66.342857</td>
      <td>00:31</td>
    </tr>
    <tr>
      <td>3</td>
      <td>-19.612701</td>
      <td>80.027027</td>
      <td>None</td>
      <td>80.027027</td>
      <td>00:31</td>
    </tr>
    <tr>
      <td>4</td>
      <td>-23.090410</td>
      <td>88.725000</td>
      <td>None</td>
      <td>88.725000</td>
      <td>00:31</td>
    </tr>
    <tr>
      <td>5</td>
      <td>-23.701031</td>
      <td>98.295455</td>
      <td>None</td>
      <td>98.295455</td>
      <td>00:31</td>
    </tr>
    <tr>
      <td>6</td>
      <td>-28.609037</td>
      <td>103.938776</td>
      <td>None</td>
      <td>103.938776</td>
      <td>00:33</td>
    </tr>
    <tr>
      <td>7</td>
      <td>-30.065474</td>
      <td>109.150943</td>
      <td>None</td>
      <td>109.150943</td>
      <td>00:34</td>
    </tr>
    <tr>
      <td>8</td>
      <td>-32.395199</td>
      <td>113.500000</td>
      <td>None</td>
      <td>113.500000</td>
      <td>00:35</td>
    </tr>
    <tr>
      <td>9</td>
      <td>-36.382816</td>
      <td>113.500000</td>
      <td>None</td>
      <td>113.500000</td>
      <td>00:35</td>
    </tr>
    <tr>
      <td>10</td>
      <td>-40.044987</td>
      <td>123.122807</td>
      <td>None</td>
      <td>123.122807</td>
      <td>00:35</td>
    </tr>
    <tr>
      <td>11</td>
      <td>-42.630875</td>
      <td>126.898305</td>
      <td>None</td>
      <td>126.898305</td>
      <td>00:31</td>
    </tr>
    <tr>
      <td>12</td>
      <td>-47.392937</td>
      <td>131.733333</td>
      <td>None</td>
      <td>131.733333</td>
      <td>00:31</td>
    </tr>
    <tr>
      <td>13</td>
      <td>-49.802406</td>
      <td>131.733333</td>
      <td>None</td>
      <td>131.733333</td>
      <td>00:32</td>
    </tr>
    <tr>
      <td>14</td>
      <td>-55.425098</td>
      <td>131.733333</td>
      <td>None</td>
      <td>131.733333</td>
      <td>00:33</td>
    </tr>
    <tr>
      <td>15</td>
      <td>-56.940617</td>
      <td>131.733333</td>
      <td>None</td>
      <td>131.733333</td>
      <td>00:35</td>
    </tr>
    <tr>
      <td>16</td>
      <td>-60.000553</td>
      <td>131.733333</td>
      <td>None</td>
      <td>131.733333</td>
      <td>00:34</td>
    </tr>
    <tr>
      <td>17</td>
      <td>-62.084160</td>
      <td>131.733333</td>
      <td>None</td>
      <td>131.733333</td>
      <td>00:35</td>
    </tr>
    <tr>
      <td>18</td>
      <td>-69.457932</td>
      <td>131.733333</td>
      <td>None</td>
      <td>131.733333</td>
      <td>00:32</td>
    </tr>
    <tr>
      <td>19</td>
      <td>-67.988037</td>
      <td>131.733333</td>
      <td>None</td>
      <td>131.733333</td>
      <td>00:39</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastprogress/fastprogress.py:74: UserWarning: Your generator is empty.
  warn(&#34;Your generator is empty.&#34;)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

