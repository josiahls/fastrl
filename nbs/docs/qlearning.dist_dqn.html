---

title: Distributional DQN


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/20h_qlearning.dist_dqn.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/20h_qlearning.dist_dqn.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DistributionalDQN" class="doc_header"><code>class</code> <code>DistributionalDQN</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dist_dqn.py#L37" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DistributionalDQN</code>(<strong><code>input_shape</code></strong>, <strong><code>n_actions</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>Notes:This is an ugly function. Is there is a way we can simplify this? Will need to look at during the refactor</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="distr_projection" class="doc_header"><code>distr_projection</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dist_dqn.py#L73" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>distr_projection</code>(<strong><code>next_distr</code></strong>, <strong><code>rewards</code></strong>, <strong><code>dones</code></strong>, <strong><code>Vmin</code></strong>, <strong><code>Vmax</code></strong>, <strong><code>n_atoms</code></strong>, <strong><code>gamma</code></strong>)</p>
</blockquote>
<p>Perform distribution projection aka Catergorical Algorithm from the
"A Distributional Perspective on RL" paper</p>
<p>Note: direct from <a href="https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On">https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On</a></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="loss_fn" class="doc_header"><code>loss_fn</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dist_dqn.py#L118" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>loss_fn</code>(<strong><code>a</code></strong>, <strong><code>b</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="calc_dist_target_batch" class="doc_header"><code>calc_dist_target_batch</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dist_dqn.py#L120" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>calc_dist_target_batch</code>(<strong><code>learn</code></strong>, <strong><code>trainer</code></strong>, <strong><code>s</code></strong>, <strong><code>a</code></strong>, <strong><code>sp</code></strong>, <strong><code>r</code></strong>, <strong><code>d</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">DistDiscreteAgent</span><span class="p">(</span><span class="n">BaseAgent</span><span class="p">):</span>
    <span class="s2">&quot;DiscreteAgent a simple discrete action selector.&quot;</span>
    <span class="n">a_selector</span><span class="p">:</span><span class="n">ActionSelector</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">device</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">preprocessor</span><span class="p">:</span><span class="n">Callable</span><span class="o">=</span><span class="n">default_states_preprocessor</span>
    <span class="n">apply_softmax</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span>

    <span class="k">def</span> <span class="nf">safe_unbatch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">o</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span><span class="k">return</span> <span class="n">o</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">o</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">1</span> <span class="k">else</span> <span class="n">o</span>
    <span class="k">def</span> <span class="nf">split_v</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">v</span><span class="p">,</span><span class="n">asl</span><span class="p">):</span> <span class="k">return</span> <span class="n">v</span><span class="p">,</span><span class="n">asl</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">asl</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">include_batch_dim</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">x</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">preprocessor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocessor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">s</span>
        <span class="n">asl</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">asl</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">asl</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="n">asl</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">v</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">only_qvals</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">==</span><span class="nb">tuple</span><span class="p">:</span><span class="n">v</span><span class="p">,</span><span class="n">asl</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">split_v</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">asl</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_softmax</span><span class="p">:</span>
            <span class="n">v</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">q</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">al</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">a_selector</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">include_batch_dim</span><span class="p">:</span><span class="n">al</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">safe_unbatch</span><span class="p">(</span><span class="n">al</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="c1">#         print(al)</span>
<span class="c1">#         if not isinstance(al,list): al=[al]</span>
        <span class="k">if</span> <span class="n">include_batch_dim</span><span class="p">:</span>
            <span class="n">al</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">al</span><span class="p">)</span>
            <span class="n">asl</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">asl</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">al</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span> <span class="n">al</span><span class="o">=</span><span class="n">al</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">asl</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span> <span class="n">asl</span><span class="o">=</span><span class="n">asl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
            <span class="k">return</span> <span class="n">al</span><span class="p">,</span><span class="n">asl</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">al</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">asl</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">env</span><span class="o">=</span><span class="s1">&#39;CartPole-v1&#39;</span>
<span class="n">model</span><span class="o">=</span><span class="n">DistributionalDQN</span><span class="p">((</span><span class="mi">4</span><span class="p">,),</span><span class="mi">2</span><span class="p">)</span>
<span class="n">agent</span><span class="o">=</span><span class="n">DistDiscreteAgent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">default_device</span><span class="p">()),</span><span class="n">device</span><span class="o">=</span><span class="n">default_device</span><span class="p">(),</span>
                    <span class="n">a_selector</span><span class="o">=</span><span class="n">EpsilonGreedyActionSelector</span><span class="p">())</span>

<span class="n">block</span><span class="o">=</span><span class="n">FirstLastExperienceBlock</span><span class="p">(</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">dls_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;bs&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;num_workers&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;verbose&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;indexed&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;shuffle_train&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">})</span>
<span class="n">blk</span><span class="o">=</span><span class="n">IterableDataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">block</span><span class="p">),</span>
                      <span class="n">splitter</span><span class="o">=</span><span class="n">FuncSplitter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="kc">False</span><span class="p">),</span>
                     <span class="p">)</span>
<span class="n">dls</span><span class="o">=</span><span class="n">blk</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">([</span><span class="n">env</span><span class="p">]</span><span class="o">*</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="o">*</span><span class="mi">1000</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="n">default_device</span><span class="p">())</span>

<span class="n">learner</span><span class="o">=</span><span class="n">TargetDQNLearner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span><span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">EpsilonTracker</span><span class="p">,</span>
                                        <span class="n">ExperienceReplay</span><span class="p">(</span><span class="n">sz</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span><span class="n">starting_els</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span><span class="n">max_steps</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env</span><span class="p">)</span><span class="o">.</span><span class="n">_max_episode_steps</span><span class="p">),</span>
                                        <span class="n">TargetDQNTrainer</span><span class="p">(</span><span class="n">target_fn</span><span class="o">=</span><span class="n">calc_dist_target_batch</span><span class="p">)],</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">AvgEpisodeRewardMetric</span><span class="p">(</span><span class="n">experience_cls</span><span class="o">=</span><span class="n">ExperienceFirstLast</span><span class="p">,</span><span class="n">always_extend</span><span class="o">=</span><span class="kc">True</span><span class="p">)])</span>
<span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">47</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span><span class="n">wd</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='44' class='' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>
      93.62% [44/47 13:42<00:56]
    </div>
    
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_avg_episode_r</th>
      <th>valid_loss</th>
      <th>valid_avg_episode_r</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>3.458412</td>
      <td>21.428571</td>
      <td>None</td>
      <td>21.428571</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>1</td>
      <td>3.044310</td>
      <td>25.164384</td>
      <td>None</td>
      <td>25.164384</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2.571930</td>
      <td>30.340659</td>
      <td>None</td>
      <td>30.340659</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.739827</td>
      <td>36.060000</td>
      <td>None</td>
      <td>36.060000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.252485</td>
      <td>41.340000</td>
      <td>None</td>
      <td>41.340000</td>
      <td>00:19</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.912612</td>
      <td>47.680000</td>
      <td>None</td>
      <td>47.680000</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.714993</td>
      <td>53.640000</td>
      <td>None</td>
      <td>53.640000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.612818</td>
      <td>59.390000</td>
      <td>None</td>
      <td>59.390000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.524101</td>
      <td>66.490000</td>
      <td>None</td>
      <td>66.490000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.454261</td>
      <td>70.300000</td>
      <td>None</td>
      <td>70.300000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.412645</td>
      <td>76.120000</td>
      <td>None</td>
      <td>76.120000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.363117</td>
      <td>81.680000</td>
      <td>None</td>
      <td>81.680000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.336479</td>
      <td>85.130000</td>
      <td>None</td>
      <td>85.130000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.304332</td>
      <td>93.450000</td>
      <td>None</td>
      <td>93.450000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.278873</td>
      <td>100.240000</td>
      <td>None</td>
      <td>100.240000</td>
      <td>00:19</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.272402</td>
      <td>106.840000</td>
      <td>None</td>
      <td>106.840000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.246317</td>
      <td>111.910000</td>
      <td>None</td>
      <td>111.910000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.233462</td>
      <td>118.930000</td>
      <td>None</td>
      <td>118.930000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.225858</td>
      <td>123.260000</td>
      <td>None</td>
      <td>123.260000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.229128</td>
      <td>128.660000</td>
      <td>None</td>
      <td>128.660000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>20</td>
      <td>0.204113</td>
      <td>132.930000</td>
      <td>None</td>
      <td>132.930000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>21</td>
      <td>0.177285</td>
      <td>137.590000</td>
      <td>None</td>
      <td>137.590000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>22</td>
      <td>0.193802</td>
      <td>142.270000</td>
      <td>None</td>
      <td>142.270000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>23</td>
      <td>0.197363</td>
      <td>146.810000</td>
      <td>None</td>
      <td>146.810000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>24</td>
      <td>0.183566</td>
      <td>151.400000</td>
      <td>None</td>
      <td>151.400000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>25</td>
      <td>0.185290</td>
      <td>157.680000</td>
      <td>None</td>
      <td>157.680000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>26</td>
      <td>0.168233</td>
      <td>163.290000</td>
      <td>None</td>
      <td>163.290000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>27</td>
      <td>0.173684</td>
      <td>167.670000</td>
      <td>None</td>
      <td>167.670000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>28</td>
      <td>0.161375</td>
      <td>171.920000</td>
      <td>None</td>
      <td>171.920000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>29</td>
      <td>0.173723</td>
      <td>176.520000</td>
      <td>None</td>
      <td>176.520000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>30</td>
      <td>0.165821</td>
      <td>181.110000</td>
      <td>None</td>
      <td>181.110000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>31</td>
      <td>0.179164</td>
      <td>183.990000</td>
      <td>None</td>
      <td>183.990000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>32</td>
      <td>0.146669</td>
      <td>189.360000</td>
      <td>None</td>
      <td>189.360000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>33</td>
      <td>0.148607</td>
      <td>193.290000</td>
      <td>None</td>
      <td>193.290000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>34</td>
      <td>0.151430</td>
      <td>197.810000</td>
      <td>None</td>
      <td>197.810000</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>35</td>
      <td>0.160303</td>
      <td>202.630000</td>
      <td>None</td>
      <td>202.630000</td>
      <td>00:19</td>
    </tr>
    <tr>
      <td>36</td>
      <td>0.168462</td>
      <td>207.440000</td>
      <td>None</td>
      <td>207.440000</td>
      <td>00:19</td>
    </tr>
    <tr>
      <td>37</td>
      <td>0.181730</td>
      <td>212.040000</td>
      <td>None</td>
      <td>212.040000</td>
      <td>00:19</td>
    </tr>
    <tr>
      <td>38</td>
      <td>0.160863</td>
      <td>216.840000</td>
      <td>None</td>
      <td>216.840000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>39</td>
      <td>0.143814</td>
      <td>224.510000</td>
      <td>None</td>
      <td>224.510000</td>
      <td>00:19</td>
    </tr>
    <tr>
      <td>40</td>
      <td>0.132378</td>
      <td>228.530000</td>
      <td>None</td>
      <td>228.530000</td>
      <td>00:19</td>
    </tr>
    <tr>
      <td>41</td>
      <td>0.138066</td>
      <td>232.910000</td>
      <td>None</td>
      <td>232.910000</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>42</td>
      <td>0.142707</td>
      <td>237.730000</td>
      <td>None</td>
      <td>237.730000</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>43</td>
      <td>0.139202</td>
      <td>242.630000</td>
      <td>None</td>
      <td>242.630000</td>
      <td>00:19</td>
    </tr>
  </tbody>
</table><p>

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='664' class='' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>
      66.40% [664/1000 00:12<00:06 0.1260]
    </div>
    
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastprogress/fastprogress.py:74: UserWarning: Your generator is empty.
  warn(&#34;Your generator is empty.&#34;)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

