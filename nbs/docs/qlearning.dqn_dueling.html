---

title: Dueling DQN


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/20f_qlearning.dqn_dueling.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/20f_qlearning.dqn_dueling.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DuelingBlock" class="doc_header"><code>class</code> <code>DuelingBlock</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn_dueling.py#L31" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DuelingBlock</code>(<strong><code>h</code></strong>, <strong><code>ao</code></strong>, <strong><code>lin_cls</code></strong>=<em><code>Linear</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DuelingDQN" class="doc_header"><code>class</code> <code>DuelingDQN</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn_dueling.py#L43" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DuelingDQN</code>(<strong><code>input_shape</code></strong>, <strong><code>n_actions</code></strong>) :: <a href="/fast-reinforcement-learning-2/qlearning.dqn.html#LinearDQN"><code>LinearDQN</code></a></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">env</span><span class="o">=</span><span class="s1">&#39;CartPole-v1&#39;</span>
<span class="n">model</span><span class="o">=</span><span class="n">DuelingDQN</span><span class="p">((</span><span class="mi">4</span><span class="p">,),</span><span class="mi">2</span><span class="p">)</span>
<span class="n">agent</span><span class="o">=</span><span class="n">DiscreteAgent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">default_device</span><span class="p">()),</span><span class="n">device</span><span class="o">=</span><span class="n">default_device</span><span class="p">(),</span>
                    <span class="n">a_selector</span><span class="o">=</span><span class="n">EpsilonGreedyActionSelector</span><span class="p">())</span>

<span class="n">block</span><span class="o">=</span><span class="n">FirstLastExperienceBlock</span><span class="p">(</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">dls_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;bs&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;num_workers&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;verbose&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;indexed&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;shuffle_train&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">})</span>
<span class="n">blk</span><span class="o">=</span><span class="n">IterableDataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">block</span><span class="p">),</span>
                      <span class="n">splitter</span><span class="o">=</span><span class="n">FuncSplitter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="kc">False</span><span class="p">),</span>
                     <span class="p">)</span>
<span class="n">dls</span><span class="o">=</span><span class="n">blk</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">([</span><span class="n">env</span><span class="p">]</span><span class="o">*</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="o">*</span><span class="mi">1000</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="n">default_device</span><span class="p">())</span>

<span class="n">learner</span><span class="o">=</span><span class="n">TargetDQNLearner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">EpsilonTracker</span><span class="p">,</span>
                                        <span class="n">ExperienceReplay</span><span class="p">(</span><span class="n">sz</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span><span class="n">starting_els</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span><span class="n">max_steps</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env</span><span class="p">)</span><span class="o">.</span><span class="n">_max_episode_steps</span><span class="p">),</span>
                                        <span class="n">TargetDQNTrainer</span><span class="p">],</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">AvgEpisodeRewardMetric</span><span class="p">(</span><span class="n">experience_cls</span><span class="o">=</span><span class="n">ExperienceFirstLast</span><span class="p">,</span><span class="n">always_extend</span><span class="o">=</span><span class="kc">True</span><span class="p">)])</span>
<span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">47</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span><span class="n">wd</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_avg_episode_r</th>
      <th>valid_loss</th>
      <th>valid_avg_episode_r</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.328026</td>
      <td>24.256410</td>
      <td>None</td>
      <td>24.256410</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.639750</td>
      <td>27.085714</td>
      <td>None</td>
      <td>27.085714</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.210546</td>
      <td>32.341176</td>
      <td>None</td>
      <td>32.341176</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>3</td>
      <td>2.083699</td>
      <td>36.850000</td>
      <td>None</td>
      <td>36.850000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>4</td>
      <td>2.650322</td>
      <td>41.570000</td>
      <td>None</td>
      <td>41.570000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>5</td>
      <td>2.596847</td>
      <td>46.880000</td>
      <td>None</td>
      <td>46.880000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>6</td>
      <td>3.123172</td>
      <td>52.320000</td>
      <td>None</td>
      <td>52.320000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>7</td>
      <td>3.288945</td>
      <td>57.680000</td>
      <td>None</td>
      <td>57.680000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>8</td>
      <td>3.305163</td>
      <td>63.390000</td>
      <td>None</td>
      <td>63.390000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>9</td>
      <td>3.322617</td>
      <td>68.160000</td>
      <td>None</td>
      <td>68.160000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>10</td>
      <td>3.498192</td>
      <td>71.220000</td>
      <td>None</td>
      <td>71.220000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>11</td>
      <td>3.690507</td>
      <td>73.250000</td>
      <td>None</td>
      <td>73.250000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>12</td>
      <td>4.311159</td>
      <td>77.440000</td>
      <td>None</td>
      <td>77.440000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>13</td>
      <td>4.009042</td>
      <td>80.200000</td>
      <td>None</td>
      <td>80.200000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>14</td>
      <td>4.114595</td>
      <td>82.830000</td>
      <td>None</td>
      <td>82.830000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>15</td>
      <td>3.826558</td>
      <td>87.980000</td>
      <td>None</td>
      <td>87.980000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>16</td>
      <td>4.063753</td>
      <td>92.630000</td>
      <td>None</td>
      <td>92.630000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>17</td>
      <td>3.889487</td>
      <td>97.310000</td>
      <td>None</td>
      <td>97.310000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>18</td>
      <td>4.414141</td>
      <td>101.940000</td>
      <td>None</td>
      <td>101.940000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>19</td>
      <td>4.272365</td>
      <td>107.170000</td>
      <td>None</td>
      <td>107.170000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>20</td>
      <td>3.557077</td>
      <td>112.300000</td>
      <td>None</td>
      <td>112.300000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>21</td>
      <td>3.744254</td>
      <td>117.320000</td>
      <td>None</td>
      <td>117.320000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>22</td>
      <td>4.477411</td>
      <td>119.370000</td>
      <td>None</td>
      <td>119.370000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>23</td>
      <td>5.670612</td>
      <td>123.300000</td>
      <td>None</td>
      <td>123.300000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>24</td>
      <td>3.783302</td>
      <td>128.070000</td>
      <td>None</td>
      <td>128.070000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>25</td>
      <td>6.040326</td>
      <td>134.380000</td>
      <td>None</td>
      <td>134.380000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>26</td>
      <td>4.862150</td>
      <td>136.780000</td>
      <td>None</td>
      <td>136.780000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>27</td>
      <td>2.666257</td>
      <td>142.310000</td>
      <td>None</td>
      <td>142.310000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>28</td>
      <td>5.248787</td>
      <td>144.910000</td>
      <td>None</td>
      <td>144.910000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>29</td>
      <td>2.874206</td>
      <td>147.430000</td>
      <td>None</td>
      <td>147.430000</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>30</td>
      <td>4.951278</td>
      <td>150.410000</td>
      <td>None</td>
      <td>150.410000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>31</td>
      <td>3.380475</td>
      <td>155.980000</td>
      <td>None</td>
      <td>155.980000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>32</td>
      <td>4.068498</td>
      <td>158.550000</td>
      <td>None</td>
      <td>158.550000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>33</td>
      <td>4.767910</td>
      <td>162.890000</td>
      <td>None</td>
      <td>162.890000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>34</td>
      <td>3.424808</td>
      <td>167.830000</td>
      <td>None</td>
      <td>167.830000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>35</td>
      <td>4.150999</td>
      <td>171.490000</td>
      <td>None</td>
      <td>171.490000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>36</td>
      <td>2.557575</td>
      <td>176.550000</td>
      <td>None</td>
      <td>176.550000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>37</td>
      <td>3.600501</td>
      <td>180.570000</td>
      <td>None</td>
      <td>180.570000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>38</td>
      <td>2.647914</td>
      <td>184.370000</td>
      <td>None</td>
      <td>184.370000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>39</td>
      <td>2.531585</td>
      <td>188.060000</td>
      <td>None</td>
      <td>188.060000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>40</td>
      <td>3.241321</td>
      <td>193.050000</td>
      <td>None</td>
      <td>193.050000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>41</td>
      <td>2.324372</td>
      <td>197.670000</td>
      <td>None</td>
      <td>197.670000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>42</td>
      <td>2.994291</td>
      <td>201.870000</td>
      <td>None</td>
      <td>201.870000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>43</td>
      <td>4.057852</td>
      <td>206.970000</td>
      <td>None</td>
      <td>206.970000</td>
      <td>00:16</td>
    </tr>
    <tr>
      <td>44</td>
      <td>2.414462</td>
      <td>211.480000</td>
      <td>None</td>
      <td>211.480000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>45</td>
      <td>2.440019</td>
      <td>217.210000</td>
      <td>None</td>
      <td>217.210000</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>46</td>
      <td>4.549252</td>
      <td>222.570000</td>
      <td>None</td>
      <td>222.570000</td>
      <td>00:17</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastprogress/fastprogress.py:74: UserWarning: Your generator is empty.
  warn(&#34;Your generator is empty.&#34;)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

