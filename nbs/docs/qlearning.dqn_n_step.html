---

title: DQN N-Steps


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/20b_qlearning.dqn_n_step.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/20b_qlearning.dqn_n_step.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DQNTrainer" class="doc_header"><code>class</code> <code>DQNTrainer</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn.py#L94" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DQNTrainer</code>(<strong><code>after_create</code></strong>=<em><code>None</code></em>, <strong><code>before_fit</code></strong>=<em><code>None</code></em>, <strong><code>before_epoch</code></strong>=<em><code>None</code></em>, <strong><code>before_train</code></strong>=<em><code>None</code></em>, <strong><code>before_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_pred</code></strong>=<em><code>None</code></em>, <strong><code>after_loss</code></strong>=<em><code>None</code></em>, <strong><code>before_backward</code></strong>=<em><code>None</code></em>, <strong><code>before_step</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_step</code></strong>=<em><code>None</code></em>, <strong><code>after_step</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_train</code></strong>=<em><code>None</code></em>, <strong><code>after_train</code></strong>=<em><code>None</code></em>, <strong><code>before_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_epoch</code></strong>=<em><code>None</code></em>, <strong><code>after_epoch</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_fit</code></strong>=<em><code>None</code></em>, <strong><code>after_fit</code></strong>=<em><code>None</code></em>) :: <code>Callback</code></p>
</blockquote>
<p>Basic class handling tweaks of the training loop by changing a <code>Learner</code> in various events</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="NStepDQNLearner" class="doc_header"><code>class</code> <code>NStepDQNLearner</code><a href="https://github.com/josiahls/fast-reinforcement-learning-2/tree/master/fastrl/qlearning/dqn_n_step.py#L52" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>NStepDQNLearner</code>(<strong><code>dls</code></strong>, <strong><code>agent</code></strong>=<em><code>None</code></em>, <strong><code>model</code></strong>=<em><code>None</code></em>, <strong><code>use_train_mets</code></strong>=<em><code>True</code></em>, <strong><code>loss_func</code></strong>=<em><code>None</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>lr</code></strong>=<em><code>0.001</code></em>, <strong><code>splitter</code></strong>=<em><code>trainable_params</code></em>, <strong><code>cbs</code></strong>=<em><code>None</code></em>, <strong><code>metrics</code></strong>=<em><code>None</code></em>, <strong><code>path</code></strong>=<em><code>None</code></em>, <strong><code>model_dir</code></strong>=<em><code>'models'</code></em>, <strong><code>wd</code></strong>=<em><code>None</code></em>, <strong><code>wd_bn_bias</code></strong>=<em><code>False</code></em>, <strong><code>train_bn</code></strong>=<em><code>True</code></em>, <strong><code>moms</code></strong>=<em><code>(0.95, 0.85, 0.95)</code></em>) :: <a href="/fast-reinforcement-learning-2/learner.html#AgentLearner"><code>AgentLearner</code></a></p>
</blockquote>
<p>Base Learner for all reinforcement learning agents</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">env</span><span class="o">=</span><span class="s1">&#39;CartPole-v1&#39;</span>
<span class="n">model</span><span class="o">=</span><span class="n">LinearDQN</span><span class="p">((</span><span class="mi">4</span><span class="p">,),</span><span class="mi">2</span><span class="p">)</span>
<span class="n">agent</span><span class="o">=</span><span class="n">DiscreteAgent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">default_device</span><span class="p">()),</span><span class="n">device</span><span class="o">=</span><span class="n">default_device</span><span class="p">(),</span>
                    <span class="n">a_selector</span><span class="o">=</span><span class="n">EpsilonGreedyActionSelector</span><span class="p">())</span>

<span class="n">block</span><span class="o">=</span><span class="n">FirstLastExperienceBlock</span><span class="p">(</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">dls_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;bs&#39;</span><span class="p">:</span><span class="mi">32</span><span class="p">,</span><span class="s1">&#39;num_workers&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;verbose&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;indexed&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;shuffle_train&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">})</span>
<span class="n">blk</span><span class="o">=</span><span class="n">IterableDataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">block</span><span class="p">),</span>
                      <span class="n">splitter</span><span class="o">=</span><span class="n">FuncSplitter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="kc">False</span><span class="p">),</span>
<span class="c1">#                       batch_tfms=lambda x:(x[&#39;s&#39;],x),</span>
                     <span class="p">)</span>
<span class="n">dls</span><span class="o">=</span><span class="n">blk</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">([</span><span class="n">env</span><span class="p">]</span><span class="o">*</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">32</span><span class="o">*</span><span class="mi">1000</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="n">default_device</span><span class="p">())</span>

<span class="n">learner</span><span class="o">=</span><span class="n">NStepDQNLearner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">EpsilonTracker</span><span class="p">,</span>
                                        <span class="n">ExperienceReplay</span><span class="p">(</span><span class="n">sz</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span><span class="n">bs</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span><span class="n">starting_els</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span><span class="n">max_steps</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env</span><span class="p">)</span><span class="o">.</span><span class="n">_max_episode_steps</span><span class="p">),</span>
                                        <span class="n">DQNTrainer</span><span class="p">],</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">AvgEpisodeRewardMetric</span><span class="p">(</span><span class="n">experience_cls</span><span class="o">=</span><span class="n">ExperienceFirstLast</span><span class="p">)])</span>
<span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span><span class="n">wd</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_avg_episode_r</th>
      <th>valid_loss</th>
      <th>valid_avg_episode_r</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>23.506865</td>
      <td>31.350000</td>
      <td>None</td>
      <td>31.350000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>1</td>
      <td>38.347233</td>
      <td>53.710000</td>
      <td>None</td>
      <td>53.710000</td>
      <td>00:13</td>
    </tr>
    <tr>
      <td>2</td>
      <td>8.918954</td>
      <td>92.310000</td>
      <td>None</td>
      <td>92.310000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3.378475</td>
      <td>143.730000</td>
      <td>None</td>
      <td>143.730000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>4</td>
      <td>6.603476</td>
      <td>194.220000</td>
      <td>None</td>
      <td>194.220000</td>
      <td>00:13</td>
    </tr>
    <tr>
      <td>5</td>
      <td>4.584166</td>
      <td>238.890000</td>
      <td>None</td>
      <td>238.890000</td>
      <td>00:13</td>
    </tr>
    <tr>
      <td>6</td>
      <td>22.217869</td>
      <td>266.190000</td>
      <td>None</td>
      <td>266.190000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>7</td>
      <td>8.952121</td>
      <td>263.560000</td>
      <td>None</td>
      <td>263.560000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>8</td>
      <td>31.645321</td>
      <td>241.610000</td>
      <td>None</td>
      <td>241.610000</td>
      <td>00:13</td>
    </tr>
    <tr>
      <td>9</td>
      <td>2.677207</td>
      <td>226.220000</td>
      <td>None</td>
      <td>226.220000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>10</td>
      <td>14.525805</td>
      <td>231.130000</td>
      <td>None</td>
      <td>231.130000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>11</td>
      <td>19.272089</td>
      <td>206.900000</td>
      <td>None</td>
      <td>206.900000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>12</td>
      <td>2.956491</td>
      <td>175.550000</td>
      <td>None</td>
      <td>175.550000</td>
      <td>00:12</td>
    </tr>
    <tr>
      <td>13</td>
      <td>7.233163</td>
      <td>161.600000</td>
      <td>None</td>
      <td>161.600000</td>
      <td>00:13</td>
    </tr>
    <tr>
      <td>14</td>
      <td>13.558823</td>
      <td>197.110000</td>
      <td>None</td>
      <td>197.110000</td>
      <td>00:13</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastprogress/fastprogress.py:74: UserWarning: Your generator is empty.
  warn(&#34;Your generator is empty.&#34;)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

