{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a8a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61569eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d15935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os,warnings,logging,typing\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.basics import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "# Local modules\n",
    "\n",
    "_logger = logging.getLogger()\n",
    "_li = _logger.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a02bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782bc163",
   "metadata": {},
   "source": [
    "# Core\n",
    "> Core libs for fastrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8322c670-596f-4c6b-bb6c-148162a50bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def fastrl_make_requirements(\n",
    "    path:Path=None, # The path to a dir with the settings.ini, if none, cwd.\n",
    "    project_file:str='settings.ini', # The file to load for reading the requirements\n",
    "    out_path:Path=None # The output path (can be relative to `path`)\n",
    "):\n",
    "    logging.basicConfig()\n",
    "    requirement_types = ['','dev_','pip_']\n",
    "    path = ifnone(path, Path.cwd())/project_file\n",
    "\n",
    "    if not path.exists(): raise OSError(f'File {path} does not exist')\n",
    "\n",
    "    out_path = ifnone(out_path, Path('extra'))\n",
    "    out_path = out_path if out_path.is_absolute() else path.parent/out_path\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "    _li('Outputting to path: %s',out_path)\n",
    "    config = Config(path.parent,path.name)\n",
    "\n",
    "    for req in requirement_types:\n",
    "        requirements = config[req+'requirements']\n",
    "\n",
    "        requirements = requirements.replace(' ','\\n')\n",
    "\n",
    "        Path(out_path/(req+'requirements.txt')).write_text(requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48520401-7c7f-48f6-b7ab-fd1aa89abe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _fmt_fld(t:typing.Tuple[str,type],namedtuple):\n",
    "    default_v = ''\n",
    "    if t[0] in namedtuple._field_defaults:\n",
    "        default_v = f' = `{namedtuple._field_defaults[t[0]]}`'\n",
    "    return ' - **%s**:`%s` '%t+default_v+getattr(namedtuple,t[0]).__doc__\n",
    "\n",
    "def add_namedtuple_doc(\n",
    "    t:typing.NamedTuple, # Primary tuple to get docs from\n",
    "    doc:str, # Primary doc for the overall tuple, where the docs for individual fields will be concated.\n",
    "    **fields_docs:dict # Field names with associated docs to be attached in the format: field_a='some documentation'\n",
    "):\n",
    "    \"Add docs to `t` from `doc` along with individual doc fields `fields_docs`\"\n",
    "    if not hasattr(t,'__base_doc__'): t.__base_doc__ = doc\n",
    "    for k,v in fields_docs.items(): getattr(t,k).__doc__ = v\n",
    "    # TODO: can we add optional default fields also?\n",
    "    flds = L(t.__annotations__.items()).map(_fmt_fld,namedtuple=t)\n",
    "    \n",
    "    s = 'Parameters:\\n'+'\\n'.join(flds)\n",
    "    t.__doc__ = doc + '\\n\\n' + s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58eb6165-9b70-47b5-b302-9049a3c1cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SimpleStep(typing.NamedTuple):\n",
    "    state:       torch.FloatTensor=torch.FloatTensor([0])\n",
    "    action:      torch.FloatTensor=torch.FloatTensor([0])\n",
    "    next_state:  torch.FloatTensor=torch.FloatTensor([0])\n",
    "    terminated:  torch.BoolTensor=torch.BoolTensor([1])\n",
    "    truncated:   torch.BoolTensor=torch.BoolTensor([1])\n",
    "    reward:      torch.FloatTensor=torch.LongTensor([0])\n",
    "    total_reward:torch.FloatTensor=torch.FloatTensor([0])\n",
    "    env_id:      torch.LongTensor=torch.LongTensor([0])\n",
    "    proc_id:     torch.LongTensor=torch.LongTensor([0])\n",
    "    step_n:      torch.LongTensor=torch.LongTensor([0])\n",
    "    episode_n:   torch.LongTensor=torch.LongTensor([0])\n",
    "    image:       torch.FloatTensor=torch.FloatTensor([0])\n",
    "    \n",
    "    @classmethod\n",
    "    def random(cls,seed=None,**flds):\n",
    "        _flds,_annos = cls._fields,cls.__annotations__\n",
    "\n",
    "        def _random_annos(anno):\n",
    "            t = anno(1)\n",
    "            if anno==torch.BoolTensor: t.random_(2) \n",
    "            else:                      t.random_(100)\n",
    "            return t\n",
    "\n",
    "        return cls(\n",
    "            *(flds.get(\n",
    "                f,_random_annos(_annos[f])\n",
    "            ) for f in _flds)\n",
    "        )\n",
    "\n",
    "add_namedtuple_doc(\n",
    "    SimpleStep,\n",
    "    'Represents a single step in an environment.',\n",
    "    state = 'Both the initial state of the environment and the previous state.',\n",
    "    next_state = 'Both the next state, and the last state in the environment',\n",
    "    terminated = \"\"\"Represents an ending condition for an environment such as reaching a goal or 'living long enough' as \n",
    "                    described by the MDP.\n",
    "                    Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155\"\"\",\n",
    "    truncated = \"\"\"Represents an ending condition for an environment that can be seen as an out of bounds condition either\n",
    "                   literally going out of bounds, breaking rules, or exceeding the timelimit allowed by the MDP.\n",
    "                   Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155'\"\"\",\n",
    "    reward = 'The single reward for this step.',\n",
    "    total_reward = 'The total accumulated reward for this episode up to this step.',\n",
    "    action = 'The action that was taken to transition from `state` to `next_state`',\n",
    "    env_id = 'The environment this step came from (useful for debugging)',\n",
    "    proc_id = 'The process this step came from (useful for debugging)',\n",
    "    step_n = 'The step number in a given episode.',\n",
    "    episode_n = 'The episode this environment is currently running through.',\n",
    "    image = \"\"\"Intended for display and logging only. If the intention is to use images for training an\n",
    "               agent, then use a env wrapper instead.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a6c520-bbc1-4b19-9217-b45fd0e02a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### SimpleStep\n",
       "\n",
       ">      SimpleStep (state:torch.FloatTensor=tensor([0.]),\n",
       ">                  action:torch.FloatTensor=tensor([0.]),\n",
       ">                  next_state:torch.FloatTensor=tensor([0.]),\n",
       ">                  terminated:torch.BoolTensor=tensor([True]),\n",
       ">                  truncated:torch.BoolTensor=tensor([True]),\n",
       ">                  reward:torch.FloatTensor=tensor([0]),\n",
       ">                  total_reward:torch.FloatTensor=tensor([0.]),\n",
       ">                  env_id:torch.LongTensor=tensor([0]),\n",
       ">                  proc_id:torch.LongTensor=tensor([0]),\n",
       ">                  step_n:torch.LongTensor=tensor([0]),\n",
       ">                  episode_n:torch.LongTensor=tensor([0]),\n",
       ">                  image:torch.FloatTensor=tensor([0.]))\n",
       "\n",
       "Represents a single step in an environment."
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SimpleStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ac338-ef2c-448e-bfdd-ff58cf001023",
   "metadata": {},
   "source": [
    "Now we can generate a couple to send their a pytorch data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cffbd42d-ada9-450e-8fd6-df58c25acc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleStep(state=tensor([0., 0.]), action=tensor([39.]), next_state=tensor([33.]), terminated=tensor([False]), truncated=tensor([True]), reward=tensor([79.]), total_reward=tensor([27.]), env_id=tensor([3]), proc_id=tensor([97]), step_n=tensor([83]), episode_n=tensor([1]), image=tensor([66.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "SimpleStep.random(state=torch.FloatTensor(2).fill_(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed64a604-8997-415c-935b-25fccf519c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleStep(state=tensor([[44.]]), action=tensor([[39.]]), next_state=tensor([[33.]]), terminated=tensor([[False]]), truncated=tensor([[True]]), reward=tensor([[79.]]), total_reward=tensor([[27.]]), env_id=tensor([[3]]), proc_id=tensor([[97]]), step_n=tensor([[83]]), episode_n=tensor([[1]]), image=tensor([[66.]])), SimpleStep(state=tensor([[56.]]), action=tensor([[99.]]), next_state=tensor([[78.]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[68.]]), total_reward=tensor([[94.]]), env_id=tensor([[33]]), proc_id=tensor([[26]]), step_n=tensor([[19]]), episode_n=tensor([[91]]), image=tensor([[54.]])), SimpleStep(state=tensor([[24.]]), action=tensor([[41.]]), next_state=tensor([[69.]]), terminated=tensor([[True]]), truncated=tensor([[True]]), reward=tensor([[80.]]), total_reward=tensor([[81.]]), env_id=tensor([[12]]), proc_id=tensor([[63]]), step_n=tensor([[60]]), episode_n=tensor([[95]]), image=tensor([[85.]]))]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "import torchdata.datapipes as dp\n",
    "\n",
    "def seed_worker(worker_id): torch.manual_seed(0)\n",
    "def random_step_generator(): \n",
    "    while True: yield SimpleStep.random()\n",
    "    \n",
    "\n",
    "pipe = dp.iter.IterableWrapper(random_step_generator(),deepcopy=False)\n",
    "pipe = pipe.batch(batch_size=3)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "dl = DataLoader2(pipe,num_workers=2,worker_init_fn=seed_worker)\n",
    "\n",
    "for o in dl:\n",
    "    print(o)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "637b5235-08c4-4492-acda-9e484afb041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "StepType = (SimpleStep,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e20de8-9b95-4a6a-98d3-de36a8d058ed",
   "metadata": {},
   "source": [
    "## Some Important Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39955d92-15ef-40ea-aa65-97ad35e0c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numpy to Tensor Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ecb7588-0bdd-49ee-a09d-5d01db67add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=np.random.randint(0,255,size=(240, 320, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0773340-350a-4e4b-9668-12638a0a5eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%timeit` not found.\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#|eval: false\n",
    "img=np.random.randint(0,255,size=(240, 320, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "853b56a2-5906-4628-a006-c14d7a6490a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.6 µs ± 2.35 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#|eval: false\n",
    "deepcopy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02c69b6e-4f20-4925-92b3-eeac7498ddbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.8 µs ± 8.45 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#|eval: false\n",
    "Tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82df9b01-b99d-45b9-88ff-0be11963d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:229.)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 ms ± 1.87 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#|eval: false\n",
    "Tensor([img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e178f-2dab-4c69-8d85-865f6d0f5295",
   "metadata": {},
   "source": [
    "You will notice that if you wrap a numpy in a list, it completely kills the performance. The solution is to\n",
    "just add a batch dim to the existing array and pass it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b60cea6-4046-452d-a94e-a0e81b5095f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.7 µs ± 468 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#|eval: false\n",
    "Tensor(np.expand_dims(img,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a29abd-9f51-4128-95aa-9342056bdc85",
   "metadata": {},
   "source": [
    "In fact we can just test this with python lists..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c23240a4-ef1e-4233-bd9b-38d1a9b37d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.38 µs ± 20.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#|eval: false\n",
    "Tensor([[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d4a2445-525d-452b-960e-aaafb819401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr=[[1]*270000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62ba802e-d49b-49c5-b6ec-2b337bfeaa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.49 ms ± 43.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#|eval: false\n",
    "Tensor(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc03634b-fcf9-4142-a09c-736747435a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr=np.array([[1]*270000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c40acfb8-ce68-4ad6-91aa-0048d22ee260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.5 µs ± 6.55 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#|eval: false\n",
    "Tensor(test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d599aa-c2a6-47a4-bb71-b2676f2c2486",
   "metadata": {},
   "source": [
    "This is horrifying just how made of a performance hit this causes... So we will be avoiding python list inputs \n",
    "to Tensors for now on..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd8c1e-8ec3-472b-adc7-d2f39a4667fd",
   "metadata": {},
   "source": [
    "## Testing\n",
    "> Additional utilities for testing anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91d25ab0-a6a9-4c01-912e-cff9bd44346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def test_in(a,b):\n",
    "    \"`test` that `a in b`\"\n",
    "    test(a,b,in_, ' in ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba915d0e-3c7b-4e3f-957f-ad3924f1365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in('o','hello')\n",
    "test_in(3,[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8569888-d828-407c-b20c-2bae8065a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _len_check(a,b): \n",
    "    return len(a)==(len(b) if not isinstance(b,int) else b)\n",
    "\n",
    "def test_len(a,b,meta_info=''):\n",
    "    \"`test` that `len(a) == int(b) or len(a) == len(b)`\"\n",
    "    test(a,b,_len_check, f' len == len {meta_info}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a2355ec-c859-4bb4-b360-03ac677236b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len([1,2,3],3)\n",
    "test_len([1,2,3],[1,2,3])\n",
    "test_len([1,2,3],'123')\n",
    "test_fail(lambda:test_len([1,2,3],'1234'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac3b0e7d-0501-4f45-853c-793a15aa47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _less_than(a,b): return a < b\n",
    "def test_lt(a,b):\n",
    "    \"`test` that `a < b`\"\n",
    "    test(a,b,_less_than, ' a < b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1f49538-4605-4f7a-bef3-50654ede0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lt(4,5)\n",
    "test_fail(lambda:test_lt(5,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d8f6b-7bf5-486b-a5d2-4baf8d1f1eb0",
   "metadata": {},
   "source": [
    "## Basic Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ff16401-674c-4ee1-9d5c-dfe07b053fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def run_tensorboard(port=6006, # The port to run tensorboard on/connect on\n",
    "                    start_tag=None, # Starting regex e.g.: experience_replay/1\n",
    "                    samples_per_plugin=None, # Sampling freq such as  images=0 (keep all)\n",
    "                    extra_args=None, # Any additional arguments in the `--arg value` format\n",
    "                    rm_glob=None # Remove old logs via a parttern e.g.: '*' will remove all files: runs/* \n",
    "                   ):\n",
    "    if rm_glob is not None:\n",
    "        for p in Path('runs').glob(rm_glob): p.delete()\n",
    "    import socket\n",
    "    from tensorboard import notebook\n",
    "    a_socket=socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    cmd=None\n",
    "    if not a_socket.connect_ex(('127.0.0.1',6006)):\n",
    "        notebook.display(port=port,height=1000)\n",
    "    else:\n",
    "        cmd=f'--logdir runs --port {port} --host=0.0.0.0'\n",
    "        if samples_per_plugin is not None: cmd+=f' --samples_per_plugin {samples_per_plugin}'\n",
    "        if start_tag is not None:          cmd+=f' --tag {start_tag}'\n",
    "        if extra_args is not None:         cmd+=f' {extra_args}'\n",
    "        notebook.start(cmd)\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "010802a9-441e-4916-8c54-705969e5060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "SHOW_TENSOR_BOARD=False\n",
    "if not os.environ.get(\"IN_TEST\", None) and SHOW_TENSOR_BOARD:\n",
    "    run_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e579231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea76e19d-667a-4235-a988-231857dc87de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
