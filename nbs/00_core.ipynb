{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a8a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61569eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42d15935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os,warnings,logging\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.basics import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "# Local modules\n",
    "\n",
    "_logger = logging.getLogger()\n",
    "_li = _logger.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a02bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782bc163",
   "metadata": {},
   "source": [
    "# Core\n",
    "> Core libs for fastrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8322c670-596f-4c6b-bb6c-148162a50bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@call_parse\n",
    "def fastrl_make_requirements(\n",
    "    path:Path=None, # The path to a dir with the settings.ini, if none, cwd.\n",
    "    project_file:str='settings.ini', # The file to load for reading the requirements\n",
    "    out_path:Path=None # The output path (can be relative to `path`)\n",
    "):\n",
    "    logging.basicConfig()\n",
    "    requirement_types = ['','dev_','pip_']\n",
    "    path = ifnone(path, Path.cwd())/project_file\n",
    "\n",
    "    if not path.exists(): raise OSError(f'File {path} does not exist')\n",
    "\n",
    "    out_path = ifnone(out_path, Path('extra'))\n",
    "    out_path = out_path if out_path.is_absolute() else path.parent/out_path\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "    _li('Outputting to path: %s',out_path)\n",
    "    config = Config(path.parent,path.name)\n",
    "\n",
    "    for req in requirement_types:\n",
    "        requirements = config[req+'requirements']\n",
    "\n",
    "        requirements = requirements.replace(' ','\\n')\n",
    "\n",
    "        Path(out_path/(req+'requirements.txt')).write_text(requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86156ce6",
   "metadata": {},
   "source": [
    "## D\n",
    "> A better dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07678e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def map_dict_ex(d,f,*args,gen=False,wise=None,**kwargs):\n",
    "    \"Like `map`, but for dicts and uses `bind`, and supports `str` and indexing\"\n",
    "    g = (bind(f,*args,**kwargs) if callable(f)\n",
    "         else f.format if isinstance(f,str)\n",
    "         else f.__getitem__)\n",
    "\n",
    "    if wise is None:  return map(g,d.items())\n",
    "    return ((k,g(v)) if wise=='value' else (g(k),v) for k,v in d.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966c81f7",
   "metadata": {},
   "source": [
    "Check that general mapping for dicts works nicely..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63fcd03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict={'a':1,'b':2,'c':3}\n",
    "test_eq(dict(map_dict_ex(test_dict,lambda t:(t[0]+'_new',t[1]+1))),{'a_new':2,'b_new':3,'c_new':4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e2e81a",
   "metadata": {},
   "source": [
    "Check that key and value wise mapping works correctly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6df8a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(dict(map_dict_ex(test_dict,lambda k:k+'_new',wise='key')),{'a_new':1,'b_new':2,'c_new':3})\n",
    "test_eq(dict(map_dict_ex(test_dict,lambda v:v+1,wise='value')),{'a':2,'b':3,'c':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9531e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "_error_msg='Found idxs: %s have values more than %s e.g.: %s'\n",
    "\n",
    "class D(dict):\n",
    "    \"Improved version of `dict` with array handling abilities\"\n",
    "    def __init__(self,*args,mapping=False,**kwargs):\n",
    "        self.mapping=mapping\n",
    "        super().__init__(*args,**kwargs)\n",
    "        \n",
    "    def eq_k(self,o:'D',with_diff=False):\n",
    "        eq=set(o.keys())==set(self.keys())\n",
    "        if with_diff: return eq,set(o.keys()).symmetric_difference(set(self.keys()))\n",
    "        return eq\n",
    "    def _new(self,*args,**kwargs): return type(self)(*args,**kwargs)\n",
    "    \n",
    "    def map(self,f,*args,gen=False,**kwargs): \n",
    "        return (self._new,noop)[gen](map_dict_ex(self,f,*args,**kwargs),mapping=True)\n",
    "    def mapk(self,f,*args,gen=False,wise='key',**kwargs):\n",
    "        return self.map(f,*args,gen=gen,wise=wise,**kwargs)\n",
    "    def mapv(self,f,*args,gen=False,wise='value',**kwargs):\n",
    "        return self.map(f,*args,gen=gen,wise=wise,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4375e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict=D({'a':1,'b':2,'c':3})\n",
    "test_eq(test_dict.map(lambda t:(t[0]+'_new',t[1]+1)),{'a_new':2,'b_new':3,'c_new':4})\n",
    "test_eq(isinstance(test_dict.map(lambda t:(t[0]+'_new',t[1]+1),gen=True),map),True)\n",
    "test_eq(dict(test_dict.map(lambda t:(t[0]+'_new',t[1]+1),gen=True)),{'a_new':2,'b_new':3,'c_new':4})\n",
    "\n",
    "test_eq(test_dict.mapk(lambda k:k+'_new'),{'a_new':1,'b_new':2,'c_new':3})\n",
    "test_eq(dict(test_dict.mapk(lambda k:k+'_new',gen=True)),{'a_new':1,'b_new':2,'c_new':3})\n",
    "\n",
    "test_eq(test_dict.mapv(lambda v:v+1,wise='value'),{'a':2,'b':3,'c':4})\n",
    "test_eq(dict(test_dict.mapv(lambda v:v+1,gen=True,wise='value')),{'a':2,'b':3,'c':4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493e7733",
   "metadata": {},
   "source": [
    "`BD` is the primary data structure that `fastrl` uses. It allows for easily iterating and doing operations on steps attained from environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a727941c",
   "metadata": {},
   "source": [
    "## BD \n",
    "> A batch wise dictionary that requires all values to be numpy,tensor, or None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc677ee",
   "metadata": {},
   "source": [
    "We need to change any indexer that is passed. We don't know if the indexer is going to\n",
    "be a numpy array, slice, tensor, or int.\n",
    "All we know is 2 things:\n",
    "- If it is an int, the batch dim will disappear\n",
    "- If it is an indexer, then the batch dim will stay, but be smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6c587ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def tensor2shape(k,t:'TensorBatch',relative_shape=False):\n",
    "    \"Converts a tensor into a dict of shapes, or a 1d numpy array\"\n",
    "    return {\n",
    "        k:t.cpu().numpy().reshape(-1,) if len(t.shape)==2 and t.shape[1]==1 else \n",
    "        [str((1,*t.shape[1:]) if relative_shape else t.shape)]*t.shape[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442bbf5",
   "metadata": {},
   "source": [
    "`tensor2shape` is a function for preparing tensors for showing in pandas. For example\n",
    "if we have a tensor that has 5 dimensions, it would be very hard to read if displayed in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0615904",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tensor2shape('test',torch.randn(3,5)),\n",
    "       {'test': ['torch.Size([3, 5])', 'torch.Size([3, 5])', 'torch.Size([3, 5])']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8cfde1",
   "metadata": {},
   "source": [
    "If the tensor has only 1 channel, then we can show its literal value..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aad0ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tensor2shape('test',torch.tensor([[1],[2],[3]]))['test'],\n",
    "        {'test': np.array([1, 2, 3])}['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfe1a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def tensor2mu(k,t:Tensor): return {f'{k}_mu':t.reshape(t.shape[0],-1).double().mean(axis=1)}\n",
    "tensor2mu.__docs__=\"Returns a dict with key `k`_mu with the mean of `t` batchwise \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71adf429",
   "metadata": {},
   "source": [
    "Outputs a dictionary that has the mean of the tensor. The returned dictionary's keys \n",
    "have the naming convention: *[k]_mu*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c1508ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "o=torch.randn(3,5)\n",
    "test_eq(tensor2mu('test',o)['test_mu'],{'test_mu': o.double().mean(axis=1)}['test_mu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5cb50",
   "metadata": {},
   "source": [
    "Ok I have reworked the tensor management soooo many times. I think the core issue is the tensors themselves. They should individually be incharge of\n",
    "determining if they match the expected batch size I think...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f9d3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TensorBatch(TensorBase):\n",
    "    \"A tensor assumes a batch dimension\"\n",
    "    def __new__(cls, x, bs=1,**kwargs):\n",
    "        res=super(TensorBatch,cls).__new__(cls,x,**kwargs)\n",
    "        setattr(res,'_bs',x.bs() if isinstance(x,cls) else bs)\n",
    "        return res\n",
    "    \n",
    "    def strict(self):\n",
    "        assert self.shape[0]==self._bs,f'Tensor has shape {self.shape} while bs is {self._bs}'\n",
    "        \n",
    "    def bs(self): return self.shape[0]\n",
    "    def get(self,*args):\n",
    "        \"Get a possible subset of a tensor while maintaining a batch dim.\"\n",
    "        res=self[args]\n",
    "        if len(self.shape)>len(res.shape): res=res.unsqueeze(0)\n",
    "        return res\n",
    "    \n",
    "    @classmethod\n",
    "    def vstack(cls,*args): \n",
    "        return cls(torch.vstack(*args),bs=L(*args).map(cls).map(Self.bs()).sum())\n",
    "              \n",
    "def obj2tensor(o):\n",
    "    return (o if isinstance(o,TensorBatch) else\n",
    "            TensorBatch(np.array(o)) if isinstance(o,(L,list)) else\n",
    "            TensorBatch(o) if isinstance(o,(np.ndarray,Tensor,TensorBatch)) else\n",
    "            TensorBatch([o])) \n",
    "\n",
    "def _get_bs(o): return o.bs if isinstance(o,TensorBatch) else TensorBatch(o).bs\n",
    "\n",
    "# export\n",
    "class BD(D):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "        self.bs=list(self.values())[0].bs\n",
    "        \n",
    "    def __radd__(self,o): return self if isinstance(o,int) else self.__add__(o) \n",
    "    def __add__(self,o):\n",
    "        return BD({k:TensorBatch.vstack((self[k],o[k])) for k in self})\n",
    "    \n",
    "    def __getitem__(self,o):\n",
    "        if is_listy(o) or isinstance(o,(TensorBatch,int,Tensor)): \n",
    "            return type(self)({k:self[k].get(o) for k in self})\n",
    "        return super().__getitem__(o)\n",
    "\n",
    "    @classmethod\n",
    "    def merge(cls,*ds,**kwargs): return cls(merge(*ds),**kwargs)\n",
    "    @delegates(pd.DataFrame)\n",
    "    def pandas(self,mu=False,relative_shape=False,jupyter_nrows=None,**kwargs):\n",
    "        \"Turns a `BD` into a pandas Dataframe optionally showing `mu` of values.\"\n",
    "        if jupyter_nrows is not None: pd.set_option('display.max_rows', jupyter_nrows)\n",
    "        return pd.DataFrame(merge(\n",
    "            *tuple(tensor2shape(k,v,relative_shape) for k,v in self.items()),\n",
    "            *(tuple(tensor2mu(k,v) for k,v in self.items()) if mu else ())\n",
    "        ),**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5090d21",
   "metadata": {},
   "source": [
    "> Note: I think that BD should do zero undirected shae correction. I think it would be better for it to validate the shapes have batch dims\n",
    "    that match. But I think that the __init__ should accept a shape_map for a key->single batch shape. I can have a default \n",
    "    key map so it can still be convenient, however this would open up BD to be more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48d0a4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBatch([[1., 2., 3., 4.],\n",
       "        [1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorBatch.vstack((Tensor([[1,2,3,4]]),Tensor([[1,2,3,4]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71465e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorBatch([1]).bs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2077ac96",
   "metadata": {},
   "source": [
    "Ok so the solution was that `BD` itself does not validate or coerce batch sizes.\n",
    "It does not check that they all match.\n",
    "It merely uses the TensorBatch object in all its operations.\n",
    "The TensorBatch object tracks and manages what the batch size is really supposed to be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e20de8-9b95-4a6a-98d3-de36a8d058ed",
   "metadata": {},
   "source": [
    "## Some Important Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39955d92-15ef-40ea-aa65-97ad35e0c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numpy to Tensor Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ecb7588-0bdd-49ee-a09d-5d01db67add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=np.random.randint(0,255,size=(240, 320, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0773340-350a-4e4b-9668-12638a0a5eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.59 ms ± 16.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "img=np.random.randint(0,255,size=(240, 320, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "853b56a2-5906-4628-a006-c14d7a6490a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298 µs ± 8.38 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "deepcopy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02c69b6e-4f20-4925-92b3-eeac7498ddbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 µs ± 8.59 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "TensorBatch(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82df9b01-b99d-45b9-88ff-0be11963d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/fastai/torch_core.py:131: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:203.)\n",
      "  else torch.tensor(x, **kwargs) if isinstance(x, (tuple,list))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 ms ± 1.91 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "TensorBatch([img])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e178f-2dab-4c69-8d85-865f6d0f5295",
   "metadata": {},
   "source": [
    "You will notice that if you wrap a numpy in a list, it completely kills the performance. The solution is to\n",
    "just add a batch dim to the existing array and pass it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b60cea6-4046-452d-a94e-a0e81b5095f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.2 µs ± 1.1 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "TensorBatch(np.expand_dims(img,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a29abd-9f51-4128-95aa-9342056bdc85",
   "metadata": {},
   "source": [
    "In fact we can just test this with python lists..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c23240a4-ef1e-4233-bd9b-38d1a9b37d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.4 µs ± 1.22 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "TensorBatch([[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d4a2445-525d-452b-960e-aaafb819401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr=[[1]*270000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62ba802e-d49b-49c5-b6ec-2b337bfeaa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.8 ms ± 172 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "TensorBatch(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc03634b-fcf9-4142-a09c-736747435a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr=np.array([[1]*270000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c40acfb8-ce68-4ad6-91aa-0048d22ee260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.3 µs ± 1.63 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "TensorBatch(test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d599aa-c2a6-47a4-bb71-b2676f2c2486",
   "metadata": {},
   "source": [
    "This is horrifying just how made of a performance hit this causes... So we will be avoiding python list inputs \n",
    "to Tensors for now on..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd8c1e-8ec3-472b-adc7-d2f39a4667fd",
   "metadata": {},
   "source": [
    "## Testing\n",
    "> Additional utilities for testing anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91d25ab0-a6a9-4c01-912e-cff9bd44346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def test_in(a,b):\n",
    "    \"`test` that `a in b`\"\n",
    "    test(a,b,in_, ' in ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba915d0e-3c7b-4e3f-957f-ad3924f1365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in('o','hello')\n",
    "test_in(3,[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8569888-d828-407c-b20c-2bae8065a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _len_check(a,b): \n",
    "    return len(a)==(len(b) if not isinstance(b,int) else b)\n",
    "\n",
    "def test_len(a,b):\n",
    "    \"`test` that `len(a) == int(b) or len(a) == len(b)`\"\n",
    "    test(a,b,_len_check, ' len == len ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a2355ec-c859-4bb4-b360-03ac677236b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len([1,2,3],3)\n",
    "test_len([1,2,3],[1,2,3])\n",
    "test_len([1,2,3],'123')\n",
    "test_fail(lambda:test_len([1,2,3],'1234'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac3b0e7d-0501-4f45-853c-793a15aa47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _less_than(a,b): return a < b\n",
    "def test_lt(a,b):\n",
    "    \"`test` that `a < b`\"\n",
    "    test(a,b,_less_than, ' a < b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1f49538-4605-4f7a-bef3-50654ede0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lt(4,5)\n",
    "test_fail(lambda:test_lt(5,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d8f6b-7bf5-486b-a5d2-4baf8d1f1eb0",
   "metadata": {},
   "source": [
    "## Basic Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ff16401-674c-4ee1-9d5c-dfe07b053fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def run_tensorboard(port=6006, # The port to run tensorboard on/connect on\n",
    "                    start_tag=None, # Starting regex e.g.: experience_replay/1\n",
    "                    samples_per_plugin=None, # Sampling freq such as  images=0 (keep all)\n",
    "                    extra_args=None, # Any additional arguments in the `--arg value` format\n",
    "                    rm_glob=None # Remove old logs via a parttern e.g.: '*' will remove all files: runs/* \n",
    "                   ):\n",
    "    if rm_glob is not None:\n",
    "        for p in Path('runs').glob(rm_glob): p.delete()\n",
    "    import socket\n",
    "    from tensorboard import notebook\n",
    "    a_socket=socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    cmd=None\n",
    "    if not a_socket.connect_ex(('127.0.0.1',6006)):\n",
    "        notebook.display(port=port,height=1000)\n",
    "    else:\n",
    "        cmd=f'--logdir runs --port {port} --host=0.0.0.0'\n",
    "        if samples_per_plugin is not None: cmd+=f' --samples_per_plugin {samples_per_plugin}'\n",
    "        if start_tag is not None:          cmd+=f' --tag {start_tag}'\n",
    "        if extra_args is not None:         cmd+=f' {extra_args}'\n",
    "        notebook.start(cmd)\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "010802a9-441e-4916-8c54-705969e5060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "SHOW_TENSOR_BOARD=False\n",
    "if not os.environ.get(\"IN_TEST\", None) and SHOW_TENSOR_BOARD:\n",
    "    run_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e579231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea76e19d-667a-4235-a988-231857dc87de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
