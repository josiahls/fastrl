{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a8a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61569eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d15935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os,warnings,typing\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.basics import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "# Local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a02bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782bc163",
   "metadata": {},
   "source": [
    "# Core\n",
    "> Core libs for fastrl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef8d62-4f3f-482d-9052-2cba2c37b8e8",
   "metadata": {},
   "source": [
    "## Primitives\n",
    "> `StepTypes` are generated by environments and used by RL models for training / execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48520401-7c7f-48f6-b7ab-fd1aa89abe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _fmt_fld(t:typing.Tuple[str,type],namedtuple):\n",
    "    default_v = ''\n",
    "    if t[0] in namedtuple._field_defaults:\n",
    "        default_v = f' = `{namedtuple._field_defaults[t[0]]}`'\n",
    "    return ' - **%s**:`%s` '%t+default_v+getattr(namedtuple,t[0]).__doc__\n",
    "\n",
    "def add_namedtuple_doc(\n",
    "    t:typing.NamedTuple, # Primary tuple to get docs from\n",
    "    doc:str, # Primary doc for the overall tuple, where the docs for individual fields will be concated.\n",
    "    **fields_docs:dict # Field names with associated docs to be attached in the format: field_a='some documentation'\n",
    "):\n",
    "    \"Add docs to `t` from `doc` along with individual doc fields `fields_docs`\"\n",
    "    if not hasattr(t,'__base_doc__'): t.__base_doc__ = doc\n",
    "    for k,v in fields_docs.items(): getattr(t,k).__doc__ = v\n",
    "    # TODO: can we add optional default fields also?\n",
    "    flds = L(t.__annotations__.items()).map(_fmt_fld,namedtuple=t)\n",
    "    \n",
    "    s = 'Parameters:\\n'+'\\n'.join(flds)\n",
    "    t.__doc__ = doc + '\\n\\n' + s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58eb6165-9b70-47b5-b302-9049a3c1cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SimpleStep(typing.NamedTuple):\n",
    "    state:       torch.FloatTensor=torch.FloatTensor([0])\n",
    "    action:      torch.FloatTensor=torch.FloatTensor([0])\n",
    "    next_state:  torch.FloatTensor=torch.FloatTensor([0])\n",
    "    terminated:  torch.BoolTensor=torch.BoolTensor([1])\n",
    "    truncated:   torch.BoolTensor=torch.BoolTensor([1])\n",
    "    reward:      torch.FloatTensor=torch.LongTensor([0])\n",
    "    total_reward:torch.FloatTensor=torch.FloatTensor([0])\n",
    "    env_id:      torch.LongTensor=torch.LongTensor([0])\n",
    "    proc_id:     torch.LongTensor=torch.LongTensor([0])\n",
    "    step_n:      torch.LongTensor=torch.LongTensor([0])\n",
    "    episode_n:   torch.LongTensor=torch.LongTensor([0])\n",
    "    image:       torch.FloatTensor=torch.FloatTensor([0])\n",
    "    \n",
    "    def clone(self):\n",
    "        return self.__class__(\n",
    "            **{fld:getattr(self,fld).clone() for fld in self.__class__._fields}\n",
    "        )\n",
    "    \n",
    "    def detach(self):\n",
    "        return self.__class__(\n",
    "            **{fld:getattr(self,fld).detach() for fld in self.__class__._fields}\n",
    "        )\n",
    "    \n",
    "    def device(self,device='cpu'):\n",
    "        return self.__class__(\n",
    "            **{fld:getattr(self,fld).to(device=device) for fld in self.__class__._fields}\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def random(cls,seed=None,**flds):\n",
    "        _flds,_annos = cls._fields,cls.__annotations__\n",
    "\n",
    "        def _random_annos(anno):\n",
    "            t = anno(1)\n",
    "            if anno==torch.BoolTensor: t.random_(2) \n",
    "            else:                      t.random_(100)\n",
    "            return t\n",
    "\n",
    "        return cls(\n",
    "            *(flds.get(\n",
    "                f,_random_annos(_annos[f])\n",
    "            ) for f in _flds)\n",
    "        )\n",
    "\n",
    "add_namedtuple_doc(\n",
    "    SimpleStep,\n",
    "    'Represents a single step in an environment.',\n",
    "    state = 'Both the initial state of the environment and the previous state.',\n",
    "    next_state = 'Both the next state, and the last state in the environment',\n",
    "    terminated = \"\"\"Represents an ending condition for an environment such as reaching a goal or 'living long enough' as \n",
    "                    described by the MDP.\n",
    "                    Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155\"\"\",\n",
    "    truncated = \"\"\"Represents an ending condition for an environment that can be seen as an out of bounds condition either\n",
    "                   literally going out of bounds, breaking rules, or exceeding the timelimit allowed by the MDP.\n",
    "                   Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155'\"\"\",\n",
    "    reward = 'The single reward for this step.',\n",
    "    total_reward = 'The total accumulated reward for this episode up to this step.',\n",
    "    action = 'The action that was taken to transition from `state` to `next_state`',\n",
    "    env_id = 'The environment this step came from (useful for debugging)',\n",
    "    proc_id = 'The process this step came from (useful for debugging)',\n",
    "    step_n = 'The step number in a given episode.',\n",
    "    episode_n = 'The episode this environment is currently running through.',\n",
    "    image = \"\"\"Intended for display and logging only. If the intention is to use images for training an\n",
    "               agent, then use a env wrapper instead.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97a6c520-bbc1-4b19-9217-b45fd0e02a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### SimpleStep\n",
       "\n",
       ">      SimpleStep (state:torch.FloatTensor=tensor([0.]),\n",
       ">                  action:torch.FloatTensor=tensor([0.]),\n",
       ">                  next_state:torch.FloatTensor=tensor([0.]),\n",
       ">                  terminated:torch.BoolTensor=tensor([True]),\n",
       ">                  truncated:torch.BoolTensor=tensor([True]),\n",
       ">                  reward:torch.FloatTensor=tensor([0]),\n",
       ">                  total_reward:torch.FloatTensor=tensor([0.]),\n",
       ">                  env_id:torch.LongTensor=tensor([0]),\n",
       ">                  proc_id:torch.LongTensor=tensor([0]),\n",
       ">                  step_n:torch.LongTensor=tensor([0]),\n",
       ">                  episode_n:torch.LongTensor=tensor([0]),\n",
       ">                  image:torch.FloatTensor=tensor([0.]))\n",
       "\n",
       "Represents a single step in an environment.\n",
       "\n",
       "Parameters:\n",
       " - **state**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`Both the initial state of the environment and the previous state.\n",
       " - **action**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`The action that was taken to transition from `state` to `next_state`\n",
       " - **next_state**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`Both the next state, and the last state in the environment\n",
       " - **terminated**:`<class 'torch.BoolTensor'>`  = `tensor([True])`Represents an ending condition for an environment such as reaching a goal or 'living long enough' as \n",
       "                    described by the MDP.\n",
       "                    Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155\n",
       " - **truncated**:`<class 'torch.BoolTensor'>`  = `tensor([True])`Represents an ending condition for an environment that can be seen as an out of bounds condition either\n",
       "                   literally going out of bounds, breaking rules, or exceeding the timelimit allowed by the MDP.\n",
       "                   Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155'\n",
       " - **reward**:`<class 'torch.FloatTensor'>`  = `tensor([0])`The single reward for this step.\n",
       " - **total_reward**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`The total accumulated reward for this episode up to this step.\n",
       " - **env_id**:`<class 'torch.LongTensor'>`  = `tensor([0])`The environment this step came from (useful for debugging)\n",
       " - **proc_id**:`<class 'torch.LongTensor'>`  = `tensor([0])`The process this step came from (useful for debugging)\n",
       " - **step_n**:`<class 'torch.LongTensor'>`  = `tensor([0])`The step number in a given episode.\n",
       " - **episode_n**:`<class 'torch.LongTensor'>`  = `tensor([0])`The episode this environment is currently running through.\n",
       " - **image**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`Intended for display and logging only. If the intention is to use images for training an\n",
       "               agent, then use a env wrapper instead."
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SimpleStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ac338-ef2c-448e-bfdd-ff58cf001023",
   "metadata": {},
   "source": [
    "Now we can generate a couple to send their a pytorch data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cffbd42d-ada9-450e-8fd6-df58c25acc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleStep(state=tensor([0., 0.]), action=tensor([39.]), next_state=tensor([33.]), terminated=tensor([False]), truncated=tensor([True]), reward=tensor([79.]), total_reward=tensor([27.]), env_id=tensor([3]), proc_id=tensor([97]), step_n=tensor([83]), episode_n=tensor([1]), image=tensor([66.]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "SimpleStep.random(state=torch.FloatTensor(2).fill_(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edbe48ea-53d7-434d-8785-e71cf594b5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleStep(state=tensor([0., 0.]), action=tensor([99.]), next_state=tensor([78.]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([68.]), total_reward=tensor([94.]), env_id=tensor([33]), proc_id=tensor([26]), step_n=tensor([19]), episode_n=tensor([91]), image=tensor([54.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleStep.random(state=torch.FloatTensor(2).fill_(0)).clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed64a604-8997-415c-935b-25fccf519c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleStep(state=tensor([[44.]]), action=tensor([[39.]]), next_state=tensor([[33.]]), terminated=tensor([[False]]), truncated=tensor([[True]]), reward=tensor([[79.]]), total_reward=tensor([[27.]]), env_id=tensor([[3]]), proc_id=tensor([[97]]), step_n=tensor([[83]]), episode_n=tensor([[1]]), image=tensor([[66.]])), SimpleStep(state=tensor([[56.]]), action=tensor([[99.]]), next_state=tensor([[78.]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[68.]]), total_reward=tensor([[94.]]), env_id=tensor([[33]]), proc_id=tensor([[26]]), step_n=tensor([[19]]), episode_n=tensor([[91]]), image=tensor([[54.]])), SimpleStep(state=tensor([[24.]]), action=tensor([[41.]]), next_state=tensor([[69.]]), terminated=tensor([[True]]), truncated=tensor([[True]]), reward=tensor([[80.]]), total_reward=tensor([[81.]]), env_id=tensor([[12]]), proc_id=tensor([[63]]), step_n=tensor([[60]]), episode_n=tensor([[95]]), image=tensor([[85.]]))]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "import torchdata.datapipes as dp\n",
    "\n",
    "def seed_worker(worker_id): torch.manual_seed(0)\n",
    "def random_step_generator(): \n",
    "    while True: yield SimpleStep.random()\n",
    "    \n",
    "\n",
    "pipe = dp.iter.IterableWrapper(random_step_generator(),deepcopy=False)\n",
    "pipe = pipe.batch(batch_size=3)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "dl = DataLoader2(pipe,num_workers=2,worker_init_fn=seed_worker)\n",
    "\n",
    "for o in dl:\n",
    "    print(o)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "637b5235-08c4-4492-acda-9e484afb041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "StepType = (SimpleStep,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd8c1e-8ec3-472b-adc7-d2f39a4667fd",
   "metadata": {},
   "source": [
    "## Testing\n",
    "> Additional utilities for testing anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91d25ab0-a6a9-4c01-912e-cff9bd44346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def test_in(a,b):\n",
    "    \"`test` that `a in b`\"\n",
    "    test(a,b,in_, ' in ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba915d0e-3c7b-4e3f-957f-ad3924f1365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in('o','hello')\n",
    "test_in(3,[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8569888-d828-407c-b20c-2bae8065a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _len_check(a,b): \n",
    "    return len(a)==(len(b) if not isinstance(b,int) else b)\n",
    "\n",
    "def test_len(a,b,meta_info=''):\n",
    "    \"`test` that `len(a) == int(b) or len(a) == len(b)`\"\n",
    "    test(a,b,_len_check, f' len == len {meta_info}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a2355ec-c859-4bb4-b360-03ac677236b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len([1,2,3],3)\n",
    "test_len([1,2,3],[1,2,3])\n",
    "test_len([1,2,3],'123')\n",
    "test_fail(lambda:test_len([1,2,3],'1234'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac3b0e7d-0501-4f45-853c-793a15aa47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _less_than(a,b): return a < b\n",
    "def test_lt(a,b):\n",
    "    \"`test` that `a < b`\"\n",
    "    test(a,b,_less_than, ' a < b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1f49538-4605-4f7a-bef3-50654ede0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lt(4,5)\n",
    "test_fail(lambda:test_lt(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e579231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea76e19d-667a-4235-a988-231857dc87de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
