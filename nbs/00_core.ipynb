{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61569eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastrl.test_utils import initialize_notebook\n",
    "initialize_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d15935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import typing\n",
    "# Third party libs\n",
    "from fastcore.test import test,test_fail \n",
    "from fastcore.basics import in_\n",
    "import torch\n",
    "# Local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a02bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5004c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "782bc163",
   "metadata": {},
   "source": [
    "# Core\n",
    "> Core objects and functions for fastrl and reinforcement learning in general"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afef8d62-4f3f-482d-9052-2cba2c37b8e8",
   "metadata": {},
   "source": [
    "## Primitives\n",
    "> `StepTypes` are generated by environments and used by RL models for training / execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48520401-7c7f-48f6-b7ab-fd1aa89abe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _fmt_fld(name,t:typing.Tuple[str,type],namedtuple):\n",
    "    default_v = ''\n",
    "    if name in namedtuple._field_defaults:\n",
    "        default_v = f' = `{namedtuple._field_defaults[name]}`'\n",
    "    return ' - **%s**:`%s` '%(name,t)+default_v+getattr(namedtuple,name).__doc__\n",
    "\n",
    "def add_namedtuple_doc(\n",
    "    t:typing.NamedTuple, # Primary tuple to get docs from\n",
    "    doc:str, # Primary doc for the overall tuple, where the docs for individual fields will be concated.\n",
    "    **fields_docs:dict # Field names with associated docs to be attached in the format: field_a='some documentation'\n",
    "):\n",
    "    \"Add docs to `t` from `doc` along with individual doc fields `fields_docs`\"\n",
    "    if not hasattr(t,'__base_doc__'): t.__base_doc__ = doc\n",
    "    for k,v in fields_docs.items(): getattr(t,k).__doc__ = v\n",
    "    # TODO: can we add optional default fields also?\n",
    "    flds = []\n",
    "    for k,v in t.__annotations__.items():\n",
    "        flds.append(_fmt_fld(k,v,t))\n",
    "    \n",
    "    s = 'Parameters:\\n\\n'+'\\n'.join(flds)\n",
    "    t.__doc__ = doc + '\\n\\n' + s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58eb6165-9b70-47b5-b302-9049a3c1cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SimpleStep(typing.NamedTuple):\n",
    "    state:       torch.FloatTensor=torch.FloatTensor([0])\n",
    "    action:      torch.FloatTensor=torch.FloatTensor([0])\n",
    "    next_state:  torch.FloatTensor=torch.FloatTensor([0])\n",
    "    terminated:  torch.BoolTensor=torch.BoolTensor([1])\n",
    "    truncated:   torch.BoolTensor=torch.BoolTensor([1])\n",
    "    reward:      torch.FloatTensor=torch.LongTensor([0])\n",
    "    total_reward:torch.FloatTensor=torch.FloatTensor([0])\n",
    "    env_id:      torch.LongTensor=torch.LongTensor([0])\n",
    "    proc_id:     torch.LongTensor=torch.LongTensor([0])\n",
    "    step_n:      torch.LongTensor=torch.LongTensor([0])\n",
    "    episode_n:   torch.LongTensor=torch.LongTensor([0])\n",
    "    image:       torch.FloatTensor=torch.FloatTensor([0])\n",
    "    \n",
    "    def clone(self):\n",
    "        return self.__class__(\n",
    "            **{fld:getattr(self,fld).clone() for fld in self.__class__._fields}\n",
    "        )\n",
    "    \n",
    "    def detach(self):\n",
    "        return self.__class__(\n",
    "            **{fld:getattr(self,fld).detach() for fld in self.__class__._fields}\n",
    "        )\n",
    "    \n",
    "    def device(self,device='cpu'):\n",
    "        return self.__class__(\n",
    "            **{fld:getattr(self,fld).to(device=device) for fld in self.__class__._fields}\n",
    "        )\n",
    "\n",
    "    def to(self,*args,**kwargs):\n",
    "        return self.__class__(\n",
    "            **{fld:getattr(self,fld).to(*args,**kwargs) for fld in self.__class__._fields}\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def random(cls,seed=None,**flds):\n",
    "        _flds,_annos = cls._fields,cls.__annotations__\n",
    "\n",
    "        def _random_annos(anno):\n",
    "            t = anno(1)\n",
    "            if anno==torch.BoolTensor: t.random_(2) \n",
    "            else:                      t.random_(100)\n",
    "            return t\n",
    "\n",
    "        return cls(\n",
    "            *(flds.get(\n",
    "                f,_random_annos(_annos[f])\n",
    "            ) for f in _flds)\n",
    "        )\n",
    "\n",
    "add_namedtuple_doc(\n",
    "    SimpleStep,\n",
    "    'Represents a single step in an environment.',\n",
    "    state = 'Both the initial state of the environment and the previous state.',\n",
    "    next_state = 'Both the next state, and the last state in the environment',\n",
    "    terminated = \"\"\"Represents an ending condition for an environment such as reaching a goal or 'living long enough' as \n",
    "                    described by the MDP.\n",
    "                    Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155\"\"\",\n",
    "    truncated = \"\"\"Represents an ending condition for an environment that can be seen as an out of bounds condition either\n",
    "                   literally going out of bounds, breaking rules, or exceeding the timelimit allowed by the MDP.\n",
    "                   Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155'\"\"\",\n",
    "    reward = 'The single reward for this step.',\n",
    "    total_reward = 'The total accumulated reward for this episode up to this step.',\n",
    "    action = 'The action that was taken to transition from `state` to `next_state`',\n",
    "    env_id = 'The environment this step came from (useful for debugging)',\n",
    "    proc_id = 'The process this step came from (useful for debugging)',\n",
    "    step_n = 'The step number in a given episode.',\n",
    "    episode_n = 'The episode this environment is currently running through.',\n",
    "    image = \"\"\"Intended for display and logging only. If the intention is to use images for training an\n",
    "               agent, then use a env wrapper instead.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97a6c520-bbc1-4b19-9217-b45fd0e02a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### SimpleStep\n",
       "\n",
       ">      SimpleStep (state:torch.FloatTensor=tensor([0.]),\n",
       ">                  action:torch.FloatTensor=tensor([0.]),\n",
       ">                  next_state:torch.FloatTensor=tensor([0.]),\n",
       ">                  terminated:torch.BoolTensor=tensor([True]),\n",
       ">                  truncated:torch.BoolTensor=tensor([True]),\n",
       ">                  reward:torch.FloatTensor=tensor([0]),\n",
       ">                  total_reward:torch.FloatTensor=tensor([0.]),\n",
       ">                  env_id:torch.LongTensor=tensor([0]),\n",
       ">                  proc_id:torch.LongTensor=tensor([0]),\n",
       ">                  step_n:torch.LongTensor=tensor([0]),\n",
       ">                  episode_n:torch.LongTensor=tensor([0]),\n",
       ">                  image:torch.FloatTensor=tensor([0.]))\n",
       "\n",
       "Represents a single step in an environment.\n",
       "\n",
       "Parameters:\n",
       "\n",
       " - **state**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`Both the initial state of the environment and the previous state.\n",
       " - **action**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`The action that was taken to transition from `state` to `next_state`\n",
       " - **next_state**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`Both the next state, and the last state in the environment\n",
       " - **terminated**:`<class 'torch.BoolTensor'>`  = `tensor([True])`Represents an ending condition for an environment such as reaching a goal or 'living long enough' as \n",
       "                    described by the MDP.\n",
       "                    Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155\n",
       " - **truncated**:`<class 'torch.BoolTensor'>`  = `tensor([True])`Represents an ending condition for an environment that can be seen as an out of bounds condition either\n",
       "                   literally going out of bounds, breaking rules, or exceeding the timelimit allowed by the MDP.\n",
       "                   Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155'\n",
       " - **reward**:`<class 'torch.FloatTensor'>`  = `tensor([0])`The single reward for this step.\n",
       " - **total_reward**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`The total accumulated reward for this episode up to this step.\n",
       " - **env_id**:`<class 'torch.LongTensor'>`  = `tensor([0])`The environment this step came from (useful for debugging)\n",
       " - **proc_id**:`<class 'torch.LongTensor'>`  = `tensor([0])`The process this step came from (useful for debugging)\n",
       " - **step_n**:`<class 'torch.LongTensor'>`  = `tensor([0])`The step number in a given episode.\n",
       " - **episode_n**:`<class 'torch.LongTensor'>`  = `tensor([0])`The episode this environment is currently running through.\n",
       " - **image**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`Intended for display and logging only. If the intention is to use images for training an\n",
       "               agent, then use a env wrapper instead."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### SimpleStep\n",
       "\n",
       ">      SimpleStep (state:torch.FloatTensor=tensor([0.]),\n",
       ">                  action:torch.FloatTensor=tensor([0.]),\n",
       ">                  next_state:torch.FloatTensor=tensor([0.]),\n",
       ">                  terminated:torch.BoolTensor=tensor([True]),\n",
       ">                  truncated:torch.BoolTensor=tensor([True]),\n",
       ">                  reward:torch.FloatTensor=tensor([0]),\n",
       ">                  total_reward:torch.FloatTensor=tensor([0.]),\n",
       ">                  env_id:torch.LongTensor=tensor([0]),\n",
       ">                  proc_id:torch.LongTensor=tensor([0]),\n",
       ">                  step_n:torch.LongTensor=tensor([0]),\n",
       ">                  episode_n:torch.LongTensor=tensor([0]),\n",
       ">                  image:torch.FloatTensor=tensor([0.]))\n",
       "\n",
       "Represents a single step in an environment.\n",
       "\n",
       "Parameters:\n",
       "\n",
       " - **state**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`Both the initial state of the environment and the previous state.\n",
       " - **action**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`The action that was taken to transition from `state` to `next_state`\n",
       " - **next_state**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`Both the next state, and the last state in the environment\n",
       " - **terminated**:`<class 'torch.BoolTensor'>`  = `tensor([True])`Represents an ending condition for an environment such as reaching a goal or 'living long enough' as \n",
       "                    described by the MDP.\n",
       "                    Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155\n",
       " - **truncated**:`<class 'torch.BoolTensor'>`  = `tensor([True])`Represents an ending condition for an environment that can be seen as an out of bounds condition either\n",
       "                   literally going out of bounds, breaking rules, or exceeding the timelimit allowed by the MDP.\n",
       "                   Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155'\n",
       " - **reward**:`<class 'torch.FloatTensor'>`  = `tensor([0])`The single reward for this step.\n",
       " - **total_reward**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`The total accumulated reward for this episode up to this step.\n",
       " - **env_id**:`<class 'torch.LongTensor'>`  = `tensor([0])`The environment this step came from (useful for debugging)\n",
       " - **proc_id**:`<class 'torch.LongTensor'>`  = `tensor([0])`The process this step came from (useful for debugging)\n",
       " - **step_n**:`<class 'torch.LongTensor'>`  = `tensor([0])`The step number in a given episode.\n",
       " - **episode_n**:`<class 'torch.LongTensor'>`  = `tensor([0])`The episode this environment is currently running through.\n",
       " - **image**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`Intended for display and logging only. If the intention is to use images for training an\n",
       "               agent, then use a env wrapper instead."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SimpleStep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f7ac338-ef2c-448e-bfdd-ff58cf001023",
   "metadata": {},
   "source": [
    "Now we can generate a couple to send their a pytorch data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cffbd42d-ada9-450e-8fd6-df58c25acc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleStep(state=tensor([0., 0.]), action=tensor([39.]), next_state=tensor([33.]), terminated=tensor([False]), truncated=tensor([True]), reward=tensor([79.]), total_reward=tensor([27.]), env_id=tensor([3]), proc_id=tensor([97]), step_n=tensor([83]), episode_n=tensor([1]), image=tensor([66.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "SimpleStep.random(state=torch.FloatTensor(2).fill_(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edbe48ea-53d7-434d-8785-e71cf594b5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleStep(state=tensor([0., 0.]), action=tensor([99.]), next_state=tensor([78.]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([68.]), total_reward=tensor([94.]), env_id=tensor([33]), proc_id=tensor([26]), step_n=tensor([19]), episode_n=tensor([91]), image=tensor([54.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleStep.random(state=torch.FloatTensor(2).fill_(0)).clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ae69b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata.dataloader2.dataloader2 import DataLoader2\n",
    "from torchdata.dataloader2.reading_service import MultiProcessingReadingService\n",
    "from torchdata.dataloader2.graph import traverse_dps\n",
    "import torchdata.datapipes as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed64a604-8997-415c-935b-25fccf519c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleStep(state=tensor([18.]), action=tensor([44.]), next_state=tensor([61.]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([33.]), total_reward=tensor([0.]), env_id=tensor([23]), proc_id=tensor([7]), step_n=tensor([95]), episode_n=tensor([24]), image=tensor([46.])), SimpleStep(state=tensor([83.]), action=tensor([45.]), next_state=tensor([68.]), terminated=tensor([True]), truncated=tensor([False]), reward=tensor([33.]), total_reward=tensor([6.]), env_id=tensor([56]), proc_id=tensor([47]), step_n=tensor([14]), episode_n=tensor([66]), image=tensor([28.])), SimpleStep(state=tensor([67.]), action=tensor([6.]), next_state=tensor([60.]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([86.]), total_reward=tensor([80.]), env_id=tensor([54]), proc_id=tensor([53]), step_n=tensor([82]), episode_n=tensor([62]), image=tensor([23.]))]\n"
     ]
    }
   ],
   "source": [
    "def seed_worker(pipe,worker_id): \n",
    "    torch.manual_seed(0)\n",
    "    return pipe\n",
    "class RandomStepMaker():\n",
    "    def __iter__(self):\n",
    "        while True: yield SimpleStep.random()\n",
    "    \n",
    "\n",
    "pipe = dp.iter.IterableWrapper(RandomStepMaker(),deepcopy=False)\n",
    "pipe = pipe.batch(batch_size=3)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "dl = DataLoader2(\n",
    "    pipe,\n",
    "    reading_service=MultiProcessingReadingService(num_workers=2,worker_init_fn=seed_worker)\n",
    ")\n",
    "\n",
    "for o in dl:\n",
    "    print(o)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637b5235-08c4-4492-acda-9e484afb041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "StepType = (SimpleStep,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d6571a7-6295-4cf1-8a3e-6c5e763b387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Record(typing.NamedTuple):\n",
    "    name:str\n",
    "    value:typing.Any"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50cd8c1e-8ec3-472b-adc7-d2f39a4667fd",
   "metadata": {},
   "source": [
    "## Testing\n",
    "> Additional utilities for testing anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91d25ab0-a6a9-4c01-912e-cff9bd44346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def test_in(a,b):\n",
    "    \"`test` that `a in b`\"\n",
    "    test(a,b,in_, ' in ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba915d0e-3c7b-4e3f-957f-ad3924f1365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in('o','hello')\n",
    "test_in(3,[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01501c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def test_out(a,b):\n",
    "    \"`test` that `a is not in b` or `a is outside b`\"\n",
    "    test_fail(test,args=(a,b,in_), msg=f'{a} not in {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7312300",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out('z','hello')\n",
    "test_out(5,[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8569888-d828-407c-b20c-2bae8065a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _len_check(a,b): \n",
    "    return len(a)==(len(b) if not isinstance(b,int) else b)\n",
    "\n",
    "def test_len(a,b,meta_info=''):\n",
    "    \"`test` that `len(a) == int(b) or len(a) == len(b)`\"\n",
    "    test(a,b,_len_check, f' len == len {meta_info}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a2355ec-c859-4bb4-b360-03ac677236b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len([1,2,3],3)\n",
    "test_len([1,2,3],[1,2,3])\n",
    "test_len([1,2,3],'123')\n",
    "test_fail(lambda:test_len([1,2,3],'1234'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac3b0e7d-0501-4f45-853c-793a15aa47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _less_than(a,b): return a < b\n",
    "def test_lt(a,b):\n",
    "    \"`test` that `a < b`\"\n",
    "    test(a,b,_less_than, ' a < b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1f49538-4605-4f7a-bef3-50654ede0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lt(4,5)\n",
    "test_fail(lambda:test_lt(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e579231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/nbdev/export.py:54: UserWarning: Notebook '/home/fastrl_user/fastrl/nbs/07_Agents/02_Continuous/12u_agents.ppo.ipynb' uses `#|export` without `#|default_exp` cell.\n",
      "Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\n",
      "See https://nbdev.fast.ai/getting_started.html for more information.\n",
      "  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\"\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea76e19d-667a-4235-a988-231857dc87de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
