{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp envs.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "import typing\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "# Local modules\n",
    "from fastrl.fastai.data.pipes.core import *\n",
    "from fastrl.fastai.data.load import *\n",
    "from fastrl.fastai.data.block import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Envs Core\n",
    "> Core Fastrl API for working with envs and plugging them into the larger ecosystem. These include:\n",
    "`Step`, generic DataPipes for env running,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50976e54-beba-4870-8812-970335b8a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Flattener(dp.iter.IterDataPipe):\n",
    "    \"Takes nested lists and unwraps them yielding 1 element at a time.\"\n",
    "    def __init__(self, source_datapipe) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for list_like_element in self.source_datapipe:\n",
    "            if not is_listy(list_like_element):\n",
    "                raise Exception(f'Expected listy object got {type(list_like_element)}\\n{list_like_element}')\n",
    "            yield from (o for o in list_like_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d29628-6f35-4554-8d81-4c869c9e2af0",
   "metadata": {},
   "source": [
    "Below we have `elements` that is a list of 3 lists. We want to flatten these into a single ordered list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88f3323-6c83-4d6f-a2e1-efbb491eceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = [list(range(10)),list(range(10,15)),list(range(15,20))]\n",
    "pipe = dp.iter.IterableWrapper(elements)\n",
    "pipe = Flattener(pipe)\n",
    "test_eq(\n",
    "    list(pipe),\n",
    "    list(range(10))+list(range(10,15))+list(range(15,20))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7b6f82c6-91b2-47ae-b3d7-9fc9f4f2ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _fmt_fld(t:typing.Tuple[str,type],namedtuple):\n",
    "    default_v = ''\n",
    "    if t[0] in namedtuple._field_defaults:\n",
    "        default_v = f' = `{namedtuple._field_defaults[t[0]]}`'\n",
    "    return ' - **%s**:`%s` '%t+default_v+getattr(namedtuple,t[0]).__doc__\n",
    "\n",
    "def add_namedtuple_doc(\n",
    "    t:typing.NamedTuple, # Primary tuple to get docs from\n",
    "    doc:str, # Primary doc for the overall tuple, where the docs for individual fields will be concated.\n",
    "    **fields_docs:dict # Field names with associated docs to be attached in the format: field_a='some documentation'\n",
    "):\n",
    "    \"Add docs to `t` from `doc` along with individual doc fields `fields_docs`\"\n",
    "    if not hasattr(t,'__base_doc__'): t.__base_doc__ = doc\n",
    "    for k,v in fields_docs.items(): getattr(t,k).__doc__ = v\n",
    "    # TODO: can we add optional default fields also?\n",
    "    flds = L(t.__annotations__.items()).map(_fmt_fld,namedtuple=t)\n",
    "    \n",
    "    s = 'Parameters:\\n'+'\\n'.join(flds)\n",
    "    t.__doc__ = doc + '\\n\\n' + s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "95707165-9e42-4f10-96f7-6de63bad6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SimpleStep(typing.NamedTuple):\n",
    "    state:       torch.FloatTensor\n",
    "    next_state:  torch.FloatTensor\n",
    "    action:      torch.FloatTensor\n",
    "    done:        torch.BoolTensor=torch.BoolTensor([1])\n",
    "    reward:      torch.FloatTensor=torch.LongTensor([0])\n",
    "    total_reward:torch.FloatTensor=torch.FloatTensor([0])\n",
    "    env_id:      torch.LongTensor=torch.LongTensor([0])\n",
    "    proc_id:     torch.LongTensor=torch.LongTensor([0])\n",
    "    step_n:      torch.LongTensor=torch.LongTensor([0])\n",
    "    episode_n:   torch.LongTensor=torch.LongTensor([0])\n",
    "    \n",
    "    @classmethod\n",
    "    def random(cls,seed=None,**flds):\n",
    "        _flds,_annos = cls._fields,cls.__annotations__\n",
    "\n",
    "        def _random_annos(anno):\n",
    "            t = anno(1)\n",
    "            if anno==torch.BoolTensor: t.random_(2) \n",
    "            else:                      t.random_(100)\n",
    "            return t\n",
    "\n",
    "        return cls(\n",
    "            *(flds.get(\n",
    "                f,_random_annos(_annos[f])\n",
    "            ) for f in _flds)\n",
    "        )\n",
    "\n",
    "add_namedtuple_doc(\n",
    "    SimpleStep,\n",
    "    'Represents a single step in an environment.',\n",
    "    state = 'Both the initial state of the environment and the previous state.',\n",
    "    next_state = 'Both the next state, and the last state in the environment',\n",
    "    done = 'Whether this step represents the end of an episode.',\n",
    "    reward = 'The single reward for this step.',\n",
    "    total_reward = 'The total accumulated reward for this episode up to this step.',\n",
    "    action = 'The action that was taken to transition from `state` to `next_state`',\n",
    "    env_id = 'The environment this step came from (useful for debugging)',\n",
    "    proc_id = 'The process this step came from (useful for debugging)',\n",
    "    step_n = 'The step number in a given episode.',\n",
    "    episode_n = 'The episode this environment is currently running through.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b1c3eef1-4727-43c1-97d2-66d68f6d7567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"SimpleStep\" class=\"doc_header\"><code>class</code> <code>SimpleStep</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>SimpleStep</code>(**`state`**:`FloatTensor`, **`next_state`**:`FloatTensor`, **`done`**:`BoolTensor`, **`action`**:`FloatTensor`, **`reward`**:`FloatTensor`=*`tensor([0])`*, **`total_reward`**:`FloatTensor`=*`tensor([0.])`*, **`env_id`**:`LongTensor`=*`tensor([0])`*, **`proc_id`**:`LongTensor`=*`tensor([0])`*, **`step_n`**:`LongTensor`=*`tensor([0])`*, **`episode_n`**:`LongTensor`=*`tensor([0])`*) :: `tuple`\n",
       "\n",
       "Represents a single step in an environment.\n",
       "\n",
       "Parameters:\n",
       " - **state**:`<class 'torch.FloatTensor'>` Both the initial state of the environment and the previous state.\n",
       " - **next_state**:`<class 'torch.FloatTensor'>` Both the next state, and the last state in the environment\n",
       " - **done**:`<class 'torch.BoolTensor'>` Whether this step represents the end of an episode.\n",
       " - **action**:`<class 'torch.FloatTensor'>` The action that was taken to transition from `state` to `next_state`\n",
       " - **reward**:`<class 'torch.FloatTensor'>`  = `tensor([0])`The single reward for this step.\n",
       " - **total_reward**:`<class 'torch.FloatTensor'>`  = `tensor([0.])`The total accumulated reward for this episode up to this step.\n",
       " - **env_id**:`<class 'torch.LongTensor'>`  = `tensor([0])`The environment this step came from (useful for debugging)\n",
       " - **proc_id**:`<class 'torch.LongTensor'>`  = `tensor([0])`The process this step came from (useful for debugging)\n",
       " - **step_n**:`<class 'torch.LongTensor'>`  = `tensor([0])`The step number in a given episode.\n",
       " - **episode_n**:`<class 'torch.LongTensor'>`  = `tensor([0])`The episode this environment is currently running through."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SimpleStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b124ef-03a1-45d0-9273-5e657cbe5f7a",
   "metadata": {},
   "source": [
    "Now we can generate a couple to send their a pytorch data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "807bc665-cce7-4f15-b380-9132e7662c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleStep(state=tensor([0., 0.]), next_state=tensor([39.]), done=tensor([True]), action=tensor([60.]), reward=tensor([63.]), total_reward=tensor([79.]), env_id=tensor([27]), proc_id=tensor([3]), step_n=tensor([97]), episode_n=tensor([83]))"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "SimpleStep.random(state=torch.FloatTensor(2).fill_(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "f26b9aa1-032e-442d-9dd6-af04cf2da3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleStep(state=tensor([1.]), next_state=tensor([66.]), done=tensor([False]), action=tensor([99.]), reward=tensor([78.]), total_reward=tensor([76.]), env_id=tensor([56]), proc_id=tensor([68]), step_n=tensor([94]), episode_n=tensor([33]))"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleStep.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "f9206974-f66d-45f9-9c80-52159720b6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleStep(state=tensor([[44.]]), next_state=tensor([[39.]]), done=tensor([[True]]), action=tensor([[60.]]), reward=tensor([[63.]]), total_reward=tensor([[79.]]), env_id=tensor([[27]]), proc_id=tensor([[3]]), step_n=tensor([[97]]), episode_n=tensor([[83]])), SimpleStep(state=tensor([[1.]]), next_state=tensor([[66.]]), done=tensor([[False]]), action=tensor([[99.]]), reward=tensor([[78.]]), total_reward=tensor([[76.]]), env_id=tensor([[56]]), proc_id=tensor([[68]]), step_n=tensor([[94]]), episode_n=tensor([[33]])), SimpleStep(state=tensor([[26.]]), next_state=tensor([[19.]]), done=tensor([[True]]), action=tensor([[54.]]), reward=tensor([[24.]]), total_reward=tensor([[41.]]), env_id=tensor([[69]]), proc_id=tensor([[69]]), step_n=tensor([[49]]), episode_n=tensor([[80]]))]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "\n",
    "def seed_worker(worker_id): torch.manual_seed(0)\n",
    "def random_step_generator(): \n",
    "    while True: yield SimpleStep.random()\n",
    "    \n",
    "\n",
    "pipe = dp.iter.IterableWrapper(random_step_generator(),deepcopy=False)\n",
    "pipe = pipe.batch(batch_size=3)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "dl = DataLoader2(pipe,num_workers=2,worker_init_fn=seed_worker)\n",
    "\n",
    "for o in dl:\n",
    "    print(o)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8334a1cf-4b5c-496d-8cce-559aaeca7e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
