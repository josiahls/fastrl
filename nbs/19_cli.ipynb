{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "import shutil\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "# Local modules\n",
    "from nbdev.quarto import _nbglob_docs,_sprun,_pre_docs,nbdev_readme,move,proc_nbs\n",
    "from nbdev.test import test_nb,_keep_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8563653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from execnb.nbio import *\n",
    "from execnb.shell import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# CLI\n",
    "> Convenience CLI utils for fastrl projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9670e393-2f79-4e99-969c-18efcb8ec48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def fastrl_make_requirements(\n",
    "    path:Path=None, # The path to a dir with the settings.ini, if none, cwd.\n",
    "    project_file:str='settings.ini', # The file to load for reading the requirements\n",
    "    out_path:Path=None, # The output path (can be relative to `path`)\n",
    "    verbose:bool=False # Output to stdout\n",
    "):\n",
    "    requirement_types = ['','dev_','pip_']\n",
    "    path = ifnone(path, Path.cwd())/project_file\n",
    "\n",
    "    if not path.exists(): raise OSError(f'File {path} does not exist')\n",
    "\n",
    "    out_path = ifnone(out_path, Path('extra'))\n",
    "    out_path = out_path if out_path.is_absolute() else path.parent/out_path\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "    if verbose: print('Outputting to path: ',out_path)\n",
    "    config = Config(path.parent,path.name)\n",
    "\n",
    "    for req in requirement_types:\n",
    "        requirements = config[req+'requirements']\n",
    "        requirements = requirements.replace(' ','\\n')\n",
    "        Path(out_path/(req+'requirements.txt')).write_text(requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66384854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from nbdev.config import *\n",
    "from nbdev.doclinks import *\n",
    "\n",
    "from fastcore.utils import *\n",
    "from fastcore.script import call_parse\n",
    "from fastcore.shutil import rmtree,move,copytree\n",
    "from fastcore.meta import delegates\n",
    "from nbdev.serve import proc_nbs,_proc_file\n",
    "from nbdev import serve_drv\n",
    "from nbdev.quarto import _ensure_quarto\n",
    "from nbdev.quarto import *\n",
    "import nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6575b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "@delegates(nbglob_cli)\n",
    "def proc_nbs(\n",
    "    path:str='', # Path to notebooks\n",
    "    n_workers:int=defaults.cpus,  # Number of workers\n",
    "    force:bool=False,  # Ignore cache and build all\n",
    "    file_glob:str='', # Only include files matching glob\n",
    "    verbose:bool=False, # verbose outputs\n",
    "    one2one:bool=True, # Run 1 notebook per process instance.\n",
    "    **kwargs):\n",
    "    \"Process notebooks in `path` for docs rendering\"\n",
    "    cfg = get_config()\n",
    "    cache = cfg.config_path/'_proc'\n",
    "    path = Path(path or cfg.nbs_path)\n",
    "    files = nbglob(path, func=Path, file_glob=file_glob, **kwargs)\n",
    "    if (path/'_quarto.yml').exists(): files.append(path/'_quarto.yml')\n",
    "\n",
    "    # If settings.ini or filter script newer than cache folder modified, delete cache\n",
    "    chk_mtime = max(cfg.config_file.stat().st_mtime, Path(__file__).stat().st_mtime)\n",
    "    cache.mkdir(parents=True, exist_ok=True)\n",
    "    cache_mtime = cache.stat().st_mtime\n",
    "    if force or (cache.exists and cache_mtime<chk_mtime): rmtree(cache)\n",
    "\n",
    "    files = files.map(_proc_file, mtime=cache_mtime, cache=cache, path=path).filter()\n",
    "    kw = {} if IN_NOTEBOOK else {'method':'spawn'}\n",
    "    if verbose: print('Using n_workers: ',n_workers,'IN_NOTEBOOK: ',IN_NOTEBOOK,kw)\n",
    "    if one2one:\n",
    "        for chunk in chunked(files,chunk_sz=max(n_workers,1)):\n",
    "            parallel(nbdev.serve_drv.main, chunk, n_workers=n_workers, pause=0.01, **kw)\n",
    "    else:\n",
    "        parallel(nbdev.serve_drv.main, files, n_workers=n_workers, pause=0.01, **kw)\n",
    "    if cache.exists(): cache.touch()\n",
    "    return cache\n",
    "\n",
    "def _pre_docs(\n",
    "        path, \n",
    "        n_workers:int=defaults.cpus, \n",
    "        verbose:bool=False,\n",
    "        one2one:bool=True, # Run 1 notebook per process instance.\n",
    "        **kwargs\n",
    "    ):\n",
    "    cfg = get_config()\n",
    "    path = Path(path) if path else cfg.nbs_path\n",
    "    _ensure_quarto()\n",
    "    refresh_quarto_yml()\n",
    "    import nbdev.doclinks\n",
    "    nbdev.doclinks._build_modidx()\n",
    "    nbdev_sidebar.__wrapped__(path=path, **kwargs)\n",
    "    cache = proc_nbs.__wrapped__(path, n_workers=n_workers, verbose=verbose, one2one=one2one)\n",
    "    return cache,cfg,path\n",
    "\n",
    "@call_parse\n",
    "@delegates(_nbglob_docs)\n",
    "def fastrl_nbdev_docs(\n",
    "    path:str=None, # Path to notebooks\n",
    "    n_workers:int=defaults.cpus,  # Number of workers\n",
    "    verbose:bool=False, # verbose outputs\n",
    "    one2one:bool=True, # Run 1 notebook per process instance.\n",
    "    **kwargs):\n",
    "    \"Create Quarto docs and README.md\"\n",
    "    cache,cfg,path = _pre_docs(path, n_workers=n_workers, verbose=verbose, one2one=one2one, **kwargs)\n",
    "    nbdev_readme.__wrapped__(path=path, chk_time=True)\n",
    "    _sprun(f'cd \"{cache}\" && quarto render --no-cache')\n",
    "    shutil.rmtree(cfg.doc_path, ignore_errors=True)\n",
    "    move(cache/cfg.doc_path.name, cfg.config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51096fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "@delegates(nbglob_cli)\n",
    "def fastrl_nbdev_test(\n",
    "    path:str=None,  # A notebook name or glob to test\n",
    "    flags:str='',  # Space separated list of test flags to run that are normally ignored\n",
    "    n_workers:int=None,  # Number of workers\n",
    "    timing:bool=False,  # Time each notebook to see which are slow\n",
    "    do_print:bool=False, # Print start and end of each notebook\n",
    "    pause:float=0.01,  # Pause time (in seconds) between notebooks to avoid race conditions\n",
    "    ignore_fname:str='.notest', # Filename that will result in siblings being ignored\n",
    "    one2one:bool=True, # Run 1 notebook per process instance.\n",
    "    **kwargs):\n",
    "    \"Test in parallel notebooks matching `path`, passing along `flags`\"\n",
    "    skip_flags = get_config().tst_flags.split()\n",
    "    force_flags = flags.split()\n",
    "    files = nbglob(path, as_path=True, **kwargs)\n",
    "    files = [f.absolute() for f in sorted(files) if _keep_file(f, ignore_fname)]\n",
    "    if len(files)==0: return print('No files were eligible for testing')\n",
    "\n",
    "    if n_workers is None: n_workers = 0 if len(files)==1 else min(num_cpus(), 8)\n",
    "    if IN_NOTEBOOK: kw = {'method':'spawn'} if os.name=='nt' else {'method':'forkserver'}\n",
    "    else: kw = {} # {'method':'spawn'}\n",
    "    with working_directory(get_config().nbs_path):\n",
    "        if one2one:\n",
    "            results = []\n",
    "            for chunk in chunked(files,chunk_sz=max(n_workers,1)):\n",
    "                results.extend(parallel(test_nb, chunk, skip_flags=skip_flags, force_flags=force_flags, n_workers=n_workers,\n",
    "                                basepath=get_config().config_path, pause=pause, do_print=do_print, **kw))\n",
    "        else:\n",
    "            results = parallel(test_nb, files, skip_flags=skip_flags, force_flags=force_flags, n_workers=n_workers,\n",
    "                            basepath=get_config().config_path, pause=pause, do_print=do_print, **kw)\n",
    "    passed,times = zip(*results)\n",
    "    if all(passed): print(\"Success.\")\n",
    "    else: \n",
    "        _fence = '='*50\n",
    "        failed = '\\n\\t'.join(f.name for p,f in zip(passed,files) if not p)\n",
    "        sys.stderr.write(f\"\\nnbdev Tests Failed On The Following Notebooks:\\n{_fence}\\n\\t{failed}\\n\")\n",
    "        sys.exit(1)\n",
    "    if timing:\n",
    "        for i,t in sorted(enumerate(times), key=lambda o:o[1], reverse=True): print(f\"{files[i].name}: {int(t)} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval:false\n",
    "# fastrl_nbdev_test(n_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed71a089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
