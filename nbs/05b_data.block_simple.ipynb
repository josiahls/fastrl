{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thousand-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loved-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "#         assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virtual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minimal-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.block_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conscious-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "from time import sleep\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.basics import *\n",
    "from fastai.callback.all import *\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "import torch\n",
    "import gym\n",
    "import numpy as np\n",
    "# Local modules\n",
    "from fastrl.core import *\n",
    "from fastrl.callback.core import *\n",
    "from fastrl.agent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64a592-a692-4b6f-992e-01ace5603d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports\n",
    "import pybulletgym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-network",
   "metadata": {},
   "source": [
    "# Data Block Simple\n",
    "> Stripped down simpler environment execution code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-operator",
   "metadata": {},
   "source": [
    "Development of this was helped by [IterableData documentation on multiple workers](https://github.com/pytorch/pytorch/blob/4949eea0ffb60dc81a0a78402fa59fdf68206718/torch/utils/data/dataset.py#L64)\n",
    "\n",
    "This code is heavily modifed from https://github.com/Shmuma/ptan\n",
    "\n",
    "Reference for env [semantics related to vectorized environments](https://github.com/openai/universe/blob/master/doc/env_semantics.rst)\n",
    "\n",
    "Useful links:\n",
    "- [torch multiprocessing](https://github.com/pytorch/pytorch/blob/a61a8d059efa0fb139a09e479b1a2c8dd1cf1a44/torch/utils/data/dataloader.py#L564)\n",
    "- [torch worker](https://github.com/pytorch/pytorch/blob/master/torch/utils/data/_utils/worker.py)\n",
    "\n",
    "This notebook walks through a more advanced usage of the `Loop` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7574233-2db1-41f0-9c76-e8942efda6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "def parse_events(loop:L): \n",
    "    return loop.filter(lambda s:in_('event.',s)).map(lambda s:s.replace('event.',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5233d45-66d9-45dd-8100-0a47f8ab25ac",
   "metadata": {},
   "source": [
    "## Source \n",
    "> The base iterable used for iterating through environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696e4679-b76b-474d-ad54-b51be56313d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "_loop=L(['event.after_create','Start Setup','event.initialize','End Setup',\n",
    "             'event.before_episodes',\n",
    "             'Start Episodes',\n",
    "                 'event.reset',\n",
    "                 'event.do_action',\n",
    "                 'event.do_step',\n",
    "                 'event.render',\n",
    "                 'event.history',\n",
    "             'End Episodes',\n",
    "             'event.after_episodes'\n",
    "             ])\n",
    "\n",
    "mk_class('source_events', **parse_events(_loop).map_dict(),\n",
    "         doc=\"All possible events as attributes to get tab-completion and typo-proofing\")\n",
    "\n",
    "_all_=['source_events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3d545f-d689-47b9-a8f6-f8d7d55fa537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "class Source(Loop):\n",
    "    _loop=_loop\n",
    "    _events=source_events\n",
    "    _default='source'    \n",
    "    end_event=parse_events(_loop)[-1]\n",
    "    \n",
    "    @delegates(Loop)\n",
    "    def __init__(self,cbs=None,**kwargs):\n",
    "        super().__init__(cbs=cbs,**kwargs)\n",
    "        store_attr(but='cbs')\n",
    "        self.idx=0\n",
    "        \n",
    "    def after_create(self):\n",
    "        self('initialize')\n",
    "        return self\n",
    "        \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            self.idx+=1\n",
    "            self('do_step')\n",
    "            yield {'this':torch.full((1,5),self.idx)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e639cfda-0bc8-483f-b1e1-d82adc64b8fc",
   "metadata": {},
   "source": [
    "So the `Source` object does a simple loop that returns a dictionary. \n",
    "This is going to be similar to what the rest of fastrl will be expecting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "128105af-6d32-4955-9354-e13f04a1348c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': tensor([[1, 1, 1, 1, 1]])}\n",
      "{'this': tensor([[2, 2, 2, 2, 2]])}\n",
      "{'this': tensor([[3, 3, 3, 3, 3]])}\n",
      "{'this': tensor([[4, 4, 4, 4, 4]])}\n",
      "{'this': tensor([[5, 5, 5, 5, 5]])}\n",
      "{'this': tensor([[6, 6, 6, 6, 6]])}\n",
      "{'this': tensor([[7, 7, 7, 7, 7]])}\n",
      "{'this': tensor([[8, 8, 8, 8, 8]])}\n",
      "{'this': tensor([[9, 9, 9, 9, 9]])}\n",
      "{'this': tensor([[10, 10, 10, 10, 10]])}\n"
     ]
    }
   ],
   "source": [
    "source=Source()\n",
    "for x,_ in zip(iter(source),range(10)): print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ce81a24-b826-4fdc-94a2-4b1de17d2f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - after_create   : []\n",
      "Start Setup\n",
      "   - initialize     : []\n",
      "End Setup\n",
      " - before_episodes: []\n",
      "Start Episodes\n",
      "   - reset          : []\n",
      "   - do_action      : []\n",
      "   - do_step        : []\n",
      "   - render         : []\n",
      "   - history        : []\n",
      "End Episodes\n",
      " - after_episodes : []\n"
     ]
    }
   ],
   "source": [
    "Source().show_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956bb8ec-d7aa-4e84-ab25-3dda97609dda",
   "metadata": {},
   "source": [
    "## Base PyTorch\n",
    "This section covers the basic dataloader in pytorch with the source object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75baef07-9a53-4215-b169-289209aadf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object of type 'generator' has no len()\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "source=Source()\n",
    "try:                   print(list(DataLoader(iter(source),batch_size=10)))\n",
    "except TypeError as e: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8061a309-909b-4f96-895e-fc3a64e5eb1c",
   "metadata": {},
   "source": [
    "Ok so the initial attempt failed. This is because we need to indicate this is an iterable dataset\n",
    "that contains `items` that are each the `Source` instance. Ok so lets make this an \n",
    "iterable dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f420f6-22e6-4cb2-93e1-48f04b196805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "class SourceDataset(IterableDataset):\n",
    "    \"Iterates through a `source` object. Allows for re-initing source connections when `num_workers>0`\"\n",
    "    def __init__(self,source=None): self.source=source\n",
    "    def __iter__(self):             \n",
    "        source=iter(self.source)\n",
    "        yield from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff153b1d-0ede-4bf3-b6b5-0fea1883248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class VerboseChecked(LoopCallback):\n",
    "    _methods=source_events\n",
    "    def __init__(self,show_worker_id=True,show_env_id=True):store_attr()\n",
    "    \n",
    "    def initialize(self):\n",
    "        worker_id=get_worker_info()\n",
    "        worker_id=worker_id.id if worker_id is not None else 0\n",
    "        if self.show_worker_id: print('Worker id: ',worker_id)\n",
    "    \n",
    "        self.env=gym.make('HumanoidPyBulletEnv-v0')\n",
    "        self.env.reset() \n",
    "    def do_step(self):\n",
    "        if self.show_env_id: print('Env Id: ',id(self.env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45058a2d-75b7-4933-85e7-9561cbf60157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker id:  0\n",
      "WalkerBase::__init__\n",
      "Env Id:  139847813541264\n",
      "Env Id:  139847813541264\n",
      "Env Id:  139847813541264\n",
      "{'this':tensor([[[1,1,1,1,1]],[[2,2,2,2,2]],[[3,3,3,3,3]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Jul 19 2021 12:32:28\n",
      "/home/fastrl_user/.local/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader,IterableDataset\n",
    "source=Source(cbs=VerboseChecked)\n",
    "source.after_create()\n",
    "dataset=SourceDataset(source)\n",
    "for x in DataLoader(dataset,batch_size=3):\n",
    "    print(str(x).replace(' ','').replace('\\n',''))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e77e84f-969d-4419-b4ab-cbe8fdf92c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker id:  0\n",
      "WalkerBase::__init__\n",
      "Env Id:  139847813016400\n",
      "Env Id:  139847813016400\n",
      "{'this':tensor([[[1,1,1,1,1]],[[2,2,2,2,2]]])}\n",
      "Env Id:  139847813016400\n",
      "Env Id:  139847813016400\n",
      "{'this':tensor([[[3,3,3,3,3]],[[4,4,4,4,4]]])}\n",
      "Env Id:  139847813016400\n",
      "Env Id:  139847813016400\n",
      "{'this':tensor([[[5,5,5,5,5]],[[6,6,6,6,6]]])}\n",
      "Env Id:  139847813016400\n",
      "Env Id:  139847813016400\n",
      "{'this':tensor([[[7,7,7,7,7]],[[8,8,8,8,8]]])}\n",
      "Env Id:  139847813016400\n",
      "Env Id:  139847813016400\n",
      "{'this':tensor([[[9,9,9,9,9]],[[10,10,10,10,10]]])}\n",
      "Env Id:  139847813016400\n",
      "Env Id:  139847813016400\n",
      "{'this':tensor([[[11,11,11,11,11]],[[12,12,12,12,12]]])}\n",
      "Env Id:  139847813016400\n",
      "Env Id:  139847813016400\n"
     ]
    }
   ],
   "source": [
    "source=Source(cbs=VerboseChecked)\n",
    "source.after_create()\n",
    "dataset=SourceDataset(source)\n",
    "for x,i in zip(DataLoader(dataset,batch_size=2,num_workers=0),range(6)):\n",
    "    print(str(x).replace(' ','').replace('\\n',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971f2fd-9d1d-46b8-a164-4bb5d048818c",
   "metadata": {},
   "source": [
    "## Fastai Compatibility\n",
    "Now lets get this working with the fastai API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b843b50-8bf1-49fe-95d8-f4e1c018cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdbd6fe-959c-403c-8d02-bc091a4d816f",
   "metadata": {},
   "source": [
    "### TfmdList Compatability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95972366-dfd4-4bd1-8d06-61c89c6aaf0b",
   "metadata": {},
   "source": [
    "> Note: First issue we run into: It would be nice to leverage the transform API and the TfmdLists\n",
    "        would be great in case we want to execute transforms on the returned items. In this case,\n",
    "        we want to forgo the `SourceDataset` since we want to use the `TfmdList`s instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a602bf9b-24b5-4518-a25a-ef7926865e40",
   "metadata": {},
   "source": [
    "> Note: Additional note, I wonder what the real difference is between a `TfmdList` and a `Dataset`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75245082-0e9b-4b98-90ec-b6fe33cd0db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source=Source(cbs=VerboseChecked)\n",
    "# dataset=SourceDataset(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505edf3-ec85-419f-997a-3588065d3520",
   "metadata": {},
   "source": [
    "So from the looks of the config below, this should be fine right? We have an iterable dataset,\n",
    "so we indicate that it is not indexed, and that shuffling wouldn't make sense. \n",
    "\n",
    "There is some strange things we need to do to actually make this work with defaults. We need to do `type_tfms` \n",
    "on the items since they need to be iterables. We then need to do `item_tfms` to tell fastai that it is supposed\n",
    "to try to iterate through these are opposed to simply \"pushing\" them through the tfm pipeline. \n",
    "\n",
    "Let's see if this works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ef0ac4-6e95-4ea0-8155-f461d8007797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting items from [<__main__.Source object at 0x7f30db3da970>]\n",
      "Found 1 items\n",
      "2 datasets of sizes 1,0\n",
      "Setting up Pipeline: \n",
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: \n",
      "Could not do one pass in your dataloader, there is something wrong in it\n",
      "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class '__main__.Source'>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dls=DataBlock(\n",
    "        blocks=TransformBlock(\n",
    "            dls_kwargs={'indexed':False,'shuffle':False}),\n",
    "    ).dataloaders([source],n=15,bs=10,num_workers=0,verbose=True)\n",
    "    for x in dls[0]:print(x)\n",
    "except TypeError as e: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b93cd-2b9a-4054-978d-0c18a2146546",
   "metadata": {},
   "source": [
    "Oops! Seems like instead of iterating through the item, it is just passing the item into the collation mechanism. \n",
    "Let's manually make the items iterable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aecd0470-7d39-4498-a1cf-9f05c3bbc277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting items from [<__main__.Source object at 0x7f30db3da970>]\n",
      "Found 1 items\n",
      "2 datasets of sizes 1,0\n",
      "Setting up Pipeline: <lambda> -> <lambda>\n",
      "Worker id:  0\n",
      "WalkerBase::__init__\n",
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: \n",
      "Could not do one pass in your dataloader, there is something wrong in it\n",
      "Worker id:  0\n",
      "WalkerBase::__init__\n",
      "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dls=DataBlock(\n",
    "        blocks=TransformBlock(\n",
    "            type_tfms=[lambda o: o.after_create(),lambda o:iter(o)],\n",
    "            dls_kwargs={'indexed':False,'shuffle':False}),\n",
    "    ).dataloaders([source],n=15,bs=10,num_workers=0,verbose=True)\n",
    "    for x in dls[0]:print(x)\n",
    "except TypeError as e:print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14b898-0f9f-40f0-8164-b44a16c91bab",
   "metadata": {},
   "source": [
    "Ok,ok lets also tell it to pull items out of the generator..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d25e370-fb8f-4ac7-9239-427d57b2359a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting items from [<__main__.Source object at 0x7f30db3da970>]\n",
      "Found 1 items\n",
      "2 datasets of sizes 1,0\n",
      "Setting up Pipeline: <lambda> -> <lambda>\n",
      "Worker id:  0\n",
      "WalkerBase::__init__\n",
      "Setting up after_item: Pipeline: <lambda> -> ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: \n",
      "Could not do one pass in your dataloader, there is something wrong in it\n",
      "Worker id:  0\n",
      "WalkerBase::__init__\n",
      "Env Id:  139847813048928\n",
      "({'this': tensor([[[1, 1, 1, 1, 1]]], device='cuda:0')},)\n"
     ]
    }
   ],
   "source": [
    "dls=DataBlock(\n",
    "    blocks=TransformBlock(\n",
    "        type_tfms=[lambda o: o.after_create(),lambda o:iter(o)],\n",
    "        item_tfms=lambda o:next(o),\n",
    "        dls_kwargs={'indexed':False,'shuffle':False}),\n",
    ").dataloaders([source],n=15,bs=10,num_workers=0,verbose=True)\n",
    "for x in dls[0]:print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b180e4-1a35-47d6-85e8-3b534fb894a5",
   "metadata": {},
   "source": [
    "Huh... It only loops once since there is only 1 \"item\" in the list. This is not desirable behavior since this is \n",
    "an iterable. The number of loops should be able to be arbitrarily defined via `n` and `bs` especially if the items\n",
    "don't have a length to them. There are a couple additional worries that I have:\n",
    "- We may not want to call `iter` of the items until they are loaded onto a worker/passed to a process. This is due to \n",
    "many/all iterable sources not being picklable. The `type_tfms` might do this too early. \n",
    "- Why do we need to define the `item_tfms` above in the first place? the dataloader should understand that the \n",
    "item is iterable to just pull from it?\n",
    "\n",
    "You might wonder why we can't just pass a source directly into the `DataBlock`, however anything passed needs to have a len..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb54d3a9-38c5-4a29-b977-765fb923971e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object of type 'Source' has no len()\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dls=DataBlock(\n",
    "            blocks=TransformBlock(\n",
    "            type_tfms=[lambda o: o.after_create(),lambda o:iter(o)],\n",
    "            item_tfms=lambda o:next(o),\n",
    "            dls_kwargs={'indexed':False,'shuffle':False})\n",
    "    ).dataloaders(source)\n",
    "except TypeError as e: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf9a994-2d7b-4997-9225-c0e5189e23ba",
   "metadata": {},
   "source": [
    "Ok... so how do get `dls` to iterate more than just the number of items? Well, the first issue is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0590ee6-9c06-4f69-aff7-604c9b7c1a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mTfmdLists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/fastai/fastai/data/core.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TfmdLists.__iter__??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3505f-e371-4c60-add4-efa74f483848",
   "metadata": {},
   "source": [
    "And..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9d16ccd-635a-4f7f-a857-5a8aa2f84cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mDatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/fastai/fastai/data/core.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Datasets.__iter__??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b43bc-6848-4ec8-bd7d-d9945519c243",
   "metadata": {},
   "source": [
    "So even though we have gone through the work to indicate that these items and the overall dataset does not have a length,\n",
    "we still are constrained by a `len` call. This seems to be a fundamental issue with the `TfmdLists`. Maybe we can trick it into \n",
    "thinking there are `n` items when there really is only one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "626b9553-4c93-4de4-9300-4753c0360f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "from itertools import cycle\n",
    "\n",
    "class IterableTfmdLists(TfmdLists):\n",
    "    def __iter__(self): return cycle(self[i] for i in range(len(self)))\n",
    "    \n",
    "class IterableDatasets(Datasets):\n",
    "    def __iter__(self): return cycle(self[i] for i in range(len(self)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31339a0-cac9-482e-88ec-aeb8384987de",
   "metadata": {},
   "source": [
    "Now that we have a custom `TfmdLists` that will cycle through all the items, we need to modfy \n",
    "`DataBlock` and `Datasets` to accept these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d56beb2d-a83e-4c15-8f1c-e7aa5d23a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "class IterableDataBlock(DataBlock):\n",
    "    tl_type = TfmdLists\n",
    "    datasets_type = Datasets\n",
    "\n",
    "    @delegates(DataBlock)\n",
    "    def __init__(self,blocks=None,datasets_type=None,n_inp=None,**kwargs):\n",
    "        blocks = L(self.blocks if blocks is None else blocks)\n",
    "        for b in blocks:\n",
    "            if getattr(b, 'tl_type', None) is not None: self.tl_type = b.tl_type\n",
    "        if datasets_type is not None: self.datasets_type=datasets_type\n",
    "        if (not is_listy(blocks) or len(blocks)==1) and n_inp is not None: n_inp=0\n",
    "        super().__init__(blocks=blocks,n_inp=n_inp, **kwargs)\n",
    "        \n",
    "    def datasets(self, source, verbose=False):\n",
    "        self.source = source                     ; pv(f\"Collecting items from {source}\", verbose)\n",
    "        items = (self.get_items or noop)(source) ; pv(f\"Found {len(items)} items\", verbose)\n",
    "        splits = (self.splitter or RandomSplitter())(items)\n",
    "#         pv(f\"{len(splits)} datasets of sizes {','.join([str(len(s)) for s in splits])}\", verbose)\n",
    "        return self.datasets_type(items, tfms=self._combine_type_tfms(), splits=splits, dl_type=self.dl_type, \n",
    "                                  n_inp=self.n_inp, verbose=verbose, tl_type=self.tl_type)\n",
    "\n",
    "@patch\n",
    "def __init__(self:Datasets, items=None, tfms=None, tls=None, n_inp=None, dl_type=None,tl_type=TfmdLists, **kwargs):\n",
    "    super(Datasets,self).__init__(dl_type=dl_type)\n",
    "    self.tls = L(tls if tls else [tl_type(items, t, **kwargs) for t in L(ifnone(tfms,[None]))])\n",
    "    self.n_inp = ifnone(n_inp, max(1, len(self.tls)-1))\n",
    "    \n",
    "class TransformBlock():\n",
    "    \"A basic wrapper that links defaults transforms for the data block API\"\n",
    "    def __init__(self, type_tfms=None, item_tfms=None, batch_tfms=None, dl_type=None, dls_kwargs=None, tl_type=None):\n",
    "        self.type_tfms  =            L(type_tfms)\n",
    "        self.item_tfms  = ToTensor + L(item_tfms)\n",
    "        self.batch_tfms =            L(batch_tfms)\n",
    "        self.dl_type,self.dls_kwargs = dl_type,({} if dls_kwargs is None else dls_kwargs)\n",
    "        self.tl_type = tl_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8251f-f359-42e7-96a8-4e6648fb1a88",
   "metadata": {},
   "source": [
    "So we have modified the fastai data block API to handle custom `TfmdList`s, let's try these out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "940de0d9-07ea-404c-8ade-781611c13833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "class Source(Loop):\n",
    "    _loop=_loop\n",
    "    _events=source_events\n",
    "    _default='source'    \n",
    "    end_event=parse_events(_loop)[-1]\n",
    "    \n",
    "    @delegates(Loop)\n",
    "    def __init__(self,cbs=None,**kwargs):\n",
    "        super().__init__(cbs=cbs,**kwargs)\n",
    "        store_attr(but='cbs')\n",
    "        self.idx=0\n",
    "        \n",
    "    def after_create(self):\n",
    "        self('initialize')\n",
    "        print('init')\n",
    "        return self\n",
    "        \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            self.idx+=1\n",
    "            self('do_step')\n",
    "            yield {'this':torch.full((1,5),self.idx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44bf923d-6b6c-4353-a485-c36d805202bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutli_recreate():\n",
    "    worker_id=get_worker_info()\n",
    "    if worker_id is not None:\n",
    "        print('reinit',worker_id.id)\n",
    "        print(worker_id)\n",
    "        [worker_id.dataset.d.items[i].after_create() for i in range(len(worker_id.dataset.d.items))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab1c9bbb-d202-430a-a8a1-cb20e8f64571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting items from [<__main__.Source object at 0x7f30daa73e80>]\n",
      "init\n",
      "Found 1 items\n",
      "Setting up Pipeline: <lambda>\n",
      "Setting up after_item: Pipeline: <lambda> -> ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: \n",
      "reinit 0reinit\n",
      " 1\n",
      "WorkerInfo(id=1, num_workers=2, seed=5318618641177852275, dataset=<fastai.data.load._FakeLoader object at 0x7f30daa374f0>)\n",
      "init\n",
      "WorkerInfo(id=0, num_workers=2, seed=5318618641177852274, dataset=<fastai.data.load._FakeLoader object at 0x7f30daa374f0>)\n",
      "init\n",
      "[{'this': tensor([[[1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[2, 2, 2, 2, 2]],\n",
      "\n",
      "        [[3, 3, 3, 3, 3]]], device='cuda:0')}]\n",
      "[{'this': tensor([[[1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[2, 2, 2, 2, 2]],\n",
      "\n",
      "        [[3, 3, 3, 3, 3]]], device='cuda:0')}]\n",
      "[{'this': tensor([[[4, 4, 4, 4, 4]],\n",
      "\n",
      "        [[5, 5, 5, 5, 5]],\n",
      "\n",
      "        [[6, 6, 6, 6, 6]]], device='cuda:0')}]\n",
      "[{'this': tensor([[[4, 4, 4, 4, 4]]], device='cuda:0')}]\n",
      "reinit0 \n",
      "WorkerInfo(id=0, num_workers=2, seed=2780370516484742933, dataset=<fastai.data.load._FakeLoader object at 0x7f30daa374f0>)\n",
      "init\n",
      "reinit 1\n",
      "WorkerInfo(id=1, num_workers=2, seed=2780370516484742934, dataset=<fastai.data.load._FakeLoader object at 0x7f30daa374f0>)\n",
      "init\n",
      "[{'this': tensor([[[1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[2, 2, 2, 2, 2]],\n",
      "\n",
      "        [[3, 3, 3, 3, 3]]], device='cuda:0')}]\n",
      "[{'this': tensor([[[1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[2, 2, 2, 2, 2]],\n",
      "\n",
      "        [[3, 3, 3, 3, 3]]], device='cuda:0')}]\n",
      "[{'this': tensor([[[4, 4, 4, 4, 4]],\n",
      "\n",
      "        [[5, 5, 5, 5, 5]],\n",
      "\n",
      "        [[6, 6, 6, 6, 6]]], device='cuda:0')}]\n",
      "[{'this': tensor([[[4, 4, 4, 4, 4]]], device='cuda:0')}]\n"
     ]
    }
   ],
   "source": [
    "source=Source()\n",
    "block=IterableDataBlock(\n",
    "    datasets_type=IterableDatasets,\n",
    "    get_items=lambda o:[j.after_create() for j in o],\n",
    "    splitter=lambda o:[[0]],\n",
    "    blocks=TransformBlock(\n",
    "        type_tfms=lambda o:iter(o),\n",
    "        item_tfms=lambda o:next(o),\n",
    "        tl_type=IterableTfmdLists,\n",
    "        dls_kwargs={'indexed':False,'shuffle':False,'persistent_workers':True,'pin_memory':True}),\n",
    ")\n",
    "dls=block.dataloaders([source],n=10,bs=3,num_workers=2,verbose=True,wif=mutli_recreate)\n",
    "for x in dls[0]:print(x)\n",
    "for x in dls[0]:print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93975f4-8cb8-4e2b-8ca2-dcf457730cf6",
   "metadata": {},
   "source": [
    "### Multi Epoch Iteration Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0574423-611c-4a57-8106-c3b7d74e2cee",
   "metadata": {},
   "source": [
    "Great! Its iterating! But it seems to reset every iteration for some reason, i.e. It should just keep counting up..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5d808db-311a-41f7-b88b-74cca95bc688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting items from [<__main__.Source object at 0x7f30daa73e80>]\n",
      "init\n",
      "Found 1 items\n",
      "Setting up Pipeline: <lambda>\n",
      "Setting up after_item: Pipeline: <lambda> -> ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: \n",
      "[{'this': tensor([[[1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[2, 2, 2, 2, 2]],\n",
      "\n",
      "        [[3, 3, 3, 3, 3]]], device='cuda:0')}]\n",
      "[{'this': tensor([[[4, 4, 4, 4, 4]],\n",
      "\n",
      "        [[5, 5, 5, 5, 5]],\n",
      "\n",
      "        [[6, 6, 6, 6, 6]]], device='cuda:0')}]\n",
      "[{'this': tensor([[[7, 7, 7, 7, 7]],\n",
      "\n",
      "        [[8, 8, 8, 8, 8]],\n",
      "\n",
      "        [[9, 9, 9, 9, 9]]], device='cuda:0')}]\n",
      "[{'this': tensor([[[10, 10, 10, 10, 10]]], device='cuda:0')}]\n",
      "[{'this': tensor([[[11, 11, 11, 11, 11]],\n",
      "\n",
      "        [[12, 12, 12, 12, 12]],\n",
      "\n",
      "        [[13, 13, 13, 13, 13]]], device='cuda:0')}]\n",
      "[{'this': tensor([[[14, 14, 14, 14, 14]],\n",
      "\n",
      "        [[15, 15, 15, 15, 15]],\n",
      "\n",
      "        [[16, 16, 16, 16, 16]]], device='cuda:0')}]\n",
      "[{'this': tensor([[[17, 17, 17, 17, 17]],\n",
      "\n",
      "        [[18, 18, 18, 18, 18]],\n",
      "\n",
      "        [[19, 19, 19, 19, 19]]], device='cuda:0')}]\n",
      "[{'this': tensor([[[20, 20, 20, 20, 20]]], device='cuda:0')}]\n"
     ]
    }
   ],
   "source": [
    "dls=block.dataloaders([source],n=10,bs=3,num_workers=0,verbose=True,wif=mutli_recreate)\n",
    "for x in dls[0]:print(x)\n",
    "for x in dls[0]:print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75f799-655e-49e6-9816-91aaa5490a15",
   "metadata": {},
   "source": [
    "You will notice that the culprit seems to be related to whether the dataloader is\n",
    "doing multiprocessing or not. Interestingly, it seems that persistent workers does not\n",
    "work (?)\n",
    "\n",
    "> Important: Note above\n",
    "    \n",
    "This is because of the line..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4120dcec-1670-4c30-b71f-1b3d8f000451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# called in context of main process (not workers/subprocesses)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'it'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/fastai/fastai/data/load.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DataLoader.__iter__??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b0eb59-d67f-47c4-b513-a70ae5f9ffd0",
   "metadata": {},
   "source": [
    "You will notice that the loader is redefined per iter. This will happen per epoch then.\n",
    "Since the workers are tied to a dataloader, it may persist the worker between batches,\n",
    "however it will not persist them between epochs. This is undesirable. We can try to fix this through by changing how loaders are\n",
    "handled if persistant worker is set to true. You will find that this does not fix the issue due to core pytorch issues that will be illistrated later..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01812a58-1a0e-4474-9bcc-ddb37a8dbcb4",
   "metadata": {},
   "source": [
    "### Custom collater's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e12219-e244-4f22-97ff-4b66048a10d3",
   "metadata": {},
   "source": [
    "Finally, we need to change how collation is handled. Since we are returning batch-wise\n",
    "dictionaries, we want to stack them. You will notice that the [[1,1,1,1]] get turned into [[[1,1,1,1]]].\n",
    "We don't want this, so lets change it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069b0199-d4e9-472d-a3f9-446bdbf9ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch.utils.data._utils.collate import default_collate_err_msg_format,int_classes,string_classes,container_abcs\n",
    "from torch.utils.data._utils.collate import *\n",
    "\n",
    "def vstack_collate(batch):\n",
    "    \"99% similar to default_collate, however vstacks tensors thus assuming they already have a batch dim\"\n",
    "\n",
    "    elem = batch[0]\n",
    "    elem_type = type(elem)\n",
    "    if isinstance(elem, torch.Tensor):\n",
    "        out = None\n",
    "        if torch.utils.data.get_worker_info() is not None:\n",
    "            # If we're in a background process, concatenate directly into a\n",
    "            # shared memory tensor to avoid an extra copy\n",
    "            numel = sum([x.numel() for x in batch])\n",
    "            storage = elem.storage()._new_shared(numel)\n",
    "            out = elem.new(storage)\n",
    "        return torch.vstack(batch, out=out)\n",
    "    elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \\\n",
    "            and elem_type.__name__ != 'string_':\n",
    "        if elem_type.__name__ == 'ndarray' or elem_type.__name__ == 'memmap':\n",
    "            # array of string classes and object\n",
    "            if np_str_obj_array_pattern.search(elem.dtype.str) is not None:\n",
    "                raise TypeError(default_collate_err_msg_format.format(elem.dtype))\n",
    "\n",
    "            return vstack_collate([torch.as_tensor(b) for b in batch])\n",
    "        elif elem.shape == ():  # scalars\n",
    "            return torch.as_tensor(batch)\n",
    "    elif isinstance(elem, float):\n",
    "        return torch.tensor(batch, dtype=torch.float64)\n",
    "    elif isinstance(elem, int_classes):\n",
    "        return torch.tensor(batch)\n",
    "    elif isinstance(elem, string_classes):\n",
    "        return batch\n",
    "    elif isinstance(elem, container_abcs.Mapping):\n",
    "        return {key: vstack_collate([d[key] for d in batch]) for key in elem}\n",
    "    elif isinstance(elem, tuple) and hasattr(elem, '_fields'):  # namedtuple\n",
    "        return elem_type(*(default_collate(samples) for samples in zip(*batch)))\n",
    "    elif isinstance(elem, container_abcs.Sequence):\n",
    "        # check to make sure that the elements in batch have consistent size\n",
    "        it = iter(batch)\n",
    "        elem_size = len(next(it))\n",
    "        if not all(len(elem) == elem_size for elem in it):\n",
    "            raise RuntimeError('each element in list of batch should be of equal size')\n",
    "        transposed = zip(*batch)\n",
    "        return [vstack_collate(samples) for samples in transposed]\n",
    "\n",
    "    raise TypeError(default_collate_err_msg_format.format(elem_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96b461f4-869b-4dc7-8fd1-ebf0d5d4b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "_collate_types = (ndarray, Tensor, typing.Mapping, str)\n",
    "\n",
    "def fr_collate(t):\n",
    "    \"A replacement for PyTorch `default_collate` which maintains types and handles `Sequence`s\"\n",
    "    b = t[0]\n",
    "    return (vstack_collate(t) if isinstance(b, _collate_types)\n",
    "            else type(t[0])([fr_collate(s) for s in zip(*t)]) if isinstance(b, Sequence)\n",
    "            else vstack_collate(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a4d7a2-0427-4f75-a9a8-54ae0beee51f",
   "metadata": {},
   "source": [
    "If the `num_worker > 0` and `persistent_workers==True`, then we need to have the loaders be re-dfined outside\n",
    "of the __iter__ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d01ec98-61a8-4875-9dc7-3844246c29bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "from fastai.data.load import _loaders\n",
    "\n",
    "class IterableTfmdDL(TfmdDL):\n",
    "    def __init__(self, dataset,bs=64, shuffle=False, num_workers=None, verbose=False, do_setup=True,**kwargs):\n",
    "        super().__init__(dataset, bs=bs, shuffle=shuffle, num_workers=num_workers,**kwargs)\n",
    "        self._loader=None\n",
    "        \n",
    "    def create_batch(self, b): return (fr_collate,fa_convert)[self.prebatched](b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa9aa2-b74b-4097-94c7-d7065ff3ec61",
   "metadata": {},
   "source": [
    "### Pytorch persistent worker Limitation\n",
    "> This is probably the worst part of the RL <-> Pytorch issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa0271-432e-4c60-862b-1bbaaf6cb522",
   "metadata": {},
   "source": [
    "I thought that:\n",
    "\n",
    "    - If self.num_workers > 0\n",
    "    - And fake_l.persistent_workers==True\n",
    "\n",
    "All I needed to do was make sure fastai doesn't destroy dls if these above cases were\n",
    "true. The below code that would be added to `IterableTfmdDL` would have fixed this.\n",
    "\n",
    "```python\n",
    "    def sample(self): \n",
    "        return (b for i,b in enumerate(self.__idxs) if i//(self.bs or 1)%self.num_workers==self.offs)\n",
    "\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.randomize()\n",
    "        self.before_iter()\n",
    "        self.__idxs=self.get_idxs() # called in context of main process (not workers/subprocesses)\n",
    "        if self.fake_l.num_workers>0 and self.fake_l.persistent_workers and self._loader is None:\n",
    "            self._loader=_loaders[self.fake_l.num_workers==0](self.fake_l)\n",
    "        \n",
    "        for b in ifnone(self._loader,_loaders[self.fake_l.num_workers==0](self.fake_l)):\n",
    "#         for b in _loaders[self.fake_l.num_workers==0](self.fake_l):\n",
    "            if self.device is not None: b = to_device(b, self.device)\n",
    "            yield self.after_batch(b)\n",
    "        self.after_iter()\n",
    "        if hasattr(self, 'it'): del(self.it)\n",
    "```\n",
    "\n",
    "This doesn't fix the issue. \n",
    "\n",
    "Per https://pytorch.org/docs/stable/data.html:\n",
    "        \n",
    "    persistent_workers (bool, optional) â€“ If True, the data loader will not shutdown the \n",
    "                                          worker processes after a dataset has been consumed once. \n",
    "                                          This allows to maintain the workers Dataset instances \n",
    "                                          alive. (default: False)\n",
    "\n",
    "Iterable datasets don't get \"consumed\" bsaed on if an environment is done. They can consumed\n",
    "if the dataset reaches an arbitrary length. This means that an agent might be in the middle of \n",
    "executing an episode, and the dataset will end, and next epoch will start from scratch.\n",
    "\n",
    "The is really bad **unless** the user does not use multiprocessing at all, or\n",
    "we make \"n\" really really big, so that we can get a few full episodes completed.\n",
    "\n",
    "Overall, it would be better to get workers to persist between epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d57ed9-bb0a-4ae0-8829-95ce33108c07",
   "metadata": {},
   "source": [
    "### Learner compat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036984bd-e1c5-49e0-a3cd-5ca950df446d",
   "metadata": {},
   "source": [
    "Let's try to plug this into a `Learner` then..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e53c96a2-c96d-4c2b-a305-bb46e5cd2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "\n",
    "class FakeModel(Module):\n",
    "    def __init__(self):\n",
    "        self.fc=Linear(5,5)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        print(x)\n",
    "        return x['this']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afcb534e-acdf-4e1e-be3b-42a99de25669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mIterableDataBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mblocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdatasets_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_inp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdl_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgetters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mitem_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mget_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mget_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mget_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Generic container to quickly build `Datasets` and `DataLoaders`\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IterableDataBlock??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc25c49c-8996-46dc-a97f-7ab7c74d2ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mTransformBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtype_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mitem_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdl_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdls_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtl_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      A basic wrapper that links defaults transforms for the data block API\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TransformBlock??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d8287d0-dd8b-4802-be9f-6e003c6040e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "def get_sources(_,ls): return [o.after_create() for o in ls]\n",
    "\n",
    "class SourceDataBlock(IterableDataBlock):\n",
    "    datasets_type=IterableDatasets\n",
    "    get_items=get_sources\n",
    "    blocks=TransformBlock(\n",
    "        type_tfms=[lambda o:iter(o)],\n",
    "        item_tfms=lambda o:next(o),\n",
    "        tl_type=IterableTfmdLists,\n",
    "        dl_type=IterableTfmdDL,\n",
    "        dls_kwargs={'indexed':False,'shuffle':False,'persistent_workers':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29001900-f72a-4ba1-a510-3badbc64d9ec",
   "metadata": {},
   "source": [
    "In addition to above, we also don't want to run evaluation epochs since there isn't a simple\n",
    "way to split envirnoments between those 2 phases. Maybe in the near future we can have this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "061681b0-790f-41cd-bfe3-b8b0f554bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def _do_epoch_validate(self:Learner,*args,**kwargs): return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b7fa13-a9a6-4eec-b430-539ce0101d6a",
   "metadata": {},
   "source": [
    "Another augmentation we need to do is allow metrics to be run during training time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef217841-5ba5-491c-b60e-a7eef6e3b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def after_create(self:Callback): \n",
    "    for cb in self.learn.cbs: \n",
    "        if hasattr(cb,'train_metrics'): cb.train_metrics=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad03a959-303b-466f-add0-e68590b0fd1f",
   "metadata": {},
   "source": [
    "Since a lot of the learners will only have the `xb` field populated, we need look at\n",
    "the len of xb also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa0dcc33-b47e-4e0c-8ccc-6a35f1513943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def after_batch(self:Recorder):\n",
    "    \"Update all metrics and records lr and smooth loss in training\"\n",
    "    if len(self.yb) == 0 and len(self.xb) == 0: return\n",
    "    mets = self._train_mets if self.training else self._valid_mets\n",
    "    for met in mets: met.accumulate(self.learn)\n",
    "    if not self.training: return\n",
    "    self.lrs.append(self.opt.hypers[-1]['lr'])\n",
    "    self.losses.append(self.smooth_loss.value)\n",
    "    self.learn.smooth_loss = self.smooth_loss.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c565d8c0-b952-41ef-98ab-8f2d1a9f0f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting items from [<__main__.Source object at 0x7f30daa2aa90>]\n",
      "Worker id:  0\n",
      "WalkerBase::__init__\n",
      "init\n",
      "Found 1 items\n",
      "Setting up Pipeline: SourceDataBlock.<lambda>\n",
      "Could not do one pass in your dataloader, there is something wrong in it\n"
     ]
    }
   ],
   "source": [
    "source=Source(cbs=VerboseChecked)\n",
    "block=SourceDataBlock()\n",
    "dls=block.dataloaders([source],n=5,bs=2,num_workers=0,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8c9fbc4-4dd2-4673-91e1-3530c7207eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn=Learner(dls,FakeModel(),loss_func=lambda o: 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd132fc0-eb9b-47a7-b153-91fce7ec2d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env Id:  139847803273664\n",
      "Env Id:  139847803273664\n",
      "{'this': tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2]], device='cuda:0')}\n",
      "Env Id:  139847803273664\n",
      "Env Id:  139847803273664\n",
      "{'this': tensor([[3, 3, 3, 3, 3],\n",
      "        [4, 4, 4, 4, 4]], device='cuda:0')}\n",
      "Env Id:  139847803273664\n",
      "{'this': tensor([[5, 5, 5, 5, 5]], device='cuda:0')}\n",
      "Env Id:  139847803273664\n",
      "Env Id:  139847803273664\n",
      "{'this': tensor([[6, 6, 6, 6, 6],\n",
      "        [7, 7, 7, 7, 7]], device='cuda:0')}\n",
      "Env Id:  139847803273664\n",
      "Env Id:  139847803273664\n",
      "{'this': tensor([[8, 8, 8, 8, 8],\n",
      "        [9, 9, 9, 9, 9]], device='cuda:0')}\n",
      "Env Id:  139847803273664\n",
      "{'this': tensor([[10, 10, 10, 10, 10]], device='cuda:0')}\n",
      "Env Id:  139847803273664\n",
      "Env Id:  139847803273664\n",
      "{'this': tensor([[11, 11, 11, 11, 11],\n",
      "        [12, 12, 12, 12, 12]], device='cuda:0')}\n",
      "Env Id:  139847803273664\n",
      "Env Id:  139847803273664\n",
      "{'this': tensor([[13, 13, 13, 13, 13],\n",
      "        [14, 14, 14, 14, 14]], device='cuda:0')}\n",
      "Env Id:  139847803273664\n",
      "{'this': tensor([[15, 15, 15, 15, 15]], device='cuda:0')}\n",
      "Env Id:  139847803273664\n",
      "Env Id:  139847803273664\n",
      "{'this': tensor([[16, 16, 16, 16, 16],\n",
      "        [17, 17, 17, 17, 17]], device='cuda:0')}\n",
      "Env Id:  139847803273664\n",
      "Env Id:  139847803273664\n",
      "{'this': tensor([[18, 18, 18, 18, 18],\n",
      "        [19, 19, 19, 19, 19]], device='cuda:0')}\n",
      "Env Id:  139847803273664\n",
      "{'this': tensor([[20, 20, 20, 20, 20]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "learn.fit(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bc7728-19f3-49df-9d9e-c5dbab7e5845",
   "metadata": {},
   "source": [
    "This looks good, however because of the `persistent worker's` issue, if we have `num_workers>>0`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92e85646-fca0-4785-895b-040b4b218211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting items from [<__main__.Source object at 0x7f30daa16ca0>]\n",
      "Worker id:  0\n",
      "WalkerBase::__init__\n",
      "init\n",
      "Found 1 items\n",
      "Setting up Pipeline: SourceDataBlock.<lambda>\n",
      "Could not do one pass in your dataloader, there is something wrong in it\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env Id:  139848597874624\n",
      "Env Id:  139848597874624Env Id: \n",
      " 139848597874624\n",
      "Env Id: Env Id:   139848597874624\n",
      "139848597874624\n",
      "{'this': tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2]], device='cuda:0')}\n",
      "{'this': tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2]], device='cuda:0')}\n",
      "{'this': tensor([[3, 3, 3, 3, 3]], device='cuda:0')}\n",
      "Env Id:  139848597874624\n",
      "Env Id:  Env Id: 139848597874624 139848597874624\n",
      "Env Id:  \n",
      "139848597874624\n",
      "Env Id:  139848597874624\n",
      "{'this': tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2]], device='cuda:0')}\n",
      "{'this': tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2]], device='cuda:0')}\n",
      "{'this': tensor([[3, 3, 3, 3, 3]], device='cuda:0')}\n",
      "Env Id:  139848597874624\n",
      "Env Id:  Env Id: 139848597874624 139848597874624\n",
      "\n",
      "Env Id:  Env Id: 139848597874624 \n",
      "139848597874624\n",
      "{'this': tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2]], device='cuda:0')}\n",
      "{'this': tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2]], device='cuda:0')}\n",
      "{'this': tensor([[3, 3, 3, 3, 3]], device='cuda:0')}\n",
      "Env Id:  139848597874624\n",
      "Env Id:  139848597874624\n",
      "Env Id:  139848597874624\n",
      "{'this': tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2]], device='cuda:0')}\n",
      "Env Id:  139848597874624\n",
      "Env Id:  139848597874624\n",
      "{'this': tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2]], device='cuda:0')}\n",
      "{'this': tensor([[3, 3, 3, 3, 3]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "source=Source(cbs=VerboseChecked)\n",
    "dls=block.dataloaders([source],n=5,bs=2,num_workers=2,verbose=True)\n",
    "learn=Learner(dls,FakeModel(),loss_func=lambda o: 0.5)\n",
    "learn.fit(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045b2d6-26e3-4d75-842f-116084e46f76",
   "metadata": {},
   "source": [
    "Yeah... so you will notice that the `source` object seems to be reset every epoch... This is because the workers\n",
    "are being re-created between epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ee0b44-4aab-45a6-a21f-1aeef8dd8595",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae89eb-4560-4f30-8cbc-0e0713a232ed",
   "metadata": {},
   "source": [
    "Getting fastai API to work with RL environments isn't too bad. I am looking forward to v3.\n",
    "The ultamate scary blocker is that fact persistent workers are not persistent for the dl's \n",
    "life cycle, but instead are persistent for a dl's iteration.\n",
    "\n",
    "For now, the most efficient way to run an agent is with `num_workers==0`. I would be interested\n",
    "in fixing this however."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5d817a-85c1-4726-af24-f5bace35ea00",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dbba804-d88e-4434-8586-f9cadd333c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: fastai\n",
      "Version: 2.4.2\n",
      "Summary: fastai simplifies training fast and accurate neural nets using modern best practices\n",
      "Home-page: https://github.com/fastai/fastai/tree/master/\n",
      "Author: Jeremy Howard, Sylvain Gugger, and contributors\n",
      "Author-email: info@fast.ai\n",
      "License: Apache Software License 2.0\n",
      "Location: /home/fastrl_user/fastai\n",
      "Requires: pip, packaging, fastcore, torchvision, matplotlib, pandas, requests, pyyaml, fastprogress, pillow, scikit-learn, scipy, spacy, torch\n",
      "Required-by: fastrl\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ordered-festival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n",
      "Converted 00_core.ipynb.\n",
      "Converted 00_nbdev_extension.ipynb.\n",
      "Converted 03_callback.core.ipynb.\n",
      "Converted 04_agent.ipynb.\n",
      "Converted 05_data.test_async.ipynb.\n",
      "Converted 05a_data.block.ipynb.\n",
      "Converted 05b_data.block_simple.ipynb.\n",
      "Converted 05c_data.gym.ipynb.\n",
      "Converted 10a_agents.dqn.core.ipynb.\n",
      "Converted 10b_agents.dqn.targets.ipynb.\n",
      "Converted 10c_agents.dqn.double.ipynb.\n",
      "Converted 10d_agents.dqn.dueling.ipynb.\n",
      "Converted 10e_agents.dqn.categorical.ipynb.\n",
      "Converted 11a_agents.policy_gradient.ppo.ipynb.\n",
      "Converted 20_test_utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted nbdev_template.ipynb.\n",
      "converting: /home/fastrl_user/fastrl/nbs/05b_data.block_simple.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import make_readme\n",
    "    make_readme()\n",
    "    notebook2script()\n",
    "    notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-spiritual",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
