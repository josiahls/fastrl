{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845eef57-00ad-4ca2-95b0-74193296c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fastai.loop_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os,sys,json\n",
    "from copy import deepcopy,copy\n",
    "from typing import *\n",
    "import types\n",
    "import logging\n",
    "import inspect\n",
    "from itertools import chain,product\n",
    "from functools import partial\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import numpy as np\n",
    "# Local modules\n",
    "from fastrl.core import test_in\n",
    "\n",
    "IN_IPYTHON=False\n",
    "\n",
    "_logger=logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbverbose.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display=Display(visible=0,size=(400,300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Loop\n",
    "> fastrl concept of generic loop objects. \n",
    "\n",
    "The goal for Loops is to make it easy to customize, and know how sections of code connects\n",
    "to other parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1f19b6-5f50-41e1-86aa-72e0e493298d",
   "metadata": {},
   "source": [
    "Ideally, a loop can consist of inner loops to have a format:\n",
    "```python\n",
    "FitLoop\n",
    "BatchLoop\n",
    "ClassicTrain\n",
    "BatchLoop\n",
    "StepLoop\n",
    "ValidStepLoop\n",
    "```\n",
    "Which might have a structure:\n",
    "```json\n",
    "{\n",
    "\"FitLoop\": [\n",
    "    \"FitLoop (epoch)\": [\n",
    "        \"ClassicTrain (train)\": [\n",
    "            \"BatchLoop (batches)\": [\n",
    "                \"StepLoop (pred)\": [],\n",
    "                \"StepLoop (loss)\": [],\n",
    "                \"StepLoop (backward)\": [],\n",
    "                \"StepLoop (step)\": [],\n",
    "                \"StepLoop (zero_grad)\": []\n",
    "            ]\n",
    "        ],\n",
    "        \"ClassicTrain (valid)\": [\n",
    "            \"BatchLoop (batches)\": [\n",
    "                \"ValidStepLoop (pred)\": [],\n",
    "                \"ValidStepLoop (loss)\": [],\n",
    "            ]\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f64010-a0ca-4200-a9a7-17c5f057fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def map_obj_attr2func_attr(obj,fn):\n",
    "    got_attrs={}\n",
    "    for k,v in inspect.signature(fn).parameters.items():\n",
    "        if k=='self':continue\n",
    "        elif v.default==inspect._empty:\n",
    "            got_attrs[k]=getattr(obj,k)\n",
    "        else:\n",
    "            got_attrs[k]=getattr(obj,k,v.default)\n",
    "    return got_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "038c183d-816e-424b-9c04-63d5f5c6f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OuterCallback(object):\n",
    "    def before_iteration(self,loss:int)->dict(this=list,that=str):pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc563e1c-b9d6-4ec0-adb6-b991ffd3996c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class A():\n",
    "    loss=0.5\n",
    "    \n",
    "a=A()\n",
    "    \n",
    "map_obj_attr2func_attr(a,OuterCallback.before_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5453067-4073-43dc-8ada-c07eaf833c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "EVENT_ORDER_MAPPING={}\n",
    "PREFIXES=['before_','on_','after_','failed_','finally_']\n",
    "\n",
    "def isevent(o): return issubclass(o.__class__,Event)\n",
    "class EventException(Exception):pass\n",
    "def _default_raise(_placeholder): raise\n",
    "def grab_parent_event(o): return o.parent_event\n",
    "\n",
    "class KwargSetAttr(object):\n",
    "    def __setattr__(self,name,value):\n",
    "        \"Allow setting attrs via kwarg.\"\n",
    "        super().__setattr__(name,value)\n",
    "\n",
    "class Events(KwargSetAttr,L):\n",
    "    def __init__(self,items=None,postfix=None,prefix=None,item_iter_hint='prefix',\n",
    "                 order=0,parent_event=None,*args,**kwargs):\n",
    "        store_attr(but='items')\n",
    "        super().__init__(items=items,*args,**kwargs)\n",
    "        \n",
    "    def flat(self):\n",
    "        return Events(chain.from_iterable(self),\n",
    "                      postfix=self.postfix,prefix=self.prefix,\n",
    "                      item_iter_hint=self.item_iter_hint,order=self.order,\n",
    "                      parent_event=self.parent_event)\n",
    "\n",
    "    def __lt__(self,o:'Event'): return self.order<o.order    \n",
    "    def todict(self): \n",
    "        return {getattr(o,self.item_iter_hint):o for o in self}\n",
    "    \n",
    "    def __repr__(self): \n",
    "        if len(self)==0: return super().__repr__()\n",
    "        return '['+'\\n'.join([str(o) for o in self])+']'\n",
    "    def run(self):\n",
    "        for o in self: o.run()                                                  # fastrl.skip_traceback\n",
    "\n",
    "class Event(KwargSetAttr):\n",
    "    def __init__(self,\n",
    "                 function:Callable,\n",
    "                 loop=None,\n",
    "                 override_name=None,\n",
    "                 override_qualname=None,\n",
    "                 override_module=None,\n",
    "                 order=None\n",
    "                ):\n",
    "        store_attr()\n",
    "        if self.function==noop and self.prefix=='failed_':\n",
    "            self.function=_default_raise\n",
    "        # We set the order over the entire Loop definition\n",
    "        if self.order is None:\n",
    "            if self.outer_name not in EVENT_ORDER_MAPPING: self.order=1\n",
    "            else: self.order=EVENT_ORDER_MAPPING[self.outer_name]\n",
    "            EVENT_ORDER_MAPPING[self.outer_name]=self.order+1\n",
    "\n",
    "        # self.original_name=self.function.__module__+'.'+self.function.__qualname__\n",
    "            \n",
    "        if self.name.startswith('_') or not any(self.name.startswith(pre) for pre in PREFIXES):\n",
    "            raise EventException(f'{self.name} needs to start with any {PREFIXES}')\n",
    "            \n",
    "        self.cbs=L()\n",
    "        \n",
    "    def climb(self):\n",
    "        \"Returns a generator that moves up to the parent/root event\"\n",
    "        if self.loop is not None:\n",
    "            yield from self.loop.climb()\n",
    "            \n",
    "    @property\n",
    "    def level(self): return len(list(self.climb()))\n",
    "        \n",
    "    @classmethod\n",
    "    def from_override_name(cls,name,**kwargs):\n",
    "        return cls(noop,override_name=name,**kwargs)\n",
    "  \n",
    "    def init_cbs(self):\n",
    "        \"Look at the cbs in the `parent_loop` and add them to `self`\"\n",
    "        cbs=L(self.climb())[-1].cbs\n",
    "        # parent_events=[self.name]+[o.parent_event.name for o in self.climb() if o.parent_event is not None]\n",
    "        parent_events=[self.qualname]+L(self.climb())\\\n",
    "                                   .map(grab_parent_event)\\\n",
    "                                   .filter(ifnone,b=False)\\\n",
    "                                   .map(Self.qualname())\n",
    "        # Check if the callback has an event relevent to self\n",
    "        for cb in L(cbs):\n",
    "            if hasattr(cb,self.name):\n",
    "                if not cb.call_on or any(o.qualname in parent_events for o in cb.call_on):\n",
    "                    self.cbs.append(cb)\n",
    "        \n",
    "    @property\n",
    "    def root_loop(self): return list(self.climb())[-1]\n",
    "    def __call__(self,*args,**kwargs): \n",
    "        ret=self.function(self.loop,*args,**kwargs)                             # fastrl.skip_traceback\n",
    "        for cb in self.cbs: \n",
    "            fn=getattr(cb,self.name)\n",
    "            params=map_obj_attr2func_attr(self.root_loop,fn)\n",
    "            \n",
    "            cb_ret=fn(**params)\n",
    "            \n",
    "            if isinstance(cb_ret,dict):\n",
    "                loop=self.root_loop\n",
    "                for k,v in cb_ret.items(): setattr(loop,k,v)\n",
    "            \n",
    "        return ret\n",
    "\n",
    "    def __lt__(self,o:'Event'): return self.order<o.order\n",
    "    @property\n",
    "    def name(self): return ifnone(self.override_name,self.function.__name__)\n",
    "    @property\n",
    "    def module(self): return ifnone(self.override_module,self.function.__module__)\n",
    "    @property\n",
    "    def qualname(self): return ifnone(self.override_qualname,self.function.__qualname__)\n",
    "    @property\n",
    "    def prefix(self): return self.name.split('_')[0]+'_'\n",
    "    @property\n",
    "    def postfix(self): return '_'.join(self.name.split('_')[1:])\n",
    "    @property\n",
    "    def outer_name(self): return self.module+'.'+self.qualname.split('.')[0]\n",
    "    @property\n",
    "    def original_name(self): \n",
    "        return self.function.__module__+'.'+self.function.__qualname__\n",
    "    \n",
    "    def __repr__(self): return self.module+'.'+self.name\n",
    "    def with_inner(self):\n",
    "        return (self,Events(postfix=self.postfix,\n",
    "                            prefix=self.prefix+'inner',\n",
    "                            order=self.order))\n",
    "\n",
    "event=Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5103c4a5-7202-4b02-84d2-22aa39040a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Loops(L):\n",
    "    def run(self):\n",
    "        for o in self: o.run()                                                  # fastrl.skip_traceback\n",
    "\n",
    "class Loop(object):\n",
    "    def __init__(self,cbs:L=None,verbose:bool=False):\n",
    "        store_attr()\n",
    "        # When a loop is initialized, we need to make sure that the events\n",
    "        # are re-initialized also\n",
    "        events(self,reset=True)\n",
    "        \n",
    "        self.parent_loop=None\n",
    "        self.parent_event=None\n",
    "        \n",
    "        _events=Events(inspect.getmembers(self)).map(Self[-1]).filter(isevent).sorted()\n",
    "        # print(Events(inspect.getmembers(self)).map(Self[-1]))\n",
    "        # 1. Make Events have the same module as the function being run\n",
    "        # 2. Convert the Events to Events+Inner Events\n",
    "        # 3. Convert [(Event,[]*inner events*)...] to [Event,[]*inner events*...]\n",
    "        # 4. Sure they are sorted correctly\n",
    "        self.default_events=Events(PREFIXES)\\\n",
    "            .map(Event.from_override_name,override_module=_events[0].module)\\\n",
    "            .map(Event.with_inner)\\\n",
    "            .flat()\\\n",
    "            .sorted()                                                           \n",
    "        self.events=_events.sorted().map(Event.with_inner).flat().sorted()\n",
    "        self.events.map(Event.__setattr__,name='loop',value=self)\n",
    "        self.sections=groupby(self.events,Self.postfix())\n",
    "        for k,v in self.sections.items():\n",
    "            self.sections[k]=merge(self.default_events.map(copy).todict(),\n",
    "                                   Events(v).todict())\n",
    "            \n",
    "    def copy(self): return self.__class__()\n",
    "    def climb(self):\n",
    "        \"Returns a generator that moves up to the parent/root event\"\n",
    "        yield self\n",
    "        if self.parent_loop is not None:\n",
    "            yield from self.parent_loop.climb()\n",
    "            \n",
    "    def run(self,sections:List[str]=None):\n",
    "        try:                                                                    # fastrl.skip_traceback\n",
    "            for k,v in self.sections.items(): \n",
    "                if sections is None or k in sections: run_section(v)            # fastrl.skip_traceback\n",
    "        except Exception as e:\n",
    "            e._show_loop_errors=self.verbose\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41cd50bb-2648-4ff8-b01c-35be10639559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _Events():\n",
    "    def __call__(self,loop,reset=False):\n",
    "        # Handle types/instances...\n",
    "        if isinstance(loop,type): attrs=loop.__dict__.items()  \n",
    "        else:                     attrs=inspect.getmembers(loop)\n",
    "        \n",
    "        for k,v in attrs:\n",
    "            if not callable(v): continue\n",
    "            if any(k.startswith(s) for s in PREFIXES):\n",
    "                if not isevent(v): setattr(loop,k,Event(v))\n",
    "                if isevent(v) and reset: setattr(loop,k,Event(v.function))\n",
    "        return loop\n",
    "        \n",
    "events=_Events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdae5eab-d828-48f3-8ce8-fc05b814becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@events\n",
    "class A(Loop):\n",
    "    def on_step(self): print('on_step')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f39d3c8-e045-4d6b-954c-876b1af7c557",
   "metadata": {},
   "source": [
    "Check that we can re-initialize `A` and that the `Event`s also reinitialize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1165c82e-e88d-4e41-8541-77686c64a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=A()\n",
    "other_a=A()\n",
    "test_ne(id(a.on_step),id(other_a.on_step))\n",
    "test_eq_type(a.on_step.loop,a)\n",
    "a_copy=a.copy()\n",
    "test_eq_type(a.on_step.loop,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3b0c785-3c05-4049-b877-4b3d57f2368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@events\n",
    "class Outer(Loop):\n",
    "    def before_step(self) :  print('before_step')\n",
    "    def on_step(self)     :  print('on_step')\n",
    "    def after_step(self)  :  print('after_step')\n",
    "    def failed_step(self) :  print('failed_step')\n",
    "    def finally_step(self):  print('finally_step')\n",
    " \n",
    "    def before_jump(self) :  print('before_jump')\n",
    "    def on_jump(self)     :  print('on_jump')\n",
    "    def after_jump(self)  :  print('after_jump')\n",
    "    def failed_jump(self) :  print('failed_jump')\n",
    "    def finally_jump(self):  print('finally_jump')\n",
    "\n",
    "class Inner(Loop):\n",
    "    call_on=L(Outer.on_step,Outer.after_step,Outer.finally_jump)\n",
    "    \n",
    "    @event\n",
    "    def before_iteration(self) : print('before_iteration')\n",
    "    @event\n",
    "    def on_iteration(self)     : print('on_iteration')\n",
    "    @event\n",
    "    def after_iteration(self)  : print('after_iteration')\n",
    "    @event\n",
    "    def failed_iteration(self) : print('failed_iteration')\n",
    "    @event\n",
    "    def finally_iteration(self): print('finally_iteration')\n",
    "\n",
    "class FailingInner(Loop):\n",
    "    call_on=L(Inner.finally_iteration)\n",
    "    \n",
    "    @event\n",
    "    def on_force_fail(self):                    \n",
    "        print('on_force_fail')\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c6bcc5e-4b59-4392-a72a-f94201839a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def run_section(section:Dict):\n",
    "    try:\n",
    "        section['before_']()\n",
    "        section['before_inner'].run()                                           # fastrl.skip_traceback\n",
    "        section['on_']()\n",
    "        section['on_inner'].run()\n",
    "        section['after_']()\n",
    "        section['after_inner'].run()                                            # fastrl.skip_traceback\n",
    "    except Exception as ex:\n",
    "        try:     \n",
    "            section['failed_']()                                                # fastrl.skip_traceback\n",
    "            raise\n",
    "        finally: \n",
    "            section['failed_inner'].run()                                       # fastrl.skip_traceback\n",
    "    finally:\n",
    "        section['finally_']()\n",
    "        section['finally_inner'].run()                                          # fastrl.skip_traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c30245c-97e9-4d05-9cc0-528304e1a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def eq_loops(a:Loop,b:Loop): return a.__class__==b.__class__\n",
    "\n",
    "def connect_loops2loop(loops:Loops,to_loop):\n",
    "    # Given `to_loop`, generate some fresh `loops`...\n",
    "    loops=Loops(loops)\n",
    "    loops=loops.map(Self.copy())\n",
    "    to_events=to_loop.events.filter(isevent).map(Self.original_name()) \n",
    "    for from_loop in loops.filter(eq_loops,b=to_loop,negate=True):\n",
    "        for call_on in from_loop.call_on:\n",
    "            if call_on.original_name in to_events:\n",
    "                _from_loop=from_loop.copy()\n",
    "                \n",
    "                _from_loop.parent_event=to_loop.sections[call_on.postfix][call_on.prefix]\n",
    "                _from_loop.parent_loop=to_loop\n",
    "                \n",
    "                _from_loop.events.filter(isevent).map(Self.init_cbs())\n",
    "\n",
    "                to_loop.sections[call_on.postfix][call_on.prefix+'inner'].extend([_from_loop])\n",
    "                connect_loops2loop(loops,_from_loop)\n",
    "    return to_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34a03f-8919-45ba-b574-9bc4e6c6b76b",
   "metadata": {},
   "source": [
    "Check that a single loop connects to the parent..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d78bf0c8-60b6-480d-80a5-0838f89228e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@events\n",
    "class A(Loop):\n",
    "    def on_step(self): print('on_step')\n",
    "    \n",
    "@events\n",
    "class B(Loop):\n",
    "    call_on=L(A.on_step)\n",
    "    def on_event(self): print('on_event')\n",
    "    \n",
    "@events\n",
    "class C(Loop):\n",
    "    call_on=L(B.on_event)\n",
    "    def on_second_step(self): print('on_second_step')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ced1c6-7bd7-4038-922d-8f76d4155020",
   "metadata": {},
   "source": [
    "Check that the parent loop does not reference any non-existant parents. We also\n",
    "expect it to have 1 section (on_step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33e06d66-caef-4203-beb7-1206839e2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_instance=connect_loops2loop((B(),C()),A())\n",
    "test_eq(a_instance.parent_loop,None)\n",
    "test_eq(a_instance.parent_event,None)\n",
    "test_eq(a_instance.on_step.root_loop,a_instance)\n",
    "test_eq(len(a_instance.sections),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3992017-ec7b-4f97-9d34-4dcf084835e3",
   "metadata": {},
   "source": [
    "Check that the inner B loop properly references A, as well as the parent event `on_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36e9b2e5-5d23-45df-b27b-0985c556311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_instance=a_instance.sections['step']['on_inner'][0]\n",
    "test_eq_type(b_instance.__class__,B)\n",
    "test_eq(b_instance.parent_loop,a_instance)\n",
    "test_eq(b_instance.parent_event,a_instance.on_step)\n",
    "test_eq(id(b_instance.on_event.loop),id(b_instance))\n",
    "test_eq(b_instance.on_event.loop.parent_loop,a_instance)\n",
    "test_eq(b_instance.on_event.root_loop,a_instance)\n",
    "test_eq(len(b_instance.sections),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be1e0bc-2e81-4698-8319-3f51aca5a4d1",
   "metadata": {},
   "source": [
    "Check that the inner C loop properly references B, as well as the parent event `on_event`.\n",
    "We also should expect the root_loop to still be the a_instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "003c1a43-756d-4c6d-b4fe-6506020ec4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_instance=b_instance.sections['event']['on_inner'][0]\n",
    "test_eq_type(c_instance.__class__,C)\n",
    "test_eq(c_instance.parent_loop,b_instance)\n",
    "test_eq(c_instance.parent_event,b_instance.on_event)\n",
    "test_eq(id(c_instance.on_second_step.loop),id(c_instance))\n",
    "test_eq(c_instance.on_second_step.loop.parent_loop,b_instance)\n",
    "test_eq(c_instance.on_second_step.root_loop,a_instance)\n",
    "test_eq(len(c_instance.sections),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ee6af60-2ddb-4de7-acc8-54619a703dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections=connect_loops2loop(Loops(FailingInner(),Inner()),Outer()).sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36585e78-3d3d-43be-83cc-f8a5d9a459c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def dict2loops(d):\n",
    "    if isinstance(d,dict):\n",
    "        for o in d.values():\n",
    "            yield from dict2loops(o)\n",
    "    elif isinstance(d,(Loops,Events)):\n",
    "        for o in d:\n",
    "            yield from dict2loops(o) \n",
    "    elif issubclass(d.__class__,Loop):\n",
    "        yield d\n",
    "        yield from dict2loops(d.sections)\n",
    "        \n",
    "def dict2events(d):\n",
    "    if isinstance(d,dict):\n",
    "        for o in d.values():\n",
    "            yield from dict2events(o)\n",
    "    elif isinstance(d,(Loops,Events)):\n",
    "        for o in d:\n",
    "            yield from dict2events(o) \n",
    "    elif issubclass(d.__class__,Loop):\n",
    "        yield from dict2events(d.sections)\n",
    "    elif issubclass(d.__class__,Event):\n",
    "        yield d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fb5b5ce-5718-4a02-ad56-add422ce3af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>,\n",
       " <__main__.Outer at 0x7f9a667d38d0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(L(dict2events(sections)).map(Self.climb()).map(L).filter().map(Self[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4c4c7a8-0874-4420-83b6-e2347b1a4eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CallbackException(Exception):pass\n",
    "\n",
    "class Callback(object):\n",
    "    call_on,loop=None,None\n",
    "    \n",
    "    @property\n",
    "    def root(self): return self.loop.root_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "796b8dc6-9efd-4fae-bbe6-3b223a606e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OuterCallback(Callback):\n",
    "    call_on=L(Outer.on_step)\n",
    "\n",
    "    def before_iteration(self,loss:int)->dict(this=list,that=str):\n",
    "        print('   OuterCallback called lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "585edc1a-b052-4eb5-8223-6968f75a3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def map_obj_attr2func_attr(obj,fn):\n",
    "    got_attrs={}\n",
    "    for k,v in inspect.signature(fn).parameters.items():\n",
    "        if k=='self':continue\n",
    "        elif v.default==inspect._empty:\n",
    "            got_attrs[k]=getattr(obj,k)\n",
    "        else:\n",
    "            got_attrs[k]=getattr(obj,k,v.default)\n",
    "    return got_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e84e6783-e4f6-4675-9a46-8cbdc9b50e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class A():\n",
    "    loss=0.5\n",
    "    \n",
    "a=A()\n",
    "    \n",
    "map_obj_attr2func_attr(a,OuterCallback.before_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "090dbaa8-80e5-4caa-80b9-f48fdd7f606c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jump': {'failed_': __main__.failed_jump,\n",
       "  'failed_inner': [],\n",
       "  'before_': __main__.before_jump,\n",
       "  'before_inner': [],\n",
       "  'on_': __main__.on_jump,\n",
       "  'on_inner': [],\n",
       "  'after_': __main__.after_jump,\n",
       "  'after_inner': [],\n",
       "  'finally_': __main__.finally_jump,\n",
       "  'finally_inner': [<__main__.Inner object at 0x7f9a66748810>]},\n",
       " 'step': {'failed_': __main__.failed_step,\n",
       "  'failed_inner': [],\n",
       "  'before_': __main__.before_step,\n",
       "  'before_inner': [],\n",
       "  'on_': __main__.on_step,\n",
       "  'on_inner': [<__main__.Inner object at 0x7f9b3d6050d0>],\n",
       "  'after_': __main__.after_step,\n",
       "  'after_inner': [<__main__.Inner object at 0x7f9a66713bd0>],\n",
       "  'finally_': __main__.finally_step,\n",
       "  'finally_inner': []}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connect_loops2loop(Loops(FailingInner(),Inner()),Outer(cbs=OuterCallback())).sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ee5f734-3931-4f32-aa89-2e1f0ec028eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#0) []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connect_loops2loop(Loops(FailingInner(),Inner()),Outer()).sections['step']['on_inner'][0].sections['iteration']['before_'].cbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71eb955a-7a2b-45f8-8ab9-c3708fa89976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iteration': {'failed_': __main__.failed_iteration,\n",
       "  'failed_inner': [],\n",
       "  'before_': __main__.before_iteration,\n",
       "  'before_inner': [],\n",
       "  'on_': __main__.on_iteration,\n",
       "  'on_inner': [],\n",
       "  'after_': __main__.after_iteration,\n",
       "  'after_inner': [],\n",
       "  'finally_': __main__.finally_iteration,\n",
       "  'finally_inner': [<__main__.FailingInner object at 0x7f9a666e7b50>]}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connect_loops2loop(FailingInner(),Inner()).sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "075878dd-51ca-47c8-a351-1cc5344a2fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _skip_traceback(s):\n",
    "    return in_('# fastrl.skip_traceback',s)\n",
    "    \n",
    "def ipy_handle_exception(self, etype, value, tb, tb_offset):\n",
    "    ## Do something fancy\n",
    "    stb = self.InteractiveTB.structured_traceback(etype,value,tb,tb_offset=tb_offset)\n",
    "    if not getattr(value,'_show_loop_errors',True):\n",
    "        tmp,idxs=[],L(stb).argwhere(_skip_traceback)\n",
    "        prev_skipped_idx=idxs[0] if idxs else 0\n",
    "        for i,s in enumerate(stb):\n",
    "            if i in idxs and i-1!=prev_skipped_idx: \n",
    "                msg='Skipped Loop Code due to # fastrl.skip_traceback found in source code,'\n",
    "                msg+=' please use Loop(...verbose=True) to view loop tracebacks\\n'\n",
    "                tmp.append(msg)\n",
    "            if i not in idxs:\n",
    "                tmp.append(s)\n",
    "            else:\n",
    "                prev_skipped_idx=i\n",
    "        stb=tmp\n",
    "    ## Do something fancy\n",
    "    self._showtraceback(type, value, stb)\n",
    "\n",
    "if IN_IPYTHON:\n",
    "    get_ipython().set_custom_exc((Exception,),ipy_handle_exception)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad6d7467-4a11-43b8-bd48-a2c6d73f1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: Outer(verbose=False).run(L(Inner(),FailingInner()),OuterCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a67c86cf-07f9-4848-ab48-2e3b1261f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: Outer(verbose=True).run(L(Inner(),FailingInner()),OuterCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a700536e-83d4-4ca9-be27-a2f1be963199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before_jump\n",
      "on_jump\n",
      "after_jump\n",
      "finally_jump\n",
      "before_iteration\n",
      "on_iteration\n",
      "after_iteration\n",
      "finally_iteration\n",
      "on_force_fail\n"
     ]
    }
   ],
   "source": [
    "with ExceptionExpected():\n",
    "    connect_loops2loop(Loops(FailingInner(),Inner()),Outer(cbs=OuterCallback())).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "275fa8c3-fd00-4175-928a-8767dea82dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n",
      "Converted 00_core.ipynb.\n",
      "Converted 00_nbdev_extension.ipynb.\n",
      "Converted 02_fastai.exception_test.ipynb.\n",
      "Converted 02a_fastai.loop.ipynb.\n",
      "Converted 02b_fastai.data.load.ipynb.\n",
      "No export destination, ignored:\n",
      "#export\n",
      "from fastai.torch_basics import *\n",
      "from torch.utils.data.dataloader import _MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter,_DatasetKind\n",
      "_loaders = (_MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter)\n",
      "No export destination, ignored:\n",
      "#export\n",
      "def _wif(worker_id):\n",
      "    set_num_threads(1)\n",
      "    info = get_worker_info()\n",
      "    ds = info.dataset.d\n",
      "    ds.num_workers,ds.offs = info.num_workers,info.id\n",
      "    set_seed(info.seed)\n",
      "    ds.wif()\n",
      "\n",
      "class _FakeLoader:\n",
      "    def _fn_noops(self, x=None, *args, **kwargs): return x\n",
      "    \n",
      "    _IterableDataset_len_called,_auto_collation,collate_fn,drop_last = None,False,_fn_noops,False\n",
      "    _index_sampler,generator,prefetch_factor  = Inf.count,None,2\n",
      "    dataset_kind = _dataset_kind = _DatasetKind.Iterable\n",
      "    \n",
      "    def __init__(self, d, pin_memory, num_workers, timeout, persistent_workers):\n",
      "        self.dataset,self.default,self.worker_init_fn = self,d,_wif\n",
      "        store_attr('d,pin_memory,num_workers,timeout,persistent_workers')\n",
      "\n",
      "    def __iter__(self): return iter(self.d.create_batches(self.d.sample()))\n",
      "\n",
      "    @property\n",
      "    def multiprocessing_context(self): return (None,multiprocessing)[self.num_workers>0]\n",
      "\n",
      "    @contextmanager\n",
      "    def no_multiproc(self):\n",
      "        old_num_workers = self.num_workers\n",
      "        try:\n",
      "            self.num_workers = 0\n",
      "            yield self.d\n",
      "        finally: self.num_workers = old_num_workers\n",
      "\n",
      "_collate_types = (ndarray, Tensor, typing.Mapping, str)\n",
      "No export destination, ignored:\n",
      "#export\n",
      "def fa_collate(t):\n",
      "    \"A replacement for PyTorch `default_collate` which maintains types and handles `Sequence`s\"\n",
      "    b = t[0]\n",
      "    return (default_collate(t) if isinstance(b, _collate_types)\n",
      "            else type(t[0])([fa_collate(s) for s in zip(*t)]) if isinstance(b, Sequence)\n",
      "            else default_collate(t))\n",
      "No export destination, ignored:\n",
      "#export\n",
      "def fa_convert(t):\n",
      "    \"A replacement for PyTorch `default_convert` which maintains types and handles `Sequence`s\"\n",
      "    return (default_convert(t) if isinstance(t, _collate_types)\n",
      "            else type(t)([fa_convert(s) for s in t]) if isinstance(t, Sequence)\n",
      "            else default_convert(t))\n",
      "No export destination, ignored:\n",
      "#export\n",
      "class SkipItemException(Exception):\n",
      "    \"Raised to notify `DataLoader` to skip an item\"\n",
      "    pass\n",
      "No export destination, ignored:\n",
      "#export\n",
      "@funcs_kwargs\n",
      "class DataLoader(GetAttr):\n",
      "    _noop_methods = 'wif before_iter after_item before_batch after_batch after_iter'.split()\n",
      "    for o in _noop_methods: exec(f\"def {o}(self, x=None, *args, **kwargs): return x\")\n",
      "    _methods = _noop_methods + 'create_batches create_item create_batch retain \\\n",
      "        get_idxs sample shuffle_fn do_batch create_batch'.split()\n",
      "    _default = 'dataset'\n",
      "    def __init__(self, dataset=None, bs=None, num_workers=0, pin_memory=False, timeout=0, batch_size=None,\n",
      "                 shuffle=False, drop_last=False, indexed=None, n=None, device=None, persistent_workers=False, **kwargs):\n",
      "        if batch_size is not None: bs = batch_size # PyTorch compatibility\n",
      "        assert not (bs is None and drop_last)\n",
      "        if indexed is None: indexed = (hasattr(dataset,'__getitem__')\n",
      "                                       and not isinstance(dataset, IterableDataset))\n",
      "        if not indexed and shuffle: raise ValueError(\"Can only shuffle an indexed dataset (not an iterable one).\")\n",
      "        if n is None:\n",
      "            try: n = len(dataset)\n",
      "            except TypeError: pass\n",
      "        store_attr('dataset,bs,shuffle,drop_last,indexed,n,pin_memory,timeout,device')\n",
      "        self.rng,self.num_workers,self.offs = random.Random(random.randint(0,2**32-1)),1,0\n",
      "        if sys.platform == \"win32\" and IN_NOTEBOOK and num_workers > 0:\n",
      "            print(\"Due to IPython and Windows limitation, python multiprocessing isn't available now.\")\n",
      "            print(\"So `number_workers` is changed to 0 to avoid getting stuck\")\n",
      "            num_workers = 0       \n",
      "        self.fake_l = _FakeLoader(self, pin_memory, num_workers, timeout, persistent_workers=persistent_workers)\n",
      "\n",
      "    def __len__(self):\n",
      "        if self.n is None: raise TypeError\n",
      "        if self.bs is None: return self.n\n",
      "        return self.n//self.bs + (0 if self.drop_last or self.n%self.bs==0 else 1)\n",
      "\n",
      "    def get_idxs(self):\n",
      "        idxs = Inf.count if self.indexed else Inf.nones\n",
      "        if self.n is not None: idxs = list(itertools.islice(idxs, self.n))\n",
      "        if self.shuffle: idxs = self.shuffle_fn(idxs)\n",
      "        return idxs\n",
      "    \n",
      "    def sample(self): \n",
      "        return (b for i,b in enumerate(self.__idxs) if i//(self.bs or 1)%self.num_workers==self.offs)\n",
      "\n",
      "    def __iter__(self):\n",
      "        self.randomize()\n",
      "        self.before_iter()\n",
      "        self.__idxs=self.get_idxs() # called in context of main process (not workers/subprocesses)\n",
      "        for b in _loaders[self.fake_l.num_workers==0](self.fake_l):\n",
      "            if self.device is not None: b = to_device(b, self.device)\n",
      "            yield self.after_batch(b)\n",
      "        self.after_iter()\n",
      "        if hasattr(self, 'it'): del(self.it)\n",
      "\n",
      "    def create_batches(self, samps):\n",
      "        if self.dataset is not None: self.it = iter(self.dataset)\n",
      "        res = filter(lambda o:o is not None, map(self.do_item, samps))\n",
      "        yield from map(self.do_batch, self.chunkify(res))\n",
      "\n",
      "    def new(self, dataset=None, cls=None, **kwargs):\n",
      "        if dataset is None: dataset = self.dataset\n",
      "        if cls is None: cls = type(self)\n",
      "        cur_kwargs = dict(dataset=dataset, num_workers=self.fake_l.num_workers, pin_memory=self.pin_memory, timeout=self.timeout,\n",
      "                          bs=self.bs, shuffle=self.shuffle, drop_last=self.drop_last, indexed=self.indexed, device=self.device)\n",
      "        for n in self._methods:\n",
      "            o = getattr(self, n)\n",
      "            if not isinstance(o, MethodType): cur_kwargs[n] = o\n",
      "        return cls(**merge(cur_kwargs, kwargs))\n",
      "\n",
      "    @property\n",
      "    def prebatched(self): return self.bs is None\n",
      "    def do_item(self, s):\n",
      "        try: return self.after_item(self.create_item(s))\n",
      "        except SkipItemException: return None\n",
      "    def chunkify(self, b): return b if self.prebatched else chunked(b, self.bs, self.drop_last)\n",
      "    def shuffle_fn(self, idxs): return self.rng.sample(idxs, len(idxs))\n",
      "    def randomize(self): self.rng = random.Random(self.rng.randint(0,2**32-1))\n",
      "    def retain(self, res, b):  return retain_types(res, b[0] if is_listy(b) else b)\n",
      "    def create_item(self, s):\n",
      "        if self.indexed: return self.dataset[s or 0]\n",
      "        elif s is None:  return next(self.it)\n",
      "        else: raise IndexError(\"Cannot index an iterable dataset numerically - must use `None`.\")\n",
      "    def create_batch(self, b): return (fa_collate,fa_convert)[self.prebatched](b)\n",
      "    def do_batch(self, b): return self.retain(self.create_batch(self.before_batch(b)), b)\n",
      "    def to(self, device): self.device = device\n",
      "    def one_batch(self):\n",
      "        if self.n is not None and len(self)==0: raise ValueError(f'This DataLoader does not contain any batches')\n",
      "        with self.fake_l.no_multiproc(): res = first(self)\n",
      "        if hasattr(self, 'it'): delattr(self, 'it')\n",
      "        return res\n",
      "No export destination, ignored:\n",
      "#export\n",
      "add_docs(DataLoader, \"API compatible with PyTorch DataLoader, with a lot more callbacks and flexibility\",\n",
      "         get_idxs       = \"Return a list of indices to reference the dataset. Calls `shuffle_fn` internally if `shuffle=True`.\",\n",
      "         sample         = \"Same as `get_idxs` but returns a generator of indices to reference the dataset.\",\n",
      "         create_batches = \"Takes output of `sample` as input, and returns batches of data. Does not apply `after_batch`.\",\n",
      "         new            = \"Create a new `DataLoader` with given arguments keeping remaining arguments same as original `DataLoader`.\",\n",
      "         prebatched     = \"Check if `bs` is None.\",\n",
      "         do_item        = \"Combines `after_item` and `create_item` to get an item from dataset by providing index as input.\",\n",
      "         chunkify       = \"Used by `create_batches` to turn generator of items (`b`) into batches.\",\n",
      "         shuffle_fn     = \"Returns a random permutation of `idxs`.\",\n",
      "         randomize      = \"Set's `DataLoader` random number generator state.\",\n",
      "         retain         = \"Cast each item of `res` to type of matching item in `b` if its a superclass.\",\n",
      "         create_item    = \"Subset of the dataset containing the index values of sample if exists, else next iterator.\",\n",
      "         create_batch   = \"Collate a list of items into a batch.\",\n",
      "         do_batch       = \"Combines `create_batch` and `before_batch` to get a batch of items. Input is a list of items to collate.\",\n",
      "         to             = \"Sets `self.device=device`.\",\n",
      "         one_batch      = \"Return one batch from `DataLoader`.\",\n",
      "         wif            = \"See pytorch `worker_init_fn` for details.\", \n",
      "         before_iter    = \"Called before `DataLoader` starts to read/iterate over the dataset.\",\n",
      "         after_item     = \"Takes output of `create_item` as input and applies this function on it.\",\n",
      "         before_batch   = \"It is called before collating a list of items into a batch. Input is a list of items.\",\n",
      "         after_batch    = \"After collating mini-batch of items, the mini-batch is passed through this function.\",\n",
      "         after_iter     = \"Called after `DataLoader` has fully read/iterated over the dataset.\")\n",
      "Warning: Exporting to \"None.py\" but this module is not part of this build\n",
      "Warning: Exporting to \"None.py\" but this module is not part of this build\n",
      "Warning: Exporting to \"None.py\" but this module is not part of this build\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_132/1620653600.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mnbverbose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcli\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmake_readme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnotebook2script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mnotebook2html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nbdev/export.py\u001b[0m in \u001b[0;36mnotebook2script\u001b[0;34m(fname, silent, to_dict, bare)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_dict\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mod_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_notebook2script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madd_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lib_path\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nbdev/export.py\u001b[0m in \u001b[0;36m_notebook2script\u001b[0;34m(fname, modules, silent, to_dict, bare)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_from_future_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mto_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_add2all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"'{f}'\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr' +$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMULTILINE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nbdev/export.py\u001b[0m in \u001b[0;36m_add2all\u001b[0;34m(fname, names, line_width)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mtw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_indent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsequent_indent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbreak_long_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mre_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_re__all__def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mtext_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{text[start:end-1]}{'' if text[end-2]=='[' else ', '}{', '.join(names)}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_all\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'start'"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbverbose.cli import *\n",
    "    make_readme()\n",
    "    notebook2script()\n",
    "    notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f6a4be-eae2-427e-8e44-5045582e4089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
