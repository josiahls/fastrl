{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fastai.data.loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "import logging\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.graph import traverse\n",
    "# Local modules\n",
    "from fastrl.fastai.data.pipes.demux import *\n",
    "from fastrl.fastai.data.pipes.mux import *\n",
    "\n",
    "_logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4426eaf6-e503-40c6-919c-cb4cc99dfe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level='INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Loop\n",
    "> Customizable loop API for fastrl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84e24d-a82a-464a-9412-1ab8de544af6",
   "metadata": {},
   "source": [
    "so we need loops within loops posibly. Or do they need to be loops? maybe they need to \n",
    "just be sections? do we even need sections? I wonder if we can leverage the torch data as more \n",
    "of a base... I want to see how far we can get with this....\n",
    "\n",
    "we also need to think about whether this is always iterable or whether we can mix and match\n",
    "map vs iter...\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f2c63bf-6951-4266-9c66-3ab59dd99d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    \"A list of data pipes that have an associated job.\"\n",
    "    call_on=L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4f0c24d-c8cf-4fcb-8e65-69528ec4aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Loop(dp.iter.IterDataPipe):\n",
    "    \"A datapipe with nesting and callback capabilities.\"\n",
    "\n",
    "    def set_cbs(self,cbs): self.callbacks = cbs\n",
    "    \n",
    "    def filter_cbs(self, cbs):\n",
    "        return tuple(cb for cb in cbs if self.__class__ in cb.call_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45f538e5-fd74-45da-bde8-5399d7bc1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# class ExceptionCatcher(Loop):\n",
    "#     def __init__(self, source_datapipe, exception_cls, **kwargs) -> None:\n",
    "#         self.source_datapipe = source_datapipe\n",
    "#         self.exception_cls = exception_cls\n",
    "#         self.kwargs = kwargs\n",
    "    \n",
    "#     def __iter__(self) -> Iterator[T_co]:\n",
    "#         while True:\n",
    "#             try:\n",
    "#                 yield from self.source_datapipe\n",
    "#             except self.exception_cls:\n",
    "#                 return\n",
    "\n",
    "class Iterationer(Loop):\n",
    "        \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    \n",
    "    def __iter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe:\n",
    "            # xb,yb = next(self.source_datapipe)\n",
    "            # pred = self.kwargs['model'](xb)\n",
    "            # loss_grad = self.kwargs['loss_grad']\n",
    "            # opt = self.kwargs['opt']\n",
    "            # loss_func = self.kwargs['loss_func']\n",
    "            # if len(yb):\n",
    "            #     loss_grad = self.loss_func(pred, *yb)\n",
    "            #     loss = loss_grad.clone()\n",
    "            # self('after_loss')\n",
    "            # if not self.training or not len(yb): return\n",
    "            # self('before_backward')\n",
    "            # loss_grad.backward()\n",
    "            # opt.step()\n",
    "            # opt.zero_grad()\n",
    "            # yield loss.detach()\n",
    "            yield 0.5\n",
    "\n",
    "class Batcher(Loop):\n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __iter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe:\n",
    "            yield element\n",
    "        \n",
    "class Trainer(Loop):\n",
    "        \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __iter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe:\n",
    "            yield element\n",
    "                \n",
    "class Validater(Loop):\n",
    "        \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __iter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe:\n",
    "            yield element\n",
    "               \n",
    "class Epocher(Loop):\n",
    "    def __init__(self, source_datapipes:tuple, **kwargs) -> None:\n",
    "        test_eq(type(source_datapipes), tuple)\n",
    "        self.source_datapipes = source_datapipes\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __iter__(self) -> Iterator[T_co]:\n",
    "        for element in zip(*self.source_datapipes):\n",
    "            yield element\n",
    "                \n",
    "class Fitter(Loop):\n",
    "    def __init__(self,iterable):\n",
    "                \n",
    "        trainer,validater = Trainer(iterable),Validater(iterable)\n",
    "        train_b, valid_b = Batcher(trainer),Batcher(validater)\n",
    "        train_it,valid_it = Iterationer(train_b),Iterationer(valid_b)\n",
    "        self.epocher = dp.iter.Zipper(train_it,valid_it)\n",
    "            \n",
    "    def __iter__(self):\n",
    "        for epoch in self.epocher: yield epoch\n",
    "\n",
    "        \n",
    "class TrainerCallback():\n",
    "    \"A list of data pipes that have an associated job.\"\n",
    "    call_on=L(Trainer)\n",
    "class IterCallback():\n",
    "    \"A list of data pipes that have an associated job.\"\n",
    "    call_on=L(Iterationer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a17f7d84-937e-406f-b50a-6ac48aac13f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def default_constructor(\n",
    "    datapipe:Union[Loop,Dict], \n",
    "    cbs:List[Callback]\n",
    "):\n",
    "    d = datapipe if isinstance(datapipe,dict) else traverse(datapipe)\n",
    "    \n",
    "    for k,v in d.items():\n",
    "        if issubclass(k.__class__,Loop): \n",
    "            filtered_cbs = k.filter_cbs(cbs)\n",
    "            _logger.info('Given loop: %s, found callbacks: %s',k,filtered_cbs)\n",
    "            k.set_cbs(filtered_cbs)\n",
    "        if not v: continue\n",
    "        default_constructor(v, cbs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e14bf4db-165c-455d-a76b-577c5c0c2a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Given loop: <__main__.Iterationer object at 0x7fa617348790>, found callbacks: (<class '__main__.IterCallback'>,)\n",
      "INFO:root:Given loop: <__main__.Batcher object at 0x7fa617348410>, found callbacks: ()\n",
      "INFO:root:Given loop: <__main__.Trainer object at 0x7fa617348d50>, found callbacks: (<class '__main__.TrainerCallback'>,)\n",
      "INFO:root:Given loop: <__main__.Iterationer object at 0x7fa617348c90>, found callbacks: (<class '__main__.IterCallback'>,)\n",
      "INFO:root:Given loop: <__main__.Batcher object at 0x7fa617348e90>, found callbacks: ()\n",
      "INFO:root:Given loop: <__main__.Validater object at 0x7fa617348ed0>, found callbacks: ()\n"
     ]
    }
   ],
   "source": [
    "default_constructor(\n",
    "    Fitter([1,2,3,4,5,6]).epocher,\n",
    "    [TrainerCallback,IterCallback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef54f8-b8c6-423a-854d-c151f53110de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6a955cf-79ef-40dd-b5b4-2bee779e645b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<torch.utils.data.datapipes.iter.combining.ZipperIterDataPipe at 0x7fa61735b7d0>: {<__main__.Iterationer at 0x7fa61735b150>: {<__main__.Batcher at 0x7fa617348f10>: {<__main__.Trainer at 0x7fa617348610>: {}}},\n",
       "  <__main__.Iterationer at 0x7fa61735b450>: {<__main__.Batcher at 0x7fa617348e50>: {<__main__.Validater at 0x7fa617348f50>: {}}}}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traverse(Fitter([1,2,3,4,5,6]).epocher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "598dee65-2600-40d0-a8b9-55bd77e87786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5, 0.5), (0.5, 0.5), (0.5, 0.5), (0.5, 0.5), (0.5, 0.5), (0.5, 0.5)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Fitter([1,2,3,4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59fff4dc-d4f2-4075-8bb3-814756ac8457",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'events' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_426/3339296944.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mOuter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m  \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'events' is not defined"
     ]
    }
   ],
   "source": [
    "# export\n",
    "@events\n",
    "class Outer(Loop):\n",
    "    \n",
    "    def before_step(self) :  print('before_step')\n",
    "    def on_step(self)     :  print('on_step')\n",
    "    def after_step(self)  :  print('after_step')\n",
    "    def failed_step(self) :  print('failed_step')\n",
    "    def finally_step(self):  print('finally_step')\n",
    " \n",
    "    def before_jump(self) :  print('before_jump')\n",
    "    def on_jump(self)     :  print('on_jump')\n",
    "    def after_jump(self)  :  print('after_jump')\n",
    "    def failed_jump(self) :  print('failed_jump')\n",
    "    def finally_jump(self):  print('finally_jump')\n",
    "\n",
    "class Inner(Loop):\n",
    "    call_on=L(Outer.on_step,Outer.after_step,Outer.finally_jump)\n",
    "    \n",
    "    @event\n",
    "    def before_iteration(self) : print('before_iteration')\n",
    "    @event\n",
    "    def on_iteration(self)     : print('on_iteration')\n",
    "    @event\n",
    "    def after_iteration(self)  : print('after_iteration')\n",
    "    @event\n",
    "    def failed_iteration(self) : print('failed_iteration')\n",
    "    @event\n",
    "    def finally_iteration(self): print('finally_iteration')\n",
    "    \n",
    "    def thingy(self): pass\n",
    "\n",
    "class FailingInner(Loop):\n",
    "    call_on=L(Inner.finally_iteration)\n",
    "    \n",
    "    @event\n",
    "    def on_force_fail(self):                    \n",
    "        print('on_force_fail')\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
