{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fastai.data.loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "import logging\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.graph import traverse\n",
    "# Local modules\n",
    "from fastrl.fastai.data.pipes.demux import *\n",
    "from fastrl.fastai.data.pipes.mux import *\n",
    "\n",
    "_logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Loop\n",
    "> Customizable loop API for fastrl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84e24d-a82a-464a-9412-1ab8de544af6",
   "metadata": {},
   "source": [
    "so we need loops within loops posibly. Or do they need to be loops? maybe they need to \n",
    "just be sections? do we even need sections? I wonder if we can leverage the torch data as more \n",
    "of a base... I want to see how far we can get with this....\n",
    "\n",
    "we also need to think about whether this is always iterable or whether we can mix and match\n",
    "map vs iter...\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1f2c63bf-6951-4266-9c66-3ab59dd99d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Callback():\n",
    "    \"A list of data pipes that have an associated job.\"\n",
    "    call_on = L()\n",
    "    exclude_under = L()\n",
    "    do_copy = False\n",
    "    immediate_parents = L()\n",
    "    root_parent = None\n",
    "    \n",
    "    def set_parents(self,immediate_parent):\n",
    "        if immediate_parent is not None: \n",
    "            self.immediate_parents.append(immediate_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f4f0c24d-c8cf-4fcb-8e65-69528ec4aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Loop(dp.iter.IterDataPipe):\n",
    "    \"A datapipe with nesting and callback capabilities.\"\n",
    "    callbacks = L()\n",
    "    \n",
    "    def set_cbs(self,cbs): \n",
    "        self.callbacks = [cb() if isinstance(cb, type) else cb for cb in cbs]\n",
    "        for cb in self.callbacks: cb.set_parents(self)\n",
    "    \n",
    "    def filter_call_on_cbs(self, cbs):\n",
    "        return tuple(cb for cb in cbs if self.__class__ in cb.call_on)\n",
    "    \n",
    "    def __repr__(self): return f'{self.__class__} {self.callbacks}'\n",
    "    \n",
    "    def handle_exeption(self,ex): raise\n",
    "    \n",
    "    def __iter__(self):\n",
    "        try:\n",
    "            for cb in self.callbacks: \n",
    "                getattr(cb,'before_'+self.__class__.__name__.lower(),noop)()\n",
    "            for record in self.__subiter__():\n",
    "            \n",
    "                for cb in self.callbacks: \n",
    "                    getattr(cb,'on_'+self.__class__.__name__.lower(),noop)()\n",
    "                yield record\n",
    "                \n",
    "            for cb in self.callbacks: \n",
    "                getattr(cb,'after_'+self.__class__.__name__.lower(),noop)()\n",
    "        except Exception as e:\n",
    "            for cb in self.callbacks: \n",
    "                getattr(cb,'failed_'+self.__class__.__name__.lower(),noop)()\n",
    "            self.handle_exeption(e)\n",
    "        finally:\n",
    "            for cb in self.callbacks: \n",
    "                getattr(cb,'finally_'+self.__class__.__name__.lower(),noop)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9d840592-3d7d-4db2-ba26-15117517f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def filter_exclude_under_cbs(\n",
    "    pipe:Union[Loop,dp.iter.IterDataPipe], \n",
    "    cbs:List[Callback]\n",
    "):\n",
    "    cbs = tuple(cb for cb in cbs if pipe.__class__  not in cb.exclude_under)\n",
    "    for v in traverse(pipe).values():\n",
    "        for k,_ in v.items():\n",
    "            cbs = filter_exclude_under_cbs(k,cbs)\n",
    "    return cbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "45f538e5-fd74-45da-bde8-5399d7bc1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iterationer(Loop):\n",
    "        \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    \n",
    "    def __subiter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe:\n",
    "            # xb,yb = next(self.source_datapipe)\n",
    "            # pred = self.kwargs['model'](xb)\n",
    "            # loss_grad = self.kwargs['loss_grad']\n",
    "            # opt = self.kwargs['opt']\n",
    "            # loss_func = self.kwargs['loss_func']\n",
    "            # if len(yb):\n",
    "            #     loss_grad = self.loss_func(pred, *yb)\n",
    "            #     loss = loss_grad.clone()\n",
    "            # self('after_loss')\n",
    "            # if not self.training or not len(yb): return\n",
    "            # self('before_backward')\n",
    "            # loss_grad.backward()\n",
    "            # opt.step()\n",
    "            # opt.zero_grad()\n",
    "            # yield loss.detach()\n",
    "            yield 0.5\n",
    "\n",
    "class Batcher(Loop):\n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __subiter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe:\n",
    "            yield element\n",
    "        \n",
    "class Trainer(Loop):\n",
    "        \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __subiter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe:\n",
    "            yield element\n",
    "                \n",
    "class Validater(Loop):\n",
    "        \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __subiter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe:\n",
    "            yield element\n",
    "               \n",
    "class Epocher(Loop):\n",
    "    def __init__(self, source_datapipes:tuple, **kwargs) -> None:\n",
    "        test_eq(type(source_datapipes), tuple)\n",
    "        self.source_datapipes = source_datapipes\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __subiter__(self) -> Iterator[T_co]:\n",
    "        for element in zip(*self.source_datapipes):\n",
    "            yield element\n",
    "                \n",
    "class Fitter(Loop):\n",
    "    def __init__(self,iterable):\n",
    "                \n",
    "        trainer,validater = Trainer(iterable),Validater(iterable)\n",
    "        train_b, valid_b = Batcher(trainer),Batcher(validater)\n",
    "        train_it,valid_it = Iterationer(train_b),Iterationer(valid_b)\n",
    "        self.epocher = dp.iter.Zipper(train_it,valid_it)\n",
    "        self.source_datapipe = self.epocher\n",
    "            \n",
    "    def __subiter__(self):\n",
    "        for epoch in self.source_datapipe: \n",
    "            yield epoch\n",
    "\n",
    "        \n",
    "class TrainerCallback(Callback):\n",
    "    \"A list of data pipes that have an associated job.\"\n",
    "    call_on=L(Trainer)\n",
    "    exclude_under=L()\n",
    "    \n",
    "    def on_trainer(self): print('on_trainer')\n",
    "    \n",
    "class IterCallback(Callback):\n",
    "    \"A list of data pipes that have an associated job.\"\n",
    "    call_on=L(Iterationer)\n",
    "    exclude_under=L(Validater)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a17f7d84-937e-406f-b50a-6ac48aac13f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def default_constructor(\n",
    "    datapipe:Union[Loop,Dict], \n",
    "    cbs:List[Callback],\n",
    "    _outer=True\n",
    "):\n",
    "    if _outer and issubclass(datapipe.__class__,Loop):\n",
    "        for cb in cbs: cb.root_parent=datapipe\n",
    "    d = datapipe if isinstance(datapipe,dict) else traverse(datapipe)\n",
    "    \n",
    "    for k,v in d.items():\n",
    "        if issubclass(k.__class__,Loop): \n",
    "            filtered_cbs = k.filter_call_on_cbs(cbs)\n",
    "            _logger.info('Given loop: %s, found callbacks: %s',k.__class__,filtered_cbs)\n",
    "            kept_cbs = filter_exclude_under_cbs(k,filtered_cbs)\n",
    "            _logger.info('Given loop: %s, filtered callbacks: %s',k.__class__,kept_cbs)\n",
    "            kept_cbs = [copy(cb) if cb.do_copy else cb for cb in kept_cbs]\n",
    "            k.set_cbs(kept_cbs)\n",
    "        if not v: continue\n",
    "        default_constructor(v, cbs, _outer=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e14bf4db-165c-455d-a76b-577c5c0c2a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Given loop: <class '__main__.Fitter'>, found callbacks: ()\n",
      "INFO:root:Given loop: <class '__main__.Fitter'>, filtered callbacks: ()\n",
      "INFO:root:Given loop: <class '__main__.Iterationer'>, found callbacks: (<class '__main__.IterCallback'>,)\n",
      "INFO:root:Given loop: <class '__main__.Iterationer'>, filtered callbacks: (<class '__main__.IterCallback'>,)\n",
      "INFO:root:Given loop: <class '__main__.Batcher'>, found callbacks: ()\n",
      "INFO:root:Given loop: <class '__main__.Batcher'>, filtered callbacks: ()\n",
      "INFO:root:Given loop: <class '__main__.Trainer'>, found callbacks: (<class '__main__.TrainerCallback'>,)\n",
      "INFO:root:Given loop: <class '__main__.Trainer'>, filtered callbacks: (<class '__main__.TrainerCallback'>,)\n",
      "INFO:root:Given loop: <class '__main__.Iterationer'>, found callbacks: (<class '__main__.IterCallback'>,)\n",
      "INFO:root:Given loop: <class '__main__.Iterationer'>, filtered callbacks: ()\n",
      "INFO:root:Given loop: <class '__main__.Batcher'>, found callbacks: ()\n",
      "INFO:root:Given loop: <class '__main__.Batcher'>, filtered callbacks: ()\n",
      "INFO:root:Given loop: <class '__main__.Validater'>, found callbacks: ()\n",
      "INFO:root:Given loop: <class '__main__.Validater'>, filtered callbacks: ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"{<class '__main__.Fitter'> []: {<torch.utils.data.datapipes.iter.combining.ZipperIterDataPipe object at 0x7ff07bd51a90>: {<class '__main__.Iterationer'> [<__main__.IterCallback object at 0x7ff07bd51410>]: {<class '__main__.Batcher'> []: {<class '__main__.Trainer'> [<__main__.TrainerCallback object at 0x7ff07bd5b3d0>]: {}}}, <class '__main__.Iterationer'> []: {<class '__main__.Batcher'> []: {<class '__main__.Validater'> []: {}}}}}}\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_pipe = Fitter([1,2,3,4,5,6])\n",
    "\n",
    "default_constructor(\n",
    "    base_pipe,\n",
    "    [TrainerCallback,IterCallback]\n",
    ")\n",
    "str(traverse(base_pipe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "598dee65-2600-40d0-a8b9-55bd77e87786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_trainer\n",
      "on_trainer\n",
      "on_trainer\n",
      "on_trainer\n",
      "on_trainer\n",
      "on_trainer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.5, 0.5), (0.5, 0.5), (0.5, 0.5), (0.5, 0.5), (0.5, 0.5), (0.5, 0.5)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(base_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c64d0-f9c6-4432-82f8-c171840afc55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
