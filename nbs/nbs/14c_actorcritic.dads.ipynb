{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp actorcritic.dads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import torch.nn.utils as nn_utils\n",
    "from fastai.torch_basics import *\n",
    "import torch.nn.functional as F\n",
    "from fastai.data.all import *\n",
    "from fastai.basics import *\n",
    "from dataclasses import field,asdict\n",
    "from typing import List,Any,Dict,Callable\n",
    "from collections import deque\n",
    "import gym\n",
    "import torch.multiprocessing as mp\n",
    "from torch.optim import *\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from fastrl.data import *\n",
    "from fastrl.async_data import *\n",
    "from fastrl.basic_agents import *\n",
    "from fastrl.learner import *\n",
    "from fastrl.metrics import *\n",
    "from fastai.callback.progress import *\n",
    "from fastrl.ptan_extension import *\n",
    "from fastrl.actorcritic.sac import *\n",
    "from fastrl.actorcritic.diayn import *\n",
    "import gym\n",
    "from torch.distributions import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "from nbdev.export2html import *\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DADS\n",
    "\n",
    "> Dynamics-Aware Unsupervised Discovery of Skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Warning: This is a partial-working version of DADS, HOWEVER a full implimentation will require a meta learner to be env agnostic. This is due to the planner needing to \n",
    "    know whether certain predicted states are more valuable than others so that it can select the right skill. Their implimenation uses GoalEnvs as opposed \n",
    "to regular envs which, is not very portable. I think after the refactor, I will use a DQN for DIAYN and DADS instead. \n",
    "I can have it so that if a goal env IS in fact being used, then it can ignore the meta learner and use the compute reward directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM\n",
    "> A neural net with a gaussian probability distribution component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Mixture Models parameterized by neural nets can be used for:\n",
    "- Giving the probability that a given `state` + `action` will result in `next_state`\n",
    "- Predict what the `next_state` will look like given a `state` + `action`\n",
    "\n",
    "Hopefully from the list above, it is understandable *why* a GMM can be useful.\n",
    "Since it has a probabilistic component, you can avoid instances of (easily) overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "class OptionalClampLinear(Module):\n",
    "    def __init__(self,num_inputs,state_dims,fix_variance:bool=False,\n",
    "                 clip_min=0.3,clip_max=10.0):\n",
    "        \"Linear layer or constant block used for std.\"\n",
    "        store_attr()\n",
    "        if not self.fix_variance: self.fc=nn.Linear(self.num_inputs,self.state_dims)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        if self.fix_variance: return torch.full((x.shape[0],self.state_dims),1.0)\n",
    "        else:                 return torch.clamp(nn.Softplus()(self.fc(x)),self.clip_min,self.clip_max)\n",
    "\n",
    "class MultiCompGMM(Module):\n",
    "    def __init__(self,num_inputs,state_dims,n_components,fix_variance:bool=False):\n",
    "        \"Multi-component GMM parameterized by a fully connected layer with optional std layer.\"\n",
    "        store_attr()\n",
    "        self.logit_fc=nn.Linear(self.num_inputs,self.n_components)\n",
    "        self.mean_fcs=nn.ModuleList([nn.Linear(self.num_inputs,self.state_dims) \n",
    "                                     for _ in range(self.n_components)])\n",
    "        self.std_fcs=nn.ModuleList([OptionalClampLinear(self.num_inputs,self.state_dims,fix_variance) \n",
    "                                    for _ in range(self.n_components)])\n",
    "        self.means,self.logits,self.stds=[],[],[]\n",
    "    \n",
    "    def forward(self,x):\n",
    "        self.means=torch.stack([o(x) for o in self.mean_fcs],dim=1)\n",
    "        self.stds=torch.stack([o(x) for o in self.std_fcs],dim=1)\n",
    "        self.logits=self.logit_fc(x)\n",
    "        return MixtureSameFamily(\n",
    "            mixture_distribution=Categorical(self.logits),\n",
    "            component_distribution=Independent(Normal(self.means,self.stds),1)\n",
    "        )\n",
    "    \n",
    "class SimpleGMM(Module):\n",
    "    def __init__(self,num_inputs,state_dims,fix_variance:bool=False):\n",
    "        \"Single-component GMM parameterized by a fully connected layer with optional std layer.\"\n",
    "        store_attr()\n",
    "        self.mean_fc=nn.Linear(self.num_inputs,self.state_dims)\n",
    "        self.std_fc=OptionalClampLinear(self.num_inputs,self.state_dims,fix_variance)\n",
    "        \n",
    "    def forward(self,x): return Independent(Normal(self.mean_fc(x),self.std_fc(x)),1)\n",
    "\n",
    "class GMM(Module):\n",
    "    def __init__(self,num_inputs,state_dims,n_components,fix_variance:bool=False):\n",
    "        \"N-component GMM parameterized by fully connected layers with optional std layers.\"\n",
    "        store_attr()\n",
    "        if self.n_components>1: self.distribution=MultiCompGMM(num_inputs,state_dims,n_components,fix_variance)\n",
    "        else:                   self.distribution=SimpleGMM(num_inputs,state_dims,fix_variance)\n",
    "        \n",
    "    def forward(self,x): return self.distribution(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GMM is going to try to predict the next state. So lets make a simple input to optimize against.\n",
    "This test will be of a hot airballoon. Lets see if we can have a reasonable next state prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABHm0lEQVR4nO3dd1xUV9rA8d+hiYKiiB0Q7CIKSrHXaGxJTIy9xBJj2ZhN3I0b901PTNvU1SRqEktiwZpE15ZmTaxYoxgLqIhdUASRft4/LiAqKgMzzADP9/MhYWbuvefhgs/cOfec5yitNUIIIUo+O2sHIIQQomhIwhdCiFJCEr4QQpQSkvCFEKKUkIQvhBClhCR8IYQoJcyS8JVSc5RSl5RSh+7xulJKTVNKnVBKHVRKtTBHu0IIIfLPXFf484Ae93m9J1A/62ssMMNM7QohhMgnsyR8rfUWIO4+m/QBvtOGHUBFpVQNc7QthBAifxyKqJ1awJlcj2Oynjt/v508PDy0j4+PBcMSQoiSZc+ePVe01lXyeq2oEr7K47k8azoopcZidPvg7e1NeHi4JeMSQogSRSl1+l6vFdUonRjAK9djT+BcXhtqrb/SWgdrrYOrVMnzTUoIIUQBFFXCXwU8lTVapxUQr7W+b3eOEEII8zJLl45SKgzoBHgopWKA1wFHAK31TGAt0As4ASQBo8zRrhBCiPwzS8LXWg9+wOsaeNYcbQkhLCctLY2YmBiSk5OtHYp4AGdnZzw9PXF0dMz3PkV101YIUQzExMRQvnx5fHx8UCqvsRbCFmitiY2NJSYmBl9f33zvJ6UVhBA5kpOTqVy5siR7G6eUonLlyiZ/EpOEL4S4jST74qEgv6cSmfBnHZjFkdgj1g5DCFEA77zzDk2aNKFZs2YEBgayc+dOAD777DOSkpJMPt68efM4d+7WKPAxY8YQERFhk7FaWolL+PEp8Sw/vpwR60fw6+lfrR2OEMIE27dvZ/Xq1ezdu5eDBw/y66+/4uVlTOEpSBLNyMi4K+F/8803+Pn52VysRaHEJXy3Mm6E9Q6jfqX6TNo0iVkHZiELtQtRPJw/fx4PDw/KlCkDgIeHBzVr1mTatGmcO3eOzp0707lzZwAmTJhAcHAwTZo04fXXX885ho+PD2+99Rbt2rUjLCyM8PBwhg4dSmBgIDdv3qRTp045M/hdXV15+eWXCQgIoFWrVly8eBGAyMhIWrVqRUhICK+99hqurq6FivXnn3+mdevWtGjRgv79+5OYmJgT60svvURoaCihoaGcOHHCQmc2i9baZr+CgoJ0QSWnJ+spW6Zo/3n+evLmyfpm2s0CH0uI0iIiIsKq7SckJOiAgABdv359PWHCBL1p06ac12rXrq0vX76c8zg2NlZrrXV6erru2LGjPnDgQM52H3zwQc52HTt21Lt3787zMaBXrVqltdZ68uTJ+u2339Zaa927d2+9aNEirbXWM2bM0C4uLgWO9fLly7p9+/Y6MTFRa631+++/r998882c7aZOnaq11vrbb7/VvXv3Nul85fX7AsL1PXJqiR2WWca+DO+2e5e6Fesybe80YhJi+G/n/1KlnJRrECI/3vzfYSLOXTfrMf1qVuD1R5vc83VXV1f27NnD1q1b2bhxIwMHDuT9999n5MiRd227dOlSvvrqK9LT0zl//jwRERE0a9YMgIEDB+YrHicnJx555BEAgoKC+OWXXwCju+bHH38EYMiQIbz44osFjnXHjh1ERETQtm1bAFJTU2ndunXO64MHD875/6RJk/IVd0GV2IQPxl3sMU3HUMetDlO2TmHQmkFM7zIdv8qF778TQliGvb09nTp1olOnTjRt2pRvv/32riR68uRJPvroI3bv3k2lSpUYOXLkbUMUXVxc8tWWo6NjzmgXe3t70tPTzR6r1ppu3boRFhaW5zFyj7ax9AipEp3ws3Xx7sL8nvN5bsNzjFg3gnfavcPDPg9bOywhbNr9rsQt5ejRo9jZ2VG/fn0A9u/fT+3atQEoX748CQkJeHh4cP36dVxcXHBzc+PixYusW7eOTp065XnM7P1M0apVK1asWMHAgQNZvHhxoWJt1aoVzz77LCdOnKBevXokJSURExNDgwYNAFiyZAlTpkxhyZIlt135W0KpSPgADd0bsqj3IiZtnMQ/N/+Tv8X/jfHNxsuYYyFsSGJiIs899xzXrl3DwcGBevXq8dVXXwEwduxYevbsSY0aNdi4cSPNmzenSZMm1KlTJ6e7JC8jR45k/PjxlC1blu3bt+crjs8++4xhw4bx8ccf07t3b9zc3AoV67x58xg8eDApKSkATJ06NSfhp6Sk0LJlSzIzM+/5KcBclLbhESzBwcHa3PXwUzNSeXP7m6yKXEV3n+683fZtyjqUNWsbQhRXR44coXHjxtYOw+qSkpIoW7YsSikWL15MWFgYK1euNHs7Pj4+hIeH4+HhUaD98/p9KaX2aK2D89q+1FzhZ3Oyd2Jq26nUq1iPT/d8mnMzt5pLNWuHJoSwEXv27GHixIloralYsSJz5syxdkhmUeoSPhg3Rkb5j8LXzZeXtrzE4DWDmdZlGv4e/tYOTQhhA9q3b8+BAwcs3s6pU6cs3kZuJW7ilSk6eXVifq/5ONk7MXL9SNafXG/tkIQQwmJKdcIHaFCpAYt6L6JJ5SZM3jKZz/d9TqbOtHZYQghhdqU+4QO4O7vzzcPf8Hi9x5l1cBYvbn6RpDTbq4MhhBCFIQk/i6O9I2+1eYsXg1/k19O/MnL9SC7cuGDtsIQQwmwk4eeilGJEkxF8/tDnRCdEM3jNYA5ePmjtsIQodX744QeUUvz111/33e7OqpS9evXi2rVrFo6u+JKEn4cOnh1Y0HMBZezLMGr9KNZErbF2SEKUKmFhYbRr1+6es1yz3Znw165dS8WKFS0cXfElCf8e6lWqR1jvMJpWacqUrVOYtnea3MwVoggkJibyxx9/MHv27JyEn5GRwYsvvkjTpk1p1qwZ06dPz7MMsY+PD1euXAHgk08+wd/fH39/fz777DPAGAbZuHFjnnnmGZo0acLDDz/MzZs3rfJzWkOpHIefX5WcK/F1t695Z+c7fP3n10TFR/Fuu3cp51jO2qEJUWL9+OOP9OjRgwYNGuDu7s7evXvZuXMnJ0+eZN++fTg4OBAXF4e7uzuffPIJGzduvGum6p49e5g7dy47d+5Ea03Lli3p2LEjlSpV4vjx44SFhfH1118zYMAAVqxYwbBhw6z00xYtsyR8pVQP4L+APfCN1vr9O153AxYA3lltfqS1nmuOti3N0d6R11u/Tr2K9fgw/EOeWvcU07tMp4ZrDWuHJoRlrZsCF/407zGrN4We7993k7CwMF544QUABg0aRFhYGFFRUYwfPx4HByNlubu73/cYv//+O0888URO1cy+ffuydetWHnvsMXx9fQkMDASMkshFPfnJmgqd8JVS9sAXQDcgBtitlFqltc69aOSzQITW+lGlVBXgqFJqodY6tbDtFwWlFMP8huHj5sPkzZMZvGYwn3X+jMCqgdYOTYgSJTY2lg0bNnDo0CGUUmRkZKCUIigoyKRCh/erEZa9QhUY5Y2lS8c0ocAJrXUUgFJqMdAHyJ3wNVBeGb8xVyAOMK3wtA1oV6sdC3stZOKGiYz+aTRvtnmTR+s+au2whLCMB1yJW8Ly5ct56qmnmDVrVs5zHTt2pEWLFsycOZNOnTrd1qWTuwxxbh06dGDkyJFMmTIFrTU//PAD8+fPL+ofx+aY46ZtLeBMrscxWc/l9jnQGDgH/Ak8r3XxvANap2IdFvVaRGDVQP7v9//j0z2fys1cIcwkLCyMJ5544rbnnnzySc6dO4e3tzfNmjUjICCARYsWAbfKEGfftM3WokULRo4cSWhoKC1btmTMmDE0b968yH4OW1Xo8shKqf5Ad631mKzHw4FQrfVzubbpB7QF/gHUBX4BArTWd62fppQaC4wF8Pb2Djp9+nSh4rOUtMw03tv5HsuOLaOTVyfeb/8+Lo75W2VHCFsl5ZGLF1PLI5vjCj8G8Mr12BPjSj63UcD3WWvsngBOAo3yOpjW+iutdbDWOrhKFdtdf9bRzpFXW73KlNApbInZwvB1wzmXeOePLYQQtsMcCX83UF8p5auUcgIGAavu2CYaeAhAKVUNaAhEmaFtq1JKMbTxUGY8NIMLiRcYvGYw+y7ts3ZYQgiRp0InfK11OjAR+Ak4AizVWh9WSo1XSo3P2uxtoI1S6k/gN+AlrfWVwrZtK9rUasPC3gsp71Sep396mpUnzL8yjhBCFJZZxuFrrdcCa+94bmau788BJXrVcF83Xxb2Wsg/N/+TV/54hchrkTzf4nns7eytHZoQQgBSWsGs3Mq4MaPrDAY2HMjcw3N5fuPz3Ei7Ye2whBACkIRvdo52jrzS6hVebvkyv5/9nWFrhxGTEGPtsIQQQhK+pQxqNIiZ3WZyKekSQ9YMYc/FPdYOSYhiwd7ensDAQPz9/Xn00UfNXu44u8DatWvX+PLLL3OeP3fuHP369TNLGxcvXuSRRx4hICAAPz8/evXqBRjF27LnEFiDJHwLalWjFYt6L8KtjBtjfh7DD8d/sHZIQti8smXLsn//fg4dOoS7uztffPGFRdq5M+HXrFmT5cuXm+XYr732Gt26dePAgQNERETw/vvGrGVJ+BZw6XryfWtpFKXaFWqzoNcCQqqF8Nq21/hw94dkZGZYOywhioXWrVtz9uxZACIjI+nRowdBQUG0b98+Z3GUZcuW4e/vT0BAAB06dABg3rx5TJw4Mec4jzzyCJs2bbrt2FOmTCEyMpLAwEAmT57MqVOn8Pf3z9m/b9++9OjRg/r16/Ovf/0rZ7/Zs2fToEEDOnXqxDPPPHNbO9nOnz+Pp6dnzuNmzZrltLl161YCAwP59NNPycjIYPLkyYSEhNCsWbOckhKbNm2iQ4cOPPHEE/j5+TF+/HgyM80wo19rbbNfQUFB2lRxiSm61bu/6n8s2a9T0zNM3t9S0jLS9Ls73tX+8/z1+F/G6+sp160dkhB3iYiIsHYI2sXFRWutdXp6uu7Xr59et26d1lrrLl266GPHjmmttd6xY4fu3Lmz1lprf39/HRMTo7XW+urVq1prrefOnaufffbZnGP27t1bb9y4UWutde3atfXly5f1yZMndZMmTXK2yf147ty52tfXV1+7dk3fvHlTe3t76+joaH327Fldu3ZtHRsbq1NTU3W7du1uayfb+vXrtZubm+7UqZOeOnWqPnv2rNZa640bN+revXvnbDdr1iz99ttva621Tk5O1kFBQToqKkpv3LhRlylTRkdGRur09HTdtWtXvWzZsrvayev3BYTre+TUElcPv2I5RwaFePPpr8eIvZHCF0Na4FLG+j+mg50D/275b+pWrMt7O99j2NphfN7lc7wqeD14ZyGs4INdH/BX3P2XGDRVI/dGvBT60n23uXnzJoGBgZw6dYqgoCC6detGYmIi27Zto3///jnbpaSkANC2bVtGjhzJgAED6Nu3r9lifeihh3BzcwPAz8+P06dPc+XKFTp27JhTnrl///4cO3bsrn27d+9OVFQU69evZ926dTRv3pxDhw7dtd3PP//MwYMHc7qS4uPjOX78OE5OToSGhlKnTh0ABg8ezO+//17oewwlrktHKcXzXevzft+mbDl2mSFf7yA2McXaYeUY0HAAs7rN4srNKwxeO5jdF3ZbOyQhbEp2H/7p06dJTU3liy++IDMzk4oVK7J///6cryNHjgAwc+ZMpk6dypkzZwgMDCQ2NhYHB4fbukCSk5NNjuPOMsrp6ekmdRW7u7szZMgQ5s+fT0hICFu2bLlrG60106dPz/mZTp48ycMPG1OW7iwHbUp56Hux/qWvhQwK9cbDtQwTw/by5IxtfDe6Jd6VbWOlqtAaoYT1DmPihomM/XksL7d6mX4NzDM6QAhzedCVuKW5ubkxbdo0+vTpw4QJE/D19WXZsmX0798frTUHDx4kICCAyMhIWrZsScuWLfnf//7HmTNn8PHx4csvvyQzM5OzZ8+ya9euu46fXVrZFKGhoUyaNImrV69Svnx5VqxYQdOmTe/absOGDbRq1Ypy5cqRkJBAZGQk3t7e2NnZ3dZm9+7dmTFjBl26dMHR0ZFjx45Rq5ZRbHjXrl2cPHmS2rVrs2TJEsaOHWviGbxbibvCz62rXzUWjmnFtZtp9J2xjUNn460dUg7vCt4s7LWQljVb8ub2N/lg1wekZxa7JQKEsKjmzZsTEBDA4sWLWbhwIbNnzyYgIIAmTZqwcqVRwmTy5Mk0bdoUf39/OnToQEBAAG3btsXX15emTZvy4osv0qJFi7uOXblyZdq2bYu/vz+TJ0/OVzy1atXi//7v/2jZsiVdu3bFz88vp9sntz179hAcHEyzZs1o3bo1Y8aMybkx6+DgQEBAAJ9++iljxozBz8+PFi1a4O/vz7hx40hPN/JA69atmTJlCv7+/vj6+t5VNrogCl0e2ZKCg4N1eHh4oY9z4lIiI+bs4lpSKjOHB9G+vu1U4UzPTOfj8I9ZcGQBbWu25cOOH1Leqby1wxKllJRHfrDExERcXV1JT0/niSeeYPTo0WZJxrlt2rSJjz76iNWrV993O2uUR7Z59aq68v3f2uDlXo5Rc3fz476z1g4ph4OdAy+FvsQbrd9g5/mdDF07lOjr0dYOSwhxD2+88UbOxDBfX18ef/xxa4eUb6XiCj/b9eQ0xn4Xzo6oOF7u1ZhnOtQx27HNYfeF3fxj0z/I1Jl80ukTWtZoae2QRCkjV/jFi1zh30cFZ0e+HR1K72Y1eGftEd5eHUFmpu284YVUD2FR70VUKVuF8b+MZ+nRpdYOSQhRgpSqhA9QxsGe6YOaM7KND7N/P8nzS/aTkm47M1+9ynuxoNcCWtdszds73ubdne/KzVxRpGz5U7+4pSC/p1KX8AHs7BSvP+rHlJ6N+N+Bc4yau5uE5DRrh5XD1cmV6V2mM8JvBGF/hTHh1wnEp9jOCCNRcjk7OxMbGytJ38ZprYmNjcXZ2dmk/UpVH35evt8bw7+WH6R+tfJ8OyqEqhVMO4GW9sPxH3hrx1t4unoyvct0fNx8rB2SKMHS0tKIiYkp0EQlUbScnZ3x9PTE0dHxtufv14df6hM+wOZjl5mwYA/uLk58OzqUulVcLd6mKfZc3MOkjZNI1+l83PFjWtdsbe2QhBA2Sm7aPkDHBlVYPLYVN1Mz6DdjG/uir1o7pNsEVQtiUe9FVCtXjQm/TiDsrzBrhySEKIYk4Wdp5lmRFRPaUKGsI4O/3sGGvy5aO6TbeJb3ZEGvBbSv1Z53d77L1B1TScu0nfsOQgjbJwk/Fx8PF5aPb0P9quV55rs9LN19xtoh3cbF0YXPOn/GKP9RLDm6hAm/yM1cIUT+ScK/Q5XyZVg8thVt6lbmXysOMv234zY1YsHezp5/BP2DqW2nsvfSXoasGUJUfJS1wxJCFAOS8PPgUsaB2SNC6Nu8Fh//coxXVx4iw4YmaAH0qdeHOd3nkJiWyLA1w9h2dpu1QxJC2DizJHylVA+l1FGl1Aml1JR7bNNJKbVfKXVYKbXZHO1akpODHR8PCGB8x7os2BHN3xbuITnNdiZoAQRWDSSsdxg1XGsw4bcJLDyy0KY+jQghbEuhE75Syh74AugJ+AGDlVJ+d2xTEfgSeExr3QTof+dxbJFSiik9G/HaI378HHGR4bN3Ep9kWzdKa7rWZH7P+XT07Mj7u97nrR1vyc1cIUSezHGFHwqc0FpHaa1TgcVAnzu2GQJ8r7WOBtBaXzJDu0VmdDtfpg9uzoEz8fSftY1z125aO6TblHMsx2edP+Np/6dZfmw5434Zx7Xka9YOSwhhY8yR8GsBuYezxGQ9l1sDoJJSapNSao9S6ikztFukHmlWk3mjQzh/LZm+X27j2EXTVsqxNDtlxwtBL/Buu3c5cOkAg9cMJvJapLXDEkLYEHMk/LwWWryzI9kBCAJ6A92BV5VSDfI8mFJjlVLhSqnwy5cvmyE882lT14Ml41qTqTX9Zmxj18k4a4d0l0frPsqcHnO4mX6TYWuHsTVmq7VDEkLYCHMk/BjAK9djT+BcHtus11rf0FpfAbYAAXkdTGv9ldY6WGsdXKWK7axMlc2vZgW+/1sbPMqXYdjsnaw/dN7aId0loEoAYb3D8CzvycQNE/nu8HdyM1cIYZaEvxuor5TyVUo5AYOAVXdssxJor5RyUEqVA1oCR8zQtlV4VirHivFtaFKzAhMW7mX+9lPWDukuNVxr8G2Pb+ns1ZkPwz/kje1vkJYhN3OFKM0KnfC11unAROAnjCS+VGt9WCk1Xik1PmubI8B64CCwC/hGa32osG1bUyUXJxaNaUWXhlV5deVhPvrpqM1dRZdzLMcnnT5hbLOxfH/8e8b8PIa4ZNvrhhJCFA2plllI6RmZvPLjIRbvPsOAYE/efaIpDva2N59tTdQaXvvjNaqUq8L0LtOpX6m+tUMSQliAVMu0IAd7O97r25S/P1SfpeExjJ2/h6RU21uhqned3sztMZeUjBSGrR3Glpgt1g5JCFHEJOGbgVKKf3RrwDtP+LPp6CUGf72TuBup1g7rLs2qNCOsdxi1K9Rm4m8TmXdons11QwkhLEcSvhkNbVmbGcOC+Ov8dfrN2MaZuCRrh3SX6i7VmddjHl1rd+XjPR/z2rbXSM2wvTcnIYT5ScI3s+5NqrNwTEtib6TSd8Y2Dp21vfLF5RzL8VHHjxgfMJ4fT/zImJ/HEHsz1tphCSEsTBK+BQT7uLN8fGsc7RSDvtrBHyeuWDuku9gpO54NfJYPO3xIRGwEkzZNIlNnWjssIYQFScK3kPrVyrPib22oVbEsI+fuYuX+s9YOKU89fHvwaqtX2XdpH0uPLrV2OEIIC5KEb0E13MqydHxrmntX4vnF+/lmq20uVPJY3cdoXaM1n+39jAs3Llg7HCGEhUjCtzC3so58NzqUnv7VmbrmCO+siSDTxhZTUUrxWuvXyNSZTN0xVUbuCFFCScIvAs6O9nw+pAVPta7N11tPMmnpflLTbau/3LO8J88GPsvmmM2sP7Xe2uEIISxAEn4RsbdTvPlYEyZ3b8jK/ecYPW83iSm2NUFrWONh+Ff25/1d70s9fSFKIEn4RUgpxbOd6/Fhv2Zsj4pl4KztXEpItnZYOezt7HmjzRtcT7nOh+EfWjscIYSZScK3gv7BXnwzIpioyzd4csY2Tl65Ye2QcjR0b8go/1GsilwlC6MLUcJIwreSzg2rEja2FTdSMnhyxjb2n7lm7ZByjAsYh08FH97a8RZJabY3W1gIUTCS8K0o0KsiKya0waWMPYO/2sHGo7ax1G8Z+zK80eYNziae5fP9n1s7HCGEmUjCtzJfDxdWTGhDnSoujPk2nGXhZx68UxEIqhbEwIYDWXhkIX9e/tPa4QghzEASvg2oWt6ZJeNa07pOZSYvP8gXG0/YxFj4F1q8gEdZD17f/rqsliVECSAJ30a4lnFgzsgQ+gTW5MOfjvL6qsNkWHmClquTK6+0fIXjV48z59Acq8YihCg8Sfg2xMnBjk8HBDK2Qx2+236aiYv2kpyWYdWYOnt3prtPd2YdnEXUNdssDSGEyB9J+DbGzk7xf70a80rvxqw7dIGn5uwi/qZ1u1OmhE6hrENZ3tj+hlTUFKIYk4Rvo8a0r8N/BwWyL/oqA2Zu53z8TavF4lHWg8khk6WiphDFnCR8G9YnsBbzRoVy9tpNnvxyG8cvJlgvlrp9pKKmEMWcJHwb17aeB0vGtSItU9Nv5nbCT8VZJQ6pqClE8WeWhK+U6qGUOqqUOqGUmnKf7UKUUhlKqX7maLe0aFLTje8ntMHdxYmh3+zkp8PWucLOXVHzp1M/WSUGIUqyxNREwi+EW+zflyrslZpSyh44BnQDYoDdwGCtdUQe2/0CJANztNbLH3Ts4OBgHR4eXqj4SpK4G6mMnrebgzHXeKuPP8Na1S7yGDIyMxi2dhjnbpxjZZ+VVHSuWOQxCFESxKfE81fcX0TERnAk9ghH4o5w6vopAFwdXflj8B/YKdOvyZVSe7TWwXm95lCoiA2hwAmtdVRWY4uBPkDEHds9B6wAQszQZqnk7uLEomda8uzCvbzy4yEuJaQwqWt9lFJFFkN2Rc1BqwfxYfiHvNPunSJrW4jiKi45LiepR8RGEBEbwdnEW8ue1nSpSePKjXm07qM0dm9M48qNC5TsH8QcCb8WkLseQAzQMvcGSqlawBNAFyThF0o5Jwe+eiqY//v+T6b9dpxL15OZ+rg/DvZFdzsmu6Lm139+TW/f3rSp1abI2hbC1l1Oumwk9Tjjyj0iNoKLSRdzXvcu742/hz/9G/THr7Ifjd0bF9knZXMk/LwuL+/sJ/oMeElrnfGgq1Gl1FhgLIC3t7cZwit5HO3t+E+/ZlSr4MznG09wOSGFz4e0oKyTfZHFMC5gHL+c/oW3drzF9499TznHckXWthC2QGvNhRsXiIiLuK1b5srNKwAoFD5uPgRXD6axe2P8KvvR0L0hFZwqWC1mc/Thtwbe0Fp3z3r8bwCt9Xu5tjnJrTcGDyAJGKu1/vF+x5Y+/Aebv/0Ur606TKBXRWaPCMHdxanI2t5zcQ8j149kuN9w/hXyryJrV4iiprUmJiEm56r9SNwRjsQe4WrKVQDslT11KtbJSex+lf1oWKmhVS6ELN2Hvxuor5TyBc4Cg4AhuTfQWvvmCmYesPpByV7kz/DWPlQpX4a/L95Pv5nb+HZUKF7uRfNHFlQtiAENBrDwyEJ6+vSkaZWmRdKuEJaUqTM5ff10TndMdnJPSDPmwTjYOVC/Yn26eHfJ6W9vUKkBzg7OVo78wQp9hQ+glOqF0W1jjzEC5x2l1HgArfXMO7adh5HwZZSOGe06GceYb3fj7GjPvFGh+NUsmo+NiamJ9FnZB7cybizpvQRHe8ciaVcIc0jPTOdk/MmcpB4RG8FfcX+RlG4s/ONk50RD94Y5V+6NKzemXsV6ONkX3SdpU93vCt8sCd9SJOGb5tjFBEbM2UVicjqzngqiTV2PIml3Y/RG/r7x70wMnMi4gHFF0qYQpkrLSCMyPjJnlMyRuCMciztGcoaxrnRZh7I0cm+Uc9Xe2L0xdSrWwdGueF3ESMIvRc5du8mIObs4HZvEJwMDeKRZzSJp98XNL7IhegPLH1tOHbc6RdKmEPeSkpHC8avHb0vux68eJy3TKETo6uhKI/dGOVftfu5+1K5QG3u7ohv4YCmS8EuZ+KQ0xny3m/DTV3m1tx+j2/k+eKdCunLzCn1+7EO9ivWY22OuRcYQC5GXpLQkjl09dlt/e+S1SNJ1OgAVnCrcltj9KvvhWd6zxP6NWvqmrbAxbuUcmf90S55fvI+3VkdwMSGZl7o3ws7OchO0sitqvvrHqyw7uoyBjQZarC1ReiWmJvJX3F85E5iOxB7h5PWTOWW73Z3daVy5MR08O+Qk+ZouNYt0cqItk4RfQjk72vPl0CBeX3WIWZujuHQ9hQ+ebIaTg+WuavrU7cOaqDV8uvdTOnp1pLpLdYu1JUq++JT4nCv2I7FHiIiL4PT10zmvVy1XFT93Px72eThnAlPVclUlud+HdOmUcFprvth4go9+Pkb7+h7MGBaEaxnLvc+fSTjDk6ueJLR6KNO7TJd/fCJfsksPZHfL3Kv0QHZib1y5MR5li2ZQQlFLy8jkdOwN6lUtX6D9pUunFFNKMbFLfaqWd+bfP/zJ4K92MGdkCFXKl7FIe17lvXg28Fk+Cv+In079RA/fHhZpRxRfl5Iu5Vyx21rpAWtKSk1n8a4zzP79JGkZmWx9qTNlHMx7E1mu8EuRDX9d5G8L91K1vDPfjQ7Fx8PFIu2kZ6YzbO0wzt84LxU1BVHXolhzcs09Sw9kJ3VbKD1gDVcSU/hu2ym+23Gaa0lphPhUYlyHunRpVLVA991klI7IsS/6KqPn7cZOKeaOCqGZZ0WLtHM07iiDVg+iV51eUlGzFIu8FslT657iRtoNmyk9YCuiY5P4emsUS8PPkJKeSTe/aozvWIeg2u6FOq4kfHGbyMuJjJizi7gbqXw5tAWdGla1SDvT9k7j6z+/ZlbXWVJRsxS6cOMCw9cNJz0zne96fodXeS9rh2QT/oyJZ9aWSNb+eR57O0Xf5p4806EO9aq6muX4kvDFXS5dT2bE3N0cv5jAf/o1o28LT7O3kZKRQr9V/UjLTJOKmqVMfEo8I9eP5PyN88zrMY9G7o2sHZJVaa35/cQVZm6O5I8TsZQv48CQVt6MbutLtQrmrcEjCV/kKSE5jXHz97AtMpYhLb0Z3qo2jWuYt/9UKmqWPsnpyYz7ZRwHrxxkZteZtKzR8sE7lVDpGZms+fM8szZHEXH+OlXLl+Hpdr4MbulNBWfLlGyQUToiT+WdHZk7KoS3V0ewdHcMi3ZGE+BVkcEhXjwaUBMXMwzflIqapUtGZgZTtk5h36V9/KfDf0ptsk9KTWdZeAxfb40i5upN6lZx4T9PNqNP85pmH3ljCrnCFwBcvZHK9/vOsnhXNMcvJeLiZM9jgTUZFOJNM0+3Qo2nT0hN4PGVj0tFzRJOa83UHVNZemwpU0KnMLTxUGuHVOTibqTy7bZTfLf9FFeT0mjhXZHxHevStXE1i850z026dES+aa3ZG32VsF1nWH3wHMlpmTSuUYHBoV70CayFW9mCJWupqFnyzTwwky/2f8Fo/9FMCppk7XCK1Jm4JL7ZGsWS8DMkp2XStXFVxnesS7BP4UbcFIQkfFEg15PTWLn/HIt3RXP43HXKONjRu2kNBoV6E+JTyeSrfqmoWXItP7acN7e/yWN1H2Nq26mlZob1obPxzNoSxZqD57C3U/QJrMW4DnWoX61gs2TNQRK+KLQ/Y+IJ2x3Nqv3nSExJp24VFwaFeNO3RS0qu+Zv1q5U1CyZNkZv5IVNL9CmZhumdZlW7OrHm0przR8nYpm1JZKtx6/gWsaBIS29GdXWhxpuZa0dniR8YT5JqemsPniexbui2Rt9DUd7xcNNqjM4xJs2dSs/sJ/yxxM/8uofr/JKy1ekomYJsO/SPp75+RnqV6zP7O6zS/TQ2/SMTNYdusCsLZEcOnsdD9cyjG7nw9CWtQvc1WkJkvCFRRy9kMDi3dF8v/cs8TfT8HYvx8AQL/oHeVL1HmOLtdaM/WUsf175kx/7/CgVNYux7Fm0lZwr8V3P73B3Lvr+6qJwMzWD5XvO8PXWk0THJVHHw4WxHerwePNaODva3oIpkvDF3bSG1ERIjofk61C5HjgUbJ3O5LQMfjp8gbBd0eyIisPeTtGlUVUGh3rRsUFV7O+46peKmsVf7lm083vOx7O8+SfuWdvVG6nM33GaedtOEXcjlUAvY8RNN79qd/1N2xIZh19SZWZAynW4eQ2Sr2X9Pz7X91mP83o9OR4y028dq2ZzGLkGnEwvqObsaE+fwFr0CazFySs3WLw7mhV7Yvgl4iI13JzpH+zFgGBPPCsZH/elombxFp8Sz4RfJ5CQmsC8HvNKXLKPuZrEN1tPsmT3GW6mZdClUVXGdahDqK97sb84kSt8a8tIu0dyvnp38r4toccbyZ77/P7sHMC5IpStmOv/brc/5+wGKQnwy6vQoCcMnA9mWNczNT2T345cJGz3GbYevwxAh/pVGBzqxUONq6FUplTULIayZ9H+eeVPZnSdUaImVkWcu85XWyL538HzKKBPYC3GdqhDw+rWG3FTENKlY0laQ9rNByTna/e+2k67cf/jO5S9PTk/KHnnft2xHOT3imTHTFj/ErR6Fnq8a9IpeJAzcUksCz/D0vAYLlxPxsPViSeDPGnZMIV//j5KKmoWExmZGfxz8z/ZEL2B/3T8Dz18iv8nM60126Nimbk5ii3HLuPiZM/gUG9Gt/OlZkXrj7gpCIsnfKVUD+C/gD3wjdb6/TteHwq8lPUwEZigtT7woOMWWcLX2rjKzU9XSF6vZ6Te//hlKtyRnN3yd+VdtiI4WGahkjytewl2zoReH0HoM2Y/fHpGJpuPXSZs1xk2Hr1ERqbGt/5mrjisY3rnL+nk3d7sbQrz0Frz9o63WXZsmemzaFOTIPUGuFaxXIAmysjUrM8acXMwJh4PVydGtfVlWMvauJWznRE3BWHRhK+UsgeOAd2AGGA3MFhrHZFrmzbAEa31VaVUT+ANrfUDPwsWKOFrDef2mZ68sxZBzvuHtLt/wr7nlXclI9nbF5NbJZkZsHgoHP8JBi+GBt0t1tTF68ksCz/D4vAo4ip+gL19Bo9X+YThLRvQwIqTVkTeZhyYwZf7vzR9Fu3NazC3F1w6DFX9oE4n46t2GyhT9L/n5LQMlu8xatycjk3Cp3I5nulQhydbeNrkiJuCsHTCb42RwLtnPf43gNb6vXtsXwk4pLWu9aBjF/gKf2o1SE++/Tl7p4J1izhXBCdXsCslk4RSEmFeL7hyAkavhxrNLNpcZqbm230b+eTQ86RfbcfNC4/Qwrsig0K9eaRZDco5FZM3yxKswLNo05JhQV84swtaPwvnD0D0duPfpp0DeIbcegOoFQQWrLF0LSmV+duNETexN1IJ8HRjfMe6PNykuk2PuCkISyf8fkAPrfWYrMfDgZZa64n32P5FoFH29vdT4IR/4jej/zp38nYsm//+7NLu+nn45iHjU8+Y38Dtge/Nhfb29rdZfmw5/Wp+wMaDzkRdvkH5Mg48FliTwaHe+Ndys3gM4m4FnkWbmQHLRsCR/8GTs6FpP+P5tGQ4sxOiNhlf5/YB2rio8ml36w2gSiOz/Hs9e+0ms7eeZPHuaJJSM+jUsArjOtSlVZ3iP+LmXiyd8PsD3e9I+KFa6+fy2LYz8CXQTmsde4/jjQXGAnh7ewedPn26UPGJArpwCOb0gEo+MHqdxT9+566oubjXYvafSWTxrmjW/HmelPRM/GtVYFCIN30Ca1LeQnXExe0KPItWa1jzDwifAz3eh1YT7r1tUhyc+h2iNhpvAHFRxvOu1W8l/zodoUJNk2L/68J1vtocxaoD59DAYwE1GduhjtnXe7BFNtGlo5RqBvwA9NRaH8vPsYvFKJ2S7MSvsHAA1HsIBoVZ/F5EdkXN55o/x9hmYwGIT0rjx/1nCdsVzV8XEijraM8jzYwCbi28K5bYqzRrK9Qs2k0fwKZ3oe0L0O1N0xq+ehpObs76BLAZkowFz/FoeOsNwKet8en9Dlprdp6MY+bmSDYdvUw5J3sGhXgzup1PzhyQ0sDSCd8B46btQ8BZjJu2Q7TWh3Nt4w1sAJ7SWm/L77El4duA8DmwehKEjDFG71g4wd6roqbWmgMx8SzeFc2qA+dISs2gQTXXnAJuFcsVbJawuNuFGxcYtnYYGTrD9Fm04XNh9QsQMAQe/7Jwfy+ZmcbN3uzun9PbIC0JlL3R55/1BpBRK5if/4pj5pYoDpy5RmUXJ0a28WF469ql8u+iKIZl9gI+wxiWOUdr/Y5SajyA1nqmUuob4Ekgu38m/V4B5SYJ30b8/Cpsmwbd3zVuvllQfipqJqak878DRtnmAzHxODnY0aNJdQaFetG6TmW56i+EQq1Fe2Q1LB0O9brCoEXmvwmbngIxu3PeAPTZPSidyU3KsCOjEYedW1A7tDfdOnbC2an0dvvJxCtROJmZt27ADZwPjR+1aHOmVNSMOHedxbuj+WHfWRKS0/GpXI6BId70C/KkSvkinMNQAhRqFu3p7TD/cajmDyNWFahER37FJ6WxYOdplv1+mPo39/NYhWN0dozANSGr/9+lCvh2vNUFVNHLYrHYIkn4ovDSbsK8R+DiYRi1xvhIbSEFqaiZnJbB2j/Ps3jXGXadisPBTtG1cTUGhXrRvn6VEjf0ztwKNYv2YgTM7WEk2tE/g0tli8R4Pt4YcRO2K5obqRl0aFCF8R3q0Lpu1qe6+LNG/39k1g3gG5eMHd3r3kr+vu2N+TElmCR8YR6Jl4zhmmnJMOZXqFTbYk0VpqLmiUuJLNkdzYq9Z4m7kUqtimUZEOzFgBBPm1igwtYUahbttTMw+2FjCO/TP1vkb+LYxQRmbY5i5f6zaOCRZjUY26EOTWreZ6iu1nDpyK3+/1O/G2VMlB3UCLz1BuDVEhzzLuVdXEnCF+Zz+Sh80w0q1IDRPxnzHCzk28Pf8lH4R3zY4cMCVdRMSc/gl4iLLN51ht9PXMFOQaeGVRkU4kWXRlVxsC8lk+keIHsW7dP+T/NC0Av53zEpzhi6m3AeRq2D6v5mi0lrze5TV5m1OZLf/rqEs6Mdg0K8ebqdL17uBRhxk54KZ/fcegOI2Q06Axycwbv1rTeA6s2K/SRLSfjCvKI2GzMofdrB0OUWmyGZnplutoqa0bFJLAmPZll4DJcSUqhavgz9gz0ZGOyNd+XSM2TvTgWeRZuaBN/1gfP7Ydj3RleJGWRman6OuMisLZHsi76Gu4sTI1obI27cXcw44ib5ujHqJ/sN4PIR4/my7uDbwUj+dTsb81CKGUn4wvz2LYSVf4Pmw+Gx6RYbrnk07iiDVg8yW0XN9IxMNvx1icW7z7Dp6CUyNbStV5lBId483KQaZRxKRj2V/NgQvYFJmyaZPos2Ix2WDIVjP0H/edDk8ULHkpKewQ97z/LVliiirtzAy70sz7SvQ/8gL8o6FcHv5Pp5OLkl6w1go/GpBYyEnzP+v4PF7k+YkyR8YRkbpsKWD+Gh16H9PyzWzLS90/j6z6+Z1W0WbWq2Mdtxz8ffZOnuGJaGn+HstZu4uzjRt3ktBoV6U6+qq9nasUWFmkW7aiLsW2CWqqrxN9NYtDOaOX+c5HJCCk1qVmB8x7r09K9uvS43reHK8Vz9/1uz1p5QRm2p7DcA79ZGyRYbIwlfWIbWsGIMHFoO/eaA/5MWaSYlI4V+q/qRlpnG9499b/aFsjMyNVuPX2bxrjP8euQi6ZmaEJ9KDArxpnezGiWmimK2Qs2i/e1t2PoRdJgMXV4pcAwX4pOZ88dJFu2MJjElnfb1PRjXoS5t69ngPIqMdKPmT/bV/5ldkJkG9mXAu+WtN4AagWZZPKiwJOELy0lLNsZfn90LI/5n/AOwgPAL4Yz6aRRP+T3F5JDJFmkD4HJCCiv2xrB4VzSnYpMo7+zAE81rMSjEG7+axb8OS6Fm0e76Gta+CC2egkenFagb78QlY8TNj/vPkpGp6d2sJuM61ClexfFSEo2qn9mfAC4eMp53drvV/1+nM7jXsUrBRkn4wrJuxMLsrsa6AmN+Nf7QLeDt7W+z/PhyFvZaiL+H+UaE5EVrzY6oOBbvjmbdoQukpmcS4OnGoFBvHg2oiWuZ4le2uVCzaA//CMtGQsOeMGC+yXWVwk/FMXNzFL8euYizox0Dgr0Y065Oybhhnngpq/9/I0RugusxxvNuXkbhtzqdjYlgRbQAjCR8YXmxkcYY/XKV4elfoJwJ3QT5lJCawOM/Po6bsxtLei/B0YL103O7eiOVH/adZfHuaI5dTKSckz1Ncl3ta31rZWGtda7vc604fNfz+tb3WS/orP1zH9d4Xue5jc75z/3aNx5l6lRuuM8gw/E05eImYJ9SL9fx7tWO8X1Q5p9Mz5xKBHX5m91r3MTp7n1ztUse5yMpNYOK5Rx5qrUPI1rXprJrCZ0FrbVR8TO7+ufJLcaFEBizkHMvAGOh2ciS8EXROL3NGKrnGQLDf7DI8ox5VdQsKlpr9kZfY+nuM5yOM9YiVqicT+1KGY+zv8+mVPaz2dvk/Ty59r19+1zPZ7fFrY1U1rFufX/781pncjBtGpcz99LU8VlqOLS6Y5tbx8z9s4Ci+s3jjIucSLxjFb6u9yXJjhVujyfXz3Lr5+WubWp7uPBki1qlb0GbzAxj6Gp290/0DmNJVDtH8Aq99QZQs4XZqtFKwhdF5+Ay+H4MNBsIT8yySB/mvSpqirsVahbt1dMwu5uxOtXTP4ObCf39Im+pSXBmh5H8IzfChYPG82UqZC0A09l4A/CoX+B/O5LwRdHa/CFsnAqd/g2dppj98PmpqCkMBZ5Fe+MKzOkONy4bM6qrNrZYjKXajdhc9f83wrVo4/lKPvDc3gKN+rlfwi9ln69EkejwIlw9CZveM/5wAwaZ9fAeZT2YHDKZV/94lWVHlz2womZptfzYcr7c/yWP1X2M51s8n/8dU2/AogEQHwNPrZRkb0kulcG/r/EFEHfSSP6JFy0yxFMSvjA/peCRz4yrlZUTja4An3ZmbaJP3T6siVrDp3s/paNXx3xV1CxNNkRv4O0db9OuVjveaPNG/se2Z6TB0hHGuPOBC8G7lWUDFbdz9zW+LEQ+CwvLcHAyaue7+8LiocbMRTNSSvFa69fIyMzgnR3vYMtdk0Vt36V9/GvLv/Bz9+Pjjh/nv2SC1rDqOTjxi/GG3aiXReMURU8SvrCcspVg6DLjpt/Cfka/sBl5lfdiYvOJbIrZxE+nfzLrsYurE1dPMPG3iVR3qc4XXb8wbVbyr6/DgTDo/DIEjbBckMJqJOELy6rkA4MXQ8IFCBtsLKRiRkMbD6VJ5Sa8t/M9riVfM+uxi5sLNy4w/tfxONk7MbPrTNNKJmz/Ev74r7F2cQfLzWQW1iUJX1ieV4gxRDNmF/w4wVgy0Uwc7Bx4s82bXE+5zofhH5rtuMVNfEo8E36dQGJaIjO6zjCtZMKfy+Gnf0Pjx6Dnf6xSDkAUDUn4omg0eRy6vQWHf4ANb5v10A3dGzLKfxSrIlex7dw2sx67OEhOT+bvG/7O6eunmdZ5mmklEyI3wA/joXY76Pu1TRT/EpYjCV8UnTZ/h6CR8PsnsOdbsx56XMA4fCr48Nb2t0hKSzLrsW1ZRmYGL215iX2X9vFu+3cJrRGa/53P7YMlw8GjAQxaWOKW+hN3k4Qvio5S0OtjqPsQrJ5kXF2aSRn7Mrze+nXOJp7li/1fmO24tkxrzTs732HDmQ28FPqSaQuPx0XBwv7GCk/DVlh0qUphO8yS8JVSPZRSR5VSJ5RSd02tVIZpWa8fVEq1MEe7ohiydzBWSarSyBjvfTHCbIcOrh7MgAYDWHBkAYeuHDLbcW3VzIMzWXZsGU/7P21ayYTESzD/CaPOy/DvjfWJRalQ6ISvlLIHvgB6An7AYKWU3x2b9QTqZ32NBWYUtl1RjDlXgKFLwbGcMaMz4aLZDv1C0At4OHvw2rbXSMtMM9txbU2BZ9GmJBhDZBMuwpClRs0WUWqY4wo/FDihtY7SWqcCi4E+d2zTB/hOG3YAFZVScllRmrl5wpDFkBQLYQON6fxmUN6pPK+0eoXjV48z99BcsxzT1hR4Fm16KiwZBhcOwYBvjdFTolQxR8KvBZzJ9Tgm6zlTtxGlTc3m8ORsOLcfVjxjdDGYQWfvzjxc+2FmHphJVHyUWY5pK7Jn0Tap3MS0WbSZmcaQ2KhNxqLzDbpbNE5hm8yR8PO6vLhznnt+tjE2VGqsUipcKRV++fLlQgcnbFyjXtDjfTi6Bn55zWyH/XfLf1PWoSxvbnuTTG2+cf/WlD2LtoZLDb54yIRZtFrDzy8baw8/9Do0N6G/X5Qo5kj4MYBXrseewLkCbAOA1vorrXWw1jq4SpWiWRJMWFmr8RA6DrZ/bqybagbZFTX3XtrLsqPLzHJMa8o9i3ZG1xlUcq6U/523TYMdX0LL8dBukuWCFDbPHAl/N1BfKeWrlHICBgGr7thmFfBU1midVkC81vq8GdoWJUWP96BBT1j3Lzj2s1kO2aduH1rVaMWnez/lwo0LZjmmNWTPor2RdoOZXWeaNov2wGLjk1OTvtD9PZlFW8oVOuFrrdOBicBPwBFgqdb6sFJqvFJqfNZma4Eo4ATwNfC3wrYrShg7e3jyG2Pdz+Wj4PzBQh+yJFTUzD2L9r+d/0tD94b53/n4r7DyWWMB7Sdmgp1MuyntzPIXoLVeq7VuoLWuq7V+J+u5mVrrmVnfa631s1mvN9VayzJW4m5lXI2hgs5uWQtwnC30IYtzRc1CzaKN2QNLh0NVPxi4wCLrC4viR97yhW2pUMNI+ikJsGig8f9CKo4VNQs1i/bKCVjUH1yqwNDlxrwHIZCEL2xRdX/o/y1cioDloyEjvVCHy11R86Pwj8wUpGUVeBZtwgVY8ASgYPgPUL6axWIUxY8kfGGb6neF3h/B8Z9h/UvG0MJCyK6ouTJypc1X1Fx2bFnBZtEmx8OCfsbC2EOXQeW6lgtSFEuS8IXtCh4NbZ6D3d8YwwoLqThU1NwQvYGpO6aaPos2LdlYSvLyEWNpyVpSrkrcTRK+sG1d3zIW5vjpZTiyulCHsvWKmgWfRZsBP4yFU1vh8RlQ7yHLBiqKLUn4wrbZ2RmrZdVqASvGwNk9hTqcrVbULNQs2nUvQcRKePgdaDbAsoGKYk0SvrB9TuWMdXFdq8CiQXAtulCHs7WKmoWaRbv1I9j9tdH11Wai5YIUJYIkfFE8uFaFIcsgPQUWDjBuUBaQLVXULNQs2r3fwYap0Gyg0fUlxANIwhfFR9VGxg3J2OOw9CnIKPjVuS1U1CzULNqj6+B/zxurh/X5QmbRinyRvxJRvNTpCI/+1yjzu3pSoYZrWrOiZnpmesFn0UbvhGUjoUYgDPgO7PN5c1eUepLwRfHTfBi0fxH2zYffPy3wYTzKevBi8IvsvbSX5ceWmzHA+yvULNpLfxllJyrUMsbal3G1XKCixJGEL4qnLq+Afz/47U049H2BD/N4vcdpVaMVn+z5pMgqas48OJPlx5abPos2/iws6GvUxRn+Pbh4WC5IUSJJwhfFk1JG37VXK/hhvNHNUaDDFG1FzQLPor15FRY8CcnXjfo4lXwsFqMouSThi+LL0RkGLQK3WrB4MMQV7OZrUVXUzJ5F275WexNn0d6EsMEQFwmDF0GNZhaLUZRskvBF8eZS2bji1ZnGcM2kuAIdxtIVNXPPov2o40f5n0WbkQ7Ln4boHcYENN8OZo9NlB6S8EXxV7mucaV/7TQsGWaM1TeRJStqnrh6gmd/e7Zgs2jX/tNY77fnB+Df16xxidJHEr4oGWq3gT5fwuk/YNXfCzRc0xIVNbNn0ZaxL2P6LNpN78OeedDuH9BynFniEaWbJHxRcjTrD51fhoOLYfMHBTqEOStqFmoW7e7ZsPl9CBwGD71WqDiEyCYJX5QsHSZDwBDY9B4cWGLy7uaqqFmoWbRH/gdrX4T63Y1JZrLwuDATSfiiZFHKSJI+7Y0FvE/9bvIhgqsH079B/wJX1CzULNpTfxg3aWsFQf95YO9gcvtC3IskfFHyODgZNXfcfY1FQa4cN/kQk4Im4eHswevbXjepomahZtFePGwMv6xU21jX1ymfN3eFyCdJ+KJkKlvJSJp2DrCwH9y4YtLu2RU1j109xrxD8/K938wDxizaMU3HmDaL9lq0MbHKqRwM+x7KuZsUrxD5UaiEr5RyV0r9opQ6nvX/u4YgKKW8lFIblVJHlFKHlVImTC8UohDcfY06+gkXjCvntGSTds9dUfNk/MkHbr/s2DK+PGDMov1787/nv6GkOJjfF1KTYNgKqOhlUpxC5Fdhr/CnAL9presDv2U9vlM68E+tdWOgFfCsUsqvkO0KkT9eIcaEpZhd8ON4yDStKua/W/4bZwdn3tj2xn0rahZ4Fm3qDaMY2rVoGBwG1ZqYFJ8Qpihswu8DfJv1/bfA43duoLU+r7Xem/V9AnAEqFXIdoXIvyaPQ9c34fAPsOFtk3bNT0XNgs+iTYNlo4xlG/vNBp+2JsUmhKkKm/Craa3Pg5HYgar321gp5QM0BwpW6UqIgmr7PASNhN8/MVaKMsHj9R6nZY2WeVbULNQs2v+9AMd/gt4fQ+NHTYpJiIJ4YMJXSv2qlDqUx1cfUxpSSrkCK4AXtNbX77PdWKVUuFIq/PLly6Y0IcS9KQW9PoK6XYyFUyI3mrCr4vXWr99VUTP3LNqZ3WaaNov2t7dg/wLoOAWCR5v60whRIA9M+Frrrlpr/zy+VgIXlVI1ALL+fymvYyilHDGS/UKt9X2Ll2utv9JaB2utg6tUqWL6TyTEvdg7Qv9vwaOhsUTipSP53vXOiprxKfGM/2V8zizaWq4m9FLunGV80ggaCZ3yuu0lhGUUtktnFTAi6/sRwMo7N1DG3avZwBGt9SeFbE+IwnGuAEOWgGNZWNgfEi7me9ehjYfiV9mP93a+x8TfJhKdEG36LNpD38O6l6DRI9D7E5lFK4pUYRP++0A3pdRxoFvWY5RSNZVSa7O2aQsMB7oopfZnffUqZLtCFFxFLyPpJ8VC2EBjOGQ+ONg58Fabt7iecp0Dlw+YPos2ajP8MA68W8OT34CdfQF/ACEKRll6hZ/CCA4O1uHh4dYOQ5RUf62FxUOgUW9jMfB8JuD1J9djp+x42Ofh/Ld1/gDM7W282Yxaa0wME8IClFJ7tNbBeb0mM21F6dWoF/R4D/5aDb/kvyJlD98epiX7uJOwoB84uxmLtUiyF1YilZlE6dZqgpGQt39urBMb+ox5j5942Vh4PDMNRq42lmMUwkok4QvR4z1jtax1/4KKtaGBCVfv95OSCIv6w/XzMGIVVDHh5q4QFiBdOkLY2cOTs6GaPywfBecPFv6Y6amwdLhxrP7zwMuEm7tCWIgkfCEAyrga1TWd3WDRQIg/W/BjZWYatfgjN8Cjn0FDE0okC2FBkvCFyFahhpH0U64bwzVTEgp2nF9fgz+XQpdXoMVT5o1RiEKQhC9EbtX9jdm4FyNg+WjISDdt/22fw7bpEPIMtH/RMjEKUUCS8IW4U/2u0OtDOP4zrH/JKHSWHweXws8vg18f6PmBzKIVNkdG6QiRl5Cn4epJ42rdvQ60fvb+25/4DX6cYKyl+8RXMotW2CRJ+ELcS9e34Oop+OllY7hm40fy3u7sXlgyHKo0hkELwdG5SMMUIr+kS0eIe7GzM67Wa7WAFWOMxH6n2EijCJtLZRi23BjlI4SNkoQvxP04lTPWxXWtYgzXvBZ967WEizD/CUDDsB+gfHWrhSlEfkjCF+JBXKvCkGWQngILB0ByPCRfh4VPwo3Lxmse9awdpRAPJH34QuRH1UYw8DtY8KSxeIrONBZQGbwEPIOsHZ0Q+SIJX4j8qtMJHv2vMYsW4IlZxhBOIYoJSfhCmKL5MMhIM1bMChhk7WiEMIkkfCFMFTzK2hEIUSBy01YIIUoJSfhCCFFKSMIXQohSQhK+EEKUEpLwhRCilJCEL4QQpYQkfCGEKCUk4QshRCmhdH5X87ECpdRl4HQBd/cArpgxHHORuEwjcZlG4jJNSYyrtta6Sl4v2HTCLwylVLjWOtjacdxJ4jKNxGUaics0pS0u6dIRQohSQhK+EEKUEiU54X9l7QDuQeIyjcRlGonLNKUqrhLbhy+EEOJ2JfkKXwghRC7FOuErpXoopY4qpU4opabk8bpSSk3Lev2gUqqFjcTVSSkVr5Tan/X1WhHFNUcpdUkpdeger1vrfD0oLmudLy+l1Eal1BGl1GGl1PN5bFPk5yyfcRX5OVNKOSuldimlDmTF9WYe21jjfOUnLqv8jWW1ba+U2qeUWp3Ha+Y9X1rrYvkF2AORQB3ACTgA+N2xTS9gHaCAVsBOG4mrE7DaCuesA9ACOHSP14v8fOUzLmudrxpAi6zvywPHbORvLD9xFfk5yzoHrlnfOwI7gVY2cL7yE5dV/say2v4HsCiv9s19vorzFX4ocEJrHaW1TgUWA33u2KYP8J027AAqKqVq2EBcVqG13gLE3WcTa5yv/MRlFVrr81rrvVnfJwBHgFp3bFbk5yyfcRW5rHOQmPXQMevrzpuE1jhf+YnLKpRSnkBv4Jt7bGLW81WcE34t4EyuxzHc/Uefn22sERdA66yPmOuUUk0sHFN+WeN85ZdVz5dSygdojnF1mJtVz9l94gIrnLOs7on9wCXgF621TZyvfMQF1vkb+wz4F5B5j9fNer6Kc8JXeTx357t2frYxt/y0uRdj+nMAMB340cIx5Zc1zld+WPV8KaVcgRXAC1rr63e+nMcuRXLOHhCXVc6Z1jpDax0IeAKhSin/OzaxyvnKR1xFfr6UUo8Al7TWe+63WR7PFfh8FeeEHwN45XrsCZwrwDZFHpfW+nr2R0yt9VrAUSnlYeG48sMa5+uBrHm+lFKOGEl1odb6+zw2sco5e1Bc1v4b01pfAzYBPe54yap/Y/eKy0rnqy3wmFLqFEbXbxel1II7tjHr+SrOCX83UF8p5auUcgIGAavu2GYV8FTWne5WQLzW+ry141JKVVdKqazvQzF+D7EWjis/rHG+Hsha5yurzdnAEa31J/fYrMjPWX7issY5U0pVUUpVzPq+LNAV+OuOzaxxvh4YlzXOl9b631prT621D0ae2KC1HnbHZmY9Xw4FD9e6tNbpSqmJwE8YI2PmaK0PK6XGZ70+E1iLcZf7BJAEjLKRuPoBE5RS6cBNYJDOuiVvSUqpMIzRCB5KqRjgdYwbWFY7X/mMyyrnC+MKbDjwZ1b/L8D/Ad65YrPGOctPXNY4ZzWAb5VS9hgJc6nWerW1/03mMy5r/Y3dxZLnS2baCiFEKVGcu3SEEEKYQBK+EEKUEpLwhRCilJCEL4QQpYQkfCGEKCUk4QshRCkhCV8IIUoJSfhCCFFK/D8VxoC6AQ5xpQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hot_air_ballon_start_states=torch.rand((5,1))\n",
    "hot_air_ballon_start_actions=torch.rand((5,1))-0.5\n",
    "hot_air_ballon_next_states=hot_air_ballon_start_states+hot_air_ballon_start_actions\n",
    "\n",
    "plt.plot(hot_air_ballon_start_states.numpy(),label='Starting Step')\n",
    "plt.plot(hot_air_ballon_start_actions.numpy(),label='Action')\n",
    "plt.plot(hot_air_ballon_next_states.numpy(),label='Resulting Step')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm=GMM(2,1,2,fix_variance=False)\n",
    "opt=Adam(gmm.parameters(),lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets see if the GMM can predict the next state accurately..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5577],\n",
       "        [ 1.6318],\n",
       "        [-0.7048],\n",
       "        [ 0.0216],\n",
       "        [-0.0761]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.hstack([hot_air_ballon_start_states,hot_air_ballon_start_actions])\n",
    "dist=gmm(x)\n",
    "hot_air_ballon_start_states+dist.mean"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "versus..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9418],\n",
       "        [ 0.5359],\n",
       "        [-0.2236],\n",
       "        [ 0.3188],\n",
       "        [ 0.4147]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_air_ballon_next_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah the GMM is way off...\n",
    "So lets first see if we can get it to optimize to predict a next state..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6004, grad_fn=<NegBackward>) tensor(-0.6004, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1176, grad_fn=<NegBackward>) tensor(-0.1176, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2016, grad_fn=<NegBackward>) tensor(0.2016, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2783, grad_fn=<NegBackward>) tensor(0.2783, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2847, grad_fn=<NegBackward>) tensor(0.2847, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "next_timesteps=hot_air_ballon_next_states-hot_air_ballon_start_states    \n",
    "x=torch.hstack([hot_air_ballon_start_states,hot_air_ballon_start_actions])\n",
    "\n",
    "for step in range(5000):\n",
    "    dist=gmm(x)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss=-torch.mean(dist.log_prob(next_timesteps))\n",
    "    loss.backward()\n",
    "    if step%1000==0:print(loss,torch.mean(dist.log_prob(next_timesteps)))\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9408],\n",
       "        [ 2.9151],\n",
       "        [-0.5615],\n",
       "        [ 0.5469],\n",
       "        [ 0.4190]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.hstack([hot_air_ballon_start_states,hot_air_ballon_start_actions])\n",
    "dist=gmm(x)\n",
    "hot_air_ballon_start_states+dist.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9418],\n",
       "        [ 0.5359],\n",
       "        [-0.2236],\n",
       "        [ 0.3188],\n",
       "        [ 0.4147]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_air_ballon_next_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better, the GMM is making a better prediction of what the next state is going to be..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skill Dynamics\n",
    "> Now that we have a working GMM, we need a way to modify our input data to be useful for the DADS agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SkillDynamics(Module):\n",
    "    def __init__(self,s_dim,a_dim,n_components,fix_variance:bool=False,\n",
    "                 use_model_mean:bool=None,use_batch_norm:bool=True,fc_params:tuple=None):\n",
    "        store_attr(but='fc_params,use_model_mean')\n",
    "        self.fc_params=ifnone(fc_params,(256,256))\n",
    "        self.use_model_mean=ifnone(use_model_mean,n_components>1)\n",
    "        if self.use_batch_norm:\n",
    "            self.s_bn,self.sp_bn=nn.BatchNorm1d(s_dim),nn.BatchNorm1d(s_dim)\n",
    "        self.fcs=nn.Sequential(*[nn.Linear((s_dim+a_dim) if i==0 else self.fc_params[i-1],p) \n",
    "                                for i,p in enumerate(self.fc_params)])\n",
    "        \n",
    "        self.gmm=GMM(self.fc_params[-1],s_dim,n_components,fix_variance)\n",
    "        \n",
    "    def forward(self,s,a,sp=None,training=True):\n",
    "        \"Returns the `GMM` distribution of `s` and `a`, mean, and **optionally** \"\\\n",
    "        \"log(p) of the state transition between `s` and `sp` if `sp` is not None.\"\n",
    "        if sp is not None: sp=sp-s\n",
    "        if not training: self.eval()\n",
    "            \n",
    "        if self.use_batch_norm:\n",
    "            s=self.s_bn(s)\n",
    "            if sp is not None: sp=self.sp_bn(sp)\n",
    "            \n",
    "        sa=torch.hstack([s,a])\n",
    "        \n",
    "        x=self.fcs(sa)\n",
    "        \n",
    "        dist=self.gmm(x)\n",
    "        self.train()\n",
    "        return dist,(sp if sp is None else dist.log_prob(sp))\n",
    "    \n",
    "    def log_prob(self,s,a,sp): return self(s,a,sp,training=False)[1]\n",
    "\n",
    "    def predict_state(self,s,a):\n",
    "        \"Returns the predicted state that `s` and `a` will result in.\"\n",
    "        dist,_=self(s,a,training=False)\n",
    "        if self.use_model_mean:\n",
    "            means,idx=dist.component_distribution.mean,torch.argmax(dist.mixture_distribution.logits,dim=1)\n",
    "            pred_s=means[[torch.arange(means.shape[0]),idx]]\n",
    "        else:\n",
    "            pred_s=dist.mean\n",
    "            \n",
    "        if self.use_batch_norm:\n",
    "            pred_s=pred_s*(self.sp_bn.running_var+1e-3).sqrt()+self.sp_bn.running_mean\n",
    "        \n",
    "        pred_s+=s\n",
    "        return pred_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SkillDynamics` module is actually pretty simple. It is tasked with getting the mean and log probability from the `GMM` and providing a convenient way to get a predicted state. It additionaly has the capability of batch normalization, noise, and input shuffling.\n",
    "\n",
    "Going back to our hot air balloon example, lets feed the states, actions, and resulting states into it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_dyn=SkillDynamics(1,1,2,fix_variance=False,use_batch_norm=False)\n",
    "opt=Adam(skill_dyn.parameters(),lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SkillDynamics(\n",
       "  (fcs): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=256, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (gmm): GMM(\n",
       "    (distribution): MultiCompGMM(\n",
       "      (logit_fc): Linear(in_features=256, out_features=2, bias=True)\n",
       "      (mean_fcs): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "        (1): Linear(in_features=256, out_features=1, bias=True)\n",
       "      )\n",
       "      (std_fcs): ModuleList(\n",
       "        (0): OptionalClampLinear(\n",
       "          (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "        )\n",
       "        (1): OptionalClampLinear(\n",
       "          (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_dyn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do a regular feed through and look at the output of our `SkillDynamics` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MixtureSameFamily(\n",
       "   Categorical(probs: torch.Size([5, 2]), logits: torch.Size([5, 2])),\n",
       "   Independent(Normal(loc: torch.Size([5, 2, 1]), scale: torch.Size([5, 2, 1])), 1)),\n",
       " tensor([-0.6008, -0.7213, -0.5231, -0.7284, -0.5756],\n",
       "        grad_fn=<LogsumexpBackward>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_dyn(hot_air_ballon_start_states,hot_air_ballon_start_actions,\n",
    "                           hot_air_ballon_next_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 3 components: `dist`, `mean`, and `log_prob`.\\\n",
    "`dist` lets the user do more advanced operations with the results.\\\n",
    "`mean` will always return since at minimum `s` and `a` need to be passed in.\\\n",
    "`log_prob` can be returned if `sp` is not None.\n",
    "\n",
    "The most immediately useful result is `log_prob` since it can be used for operations that need to know *what is the probability of this state occuring.*\n",
    "\n",
    "However, like we said earlier, `dist` is returned because we might want to do more advanced operations. For example `predict_state`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Prediction:',\n",
       " tensor([[ 0.5668],\n",
       "         [ 0.0963],\n",
       "         [-0.1007],\n",
       "         [-0.1085],\n",
       "         [ 0.1359]], grad_fn=<AddBackward0>),\n",
       " 'Actual',\n",
       " tensor([[ 0.9418],\n",
       "         [ 0.5359],\n",
       "         [-0.2236],\n",
       "         [ 0.3188],\n",
       "         [ 0.4147]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Prediction:',\\\n",
    "skill_dyn.predict_state(hot_air_ballon_start_states,hot_air_ballon_start_actions),\\\n",
    "'Actual',\\\n",
    "hot_air_ballon_next_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This state prediction seems terrible! Obviously, we need to train `skill_dyn` so this is more accurate. You may notice the number of steps is 100 as opposed to 5000! This is because we are actually feeding a linear layer's output into the `GMM` as opposed to the `s+a` tensor directly. This is called a `latent space`, and these have friendlier values for the `GMM` to learn against. You will also see later that the results are a little more accurate also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6298, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2764, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2832, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2848, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2850, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def train(steps=100,print_every=20):\n",
    "    skill_dyn.train()\n",
    "    for step in range(steps):\n",
    "        _,log_prob=skill_dyn(hot_air_ballon_start_states,hot_air_ballon_start_actions,\n",
    "                       hot_air_ballon_next_states)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss=-torch.mean(log_prob)\n",
    "        loss.backward()\n",
    "        if step%print_every==0:print(loss,torch.mean(dist.log_prob(next_timesteps)))\n",
    "        opt.step()\n",
    "    skill_dyn.eval()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Prediction:',\n",
       " tensor([[ 0.9420],\n",
       "         [ 0.5352],\n",
       "         [-0.2225],\n",
       "         [ 0.3178],\n",
       "         [ 0.4147]], grad_fn=<AddBackward0>),\n",
       " 'Actual',\n",
       " tensor([[ 0.9418],\n",
       "         [ 0.5359],\n",
       "         [-0.2236],\n",
       "         [ 0.3188],\n",
       "         [ 0.4147]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Prediction:',\\\n",
    "skill_dyn.predict_state(hot_air_ballon_start_states,hot_air_ballon_start_actions),\\\n",
    "'Actual',\\\n",
    "hot_air_ballon_next_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! It is ok they are not exact, we want `SkillDynamics` to have a general idea on how current states and their actions can cause the state to change.\n",
    "\n",
    "But here is a small wrench in the works. You will notice that the state spaces we are feeding into the model have values [-1, 1] which are nice and friendly to train our model on but also **highly unrealistic in the real world**. We will likely see values [-10,1000] possibly. Can we train on these? Let's convert our ballon problem into meters. We don't need to worry about actions because the values of actions are usually *within our control*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hot_air_ballon_start_states=torch.rand((5,1))*100\n",
    "hot_air_ballon_start_actions=torch.rand((5,1))-0.5\n",
    "hot_air_ballon_next_states=hot_air_ballon_start_states+hot_air_ballon_start_actions*100\n",
    "\n",
    "plt.plot(hot_air_ballon_start_states.numpy(),label='Starting Step')\n",
    "plt.plot(hot_air_ballon_start_actions.numpy()*100,label='Action')\n",
    "plt.plot(hot_air_ballon_next_states.numpy(),label='Resulting Step')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are much bigger values... Training a model on these without normalzing can be very hard. \n",
    "The worst part is that in order to normalize something like states,\n",
    "you would need to know *what is the absolute minimum and maximum this state will ever be*. This is a general problem in RL because when the agent is first\n",
    "starting the states might start small, such as being newer the origin 0,0, but everntually as the agent gets better it starts to get to states like -20,100.\n",
    "Our model needs to convert these into nice [0,1] or [-1,1] values.\n",
    "\n",
    "So first, lets see if we can even learn anything without batch norm..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Prediction:',\n",
       " tensor([[43.4535],\n",
       "         [43.6629],\n",
       "         [ 9.4961],\n",
       "         [29.2001],\n",
       "         [72.0843]], grad_fn=<AddBackward0>),\n",
       " 'Actual',\n",
       " tensor([[ -2.8968],\n",
       "         [ 58.4662],\n",
       "         [  0.5869],\n",
       "         [ 68.1590],\n",
       "         [102.4890]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_dyn=SkillDynamics(1,1,2,fix_variance=False,use_batch_norm=False)\n",
    "opt=Adam(skill_dyn.parameters(),lr=3e-4)\n",
    "'Prediction:',\\\n",
    "skill_dyn.predict_state(hot_air_ballon_start_states,hot_air_ballon_start_actions),\\\n",
    "'Actual',\\\n",
    "hot_air_ballon_next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5003.8320, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(12.0101, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(11.0967, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(10.1336, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(9.3372, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(8.7437, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train(300,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Prediction:',\n",
       " tensor([[ 62.1747],\n",
       "         [ 62.4905],\n",
       "         [ 13.6204],\n",
       "         [ 41.8130],\n",
       "         [103.1418]], grad_fn=<AddBackward0>),\n",
       " 'Actual',\n",
       " tensor([[ -2.8968],\n",
       "         [ 58.4662],\n",
       "         [  0.5869],\n",
       "         [ 68.1590],\n",
       "         [102.4890]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Prediction:',\\\n",
    "skill_dyn.predict_state(hot_air_ballon_start_states,hot_air_ballon_start_actions),\\\n",
    "'Actual',\\\n",
    "hot_air_ballon_next_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm... It's diffinitely not amazing. The worst part is that this will likely be made worst with larger and differing batches. Lets see if using batch norm makes this better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Prediction:',\n",
       " tensor([[50.2478],\n",
       "         [50.4456],\n",
       "         [11.1089],\n",
       "         [33.7702],\n",
       "         [83.1706]], grad_fn=<AddBackward0>),\n",
       " 'Actual',\n",
       " tensor([[ -2.8968],\n",
       "         [ 58.4662],\n",
       "         [  0.5869],\n",
       "         [ 68.1590],\n",
       "         [102.4890]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_dyn=SkillDynamics(1,1,2,fix_variance=False,use_batch_norm=True)\n",
    "opt=Adam(skill_dyn.parameters(),lr=3e-4)\n",
    "'Prediction:',\\\n",
    "skill_dyn.predict_state(hot_air_ballon_start_states,hot_air_ballon_start_actions),\\\n",
    "'Actual',\\\n",
    "hot_air_ballon_next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5489, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2800, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2850, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2850, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2850, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2850, grad_fn=<NegBackward>) tensor(0.2850, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train(300,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Prediction:',\n",
       " tensor([[ -8.5025],\n",
       "         [ 59.4843],\n",
       "         [ -0.7764],\n",
       "         [ 71.8733],\n",
       "         [105.0412]], grad_fn=<AddBackward0>),\n",
       " 'Actual',\n",
       " tensor([[ -2.8968],\n",
       "         [ 58.4662],\n",
       "         [  0.5869],\n",
       "         [ 68.1590],\n",
       "         [102.4890]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Prediction:',\\\n",
    "skill_dyn.predict_state(hot_air_ballon_start_states,hot_air_ballon_start_actions),\\\n",
    "'Actual',\\\n",
    "hot_air_ballon_next_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It seems that batch norm makes `SkillDynamics` compatible with state space inputs of varying values \n",
    "that will addapt as the agent explores its environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DADS Agent\n",
    "\n",
    "Some important notes...\n",
    "\n",
    "Earlier `SkillDynamics` had:\n",
    "```python\n",
    "SkillDynamics(s_dim=1,a_dim=1,n_components=2)\n",
    "```\n",
    "where `a_dim` was the action dimension. In reality this is the **skill** dimension. You could say that if `a_dim` is being fed raw actions, then `SkillDynamics` should be renamed `ActionDynamics`.\n",
    "\n",
    "However, you will see in `DADS`, that the `SkillDynamics` is always fed the skills as opposed to the primitive actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginalization methods\n",
    "> Ways of calculating the denominator.\n",
    "\n",
    "A good reference is [Probability concepts explained: Marginalisation](https://towardsdatascience.com/probability-concepts-explained-marginalisation-2296846344fc). We need to calculate the intrinsic reward whose primary goal is to say:\n",
    "- Did this skill produce predictable results? If so, let's reward it for doing so!\n",
    "\n",
    "The actual math from the [Dynamics-Aware Unsupervised Discovery of Skills](https://arxiv.org/abs/1907.01657) for intrinsic reward:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5><center>\n",
    "$r_z(s,a,s')=\\log{\\frac{q_{\\phi}(s' \\mid s,z)}{\\sum_{i=1}^L q_{\\phi}(s' \\mid s,z_i)}}+\\log{L},~~ z_i \\sim p(z)$\n",
    "</center></h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of getting the intrinsic reward is getting the denominator:\n",
    "$\\sum_{i=1}^L q_{\\phi}(s' \\mid s,z_i)$ which is going to be the *all other possible skills*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def discrete_uniform(current_skill,latent_sz:int=2,alt_s:Tensor=None,deterministic:bool=False):\n",
    "    \"Returns a uniform discrete distribution.\"\n",
    "    if deterministic: \n",
    "        return torch.cat([torch.roll(current_skill,i,dims=1) for i in range(1,alt_s.shape[0])])\n",
    "    return Multinomial(1,probs=Tensor([1./latent_sz]*latent_sz)).sample_n(alt_s.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_size=5 # Skill \n",
    "alt_s=torch.ones((5,3))\n",
    "current_skill=Tensor([[0,0,0,1,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the current skill that was used..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and so the other skills to compare it with are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_uniform(current_skill,latent_sz=skill_size,alt_s=alt_s,deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... but this isn't very random is it? It just rolling them so let's add some random\n",
    "alternative skills to look at..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/torch/distributions/distribution.py:134: UserWarning: sample_n will be deprecated. Use .sample((n,)) instead\n",
      "  warnings.warn('sample_n will be deprecated. Use .sample((n,)) instead', UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_uniform(current_skill,latent_sz=skill_size,alt_s=alt_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you may ask, what if the skill is continuous? For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000, 0.2000, 0.3000, 0.2000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_skill=Tensor([[0.1,0.2,0.2,0.3,0.2]]);current_skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well then we have a few other disributions to sample instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "def show2d(t:Tensor): \n",
    "    plt.imshow(t.numpy(), cmap='hot', interpolation='nearest')\n",
    "    plt.show()\n",
    "#     plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def cont_gaussian(sz:int,alt_s:Tensor):\n",
    "    \"Returns a continuous guassian distribution of size `sz`\"\n",
    "    return MultivariateNormal(torch.zeros(sz),torch.eye(sz)).sample_n(alt_s.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8993,  0.8411, -1.3920, -1.3856, -0.4493],\n",
       "        [-0.3804,  0.4599,  1.8147, -1.1779, -0.5150],\n",
       "        [ 2.4599, -1.0070, -0.5137, -0.5224, -1.1733],\n",
       "        [-1.0389,  0.3686,  1.5772, -1.1345, -0.3982],\n",
       "        [-0.9570,  0.6416,  0.9712,  1.5836, -2.3628]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_gaussian(skill_size,alt_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show2d(cont_gaussian(skill_size,alt_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def cont_uniform(sz,alt_s:Tensor,low=-1.0, high=1.0):\n",
    "    return torch.zeros((alt_s.shape[0],sz)).uniform_(low,high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1931, -0.6300,  0.1852, -0.8393, -0.6247],\n",
       "        [-0.2492, -0.0581,  0.0997,  0.7833, -0.7303],\n",
       "        [-0.5231, -0.9337,  0.4834,  0.6524,  0.1891],\n",
       "        [-0.9139, -0.5005, -0.0554, -0.7323,  0.4625],\n",
       "        [ 0.4625, -0.5545,  0.6470,  0.2621,  0.5467]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_uniform(skill_size,alt_s,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show2d(cont_uniform(skill_size,alt_s,-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(SAC)\n",
    "class DADS(SAC):\n",
    "    def __init__(self,num_inputs,action_space,num_skills:int=20,include_actions:bool=False,hidden_size=100,lr=0.003,\n",
    "                 n_components:int=4,prior_samples:int=100,latent_sz:int=2,latent_prior_method='',\n",
    "                 skill_lr=3e-4,episide_horizon:int=1,planning_horizon:int=1,\n",
    "                 primitive_horizon:int=1,train_dyn=True,**kwargs):\n",
    "        store_attr()\n",
    "        self.num_inputs=num_inputs+self.num_skills\n",
    "        self.original_num_inputs=num_inputs\n",
    "        self.skill_dyn=SkillDynamics(self.original_num_inputs,self.num_skills,self.n_components)\n",
    "        super().__init__(self.num_inputs,self.action_space,hidden_size=hidden_size,lr=lr,**kwargs)\n",
    "        self.skill_opt=Adam(self.skill_dyn.parameters(),lr=3e-4)\n",
    "        \n",
    "        self.p_z=np.full(self.num_skills,1.0/self.num_skills)\n",
    "        self.log_p_z_episode=[]\n",
    "        self.z=0\n",
    "        self.reset_z()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def intrinsic_reward(self,s,skill:Tensor,sp,gpu_limit=20*4000):\n",
    "        \"Given a batch of `s` and `sp` what is the reward for using skill `z`?\"\n",
    "        n_repetitions=self.prior_samples if self.prior_samples>0 else self.num_skills-1\n",
    "        alt_s=torch.cat([s]*n_repetitions,axis=0)\n",
    "        alt_sp=torch.cat([sp]*n_repetitions,axis=0)\n",
    "        \n",
    "        if self.latent_prior_method=='discrete_uniform' and not self.prior_samples: \n",
    "            alt_skill=discrete_uniform(skill,self.num_skills,alt_s,True)\n",
    "        elif self.latent_prior_method=='discrete_uniform':\n",
    "            alt_skill=discrete_uniform(skill,self.num_skills,alt_s,False)\n",
    "        elif self.latent_prior_method=='cont_gaussian':\n",
    "            alt_skill=cont_gaussian(self.num_skills,alt_s)\n",
    "        else:\n",
    "            alt_skill=cont_uniform(self.num_skills,alt_s)\n",
    "            \n",
    "        logp=self.skill_dyn.log_prob(s,skill,sp)\n",
    "        \n",
    "        if alt_s.shape[0]<=gpu_limit:\n",
    "            logp_altz=self.skill_dyn.log_prob(alt_s,alt_skill,alt_sp)\n",
    "        else:\n",
    "            # TODO JL: Does this chunking code have to be so complex? Does fastcore have something\n",
    "            logp_altz=[]\n",
    "            for idx in range(alt_s.shape[0]//gpu_limit):\n",
    "                start_idx=idx*gpu_limit\n",
    "                end_idx=(idx+1)*gpu_limit\n",
    "                logp_altz.append(\n",
    "                    self.skill_dyn.log_prob(alt_s[start_idx:end_idx],\n",
    "                                            alt_skill[start_idx:end_idx],\n",
    "                                            alt_sp[start_idx:end_idx])\n",
    "                )\n",
    "            # TODO: JL: ok what is the scenario where this if statement is needed?\n",
    "            if alt_s.shape[0]%gpu_limit:\n",
    "                start_idx=alt_s.shape[0]%gpu_limit\n",
    "                logp_altz.append(  \n",
    "                    self.skill_dyn.log_prob(alt_s[-start_idx:],\n",
    "                                            alt_skill[-start_idx:],\n",
    "                                            alt_sp[-start_idx:]))\n",
    "            logp_altz=torch.cat(logp_altz)\n",
    "        logp_altz=torch.stack(torch.chunk(logp_altz,n_repetitions))\n",
    "\n",
    "        intrinsic_reward=np.log(n_repetitions+1)-torch.log(\n",
    "            1+torch.exp(torch.clamp(logp_altz-logp.reshape(1,-1),-50,50)).sum(dim=0)\n",
    "        )\n",
    "\n",
    "        return intrinsic_reward.reshape(-1,1),logp,logp_altz\n",
    "    \n",
    "    # TODO: They have batch weighting here. Maybe look into\n",
    "    def increase_skill_opt(self,log_prob:Tensor):\n",
    "        self.skill_opt.zero_grad()\n",
    "        loss=-torch.mean(log_prob)\n",
    "        loss.backward()\n",
    "        self.skill_opt.step()\n",
    "        \n",
    "    def decrease_skill_opt(self,log_prob:Tensor):\n",
    "        self.skill_opt.zero_grad()\n",
    "        loss=torch.mean(log_prob)\n",
    "        loss.backward()\n",
    "        self.skill_opt.step()\n",
    "        \n",
    "    def sample_z(self):\n",
    "        \"\"\"Samples z from p(z), using probabilities in self._p_z.\"\"\"\n",
    "        return np.random.choice(self.num_skills,p=self.p_z)\n",
    "    \n",
    "    def reset_z(self): self.z=self.sample_z()\n",
    "    def __call__(self,s,asl):\n",
    "        aug_s=self.concat_obs_z(s,self.z)\n",
    "        return super().__call__(aug_s,asl)\n",
    "    \n",
    "    def concat_obs_z(self,obs,z):\n",
    "        \"\"\"Concatenates the observation to a one-hot encoding of Z.\"\"\"\n",
    "        assert np.isscalar(z)\n",
    "        if type(obs)==list and len(obs)==1: obs=obs[0]\n",
    "        if len(obs.shape)==2 and obs.shape[0]==1: obs=obs[0]\n",
    "            \n",
    "        z_one_hot=np.zeros(self.num_skills)\n",
    "        z_one_hot[z]=1\n",
    "        if type(obs)==Tensor: obs=obs.cpu()\n",
    "        return torch.FloatTensor(np.hstack([obs,z_one_hot])).reshape(1,-1)\n",
    "    \n",
    "    def update_parameters(self, *yb, learn):\n",
    "        batch=learn.sample_yb\n",
    "\n",
    "        state_batch=torch.stack([o.state.to(device=default_device()) for o in batch]).float()\n",
    "        next_state_batch=torch.stack([o.last_state.to(device=default_device()) for o in batch]).float()\n",
    "        action_batch=torch.stack([o.action.to(device=default_device()) for o in batch]).float()\n",
    "        reward_batch=torch.stack([o.reward.to(device=default_device()) for o in batch]).float()\n",
    "        mask_batch=torch.stack([o.done.to(device=default_device()) for o in batch]).float().unsqueeze(1)\n",
    "        \n",
    "        if self.train_dyn:\n",
    "            self.increase_skill_opt(self.skill_dyn.log_prob(\n",
    "                state_batch[:,:self.num_skills],\n",
    "                state_batch[:,self.num_skills:],\n",
    "                next_state_batch[:,:self.num_skills]\n",
    "            ))\n",
    "            \n",
    "            reward_batch,_,_=self.intrinsic_reward(                \n",
    "                state_batch[:,:self.num_skills],\n",
    "                state_batch[:,self.num_skills:],\n",
    "                next_state_batch[:,:self.num_skills])\n",
    "#             print(reward_batch)\n",
    "            \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            next_state_action, next_state_log_pi, _ = self.policy.sample(next_state_batch)\n",
    "            qf1_next_target, qf2_next_target = self.critic_target(next_state_batch, next_state_action)\n",
    "            min_qf_next_target = torch.min(qf1_next_target, qf2_next_target) - self.alpha * next_state_log_pi\n",
    "            next_q_value = reward_batch + (1-mask_batch) * self.gamma * (min_qf_next_target)\n",
    "        qf1, qf2 = self.critic(state_batch, action_batch)  # Two Q-functions to mitigate positive bias in the policy improvement step\n",
    "        qf1_loss = F.mse_loss(qf1, next_q_value)  # JQ = (st,at)~D[0.5(Q1(st,at) - r(st,at) - (st+1~p[V(st+1)]))^2]\n",
    "        qf2_loss = F.mse_loss(qf2, next_q_value)  # JQ = (st,at)~D[0.5(Q1(st,at) - r(st,at) - (st+1~p[V(st+1)]))^2]\n",
    "        qf_loss = qf1_loss + qf2_loss\n",
    "\n",
    "        self.critic_optim.zero_grad()\n",
    "        qf_loss.backward()\n",
    "        self.critic_optim.step()\n",
    "\n",
    "        pi, log_pi, _ = self.policy.sample(state_batch)\n",
    "\n",
    "        qf1_pi, qf2_pi = self.critic(state_batch, pi)\n",
    "        min_qf_pi = torch.min(qf1_pi, qf2_pi)\n",
    "\n",
    "        policy_loss = ((self.alpha * log_pi) - min_qf_pi).mean() # J = stD,tN[ * log(f(t;st)|st)  Q(st,f(t;st))]\n",
    "\n",
    "        self.policy_optim.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        self.policy_optim.step()\n",
    "\n",
    "        if self.automatic_entropy_tuning:\n",
    "            alpha_loss = -(self.log_alpha * (log_pi + self.target_entropy).detach()).mean()\n",
    "\n",
    "            self.alpha_optim.zero_grad()\n",
    "            alpha_loss.backward()\n",
    "            self.alpha_optim.step()\n",
    "\n",
    "            self.alpha = self.log_alpha.exp()\n",
    "            alpha_tlogs = self.alpha.clone() # For TensorboardX logs\n",
    "        else:\n",
    "            alpha_loss = torch.tensor(0.).to(self.device)\n",
    "            alpha_tlogs = torch.tensor(self.alpha) # For TensorboardX logs\n",
    "\n",
    "\n",
    "        if self.updates % self.target_update_interval == 0:\n",
    "            soft_update(self.critic_target, self.critic, self.tau)\n",
    "        self.updates+=1\n",
    "#         print(self.updates)\n",
    "#         print('complete')\n",
    "        return qf1_loss+ qf2_loss+ policy_loss+ alpha_loss+ alpha_tlogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DADS(model=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dads=DADS(1,gym.spaces.Box(-1,1,(1,)),2);dads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3687],\n",
       "        [ 0.0740],\n",
       "        [-0.6713],\n",
       "        [-2.2072],\n",
       "        [ 0.0245]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrinsic_reward,_,_=dads.intrinsic_reward(hot_air_ballon_start_states,\n",
    "                      Tensor([[0,1]]*5),\n",
    "                      hot_air_ballon_next_states);intrinsic_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the `DADS.__call__` function, unlike other agents, has a planning behavior. We want to test that as it learns,\n",
    "the planners get better at estimating the future states its going to be in.\n",
    "\n",
    "For now, we will be using dicrete skills until we refactor. The continuous implimentation is [MPPI (Williams et al., 2016)](https://www.cc.gatech.edu/~bboots3/files/InformationTheoreticMPC.pdf) and is used by DADS for continuous actions for the goal of making sure they have smooth transitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Warning: The orignal implimentation, the planning section gets the predicted states for all of the skill. How does it decide which state to go with? \n",
    "Well... It uses (probably) straight line distance to the goal state... This means that the planner in DADS will **only work with environments with linear dense goals**.\n",
    "Because of this, instead we have an implimentation that simply looks ahead given a constant goal.\n",
    "\n",
    "Below is a non-working example of the planner. This requires the env to have a goal that can be recalculated:\n",
    "```python\n",
    "class Planner(object):\n",
    "    def __init__(self,init_s,agent:DADS,env,episide_horizon:int=1,planning_horizon:int=1,\n",
    "                 primitive_horizon:int=10):\n",
    "        store_attr()\n",
    "    \n",
    "    def __next__(self):\n",
    "        init_skills=torch.eye(self.agent.num_skills)\n",
    "        s=copy(self.init_s)\n",
    "        for _ in range(self.episide_horizon//self.primitive_horizon):\n",
    "            running_s=Tensor([s]*agent.num_skills)\n",
    "            computed_reward=0\n",
    "            for _ in range(self.planning_horizon):\n",
    "                pred_s=self.agent.skill_dny.predict_state(running_s[:,:self.num_skills],\n",
    "                                                          init_skills)\n",
    "                computed_reward+=env.compute_reward(running_s[:,:self.num_skills],\n",
    "                                                    pred_s)\n",
    "                \n",
    "            agent.z=torch.argmax(computed_reward)\n",
    "            s=agent.concat_obs_z(s,agent.z)\n",
    "            yield s\n",
    "```\n",
    "Once we add a Meta Learner, we can replace the `computed_reward+=env.compute_reward` with something like a `DDQN` so that `DADS` can perform in-operation\n",
    "skill switching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from pybulletgym.envs import *\n",
    "from IPython import display\n",
    "import PIL.Image\n",
    "%matplotlib inline\n",
    "\n",
    "env=gym.make('InvertedPendulumPyBulletEnv-v0')\n",
    "s=env.reset()\n",
    "\n",
    "dads=DADS(1,gym.spaces.Box(-1,1,(1,)),2);dads\n",
    "\n",
    "planner=Planner(s,dads)\n",
    "\n",
    "for _ in range(200):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(PIL.Image.fromarray(env.render(mode='rgb_array')))\n",
    "\n",
    "#     agent.z=z\n",
    "#     a,_=agent(s,None)\n",
    "\n",
    "    s,r,d,_=env.step(a)\n",
    "    if d:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceReplay(Callback):\n",
    "    def __init__(self,sz=100,bs=128,starting_els=1,max_steps=1):\n",
    "        store_attr()\n",
    "        self.queue=deque(maxlen=int(sz))\n",
    "        self.max_steps=max_steps\n",
    "        \n",
    "    def before_fit(self):\n",
    "        self.learn.agent.warming_up=True\n",
    "        while len(self.queue)<self.starting_els:\n",
    "            for i,o in enumerate(self.dls.train):\n",
    "                batch=[ExperienceFirstLast(state=o[0][i],action=o[1][i],reward=o[2][i],\n",
    "                                    last_state=o[3][i], done=(o[4][i] and self.max_steps!=o[6][i]),episode_reward=o[5][i],steps=o[6][i])\n",
    "                                    for i in range(len(o[0]))]\n",
    "#                 print(self.max_steps,max([o.steps for o in batch]))\n",
    "                for _b in batch: self.queue.append(_b)\n",
    "                if len(self.queue)>self.starting_els:break\n",
    "        self.learn.agent.warming_up=False\n",
    "\n",
    "#     def after_epoch(self):\n",
    "#         print(len(self.queue))\n",
    "    def before_batch(self):\n",
    "#         print(len(self.queue))\n",
    "        b=list(self.learn.xb)+list(self.learn.yb)\n",
    "        batch=[ExperienceFirstLast(state=b[0][i],action=b[1][i],reward=b[2][i],\n",
    "                                last_state=b[3][i], done=(b[4][i] and self.max_steps!=b[6][i]),episode_reward=b[5][i],\n",
    "                                steps=b[6][i])\n",
    "                                for i in range(len(b[0]))]\n",
    "        for _b in batch: self.queue.append(_b)\n",
    "        idxs=np.random.randint(0,len(self.queue), self.bs)\n",
    "        self.learn.sample_yb=[self.queue[i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SACCriticTrainer(Callback):\n",
    "    def after_batch(self): \n",
    "        self.learn.dls.bs=1\n",
    "        for d in self.learn.dls.loaders: d.bs=1\n",
    "        \n",
    "    def after_loss(self):raise CancelBatchException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DADSTrainer(ExperienceReplay):\n",
    "\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        self.log_p_z_episode=[]\n",
    "        super().__init__(*args,**kwargs)\n",
    "        \n",
    "    def before_fit(self):\n",
    "        self.learn.agent.warming_up=True\n",
    "        while len(self.queue)<self.starting_els:\n",
    "            for i,o in enumerate(self.dls.train):\n",
    "                z=self.learn.agent.z\n",
    "                batch=[ExperienceFirstLast(state=self.learn.agent.concat_obs_z(o[0][i],z)[0],\n",
    "                                           action=o[1][i],\n",
    "                                           reward=o[2][i],\n",
    "                                           last_state=self.learn.agent.concat_obs_z(o[3][i],z)[0], \n",
    "                                           done=(o[4][i] and self.max_steps!=o[6][i]),\n",
    "                                           episode_reward=o[5][i],steps=o[6][i])\n",
    "                                    for i in range(len(o[0]))]\n",
    "#                 print(self.max_steps,max([o.steps for o in batch]))\n",
    "#                 print(batch[0])\n",
    "#                 for k in range(len(batch)):\n",
    "#                     intrinsic_reward,disc_out=self.learn.agent.intrinsic_reward(Tensor(batch[k].last_state))\n",
    "#                     self.learn.agent.increase_skill_opt(self.agent.z,disc_out)\n",
    "#                     batch[k]=ExperienceFirstLast(\n",
    "#                         state=batch[k].state.to(device=default_device()),\n",
    "#                         action=batch[k].action,\n",
    "#                         reward=batch[k].reward,\n",
    "#                         last_state=batch[k].last_state.to(device=default_device()),\n",
    "#                         done=batch[k].done,\n",
    "#                         episode_reward=batch[k].episode_reward,\n",
    "#                         steps=batch[k].steps\n",
    "#                     )\n",
    "\n",
    "\n",
    "#                 print(batch[0])\n",
    "                for _b in batch:self.queue.append(_b)\n",
    "                if any([_b.done for _b in batch]): self.learn.agent.reset_z()\n",
    "                if len(self.queue)>self.starting_els:break\n",
    "        self.learn.agent.warming_up=False\n",
    "\n",
    "# #     def after_epoch(self):\n",
    "# #         print(len(self.queue))\n",
    "    def before_batch(self):\n",
    "#         print(len(self.queue))\n",
    "        b=list(self.learn.xb)+list(self.learn.yb)\n",
    "        z=self.learn.agent.z\n",
    "        batch=[ExperienceFirstLast(state=self.learn.agent.concat_obs_z(b[0][i],z)[0],\n",
    "                                   action=b[1][i],\n",
    "                                   reward=b[2][i],\n",
    "                                   last_state=self.learn.agent.concat_obs_z(b[3][i],z)[0], \n",
    "                                   done=(b[4][i] and self.max_steps!=b[6][i]),\n",
    "                                   episode_reward=b[5][i],steps=b[6][i])\n",
    "              for i in range(len(b[0]))]\n",
    "        \n",
    "#         for k in range(len(batch)):\n",
    "#             intrinsic_reward,disc_out=self.learn.agent.intrinsic_reward(Tensor(batch[k].last_state))\n",
    "#             self.learn.agent.discriminator_learn(self.agent.z,disc_out)\n",
    "#             batch[k]=ExperienceFirstLast(\n",
    "#                 state=batch[k].state.to(device=default_device()),\n",
    "#                 action=batch[k].action,\n",
    "#                 reward=intrinsic_reward,\n",
    "#                 last_state=batch[k].last_state.to(device=default_device()),\n",
    "#                 done=batch[k].done,\n",
    "#                 episode_reward=batch[k].episode_reward,\n",
    "#                 steps=batch[k].steps\n",
    "#             )\n",
    "        \n",
    "#         print(self.learn.xb)\n",
    "        self.learn.xb=(torch.stack([e.state for e in batch]),)\n",
    "#         print(self.learn.yb)\n",
    "        self.learn.yb=(torch.stack([o.action for o in batch]),\n",
    "                       torch.stack([o.reward for o in batch]),\n",
    "                       torch.stack([o.last_state for o in batch]),\n",
    "                       torch.stack([o.done for o in batch]),\n",
    "                       torch.stack([o.episode_reward for o in batch]),\n",
    "                       torch.stack([o.steps for o in batch]))\n",
    "#         print(self.learn.yb)\n",
    "        \n",
    "        for _b in batch: self.queue.append(_b)\n",
    "        idxs=np.random.randint(0,len(self.queue), self.bs)\n",
    "        self.learn.sample_yb=[self.queue[i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_avg_episode_r</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_avg_episode_r</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-3.924977</td>\n",
       "      <td>26.916667</td>\n",
       "      <td>None</td>\n",
       "      <td>26.916667</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-3.294553</td>\n",
       "      <td>41.511628</td>\n",
       "      <td>None</td>\n",
       "      <td>41.511628</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-2.442293</td>\n",
       "      <td>52.387755</td>\n",
       "      <td>None</td>\n",
       "      <td>52.387755</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-2.159690</td>\n",
       "      <td>61.200000</td>\n",
       "      <td>None</td>\n",
       "      <td>61.200000</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-2.214790</td>\n",
       "      <td>68.483871</td>\n",
       "      <td>None</td>\n",
       "      <td>68.483871</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-2.215024</td>\n",
       "      <td>74.260870</td>\n",
       "      <td>None</td>\n",
       "      <td>74.260870</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-2.351509</td>\n",
       "      <td>78.680000</td>\n",
       "      <td>None</td>\n",
       "      <td>78.680000</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-2.919187</td>\n",
       "      <td>83.320988</td>\n",
       "      <td>None</td>\n",
       "      <td>83.320988</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-2.729967</td>\n",
       "      <td>87.372093</td>\n",
       "      <td>None</td>\n",
       "      <td>87.372093</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-2.266962</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>None</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pybulletgym.envs import *\n",
    "\n",
    "env='InvertedPendulumPyBulletEnv-v0'\n",
    "agent=DADS(5,gym.make(env).action_space,gamma=0.99,tau=0.005,alpha=0.1,hidden_size=300,num_skills=5)\n",
    "block=FirstLastExperienceBlock(agent=agent,seed=0,n_steps=2,exclude_nones=True,\n",
    "                               dls_kwargs={'bs':1,'num_workers':0,'verbose':False,'indexed':True,'shuffle_train':False})\n",
    "blk=IterableDataBlock(blocks=(block),splitter=FuncSplitter(lambda x:False))\n",
    "dls=blk.dataloaders([env]*1,n=1000,device=default_device())\n",
    "\n",
    "learner=SACLearner(dls,agent=agent,cbs=[DADSTrainer(sz=1000000,bs=64,starting_els=1000,max_steps=gym.make(env)._max_episode_steps),\n",
    "                                        SACCriticTrainer],\n",
    "                   metrics=[AvgEpisodeRewardMetric(experience_cls=ExperienceFirstLast)])\n",
    "learner.fit(10,lr=0.003,wd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=320x240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# slow\n",
    "import gym\n",
    "from IPython import display\n",
    "import PIL.Image\n",
    "%matplotlib inline\n",
    "\n",
    "env=gym.make('InvertedPendulumPyBulletEnv-v0')\n",
    "s=env.reset()\n",
    "\n",
    "for z in range(5):\n",
    "    for i in range(0,100,20):\n",
    "        s=env.reset()\n",
    "        env.seed(i)\n",
    "        for _ in range(200):\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(PIL.Image.fromarray(env.render(mode='rgb_array')))\n",
    "\n",
    "            agent.z=z\n",
    "            a,_=agent(s,None)\n",
    "\n",
    "            s,r,d,_=env.step(a)\n",
    "            if d:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_wrappers.ipynb.\n",
      "Converted 03_basic_agents.ipynb.\n",
      "Converted 04_learner.ipynb.\n",
      "Converted 05a_ptan_extend.ipynb.\n",
      "Converted 05b_data.ipynb.\n",
      "Converted 05c_async_data.ipynb.\n",
      "Converted 13_metrics.ipynb.\n",
      "Converted 14a_actorcritic.sac.ipynb.\n",
      "Converted 14b_actorcritic.diayn.ipynb.\n",
      "Converted 14c_actorcritic.dads.ipynb.\n",
      "Converted 15_actorcritic.a3c_data.ipynb.\n",
      "Converted 16_actorcritic.a2c.ipynb.\n",
      "Converted 18_policy_gradient.ppo.ipynb.\n",
      "Converted 19_policy_gradient.trpo.ipynb.\n",
      "Converted 20a_qlearning.dqn.ipynb.\n",
      "Converted 20b_qlearning.dqn_n_step.ipynb.\n",
      "Converted 20c_qlearning.dqn_target.ipynb.\n",
      "Converted 20d_qlearning.dqn_double.ipynb.\n",
      "Converted 20e_qlearning.dqn_noisy.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted notes.ipynb.\n",
      "converting: /opt/project/fastrl/nbs/14c_actorcritic.dads.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "from nbdev.export2html import *\n",
    "notebook2script()\n",
    "notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
