{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp actorcritic.sac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import torch.nn.utils as nn_utils\n",
    "from fastai.torch_basics import *\n",
    "import torch.nn.functional as F\n",
    "from fastai.data.all import *\n",
    "from fastai.basics import *\n",
    "from dataclasses import field,asdict\n",
    "from typing import List,Any,Dict,Callable\n",
    "from collections import deque\n",
    "import gym\n",
    "import torch.multiprocessing as mp\n",
    "from torch.optim import *\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from fastrl.data import *\n",
    "from fastrl.async_data import *\n",
    "from fastrl.basic_agents import *\n",
    "from fastrl.learner import *\n",
    "from fastrl.metrics import *\n",
    "from fastai.callback.progress import *\n",
    "from fastrl.ptan_extension import *\n",
    "\n",
    "from torch.distributions import *\n",
    "\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "from nbdev.export2html import *\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "HID_SIZE = 64\n",
    "\n",
    "class ModelActor(nn.Module):\n",
    "    def __init__(self, obs_size, act_size):\n",
    "        super(ModelActor, self).__init__()\n",
    "\n",
    "        self.mu = nn.Sequential(\n",
    "            nn.Linear(obs_size, HID_SIZE),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(HID_SIZE, HID_SIZE),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(HID_SIZE, act_size),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.logstd = nn.Parameter(torch.zeros(act_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mu(x.float())\n",
    "\n",
    "\n",
    "class ModelCritic(nn.Module):\n",
    "    def __init__(self, obs_size):\n",
    "        super(ModelCritic, self).__init__()\n",
    "\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(obs_size, HID_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HID_SIZE, HID_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HID_SIZE, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.value(x.float())\n",
    "\n",
    "\n",
    "class AgentA2C(BaseAgent):\n",
    "    \n",
    "    preprocessor:Callable=default_states_preprocessor\n",
    "    def __init__(self, model, device=\"cpu\"):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, states, agent_states):\n",
    "        states_v = torch.tensor(np.stack(states)).float().to(self.device) #self.preprocessor(states[0].reshape(1,-1))\n",
    "\n",
    "        mu_v = self.model(states_v)\n",
    "        mu = mu_v.data.cpu().numpy()\n",
    "        logstd = self.model.logstd.data.cpu().numpy()\n",
    "        actions = mu + np.exp(logstd) * np.random.normal(size=logstd.shape)\n",
    "        actions = np.clip(actions, -1, 1)\n",
    "#         print(actions)\n",
    "        return actions, agent_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "GAMMA = 0.99\n",
    "GAE_LAMBDA = 0.95\n",
    "\n",
    "LEARNING_RATE_ACTOR = 1e-4\n",
    "LEARNING_RATE_CRITIC = 1e-3\n",
    "\n",
    "PPO_EPS = 0.2\n",
    "PPO_EPOCHES = 10\n",
    "PPO_BATCH_SIZE = 64\n",
    "\n",
    "def calc_logprob(mu_v, logstd_v, actions_v):\n",
    "    p1 = - ((mu_v - actions_v) ** 2) / (2*torch.exp(logstd_v).clamp(min=1e-3))\n",
    "    p2 = - torch.log(torch.sqrt(2 * math.pi * torch.exp(logstd_v)))\n",
    "    return p1 + p2\n",
    "\n",
    "\n",
    "def calc_adv_ref(trajectory, net_crt, states_v, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    By trajectory calculate advantage and 1-step ref value\n",
    "    :param trajectory: trajectory list\n",
    "    :param net_crt: critic network\n",
    "    :param states_v: states tensor\n",
    "    :return: tuple with advantage numpy array and reference values\n",
    "    \"\"\"\n",
    "    values_v = net_crt(states_v)\n",
    "    values = values_v.squeeze().data.cpu().numpy()\n",
    "    # generalized advantage estimator: smoothed version of the advantage\n",
    "    last_gae = 0.0\n",
    "    result_adv = []\n",
    "    result_ref = []\n",
    "    for val, next_val, (exp,) in zip(reversed(values[:-1]), reversed(values[1:]),\n",
    "                                     reversed(trajectory[:-1])):\n",
    "        if exp.done:\n",
    "            delta = exp.reward - val\n",
    "            last_gae = delta\n",
    "        else:\n",
    "            delta = exp.reward + GAMMA * next_val - val\n",
    "            last_gae = delta + GAMMA * GAE_LAMBDA * last_gae\n",
    "        result_adv.append(last_gae)\n",
    "        result_ref.append(last_gae + val)\n",
    "\n",
    "    adv_v = torch.FloatTensor(list(reversed(result_adv))).to(device)\n",
    "    ref_v = torch.FloatTensor(list(reversed(result_ref))).to(device)\n",
    "    return adv_v, ref_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "TRPO_MAX_KL = 0.01\n",
    "TRPO_DAMPING = 0.1\n",
    "\n",
    "def get_flat_params_from(model):\n",
    "    params = []\n",
    "    for param in model.parameters():\n",
    "        params.append(param.data.view(-1))\n",
    "\n",
    "    flat_params = torch.cat(params)\n",
    "    return flat_params\n",
    "\n",
    "\n",
    "def set_flat_params_to(model, flat_params):\n",
    "    prev_ind = 0\n",
    "    for param in model.parameters():\n",
    "        flat_size = int(np.prod(list(param.size())))\n",
    "        param.data.copy_(\n",
    "            flat_params[prev_ind:prev_ind + flat_size].view(param.size()))\n",
    "        prev_ind += flat_size\n",
    "\n",
    "\n",
    "def conjugate_gradients(Avp, b, nsteps, residual_tol=1e-10, device=\"cpu\"):\n",
    "    x = torch.zeros(b.size()).to(device)\n",
    "    r = b.clone()\n",
    "    p = b.clone()\n",
    "    rdotr = torch.dot(r, r)\n",
    "    for i in range(nsteps):\n",
    "        _Avp = Avp(p)\n",
    "        alpha = rdotr / torch.dot(p, _Avp)\n",
    "        x += alpha * p\n",
    "        r -= alpha * _Avp\n",
    "        new_rdotr = torch.dot(r, r)\n",
    "        betta = new_rdotr / rdotr\n",
    "        p = r + betta * p\n",
    "        rdotr = new_rdotr\n",
    "        if rdotr < residual_tol:\n",
    "            break\n",
    "    return x\n",
    "\n",
    "\n",
    "def linesearch(model,\n",
    "               f,\n",
    "               x,\n",
    "               fullstep,\n",
    "               expected_improve_rate,\n",
    "               max_backtracks=10,\n",
    "               accept_ratio=.1):\n",
    "    fval = f().data\n",
    "    for (_n_backtracks, stepfrac) in enumerate(.5**np.arange(max_backtracks)):\n",
    "        xnew = x + fullstep * stepfrac\n",
    "        set_flat_params_to(model, xnew)\n",
    "        newfval = f().data\n",
    "        actual_improve = fval - newfval\n",
    "        expected_improve = expected_improve_rate * stepfrac\n",
    "        ratio = actual_improve / expected_improve\n",
    "\n",
    "        if ratio.item() > accept_ratio and actual_improve.item() > 0:\n",
    "            return True, xnew\n",
    "    return False, x\n",
    "\n",
    "def trpo_step(model, get_loss, get_kl, max_kl, damping, device=\"cpu\"):\n",
    "    loss = get_loss()\n",
    "    grads = torch.autograd.grad(loss, model.parameters())\n",
    "    loss_grad = torch.cat([grad.view(-1) for grad in grads]).data\n",
    "\n",
    "    def Fvp(v):\n",
    "        kl = get_kl()\n",
    "        kl = kl.mean()\n",
    "\n",
    "        grads = torch.autograd.grad(kl, model.parameters(), create_graph=True)\n",
    "        flat_grad_kl = torch.cat([grad.view(-1) for grad in grads])\n",
    "\n",
    "        v_v = torch.tensor(v).to(device)\n",
    "        kl_v = (flat_grad_kl * v_v).sum()\n",
    "        grads = torch.autograd.grad(kl_v, model.parameters())\n",
    "        flat_grad_grad_kl = torch.cat([grad.contiguous().view(-1) for grad in grads]).data\n",
    "\n",
    "        return flat_grad_grad_kl + v * damping\n",
    "\n",
    "    stepdir = conjugate_gradients(Fvp, -loss_grad, 10, device=device)\n",
    "\n",
    "    shs = 0.5 * (stepdir * Fvp(stepdir)).sum(0, keepdim=True)\n",
    "\n",
    "    lm = torch.sqrt(shs / max_kl)\n",
    "    fullstep = stepdir / lm[0]\n",
    "\n",
    "    neggdotstepdir = (-loss_grad * stepdir).sum(0, keepdim=True)\n",
    "\n",
    "    prev_params = get_flat_params_from(model)\n",
    "    success, new_params = linesearch(model, get_loss, prev_params, fullstep,\n",
    "                                     neggdotstepdir / lm[0])\n",
    "    set_flat_params_to(model, new_params)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def loss_func(*yb,learn):\n",
    "    b=list(learn.xb)+list(learn.yb)\n",
    "    yxb=b\n",
    "    trajectory=[(Experience(state=b[0][i],action=b[1][i],reward=b[2][i],\n",
    "                done=(b[3][i] and learn.max_step!=b[5][i]),episode_reward=b[4][i],\n",
    "                steps=b[5][i]),) for i in range(len(b[0]))]\n",
    "    net_crt=learn.net_crt\n",
    "    net_act=learn.model\n",
    "    opt_crt=learn.opt_crt\n",
    "    \n",
    "\n",
    "    traj_states = [t[0].state for t in trajectory]\n",
    "    traj_actions = [t[0].action for t in trajectory]\n",
    "#     traj_states = [t.state for t in trajectory]\n",
    "#     traj_actions = [t.action for t in trajectory]\n",
    "#     traj_states_v = torch.FloatTensor(traj_states).to(device)\n",
    "#     traj_actions_v = torch.FloatTensor(traj_actions).to(device)\n",
    "    traj_states_v = torch.stack(traj_states).float().to(default_device())\n",
    "    traj_actions_v = torch.stack(traj_actions).float().to(default_device())\n",
    "#     print(traj_states_v.size(),net_act)\n",
    "    traj_adv_v, traj_ref_v = calc_adv_ref(trajectory, net_crt, traj_states_v, device=default_device())\n",
    "    mu_v = net_act(traj_states_v)\n",
    "    old_logprob_v = calc_logprob(mu_v, net_act.logstd, traj_actions_v)\n",
    "\n",
    "    # normalize advantages\n",
    "    traj_adv_v = (traj_adv_v - torch.mean(traj_adv_v)) / torch.std(traj_adv_v)\n",
    "\n",
    "    # drop last entry from the trajectory, an our adv and ref value calculated without it\n",
    "    trajectory = trajectory[:-1]\n",
    "    old_logprob_v = old_logprob_v[:-1].detach()\n",
    "    traj_states_v = traj_states_v[:-1]\n",
    "    traj_actions_v = traj_actions_v[:-1]\n",
    "    sum_loss_value = 0.0\n",
    "    sum_loss_policy = 0.0\n",
    "    count_steps = 0\n",
    "\n",
    "    # critic step\n",
    "    opt_crt.zero_grad()\n",
    "    value_v = net_crt(traj_states_v)\n",
    "    loss_value_v = F.mse_loss(value_v.squeeze(-1), traj_ref_v)\n",
    "    loss_value_v.backward()\n",
    "#     print(loss_value_v)\n",
    "    opt_crt.step()\n",
    "\n",
    "    # actor step\n",
    "    def get_loss():\n",
    "        mu_v = net_act(traj_states_v)\n",
    "        logprob_v = calc_logprob(mu_v, net_act.logstd, traj_actions_v)\n",
    "        action_loss_v = -traj_adv_v.unsqueeze(dim=-1) * torch.exp(logprob_v - old_logprob_v)\n",
    "#         print(action_loss_v,action_loss_v.mean())\n",
    "        return action_loss_v.mean()\n",
    "\n",
    "    def get_kl():\n",
    "        mu_v = net_act(traj_states_v)\n",
    "        logstd_v = net_act.logstd\n",
    "        mu0_v = mu_v.detach()\n",
    "        logstd0_v = logstd_v.detach()\n",
    "        std_v = torch.exp(logstd_v)\n",
    "        std0_v = std_v.detach()\n",
    "        kl = logstd_v - logstd0_v + (std0_v ** 2 + (mu0_v - mu_v) ** 2) / (2.0 * std_v ** 2) - 0.5\n",
    "        return kl.sum(1, keepdim=True)\n",
    "\n",
    "    loss=trpo_step(net_act, get_loss, get_kl, TRPO_MAX_KL, TRPO_DAMPING, device=default_device())\n",
    "\n",
    "    return torch.tensor(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TRPOTrainer(Callback):\n",
    "    def after_loss(self):raise CancelBatchException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TRPOLearner(AgentLearner):\n",
    "    def __init__(self,dls,agent=None,crtic_lr=1e-3,max_step=1,**kwargs):\n",
    "        store_attr()\n",
    "        self.net_crt=ModelCritic(26).to(default_device())\n",
    "        self.opt_crt = Adam(self.net_crt.parameters(), lr=crtic_lr)\n",
    "\n",
    "        super().__init__(dls,loss_func=partial(loss_func,learn=self),model=agent.model,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WalkerBase::__init__\n",
      "WalkerBase::__init__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_avg_episode_r</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_avg_episode_r</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.867225</td>\n",
       "      <td>None</td>\n",
       "      <td>1.867225</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.581237</td>\n",
       "      <td>None</td>\n",
       "      <td>4.581237</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.013871</td>\n",
       "      <td>None</td>\n",
       "      <td>6.013871</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.744021</td>\n",
       "      <td>None</td>\n",
       "      <td>6.744021</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.103516</td>\n",
       "      <td>None</td>\n",
       "      <td>7.103516</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.459056</td>\n",
       "      <td>None</td>\n",
       "      <td>7.459056</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.711311</td>\n",
       "      <td>None</td>\n",
       "      <td>7.711311</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.075411</td>\n",
       "      <td>None</td>\n",
       "      <td>8.075411</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.610297</td>\n",
       "      <td>None</td>\n",
       "      <td>8.610297</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.437673</td>\n",
       "      <td>None</td>\n",
       "      <td>9.437673</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.331005</td>\n",
       "      <td>None</td>\n",
       "      <td>11.331005</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.907000</td>\n",
       "      <td>None</td>\n",
       "      <td>12.907000</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.910796</td>\n",
       "      <td>None</td>\n",
       "      <td>14.910796</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.457663</td>\n",
       "      <td>None</td>\n",
       "      <td>17.457663</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.343821</td>\n",
       "      <td>None</td>\n",
       "      <td>20.343821</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.993520</td>\n",
       "      <td>None</td>\n",
       "      <td>23.993520</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.274211</td>\n",
       "      <td>None</td>\n",
       "      <td>28.274211</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.292387</td>\n",
       "      <td>None</td>\n",
       "      <td>34.292387</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.755539</td>\n",
       "      <td>None</td>\n",
       "      <td>43.755539</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.928651</td>\n",
       "      <td>None</td>\n",
       "      <td>66.928651</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/ipykernel_launcher.py:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/ipykernel_launcher.py:161: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastprogress/fastprogress.py:74: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import pybulletgym\n",
    "env='HalfCheetahPyBulletEnv-v0'\n",
    "agent=AgentA2C(ModelActor(26, 6).to(default_device()), device=default_device())\n",
    "\n",
    "block=ExperienceBlock(agent=agent,seed=0,n_steps=1,\n",
    "                      dls_kwargs={'bs':2049,'num_workers':0,'verbose':False,'indexed':True,'shuffle_train':False})\n",
    "blk=IterableDataBlock(blocks=(block),splitter=FuncSplitter(lambda x:False))\n",
    "dls=blk.dataloaders([env]*1,n=2049*10,device=default_device())\n",
    "\n",
    "learner=TRPOLearner(dls,agent=agent,cbs=[TRPOTrainer], metrics=[AvgEpisodeRewardMetric(Experience)],max_step=gym.make(env)._max_episode_steps)\n",
    "learner.fit(20,lr=0.001,wd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
