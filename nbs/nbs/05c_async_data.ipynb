{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp async_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.basics import *\n",
    "import torch.multiprocessing as mp\n",
    "from fastrl.data import *\n",
    "from fastrl.basic_agents import *\n",
    "from fastcore.all import *\n",
    "from dataclasses import field,asdict\n",
    "from typing import List,Any,Dict,Callable\n",
    "from collections import deque\n",
    "import gym\n",
    "import queue\n",
    "from queue import Empty\n",
    "import sys\n",
    "import traceback\n",
    "from time import sleep\n",
    "\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from itertools import product\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "\n",
    "import torch \n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.cudaStatus()\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "\n",
    "from fastrl.learner import *\n",
    "\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async Experience Blocks\n",
    "\n",
    "> Extend traditional experience blocks to run environments asynchronously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the challenges involve being able to run async envs in `spawned` process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define a more convenient `Process` object to work with. It allows for easily passing the `data_fit` callable along with allowing to query the `kwargs` using the fastai delegates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _noopo():\n",
    "    def __getattr__(self,*args):       return noopo\n",
    "    def __call__(self,*args,**kwargs): return noopo\n",
    "    def __getitem__(self,*args):       return noopo\n",
    "    def __bool__(self):                return False\n",
    "noopo = _noopo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def template_data_fit(train_queue=None,items:L=None,\n",
    "                      agent:BaseAgent=None,experience_block:ExperienceBlock=None,\n",
    "                      cancel=None):\n",
    "    sleep(3)\n",
    "    train_queue=ifnone(train_queue,mp.JoinableQueue)\n",
    "    cancel=ifnone(cancel,mp.Event)\n",
    "    ifnone(pipe_out,noopo).send('Hello')\n",
    "    try:\n",
    "        blk=IterableDataBlock(blocks=(experience_block(agent=agent())),\n",
    "                          splitter=FuncSplitter(lambda x:False))\n",
    "        dls=blk.dataloaders(items,device=get_default_device())\n",
    "        while True:\n",
    "            for xb in dls[0]:\n",
    "                xb=[o.cpu().numpy()[0] for o in xb]\n",
    "                xb=[ExperienceFirstLast(state=xb[0],action=xb[1],reward=xb[2],\n",
    "                                        last_state=xb[3], # if not xb[4] else None,\n",
    "                                        done=xb[4],\n",
    "                                        episode_reward=xb[5])]\n",
    "\n",
    "                new_rewards = [o.episode_reward for o in xb if o.done and int(o.episode_reward) != 0]\n",
    "                if new_rewards: train_queue.put(TotalReward(reward=np.mean(new_rewards)))\n",
    "\n",
    "                for x in xb: train_queue.put(x)\n",
    "                if cancel.is_set():\n",
    "                    train_queue.put(None)\n",
    "                    return None\n",
    "    finally:\n",
    "        cancel.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataFitProcess(mp.Process):\n",
    "    @delegates(template_data_fit,but=['train_queue','items','pipe_in','pipe_out'])\n",
    "    def __init__(self,start:bool=False,data_fit=None,**kwargs):\n",
    "        super().__init__(target=ifnone(data_fit,template_data_fit),kwargs=kwargs)\n",
    "#         sleep(3)\n",
    "        if start: \n",
    "            self.start()\n",
    "            print('starting')\n",
    "        \n",
    "    def termijoin(self):\n",
    "        self.terminate()\n",
    "        self.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _LinearA2C(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(_LinearA2C, self).__init__()\n",
    "\n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        fx=x.float()\n",
    "        return self.policy(fx),self.value(fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def safe_get(q,e,p_in):\n",
    "    while not e.is_set():\n",
    "        if ifnone(p_in,noopo).poll(): print(p_in.recv())\n",
    "        try: return q.get_nowait()\n",
    "        except Empty:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "TotalReward = collections.namedtuple('TotalReward', field_names='reward')\n",
    "\n",
    "class MultiProcessTfm(Transform):\n",
    "    def __init__(self,\n",
    "                 n_processes: int = 1, process_cls=None,\n",
    "                 cancel=None,\n",
    "                 verbose: str = False,\n",
    "                 regular_get: bool = True,\n",
    "                 tracker=None\n",
    "                 ):\n",
    "        store_attr(but='process_cls')\n",
    "        self.process_cls=ifnone(process_cls,DataFitProcess)\n",
    "        self.queue = mp.JoinableQueue(maxsize=self.n_processes)\n",
    "        self.cancel = ifnone(self.cancel,mp.Event())\n",
    "        self.pipe_in, self.pipe_out = mp.Pipe(False) if self.verbose else (None, None)\n",
    "        self.cached_items = []\n",
    "        self._place_holder_out = None\n",
    "        self.step_idx=0\n",
    "\n",
    "    def setup(self, items: TfmdSource, train_setup=False):\n",
    "        pv('setting up',self.verbose)\n",
    "        self.cancel.clear()\n",
    "        if len(items.items) != 0 and not issubclass(items.items[0].__class__, DataFitProcess):\n",
    "            self.cached_items = deepcopy(items.items)\n",
    "        self.reset(items)\n",
    "\n",
    "    def reset(self, items: TfmdSource, train_setup=False):\n",
    "        pv('reset',self.verbose)\n",
    "        self.step_idx = 0\n",
    "        self.close(items)\n",
    "        self.cancel.clear()\n",
    "        self.queue = mp.JoinableQueue(maxsize=self.n_processes)\n",
    "        items.items = [self.process_cls(start=True, items=self.cached_items,train_queue=self.queue,cancel=self.cancel)\n",
    "                       for _ in range(self.n_processes)]\n",
    "        if not all([p.is_alive() for p in items.items]): raise CancelFitException()\n",
    "\n",
    "    def close(self, items: TfmdSource):\n",
    "        self.step_idx = 0\n",
    "        pv('close',self.verbose)\n",
    "        self.cancel.set()\n",
    "        try:\n",
    "            while not self.queue.empty():o=self.queue.get()\n",
    "        except (ConnectionResetError, FileNotFoundError, EOFError, ConnectionRefusedError, RuntimeError):\n",
    "            print('exception? is the queue empty? ',self.queue.empty())\n",
    "        for o in [p for p in items.items if issubclass(p.__class__, DataFitProcess)]:\n",
    "            o.termijoin()\n",
    "            del o\n",
    "            torch.cuda.empty_cache()\n",
    "        items.items.clear()\n",
    "\n",
    "    def encodes(self, o):\n",
    "        pv('encodes {o}', self.verbose)\n",
    "        while True:\n",
    "            if not self.cancel.is_set():\n",
    "                o=safe_get(self.queue,self.cancel,self.pipe_in) if not self.regular_get else self.queue.get()\n",
    "                self._place_holder_out = ifnone(self._place_holder_out, o)\n",
    "                if isinstance(o, TotalReward):\n",
    "                    if ifnone(self.tracker,noopo()).reward(o.reward, self.step_idx):sys.exit()\n",
    "                    self.step_idx+=1\n",
    "                    continue\n",
    "                return [o]\n",
    "            else:\n",
    "                raise CancelFitException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def AsyncExperienceBlock(experience_block, agent=None, data_fit=None, n_processes=1, n=200, bs=1,**kwargs):\n",
    "    process_cls = partial(\n",
    "        DataFitProcess,\n",
    "        agent=agent,\n",
    "        experience_block=experience_block,\n",
    "        data_fit=data_fit\n",
    "    )\n",
    "\n",
    "    return TransformBlock(type_tfms=[\n",
    "        MultiProcessTfm(process_cls=process_cls, n_processes=n_processes, **kwargs)],\n",
    "                          dl_type=TfmdSourceDL, dls_kwargs={'bs': bs, 'num_workers': 0, 'verbose': False, 'indexed': True,\n",
    "                                      'shuffle_train': False, 'n': n})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_wrappers.ipynb.\n",
      "Converted 03_basic_agents.ipynb.\n",
      "Converted 04_learner.ipynb.\n",
      "Converted 05a_data.ipynb.\n",
      "Converted 05b_async_data.ipynb.\n",
      "Converted 06_basic_train.ipynb.\n",
      "Converted 13_metrics.ipynb.\n",
      "Converted 14_actorcritic.sac.ipynb.\n",
      "Converted 15_actorcritic.a3c_data.ipynb.\n",
      "Converted 16_actorcritic.a2c.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting: /opt/project/fastrl/nbs/05b_async_data.ipynb\n",
      "converting: /opt/project/fastrl/nbs/15_actorcritic.a3c_data.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "from nbdev.export2html import *\n",
    "notebook2script()\n",
    "notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
