{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp actorcritic.a3c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn.utils as nn_utils\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.basics import *\n",
    "from dataclasses import field,asdict\n",
    "from typing import List,Any,Dict,Callable\n",
    "from collections import deque\n",
    "import gym\n",
    "import torch.multiprocessing as mp\n",
    "from torch.optim import *\n",
    "\n",
    "from fastrl.data import *\n",
    "from fastrl.async_data import *\n",
    "from fastrl.basic_agents import *\n",
    "from fastrl.learner import *\n",
    "from fastrl.metrics import *\n",
    "from fastrl.ptan_extension import *\n",
    "\n",
    "if IN_NOTEBOOK:\n",
    "    from IPython import display\n",
    "    import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.imports import *\n",
    "if not os.environ.get(\"IN_TEST\", None):\n",
    "    assert IN_NOTEBOOK\n",
    "    assert not IN_COLAB\n",
    "    assert IN_IPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A3C Datawise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3C Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LinearA2C(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(LinearA2C, self).__init__()\n",
    "\n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        fx=x.float()\n",
    "        return self.policy(fx),self.value(fx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3C Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def unbatch(batch, net, val_gamma,device='cpu'):\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    not_done_idx = []\n",
    "    last_states = []\n",
    "    for idx, exp in enumerate(batch):\n",
    "#         print(exp.state.numpy().shape,int(exp.action),float(exp.reward),exp.last_state.numpy().shape if not bool(exp.done) else None,exp.done)\n",
    "        states.append(np.array(exp.state.cpu().detach().numpy(), copy=False))\n",
    "        actions.append(int(exp.action.cpu().detach()))\n",
    "        rewards.append(float(exp.reward.cpu().detach()))\n",
    "        if not exp.done:\n",
    "            not_done_idx.append(idx)\n",
    "            last_states.append(np.array(exp.last_state.cpu().detach().numpy(), copy=False))\n",
    "    states_v = torch.FloatTensor(states).to(device)\n",
    "    actions_t = torch.LongTensor(actions).to(device)\n",
    "    # handle rewards\n",
    "    rewards_np = np.array(rewards, dtype=np.float32)\n",
    "    if not_done_idx:\n",
    "        last_states_v = torch.FloatTensor(last_states).to(device)\n",
    "        last_vals_v = net(last_states_v)[1]\n",
    "        last_vals_np = last_vals_v.data.cpu().numpy()[:, 0]\n",
    "        rewards_np[not_done_idx] += val_gamma * last_vals_np\n",
    "\n",
    "    ref_vals_v = torch.FloatTensor(rewards_np).to(device)\n",
    "    return states_v, actions_t, ref_vals_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def loss_func(pred,a,r,sp,d,episode_rewards,learn=None):\n",
    "\n",
    "    b=list(learn.xb)+list(learn.yb)\n",
    "    batch=[ExperienceFirstLast(state=b[0][i],action=b[1][i],reward=b[2][i],\n",
    "                            last_state=b[3][i] if not b[4][i] else None, done=b[4][i],episode_reward=b[5][i])\n",
    "                            for i in range(len(b[0]))]\n",
    "\n",
    "    states_v, actions_t, vals_ref_v = \\\n",
    "        unbatch(batch, learn.model,val_gamma=learn.discount**learn.reward_steps, device=default_device())\n",
    "    batch.clear()\n",
    "\n",
    "    logits_v, value_v = learn.model(states_v)\n",
    "\n",
    "    loss_value_v = F.mse_loss(value_v.squeeze(-1), vals_ref_v)\n",
    "\n",
    "    log_prob_v = F.log_softmax(logits_v, dim=1)\n",
    "    adv_v = vals_ref_v - value_v.detach()\n",
    "    log_prob_actions_v = adv_v * log_prob_v[range(128), actions_t]\n",
    "    loss_policy_v = -log_prob_actions_v.mean()\n",
    "    prob_v = F.softmax(logits_v, dim=1)\n",
    "    entropy_loss_v = learn.entropy_beta * (prob_v * log_prob_v).sum(dim=1).mean()\n",
    "    loss_v = entropy_loss_v + loss_value_v + loss_policy_v\n",
    "\n",
    "    return loss_v\n",
    "\n",
    "class A3CLearner(AgentLearner):\n",
    "    def __init__(self,dls,discount=0.99,entropy_beta=0.01,clip_grad=0.1,reward_steps=1,**kwargs):\n",
    "        super().__init__(dls,loss_func=partial(loss_func,learn=self),**kwargs)\n",
    "        self.opt=OptimWrapper(AdamW(self.model.parameters(),eps=1e-3))\n",
    "        self.model.share_memory()\n",
    "        self.discount=discount\n",
    "        self.entropy_beta=entropy_beta\n",
    "        self.reward_steps=reward_steps\n",
    "        self.clip_grad=clip_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class A3CTrainer(Callback):\n",
    "    def after_backward(self):\n",
    "        nn_utils.clip_grad_norm_(self.learn.model.parameters(),self.learn.clip_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def data_fit(train_queue=None,items:L=None,agent=None,experience_block=None,\n",
    "             cancel=None):\n",
    "    try:\n",
    "        print('hi1')\n",
    "        blk=IterableDataBlock(blocks=(experience_block(agent=agent())),\n",
    "                              splitter=FuncSplitter(lambda x:False))\n",
    "        dls=blk.dataloaders(items,device=default_device())#,n=128*100)\n",
    "        while True:\n",
    "            print('hi')\n",
    "            for xb in dls[0]:\n",
    "                xb=[o.cpu().numpy()[0] for o in xb]\n",
    "                xb=[ExperienceFirstLast(state=xb[0],action=xb[1],reward=xb[2],\n",
    "                                        last_state=xb[3], # if not xb[4] else None,\n",
    "                                        done=xb[4],\n",
    "                                        episode_reward=xb[5])]\n",
    "\n",
    "                new_rewards = [o.episode_reward for o in xb if o.done and int(o.episode_reward) != 0]\n",
    "                if new_rewards: train_queue.put(TotalReward(reward=np.mean(new_rewards)))\n",
    "\n",
    "                for x in xb: train_queue.put(x)\n",
    "                if cancel.is_set():\n",
    "                    train_queue.put(None)\n",
    "                    return None\n",
    "    finally:\n",
    "        cancel.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "starting\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_avg_episode_r</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_avg_episode_r</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19.194157</td>\n",
       "      <td>23.660611</td>\n",
       "      <td>None</td>\n",
       "      <td>23.660611</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>26.692215</td>\n",
       "      <td>29.130821</td>\n",
       "      <td>None</td>\n",
       "      <td>29.130821</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>35.559528</td>\n",
       "      <td>63.534667</td>\n",
       "      <td>None</td>\n",
       "      <td>63.534667</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>49.418739</td>\n",
       "      <td>79.073167</td>\n",
       "      <td>None</td>\n",
       "      <td>79.073167</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>55.525867</td>\n",
       "      <td>123.143333</td>\n",
       "      <td>None</td>\n",
       "      <td>123.143333</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>61.535820</td>\n",
       "      <td>161.861667</td>\n",
       "      <td>None</td>\n",
       "      <td>161.861667</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>79.512482</td>\n",
       "      <td>186.555000</td>\n",
       "      <td>None</td>\n",
       "      <td>186.555000</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>84.288086</td>\n",
       "      <td>209.763333</td>\n",
       "      <td>None</td>\n",
       "      <td>209.763333</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>97.959930</td>\n",
       "      <td>216.406667</td>\n",
       "      <td>None</td>\n",
       "      <td>216.406667</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>110.241119</td>\n",
       "      <td>207.075000</td>\n",
       "      <td>None</td>\n",
       "      <td>207.075000</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastrl/lib/python3.7/site-packages/fastprogress/fastprogress.py:74: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    import gym\n",
    "    from fastai.torch_basics import *\n",
    "    from fastai.data.all import *\n",
    "    from fastai.basics import *\n",
    "    from fastrl.data import *\n",
    "    from fastrl.async_data import *\n",
    "    from fastrl.basic_agents import *\n",
    "    from fastrl.learner import *\n",
    "    from fastrl.metrics import *\n",
    "    from fastrl.actorcritic.a3c_data import data_fit,A3CTrainer,loss_func,A3CLearner,unbatch,LinearA2C\n",
    "    \n",
    "    try:\n",
    "        mp.set_start_method('spawn')\n",
    "    except Exception: pass\n",
    "    \n",
    "    env = gym.make('CartPole-v1')\n",
    "    net = LinearA2C(env.observation_space.shape, env.action_space.n).to(default_device())\n",
    "    net.share_memory()\n",
    "    \n",
    "    block=AsyncExperienceBlock(\n",
    "        agent=partial(ActorCriticAgent, model=net, device='cuda'),\n",
    "        experience_block=partial(FirstLastExperienceBlock, a=0, seed=0, n_steps=4, dls_kwargs={'bs': 1, 'num_workers': 0,\n",
    "                                                                      'verbose': False,\n",
    "                                                                      'indexed': True,\n",
    "                                                                      'shuffle_train': False,\n",
    "                                                                      'n':128*1000}),\n",
    "        data_fit=data_fit,\n",
    "        n_processes=3,\n",
    "    )\n",
    "\n",
    "    blk = IterableDataBlock(blocks=(block), splitter=FuncSplitter(lambda x: False))\n",
    "    dls = blk.dataloaders(['CartPole-v1'] * 15, bs=128, num_workers=0, verbose=False,\n",
    "                          indexed=True, shuffle_train=False, n=128*100, device=default_device())\n",
    "\n",
    "    agent=ActorCriticAgent(model=net)\n",
    "    learner=A3CLearner(dls,agent=agent,cbs=[A3CTrainer],reward_steps=4,metrics=[AvgEpisodeRewardMetric()])\n",
    "    learner.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_wrappers.ipynb.\n",
      "Converted 03_basic_agents.ipynb.\n",
      "Converted 04_learner.ipynb.\n",
      "Converted 05a_data.ipynb.\n",
      "Converted 05b_async_data.ipynb.\n",
      "Converted 13_metrics.ipynb.\n",
      "Converted 14_actorcritic.sac.ipynb.\n",
      "Converted 15_actorcritic.a3c_data.ipynb.\n",
      "Converted 16_actorcritic.a2c.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted notes.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "from nbdev.export2html import *\n",
    "notebook2script()\n",
    "notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
