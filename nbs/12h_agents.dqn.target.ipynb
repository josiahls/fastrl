{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.dqn.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "from collections import deque\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from torch.utils.data.datapipes._typing import _DataPipeMeta, _IterDataPipeMeta\n",
    "# Local modules\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "\n",
    "from fastrl.core import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.fastai.data.block import *\n",
    "from fastrl.memory.experience_replay import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.agents.discrete import *\n",
    "from fastrl.loggers.core import *\n",
    "from fastrl.loggers.jupyter_visualizers import *\n",
    "from fastrl.learner.core import *\n",
    "from fastrl.agents.dqn.basic import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Target\n",
    "> DQN that uses snapshots from the NN module to stabilize training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c98be0-6288-443a-b4ab-9390fbe3081c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Training DataPipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc8c66df-7063-4c77-915b-2c2c8c1b4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TargetQCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,discount=0.99,nsteps=1,target_sync=300):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.discount = discount\n",
    "        self.nsteps = nsteps\n",
    "        self.learner = find_dp(self,LearnerBase)\n",
    "        self.learner.target_model=deepcopy(self.learner.model)\n",
    "        self.target_sync = target_sync\n",
    "        self.n_batch = 0\n",
    "                \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            try:\n",
    "                self.learner.done_mask = batch.terminated.reshape(-1,)\n",
    "                with torch.no_grad():\n",
    "                    self.learner.next_q = self.learner.target_model(batch.next_state)\n",
    "                self.learner.next_q = self.learner.next_q.max(dim=1).values.reshape(-1,1)\n",
    "                self.learner.next_q[self.learner.done_mask] = 0 #xb[done_mask]['reward']\n",
    "                self.learner.targets = batch.reward+self.learner.next_q*(self.discount**self.nsteps)\n",
    "                self.learner.pred = self.learner.model(batch.state)\n",
    "\n",
    "                t_q=self.learner.pred.clone()\n",
    "                t_q.scatter_(1,batch.action.long(),self.learner.targets)\n",
    "\n",
    "                self.learner.loss_grad = self.learner.loss_func(self.learner.pred, t_q)\n",
    "                \n",
    "                if self.n_batch%self.target_sync==0:\n",
    "                    self.learner.target_model.load_state_dict(self.learner.model.state_dict())\n",
    "                self.n_batch+=1\n",
    "                \n",
    "                yield batch\n",
    "            except RuntimeError as e:\n",
    "                print(f'Failed on batch: {batch}')\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c50c9dd-89fc-4a89-a6f0-ccd6126135d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DQNLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    logger_bases=None,\n",
    "    loss_func=MSELoss(),\n",
    "    opt=AdamW,\n",
    "    lr=0.005,\n",
    "    bs=128,\n",
    "    max_sz=10000,\n",
    "    nsteps=1\n",
    ") -> LearnerHead:\n",
    "    learner = LearnerBase(model,dls,loss_func=MSELoss(),opt=opt(model.parameters(),lr=lr))\n",
    "    learner = BatchCollector(learner,logger_bases=logger_bases,batch_on_pipe=LearnerBase)\n",
    "    learner = EpocherCollector(learner,logger_bases=logger_bases)\n",
    "    for logger_base in logger_bases: learner = logger_base.connect_source_datapipe(learner)\n",
    "    learner = RollingTerminatedRewardCollector(learner,logger_bases)\n",
    "    learner = EpisodeCollector(learner,logger_bases)\n",
    "    learner = ExperienceReplay(learner,bs=bs,max_sz=max_sz,clone_detach=dls[0].num_workers>0)\n",
    "    learner = StepBatcher(learner)\n",
    "    learner = TargetQCalc(learner,nsteps=nsteps)\n",
    "    learner = ModelLearnCalc(learner)\n",
    "    learner = LossCollector(learner,logger_bases)\n",
    "    learner = LearnerHead(learner)\n",
    "    return learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f9ed8-fb05-40a1-ac0d-d4cafee8fa07",
   "metadata": {},
   "source": [
    "Try training with basic defaults..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63d9b481-5998-472a-a2df-18d79bf07ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>episode</th>\n",
       "      <th>rolling_reward</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.024505302</td>\n",
       "      <td>40</td>\n",
       "      <td>25.358974</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0.749500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.036232878</td>\n",
       "      <td>70</td>\n",
       "      <td>28.724638</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0.499250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.102315</td>\n",
       "      <td>97</td>\n",
       "      <td>31.260416</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.060944464</td>\n",
       "      <td>107</td>\n",
       "      <td>36.94</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.21567708</td>\n",
       "      <td>115</td>\n",
       "      <td>45.24</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.19259728</td>\n",
       "      <td>122</td>\n",
       "      <td>53.49</td>\n",
       "      <td>6</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.052362118</td>\n",
       "      <td>131</td>\n",
       "      <td>61.41</td>\n",
       "      <td>7</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.20539467</td>\n",
       "      <td>136</td>\n",
       "      <td>70.03</td>\n",
       "      <td>8</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.16388416</td>\n",
       "      <td>139</td>\n",
       "      <td>79.7</td>\n",
       "      <td>9</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.36947852</td>\n",
       "      <td>143</td>\n",
       "      <td>87.45</td>\n",
       "      <td>10</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.114471994</td>\n",
       "      <td>149</td>\n",
       "      <td>97.43</td>\n",
       "      <td>11</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.25285804</td>\n",
       "      <td>157</td>\n",
       "      <td>104.46</td>\n",
       "      <td>12</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.18410252</td>\n",
       "      <td>167</td>\n",
       "      <td>111.47</td>\n",
       "      <td>13</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.74844766</td>\n",
       "      <td>177</td>\n",
       "      <td>116.59</td>\n",
       "      <td>14</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.196775</td>\n",
       "      <td>185</td>\n",
       "      <td>124.48</td>\n",
       "      <td>15</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.25312394</td>\n",
       "      <td>191</td>\n",
       "      <td>132.3</td>\n",
       "      <td>16</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.20107326</td>\n",
       "      <td>195</td>\n",
       "      <td>137.64</td>\n",
       "      <td>17</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.3558294</td>\n",
       "      <td>203</td>\n",
       "      <td>145.39</td>\n",
       "      <td>18</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.3630662</td>\n",
       "      <td>212</td>\n",
       "      <td>144.56</td>\n",
       "      <td>19</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.4591792</td>\n",
       "      <td>220</td>\n",
       "      <td>142.57</td>\n",
       "      <td>20</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.7171277</td>\n",
       "      <td>228</td>\n",
       "      <td>144.12</td>\n",
       "      <td>21</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5451607</td>\n",
       "      <td>235</td>\n",
       "      <td>143.61</td>\n",
       "      <td>22</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.42969412</td>\n",
       "      <td>242</td>\n",
       "      <td>134.24</td>\n",
       "      <td>23</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.22388938</td>\n",
       "      <td>249</td>\n",
       "      <td>129.76</td>\n",
       "      <td>24</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.308748</td>\n",
       "      <td>253</td>\n",
       "      <td>133.6</td>\n",
       "      <td>24</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastrl.envs.gym import *\n",
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n",
    "                 batch_on_pipe=BatchCollector)\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,[logger_base],max_steps=4000)\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False)\n",
    ")\n",
    "# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=1000,bs=1))\n",
    "# Setup the Learner\n",
    "learner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=100_000)\n",
    "# learner.fit(3)\n",
    "learner.fit(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0ed73-7bbf-415b-9ee7-9a95de31d638",
   "metadata": {},
   "source": [
    "The DQN learners, but I wonder if we can get it to learn faster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95d510e-38c1-458c-9830-df5a68e6a53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>episode</th>\n",
       "      <th>rolling_reward</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.16360937</td>\n",
       "      <td>76</td>\n",
       "      <td>25.43</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0.810700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.97472405</td>\n",
       "      <td>120</td>\n",
       "      <td>41.56</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0.616600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.7758416</td>\n",
       "      <td>143</td>\n",
       "      <td>64.6</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0.419400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.2820246</td>\n",
       "      <td>152</td>\n",
       "      <td>97.72</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.7946675</td>\n",
       "      <td>158</td>\n",
       "      <td>134.02</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4.156575</td>\n",
       "      <td>164</td>\n",
       "      <td>159.68</td>\n",
       "      <td>6</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.9091346</td>\n",
       "      <td>170</td>\n",
       "      <td>194.42</td>\n",
       "      <td>7</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7.9426823</td>\n",
       "      <td>174</td>\n",
       "      <td>229.54</td>\n",
       "      <td>8</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.387251</td>\n",
       "      <td>179</td>\n",
       "      <td>262.16</td>\n",
       "      <td>9</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.265861</td>\n",
       "      <td>185</td>\n",
       "      <td>298.84</td>\n",
       "      <td>9</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n",
    "                 batch_on_pipe=BatchCollector)\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,[logger_base],max_steps=10000)\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True) # We basically merge 2 steps into 1 and skip. \n",
    ")\n",
    "# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=1000,bs=1))\n",
    "# Setup the Learner\n",
    "learner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=20_000,nsteps=2,lr=0.001)\n",
    "# learner.fit(3)\n",
    "learner.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6de0f41e-2eda-4227-9fa8-f2e0b920754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.loggers.jupyter_visualizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15937f36-8efa-4163-bc67-20019d18c98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7482490a-475e-4c46-b1fa-193bf68b7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.envs.gym import GymTypeTransform,GymStepper\n",
    "\n",
    "def gym_pipe_base(envs,total_steps,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformLoop(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle(count=total_steps)\n",
    "    pipe = GymStepper(pipe,agent=agent,seed=seed,include_images=True)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc10e61-4f65-4a17-a5a9-489bb466af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8784650-6f5c-42b7-9a72-68a0d37d8983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "video_logger = SimpleJupyterVideoPlayer()\n",
    "\n",
    "pipe = gym_pipe_base(['CartPole-v1'],1000,seed=None)\n",
    "pipe = ImageCollector(pipe,[video_logger])\n",
    "\n",
    "pipe = video_logger.connect_source_datapipe(pipe)\n",
    "\n",
    "for o in pipe:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d3626-1702-4f22-ae15-bb93a75bec68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
