{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.dqn.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "from collections import deque\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from torch.utils.data.datapipes._typing import _DataPipeMeta, _IterDataPipeMeta\n",
    "from torchdata.dataloader2.graph import find_dps,traverse\n",
    "# Local modules\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "\n",
    "from fastrl.core import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.fastai.data.block import *\n",
    "from fastrl.memory.experience_replay import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.agents.discrete import *\n",
    "from fastrl.loggers.core import *\n",
    "from fastrl.loggers.jupyter_visualizers import *\n",
    "from fastrl.learner.core import *\n",
    "from fastrl.agents.dqn.basic import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Target\n",
    "> DQN that uses snapshots from the NN module to stabilize training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c98be0-6288-443a-b4ab-9390fbe3081c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Training DataPipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc8c66df-7063-4c77-915b-2c2c8c1b4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TargetQCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,discount=0.99,nsteps=1,target_sync=300):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.discount = discount\n",
    "        self.nsteps = nsteps\n",
    "        self.learner = find_dp(traverse(self),LearnerBase)\n",
    "        self.learner.target_model=deepcopy(self.learner.model)\n",
    "        self.target_sync = target_sync\n",
    "        self.n_batch = 0\n",
    "                \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            try:\n",
    "                self.learner.done_mask = batch.terminated.reshape(-1,)\n",
    "                with torch.no_grad():\n",
    "                    self.learner.next_q = self.learner.target_model(batch.next_state)\n",
    "                self.learner.next_q = self.learner.next_q.max(dim=1).values.reshape(-1,1)\n",
    "                self.learner.next_q[self.learner.done_mask] = 0 #xb[done_mask]['reward']\n",
    "                self.learner.targets = batch.reward+self.learner.next_q*(self.discount**self.nsteps)\n",
    "                self.learner.pred = self.learner.model(batch.state)\n",
    "\n",
    "                t_q=self.learner.pred.clone()\n",
    "                t_q.scatter_(1,batch.action.long(),self.learner.targets)\n",
    "\n",
    "                self.learner.loss_grad = self.learner.loss_func(self.learner.pred, t_q)\n",
    "                \n",
    "                if self.n_batch%self.target_sync==0:\n",
    "                    self.learner.target_model.load_state_dict(self.learner.model.state_dict())\n",
    "                self.n_batch+=1\n",
    "                \n",
    "                yield batch\n",
    "            except RuntimeError as e:\n",
    "                print(f'Failed on batch: {batch}')\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c50c9dd-89fc-4a89-a6f0-ccd6126135d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DQNLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    logger_bases=None,\n",
    "    loss_func=MSELoss(),\n",
    "    opt=AdamW,\n",
    "    lr=0.005,\n",
    "    bs=128,\n",
    "    max_sz=10000,\n",
    "    nsteps=1\n",
    ") -> LearnerHead:\n",
    "    learner = LearnerBase(model,dls,loss_func=MSELoss(),opt=opt(model.parameters(),lr=lr))\n",
    "    learner = BatchCollector(learner,logger_bases=logger_bases,batch_on_pipe=LearnerBase)\n",
    "    learner = EpocherCollector(learner,logger_bases=logger_bases)\n",
    "    for logger_base in logger_bases: learner = logger_base.connect_source_datapipe(learner)\n",
    "    learner = RollingTerminatedRewardCollector(learner,logger_bases)\n",
    "    learner = EpisodeCollector(learner,logger_bases)\n",
    "    learner = ExperienceReplay(learner,bs=bs,max_sz=max_sz,clone_detach=dls[0].num_workers>0)\n",
    "    learner = StepBatcher(learner)\n",
    "    learner = TargetQCalc(learner,nsteps=nsteps)\n",
    "    learner = ModelLearnCalc(learner)\n",
    "    learner = LossCollector(learner,logger_bases)\n",
    "    learner = LearnerHead(learner)\n",
    "    return learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f9ed8-fb05-40a1-ac0d-d4cafee8fa07",
   "metadata": {},
   "source": [
    "Try training with basic defaults..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63d9b481-5998-472a-a2df-18d79bf07ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>episode</th>\n",
       "      <th>rolling_reward</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.0148252845</td>\n",
       "      <td>45</td>\n",
       "      <td>22.5</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0.749500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.11912983</td>\n",
       "      <td>75</td>\n",
       "      <td>27.027027</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0.499250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.052749373</td>\n",
       "      <td>99</td>\n",
       "      <td>30.27551</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.08344684</td>\n",
       "      <td>108</td>\n",
       "      <td>37.47</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.48242885</td>\n",
       "      <td>116</td>\n",
       "      <td>46.07</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.17665659</td>\n",
       "      <td>123</td>\n",
       "      <td>54.37</td>\n",
       "      <td>6</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.22949357</td>\n",
       "      <td>129</td>\n",
       "      <td>64.3</td>\n",
       "      <td>7</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5556161</td>\n",
       "      <td>135</td>\n",
       "      <td>70.21</td>\n",
       "      <td>8</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.25443685</td>\n",
       "      <td>143</td>\n",
       "      <td>79.19</td>\n",
       "      <td>9</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.9242737</td>\n",
       "      <td>148</td>\n",
       "      <td>88.86</td>\n",
       "      <td>10</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.23920195</td>\n",
       "      <td>157</td>\n",
       "      <td>96.46</td>\n",
       "      <td>11</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.47629455</td>\n",
       "      <td>166</td>\n",
       "      <td>102.76</td>\n",
       "      <td>12</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.3029395</td>\n",
       "      <td>173</td>\n",
       "      <td>110.11</td>\n",
       "      <td>13</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.19774938</td>\n",
       "      <td>178</td>\n",
       "      <td>118.1</td>\n",
       "      <td>14</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.19138603</td>\n",
       "      <td>183</td>\n",
       "      <td>126.69</td>\n",
       "      <td>15</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.22072096</td>\n",
       "      <td>190</td>\n",
       "      <td>134.46</td>\n",
       "      <td>16</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5644537</td>\n",
       "      <td>197</td>\n",
       "      <td>140.68</td>\n",
       "      <td>17</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.42710733</td>\n",
       "      <td>206</td>\n",
       "      <td>143.69</td>\n",
       "      <td>18</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.51321334</td>\n",
       "      <td>211</td>\n",
       "      <td>145.83</td>\n",
       "      <td>19</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.8043925</td>\n",
       "      <td>217</td>\n",
       "      <td>149.13</td>\n",
       "      <td>20</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.24947134</td>\n",
       "      <td>223</td>\n",
       "      <td>150.31</td>\n",
       "      <td>21</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.61280406</td>\n",
       "      <td>231</td>\n",
       "      <td>146.54</td>\n",
       "      <td>22</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.17209046</td>\n",
       "      <td>238</td>\n",
       "      <td>146.99</td>\n",
       "      <td>23</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.68903434</td>\n",
       "      <td>244</td>\n",
       "      <td>147.96</td>\n",
       "      <td>24</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.40998378</td>\n",
       "      <td>252</td>\n",
       "      <td>145.26</td>\n",
       "      <td>24</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastrl.envs.gym import *\n",
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n",
    "                 batch_on_pipe=BatchCollector)\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,[logger_base],max_steps=4000)\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False)\n",
    ")\n",
    "# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=1000,bs=1))\n",
    "# Setup the Learner\n",
    "learner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=100_000)\n",
    "# learner.fit(3)\n",
    "learner.fit(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0ed73-7bbf-415b-9ee7-9a95de31d638",
   "metadata": {},
   "source": [
    "The DQN learners, but I wonder if we can get it to learn faster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c95d510e-38c1-458c-9830-df5a68e6a53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>episode</th>\n",
       "      <th>rolling_reward</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.13890263</td>\n",
       "      <td>74</td>\n",
       "      <td>26.04</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0.810900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.1973386</td>\n",
       "      <td>113</td>\n",
       "      <td>44.08</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0.616200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.116028</td>\n",
       "      <td>132</td>\n",
       "      <td>71.6</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0.418800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.5524232</td>\n",
       "      <td>144</td>\n",
       "      <td>105.78</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0.219800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.2480583</td>\n",
       "      <td>152</td>\n",
       "      <td>135.56</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.28455</td>\n",
       "      <td>158</td>\n",
       "      <td>162.78</td>\n",
       "      <td>6</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6.439022</td>\n",
       "      <td>167</td>\n",
       "      <td>189.26</td>\n",
       "      <td>7</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6.0712805</td>\n",
       "      <td>175</td>\n",
       "      <td>210.96</td>\n",
       "      <td>8</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4.9676175</td>\n",
       "      <td>183</td>\n",
       "      <td>236.26</td>\n",
       "      <td>9</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5.902592</td>\n",
       "      <td>190</td>\n",
       "      <td>246.12</td>\n",
       "      <td>9</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n",
    "                 batch_on_pipe=BatchCollector)\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,[logger_base],max_steps=10000)\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True) # We basically merge 2 steps into 1 and skip. \n",
    ")\n",
    "# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=1000,bs=1))\n",
    "# Setup the Learner\n",
    "learner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=20_000,nsteps=2,lr=0.001)\n",
    "# learner.fit(3)\n",
    "learner.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6de0f41e-2eda-4227-9fa8-f2e0b920754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.loggers.jupyter_visualizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15937f36-8efa-4163-bc67-20019d18c98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7482490a-475e-4c46-b1fa-193bf68b7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.envs.gym import GymTypeTransform,GymStepper\n",
    "\n",
    "def gym_pipe_base(envs,total_steps,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformLoop(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle(count=total_steps)\n",
    "    pipe = GymStepper(pipe,agent=agent,seed=seed,include_images=True)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dc10e61-4f65-4a17-a5a9-489bb466af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8784650-6f5c-42b7-9a72-68a0d37d8983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "video_logger = SimpleJupyterVideoPlayer()\n",
    "\n",
    "pipe = gym_pipe_base(['CartPole-v1'],1000,seed=None)\n",
    "pipe = ImageCollector(pipe,[video_logger])\n",
    "\n",
    "pipe = video_logger.connect_source_datapipe(pipe)\n",
    "\n",
    "for o in pipe:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/astroid/node_classes.py:96: DeprecationWarning: The 'astroid.node_classes' module is deprecated and will be replaced by 'astroid.nodes' in astroid 3.0.0\n",
      "  DeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d3626-1702-4f22-ae15-bb93a75bec68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
