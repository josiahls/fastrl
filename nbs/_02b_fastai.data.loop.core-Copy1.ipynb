{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fastai.data.loop.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "import logging\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.graph import traverse\n",
    "from torchdata.datapipes import functional_datapipe\n",
    "# Local modules\n",
    "\n",
    "\n",
    "_logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Loop\n",
    "> Customizable loop API for fastrl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84e24d-a82a-464a-9412-1ab8de544af6",
   "metadata": {},
   "source": [
    "so we need loops within loops posibly. Or do they need to be loops? maybe they need to \n",
    "just be sections? do we even need sections? I wonder if we can leverage the torch data as more \n",
    "of a base... I want to see how far we can get with this....\n",
    "\n",
    "we also need to think about whether this is always iterable or whether we can mix and match\n",
    "map vs iter...\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f2c63bf-6951-4266-9c66-3ab59dd99d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Callback():\n",
    "    \"A list of data pipes that have an associated job.\"\n",
    "    call_on = L()\n",
    "    exclude_under = L()\n",
    "    do_copy = False\n",
    "    immediate_parents = L()\n",
    "    root_parent = None\n",
    "    pipes = L()\n",
    "    \n",
    "    def set_parents(self,immediate_parent):\n",
    "        if immediate_parent is not None: \n",
    "            self.immediate_parents.append(immediate_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efed2052-6909-4efa-8557-50cb644ccc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def filter_call_on_cbs(obj, cbs): return tuple(cb for cb in cbs if obj.__class__ in cb.call_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a484ec89-6106-4d24-b49f-5417bb52ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def attach_callbacks(self:dp.map.MapDataPipe,cbs):\n",
    "    pipe = self\n",
    "    cbs = filter_call_on_cbs(self,cbs)\n",
    "    for cb in cbs:\n",
    "        for dp in cb.pipes: pipe = dp(pipe)\n",
    "    return pipe\n",
    "\n",
    "@patch\n",
    "def attach_callbacks(self:dp.iter.IterDataPipe,cbs):\n",
    "    pipe = self\n",
    "    cbs = filter_call_on_cbs(self,cbs)\n",
    "    for cb in cbs:\n",
    "        for dp in cb.pipes: pipe = dp(pipe)\n",
    "    return pipe\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4f0c24d-c8cf-4fcb-8e65-69528ec4aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "dp.map.MapDataPipe.callbacks = L()\n",
    "dp.iter.IterDataPipe.callbacks = L()\n",
    "\n",
    "@patch\n",
    "def __repr__(self:dp.map.MapDataPipe):\n",
    "    if self.repr_hook is not None:\n",
    "        return self.repr_hook(self)\n",
    "    # Instead of showing <torch. ... .MapperMapDataPipe object at 0x.....>, return the class name\n",
    "    str_rep = str(self.__class__.__qualname__)\n",
    "    if self.callbacks: return str_rep + str(self.callbacks)\n",
    "    return str_rep\n",
    "\n",
    "@patch\n",
    "def __str__(self:dp.map.MapDataPipe):\n",
    "    if self.str_hook is not None:\n",
    "        return self.str_hook(self)\n",
    "    # Instead of showing <torch. ... .MapperMapDataPipe object at 0x.....>, return the class name\n",
    "    str_rep = str(self.__class__.__qualname__)\n",
    "    if self.callbacks: return str_rep + str(self.callbacks)\n",
    "    return str_rep\n",
    "\n",
    "@patch\n",
    "def __repr__(self:dp.iter.IterDataPipe):\n",
    "    if self.repr_hook is not None:\n",
    "        return self.repr_hook(self)\n",
    "    # Instead of showing <torch. ... .MapperMapDataPipe object at 0x.....>, return the class name\n",
    "    str_rep = str(self.__class__.__qualname__)\n",
    "    if self.callbacks: return str_rep + str(self.callbacks)\n",
    "    return str_rep\n",
    "\n",
    "@patch\n",
    "def __str__(self:dp.iter.IterDataPipe):\n",
    "    if self.str_hook is not None:\n",
    "        return self.str_hook(self)\n",
    "    # Instead of showing <torch. ... .MapperMapDataPipe object at 0x.....>, return the class name\n",
    "    str_rep = str(self.__class__.__qualname__)\n",
    "    if self.callbacks: return str_rep + str(self.callbacks)\n",
    "    return str_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d9f6af-9ae0-4b25-bdc3-361346a7bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def set_cbs(loop,cbs): \n",
    "    name = loop.__class__.__name__.lower()\n",
    "    loop.callbacks = [cb() if isinstance(cb, type) else cb for cb in cbs]\n",
    "    for cb in loop.callbacks: cb.set_parents(loop)\n",
    "    for s in ['before','on','after','failed','finally']:\n",
    "        setattr(loop,f'cb_{s}', L(getattr(cb,f'{s}_{name}') for cb in loop.callbacks if hasattr(cb,f'{s}_{name}')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d840592-3d7d-4db2-ba26-15117517f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def filter_exclude_under_cbs(\n",
    "    pipe:Union[dp.map.MapDataPipe,dp.iter.IterDataPipe], \n",
    "    cbs:List[Callback]\n",
    "):\n",
    "    cbs = tuple(cb for cb in cbs if pipe.__class__  not in cb.exclude_under)\n",
    "    for v in traverse(pipe).values():\n",
    "        for k,_ in v.items():\n",
    "            cbs = filter_exclude_under_cbs(k,cbs)\n",
    "    return cbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670fe378-ec5a-4ead-9495-63afc83d6300",
   "metadata": {},
   "source": [
    "Below is a simple example of a custom training setup. We will be re-defining these later. Below demonstrates a neive implimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba1b5663-4e48-4e2f-920d-5864d8c813a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from functools import wraps\n",
    "\n",
    "def soft_compose(loop,attr): return compose(*getattr(loop,attr,L()))\n",
    "\n",
    "def callback_iter(f):\n",
    "    @wraps(f)\n",
    "    def _inner(self):\n",
    "        try:\n",
    "            soft_compose(self,'cb_after')()\n",
    "            for record in f(self):\n",
    "                self.x = record\n",
    "                soft_compose(self,'cb_on')()\n",
    "                yield record\n",
    "                del self.x\n",
    "            soft_compose(self,'cb_after')()\n",
    "        except Exception:\n",
    "            if len(getattr(self,'cb_failed',L()))==0: raise\n",
    "            else:                                     soft_compose(self,'cb_failed')()\n",
    "        finally:\n",
    "            soft_compose(self,'cb_finally')()\n",
    "    return _inner\n",
    "\n",
    "def callback_getitem(f):\n",
    "    @wraps(f)\n",
    "    def _inner(self, index):\n",
    "        ex_occured = False\n",
    "        try:\n",
    "            soft_compose(self,'cb_before')()\n",
    "            self.x = f(self, index)\n",
    "            soft_compose(self,'cb_on')()\n",
    "            return self.x\n",
    "        except Exception:\n",
    "            ex_occured = True\n",
    "            if len(getattr(self,'cb_failed',L()))==0: raise\n",
    "            else:                                     soft_compose(self,'cb_failed')()\n",
    "        finally:\n",
    "            del self.x\n",
    "            if not ex_occured: \n",
    "                soft_compose(self,'cb_after')()\n",
    "            soft_compose(self,'cb_finally')()\n",
    "    return _inner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56b3c5df-10bd-4149-9d89-270872b97681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "dp.map.Batcher.__getitem__ = callback_getitem(dp.map.Batcher.__getitem__)\n",
    "dp.iter.Batcher.__iter__ = callback_iter(dp.iter.Batcher.__iter__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80a6386-065a-4fcd-8d0b-782322b75af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c74e0435-bb15-4a51-848c-28152c4daaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = dp.iter.IterableWrapper([1,2,3,4,5])\n",
    "batch_dp = dp.iter.Batcher(pipe,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31b394f6-62d7-408a-ac6b-6bc5ee3e0b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4], [5]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(batch_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45f538e5-fd74-45da-bde8-5399d7bc1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.fastai.data.pipes.map.demux import *\n",
    "from fastrl.fastai.data.pipes.map.mux import *\n",
    "\n",
    "class Iterationer(dp.iter.IterDataPipe):\n",
    "        \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    @callback_iter\n",
    "    def __iter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe: yield 0.5\n",
    "\n",
    "\n",
    "class Trainer(dp.iter.IterDataPipe):\n",
    "        \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    @callback_iter\n",
    "    def __iter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe:\n",
    "            yield element\n",
    "                \n",
    "class Validater(dp.iter.IterDataPipe):\n",
    "        \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    @callback_iter\n",
    "    def __iter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe:\n",
    "            yield element\n",
    "               \n",
    "class Epocher(dp.iter.IterDataPipe):\n",
    "    def __init__(self, source_datapipes:tuple, **kwargs) -> None:\n",
    "        test_eq(type(source_datapipes), tuple)\n",
    "        self.source_datapipes = source_datapipes\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    @callback_iter\n",
    "    def __iter__(self) -> Iterator[T_co]:\n",
    "        for element in zip(*self.source_datapipes):\n",
    "            yield element\n",
    "                \n",
    "class Fitter(dp.iter.IterDataPipe):\n",
    "    def __init__(self,iterable):\n",
    "                \n",
    "        self.trainer,self.validater = Trainer(iterable),Validater(iterable)\n",
    "        self.train_b, self.valid_b = dp.iter.Batcher(self.trainer,2),dp.iter.Batcher(self.validater,2)\n",
    "        self.train_it,self.valid_it = Iterationer(self.train_b),Iterationer(self.valid_b)\n",
    "        self.epocher = dp.iter.Zipper(self.train_it,self.valid_it)\n",
    "        self.source_datapipe = self.epocher\n",
    "            \n",
    "    @callback_iter\n",
    "    def __iter__(self):\n",
    "        for epoch in self.source_datapipe: \n",
    "            yield epoch\n",
    "        \n",
    "class TrainerCallback(Callback):\n",
    "    \"A list of data pipes that have an associated job.\"\n",
    "    call_on=L(Trainer)\n",
    "    exclude_under=L()\n",
    "    \n",
    "    def on_trainer(self): print('on_trainer')\n",
    "    \n",
    "class IterCallback(Callback):\n",
    "    \"A list of data pipes that have an associated job.\"\n",
    "    call_on=L(Iterationer)\n",
    "    exclude_under=L(Validater)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a17f7d84-937e-406f-b50a-6ac48aac13f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def default_constructor(\n",
    "    datapipe:Union[dp.map.MapDataPipe,dp.iter.IterDataPipe,Dict], \n",
    "    cbs:List[Callback],\n",
    "    _outer=True # Only used to differentiate between recursive calls and initial.\n",
    "):\n",
    "    if _outer:\n",
    "        for cb in cbs: cb.root_parent=datapipe\n",
    "    d = datapipe if isinstance(datapipe,dict) else traverse(datapipe)\n",
    "    \n",
    "    for k,v in d.items():\n",
    "        filtered_cbs = filter_call_on_cbs(k,cbs)\n",
    "        _logger.info('Given loop: %s, found callbacks: %s',k.__class__,filtered_cbs)\n",
    "        kept_cbs = filter_exclude_under_cbs(k,filtered_cbs)\n",
    "        _logger.info('Given loop: %s, filtered callbacks: %s',k.__class__,kept_cbs)\n",
    "        kept_cbs = [copy(cb) if cb.do_copy else cb for cb in kept_cbs]\n",
    "        set_cbs(k,kept_cbs)\n",
    "        if not v: continue\n",
    "        default_constructor(v, cbs, _outer=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e14bf4db-165c-455d-a76b-577c5c0c2a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{Fitter: {Trainer[<__main__.TrainerCallback object at 0x7fa2d1001050>]: {}, Validater: {}, BatcherIterDataPipe: {Trainer[<__main__.TrainerCallback object at 0x7fa2d1001050>]: {}}, BatcherIterDataPipe: {Validater: {}}, Iterationer[<__main__.IterCallback object at 0x7fa2d1003610>]: {BatcherIterDataPipe: {Trainer[<__main__.TrainerCallback object at 0x7fa2d1001050>]: {}}}, Iterationer: {BatcherIterDataPipe: {Validater: {}}}, ZipperIterDataPipe: {Iterationer[<__main__.IterCallback object at 0x7fa2d1003610>]: {BatcherIterDataPipe: {Trainer[<__main__.TrainerCallback object at 0x7fa2d1001050>]: {}}}, Iterationer: {BatcherIterDataPipe: {Validater: {}}}}}}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_pipe = Fitter([1,2,3,4,5,6])\n",
    "\n",
    "default_constructor(\n",
    "    base_pipe,\n",
    "    [TrainerCallback,IterCallback]\n",
    ")\n",
    "str(traverse(base_pipe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "598dee65-2600-40d0-a8b9-55bd77e87786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_trainer\n",
      "on_trainer\n",
      "on_trainer\n",
      "on_trainer\n",
      "on_trainer\n",
      "on_trainer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.5, 0.5), (0.5, 0.5), (0.5, 0.5)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(base_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c64d0-f9c6-4432-82f8-c171840afc55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
