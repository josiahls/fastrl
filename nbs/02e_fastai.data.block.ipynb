{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp fastai.data.block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "from typing import Any,Callable,Generator\n",
    "from inspect import isfunction,ismethod\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from torch.utils.data.datapipes._typing import _DataPipeMeta, _IterDataPipeMeta\n",
    "from fastai.torch_core import *\n",
    "from fastai.data.transforms import *\n",
    "import torchdata.datapipes as dp\n",
    "from collections import deque\n",
    "from fastai.imports import *\n",
    "# Local modules\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Data Block\n",
    "> High level API to quickly get your data in a `DataLoader`s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63392058-2c52-4282-94f7-3c01400845d9",
   "metadata": {},
   "source": [
    "## Transform Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c189134b-414d-4a46-a7ce-5d7a75594655",
   "metadata": {},
   "source": [
    "> Note: We will first validate the lower level API on a dqn before making the data block. This is going to be a naive implimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec802048-caeb-4149-adb5-e57592ded1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TransformBlock():\n",
    "    \"A basic wrapper that links defaults transforms for the data block API\"\n",
    "    def __init__(self, \n",
    "        # A function that initializes a datapipeline and returns a datapipe.\n",
    "        # Minimum must support:\n",
    "        #\n",
    "        #     `pipe_fn(source, bs, n)`\n",
    "        #\n",
    "        # Where:\n",
    "        #   - `source` is the data to be input into the datapipes\n",
    "        #   - `bs` is the batch size of the returned data\n",
    "        #   - `n` is the number of iterations to make through the datapipes per epoch                 \n",
    "        pipe_fn:Callable[[Any,int,int],_DataPipeMeta]=None, \n",
    "        # One or more `Transform`s for converting types. These will be re-called if workers!=0 for the dataloader.\n",
    "        type_tfms:list=None, \n",
    "        item_tfms:list=None, # `ItemTransform`s, applied per peice of data (not batch)\n",
    "        batch_tfms:list=None, # `Transform`s applied over a batch of data\n",
    "        # `Callback`s for use in dataloaders. These usually augment a preexisting pipeline in some way\n",
    "        cbs:list=None,\n",
    "        pipe_fn_kwargs:dict=None, # Additional arguments to be passed to `pipe_fn`\n",
    "        dl_type:DataLoader2=None, # Task specific `TfmdDL`, defaults to `TfmdDL`\n",
    "        dls_kwargs:dict=None, # Additional arguments to be passed to `DataLoaders`\n",
    "    ):\n",
    "        self.type_tfms                   = L(type_tfms)\n",
    "        self.item_tfms                   = L(item_tfms)\n",
    "        self.batch_tfms                  = L(batch_tfms)\n",
    "        self.pipe_fn,self.pipe_fn_kwargs = pipe_fn,ifnone(pipe_fn_kwargs,{})\n",
    "        self.cbs                         = L(cbs)\n",
    "        self.dl_type,self.dls_kwargs     = dl_type,ifnone(dls_kwargs,{})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075032b7-af30-4174-89c1-3404196fc6d1",
   "metadata": {},
   "source": [
    "I have some thoughts on `TransformBlock`. I'm wondering if it would be so bad to have each `TransformBlock` serve as a guaranteed input and a guaranteed output as opposed to https://github.com/fastai/fastai/blob/5b6786a3cf4f98b86dcfed8b30738455ede2c640/fastai/data/block.py#L102 where the n_inp could change based on `get_x,get_y`.  \n",
    "\n",
    "I think the main issue for me is that there isnt always a `y` in what im doing so the usage of DataBlock can feel awkward. I also find the nesting of functions difficult to debug easily, which is an issue if the idea is that new users will try to plugin their own stuff.\n",
    "\n",
    "I felt it got more confusing when the blocks are merged together also.\n",
    "\n",
    "I think that it would be better, that a `TransformBlock` was 1:1 with a dataloader. So if you have 2 transform blocks,\n",
    "you have 2 dataloaders that do inputs and outputs. In RL I imagine having 2 separate environments running at the same time and \n",
    "collecting information from both of them. The required transforms might be different, so having separate `TransformBlocks` would\n",
    "simplify things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b69adc7-2512-450d-9dc3-c12c1d5901ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DataBlock(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Each transform block will have its own dataloader. \n",
    "        blocks:List[TransformBlock]=None, \n",
    "    ):\n",
    "        store_attr(but='blocks')\n",
    "        self.blocks = L(blocks)\n",
    "\n",
    "    def datapipes(\n",
    "        self,\n",
    "        source:Any,\n",
    "        bs=1,\n",
    "        n=1,\n",
    "        return_blocks:bool=False\n",
    "    ) -> Generator[Union[Tuple[_DataPipeMeta,TransformBlock],_DataPipeMeta],None,None]:\n",
    "        for b in self.blocks:\n",
    "            pipe = b.pipe_fn(source,bs=bs,n=n,**b.pipe_fn_kwargs)\n",
    "            yield (pipe,b) if return_blocks else pipe\n",
    "        \n",
    "    def dataloaders(\n",
    "        self,\n",
    "        source:Any,\n",
    "        bs=1,\n",
    "        n=1,\n",
    "        n_workers=0,\n",
    "        **kwargs\n",
    "    ) -> Generator[DataLoader2,None,None]:\n",
    "        for pipe,block in self.datapipes(source,bs=bs,n=n,return_blocks=True,**kwargs):\n",
    "            yield block.dl_type(pipe,**merge(kwargs,block.dls_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8d8e7-e153-41a3-ac31-22f936720d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
