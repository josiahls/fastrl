{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fastai.data.block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from typing import Any,Callable\n",
    "from inspect import isfunction,ismethod\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from fastai.torch_core import *\n",
    "from fastai.data.transforms import *\n",
    "import torchdata.datapipes as dp\n",
    "from collections import deque\n",
    "from fastai.imports import *\n",
    "# Local modules\n",
    "from fastrl.fastai.data.load import *\n",
    "from fastrl.fastai.data.pipes.core import *\n",
    "from fastrl.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Data Block\n",
    "> High level API to quickly get your data in a `DataLoader`s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63392058-2c52-4282-94f7-3c01400845d9",
   "metadata": {},
   "source": [
    "## Transform Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c189134b-414d-4a46-a7ce-5d7a75594655",
   "metadata": {},
   "source": [
    "> Note: We will first validate the lower level API on a dqn before making the data block. This is going to be a naive implimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c518d8b6-858c-41a3-a9cc-23fefea2ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _merge_grouper(o):\n",
    "    if isinstance(o, LambdaType): return id(o)\n",
    "    elif isinstance(o, type): return o\n",
    "    elif (isfunction(o) or ismethod(o)): return o.__qualname__\n",
    "    return o.__class__\n",
    "\n",
    "def _merge_tfms(*tfms):\n",
    "    \"Group the `tfms` in a single list, removing duplicates (from the same class) and instantiating\"\n",
    "    g = groupby(concat(*tfms), _merge_grouper)\n",
    "    return L(v[-1] for k,v in g.items()).map(instantiate)\n",
    "\n",
    "def _zip(x): return L(x).zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec802048-caeb-4149-adb5-e57592ded1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TransformBlock():\n",
    "    \"A basic wrapper that links defaults transforms for the data block API\"\n",
    "    def __init__(self, \n",
    "        type_tfms:list=None, # One or more `Transform`s for converting types. These will be re-called if workers!=0 for the dataloader.\n",
    "        item_tfms:list=None, # `ItemTransform`s, applied on an item\n",
    "        batch_tfms:list=None, # `Transform`s or `RandTransform`s, applied by batch\n",
    "        cbs:list=None, # `Callback`s for use in dataloaders\n",
    "        dl_type:DataLoader2=None, # Task specific `TfmdDL`, defaults to `TfmdDL`\n",
    "        dls_kwargs:dict=None, # Additional arguments to be passed to `DataLoaders`\n",
    "    ):\n",
    "        self.type_tfms  =            L(type_tfms)\n",
    "        self.item_tfms  =            L(item_tfms)\n",
    "        self.batch_tfms =            L(batch_tfms)\n",
    "        self.cbs        =            L(cbs)\n",
    "        self.dl_type,self.dls_kwargs = dl_type,({} if dls_kwargs is None else dls_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9c25da7-6dae-4f33-82fb-5ae633ded351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def simple_iter_loader_loop(\n",
    "    items:Iterable,\n",
    "    cbs:Optional[List[Callback]]=None,\n",
    "    type_tfms:Optional[Transform]=None,\n",
    "    item_tfms:Optional[Transform]=None,\n",
    "    batch_tfms:Optional[Transform]=None,\n",
    "    bs:int=2,\n",
    "    n:int=1\n",
    "):\n",
    "    pipe = dp.map.SequenceWrapper(items)\n",
    "    pipe = TypeTransformLoop(pipe, type_tfms=ifnone(type_tfms,L()))\n",
    "    pipe = dp.map.InMemoryCacheHolder(pipe)\n",
    "    pipe = dp.iter.MapToIterConverter(pipe) # Will intialize the gym object, which will be an issue when doing multiproc\n",
    "    pipe = dp.iter.ShardingFilter(pipe)\n",
    "    pipe = pipe.cycle(count=n)\n",
    "    pipe = ItemTransformLoop(pipe, item_tfms=ifnone(item_tfms,L()))\n",
    "    pipe = dp.iter.Batcher(pipe,bs)\n",
    "    pipe = BatchTransformLoop(pipe, batch_tfms=ifnone(batch_tfms,L()))\n",
    "    \n",
    "    for _pipe in reversed(find_pipes(pipe,lambda o:True)): pipe = _pipe.add_cbs_before(cbs)\n",
    "    for _pipe in reversed(find_pipes(pipe,lambda o:True)): pipe = _pipe.add_cbs_after(cbs)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc7fdc-96e2-4039-8c59-0b7844df16ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b69adc7-2512-450d-9dc3-c12c1d5901ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataBlock(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        blocks:List[TransformBlock]=None, # Transform blocks to use \n",
    "        loader_loop:Callable=None,\n",
    "        dl_type=None\n",
    "    ):\n",
    "        store_attr(but='loader_loop')\n",
    "        self.loader_loop = ifnone(loader_loop,default_loader_loop)\n",
    "        blocks = L(self.blocks if blocks is None else blocks)\n",
    "        blocks = L(b() if callable(b) else b for b in blocks)\n",
    "        self.type_tfms = blocks.attrgot('type_tfms', L())\n",
    "\n",
    "        self.cbs = blocks.attrgot('cbs', L())\n",
    "        self.item_tfms  = _merge_tfms(*blocks.attrgot('item_tfms',  L()))\n",
    "        self.batch_tfms = _merge_tfms(*blocks.attrgot('batch_tfms', L()))\n",
    "        for b in blocks:\n",
    "            if getattr(b, 'dl_type', None) is not None: self.dl_type = b.dl_type\n",
    "        if dl_type is not None: self.dl_type = dl_type\n",
    "        self.dataloaders = delegates(self.dl_type.__init__)(self.dataloaders)\n",
    "        self.dls_kwargs = merge(*blocks.attrgot('dls_kwargs', {}))\n",
    "\n",
    "    def datapipes(\n",
    "        self,\n",
    "        source:Any,\n",
    "        bs=2,\n",
    "        n=1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return L(self.loader_loop(\n",
    "            source,\n",
    "            cbs=cbs,\n",
    "            type_tfms=type_tfms,\n",
    "            item_tfms=self.item_tfms,\n",
    "            batch_tfms=self.batch_tfms,\n",
    "            bs=bs,\n",
    "            n=n,\n",
    "            **kwargs\n",
    "        ) for type_tfms,cbs in zip(self.type_tfms,self.cbs))\n",
    "        \n",
    "    def dataloaders(\n",
    "        self,\n",
    "        source:Any,\n",
    "        n_workers=0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        pipes = self.datapipes(source,**kwargs)\n",
    "        return L(pipes).map(DataLoader2,num_workers=n_workers,**self.dls_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d782b9-cc27-4e7c-a017-d7bd71fcb4b4",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb74ef4f-e4c8-4362-8db2-dca0a853ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import gym\n",
    "\n",
    "class Flattener(dp.iter.IterDataPipe):\n",
    "    \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for o in self.source_datapipe:\n",
    "            if not is_listy(o):\n",
    "                raise Exception(f'Expected listy object got {type(o)}\\n{o}')\n",
    "            for oo in o: yield oo\n",
    "            \n",
    "class NStepPipe(dp.iter.IterDataPipe):\n",
    "    \n",
    "    def __init__(self, source_datapipe, n=1, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.n = n\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        buffer = []\n",
    "        for o in self.source_datapipe:\n",
    "            if not type(o)==dict:\n",
    "                raise Exception(f'Expected dict object generated from `make_step` got {type(o)}\\n{o}')\n",
    "        \n",
    "            buffer.append(o)\n",
    "            if not o['done'] and len(buffer)<self.n: continue\n",
    "            \n",
    "            while o['done'] and len(buffer)!=0:\n",
    "                yield tuple(buffer)\n",
    "                buffer.pop(0)\n",
    "                \n",
    "            if not o['done']:\n",
    "                yield tuple(buffer)\n",
    "                buffer.pop(0)\n",
    "                \n",
    "class NSkipPipe(dp.iter.IterDataPipe):\n",
    "    \n",
    "    def __init__(self, source_datapipe, n=1, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.n = n\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        skip_idx = 0\n",
    "        for o in self.source_datapipe:\n",
    "            if not type(o)==dict:\n",
    "                raise Exception(f'Expected dict object generated from `make_step` got {type(o)}\\n{o}')\n",
    "            \n",
    "            skip_idx += 1 # Be aware of the ordering here. we want to always show the first step when we can. \n",
    "            if skip_idx%self.n==0 or o['done']: \n",
    "                yield o\n",
    "                if o['done']: skip_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14877e71-cc13-47a0-9d56-9c16e9849d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class NStepCallback(Callback):\n",
    "    def __init__(self,nsteps=1,nskip=1):\n",
    "        store_attr()\n",
    "\n",
    "    def add_nstep_pipes(self,before=None,after=ItemTransformLoop,not_under=None) -> List[dp.iter.IterDataPipe]:\n",
    "        return L(partial(NSkipPipe,n=self.nskip),\n",
    "                 partial(NStepPipe, n=self.nsteps),\n",
    "                 Flattener\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6517ff08-afc7-4990-acf0-bb05205e17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DictCollate(Transform):\n",
    "    def encodes(self,o): return L(o).map(BD).sum()\n",
    "    \n",
    "class DictToTensor(Transform):\n",
    "    def encodes(self,o:dict):\n",
    "        for k,v in o.items(): \n",
    "            v = TensorBatch(v)\n",
    "            if len(v.shape)==0: v = v.unsqueeze(0)\n",
    "            o[k] = v\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0a61a9a-a7ce-4960-ba95-ca387c0a5164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def make_step(\n",
    "    state,\n",
    "    next_state,\n",
    "    done,\n",
    "    reward,\n",
    "    sum_reward,\n",
    "    action,\n",
    "    env_id\n",
    "):\n",
    "    return dict(state=state,next_state=next_state,done=done,reward=reward,\n",
    "                sum_reward=sum_reward,action=action,env_id=env_id)\n",
    "\n",
    "class GymTypeTransform(Transform):\n",
    "    def encodes(self,o): return gym.make(o)\n",
    "    \n",
    "class GymStepTransform(Transform):\n",
    "    @delegates(Transform)\n",
    "    def __init__(self,agent=None,**kwargs):\n",
    "        self.agent = agent\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def encodes(self,o:gym.Env):\n",
    "        \n",
    "        if getattr(o,'is_done',True):\n",
    "            state = o.reset(seed=getattr(self,'seed',0))\n",
    "            o.is_done = False\n",
    "            o.sum_reward = 0\n",
    "            o.step_info = make_step(state,None,False,None,0,None,env_id=id(o))\n",
    "        else:\n",
    "            state = o.state\n",
    "            \n",
    "        self.agent.agent_base.iterator.append(o.step_info)\n",
    "        for action in self.agent:\n",
    "            next_state,reward,done,_ = o.step(action)\n",
    "            o.sum_reward += reward\n",
    "        \n",
    "        if done: o.is_done = True\n",
    "        o.step_info = make_step(state,next_state,done,reward,o.sum_reward,action,env_id=id(o))\n",
    "        \n",
    "        print('taking step')\n",
    "        \n",
    "        return o.step_info\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb48210f-aa14-4f18-812f-1b370c694cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)\n",
    "\n",
    "class Agent(dp.iter.IterDataPipe):\n",
    "    def __init__(self,model,iterator):\n",
    "        self.model = model\n",
    "        self.iterator = iterator\n",
    "        self.agent_base = self\n",
    "        \n",
    "    def __iter__(self):\n",
    "        while self.iterator:\n",
    "            yield self.iterator.pop(0)\n",
    "\n",
    "\n",
    "class RawOutOfStep(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,agent_base,key): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.key = key\n",
    "        self.agent_base = agent_base\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for o in self.source_datapipe:\n",
    "            x = tensor(o[self.key])\n",
    "            x = self.agent_base.model(x)\n",
    "            yield x\n",
    "            \n",
    "class ArgmaxOfStep(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,agent_base): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = agent_base\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for o in self.source_datapipe:\n",
    "            yield torch.argmax(o)\n",
    "            \n",
    "class ToDiscrete(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,agent_base): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = agent_base\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for x in self.source_datapipe:\n",
    "            if isinstance(x,Tensor):\n",
    "                if len(x.shape)==0:\n",
    "                    yield int(x)\n",
    "                else:\n",
    "                    yield x.long()\n",
    "            else:\n",
    "                raise Exception(f'Cant convert to discrete: {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7713f8f9-7e23-4433-9465-7eb637ab599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DiscreteEpsilonRandomSelect(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    def __init__(self,source_datapipe,agent_base,n_actions,idx=0,min_epsilon=0.2,max_epsilon=1,max_steps=5000):\n",
    "        self.n_actions = n_actions\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = agent_base\n",
    "        self.agent_base.epislon_selector = self \n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.epsilon = max_epsilon\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.max_steps = max_steps\n",
    "        self.idx = idx\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for action in self.source_datapipe:\n",
    "            mask = np.random.random(size=self.n_actions) < self.epsilon\n",
    "            rand_actions = np.random.choice(self.n_actions, sum(mask))\n",
    "            action = action.cpu().detach().numpy().reshape((-1,))\n",
    "            action[mask] = rand_actions\n",
    "            action=Tensor(action).long().reshape(-1,1)\n",
    "\n",
    "            if self.agent_base.model.training: \n",
    "                self.idx += 1\n",
    "                self.epsilon = max(self.min_epsilon,self.max_epsilon-self.idx/self.max_steps)\n",
    "            yield action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "456f581c-6266-4876-b970-da1c6ff059b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_info = dict(state=np.random.sample((1,4)),\n",
    "                 next_state=np.random.sample((1,4)),\n",
    "                 action=np.random.sample((1,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0072a93c-e0fe-45d4-bc13-26718ac32d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(4,2)\n",
    "agent_base = Agent(model,[test_info])\n",
    "agent = RawOutOfStep(agent_base,agent_base,'state')\n",
    "agent = DiscreteEpsilonRandomSelect(agent,agent_base,2,min_epsilon=0)\n",
    "agent = ArgmaxOfStep(agent,agent_base)\n",
    "agent = ToDiscrete(agent,agent_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10bc702-0183-41f9-b086-e34213839fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9998\n",
      "0 0.9598\n",
      "1 0.9198\n",
      "0 0.8798\n",
      "0 0.8398\n",
      "0 0.7998000000000001\n",
      "0 0.7598\n",
      "0 0.7198\n",
      "0 0.6798\n",
      "0 0.6397999999999999\n",
      "0 0.5998\n",
      "0 0.5598000000000001\n",
      "0 0.5198\n",
      "0 0.4798\n",
      "1 0.43979999999999997\n",
      "0 0.39980000000000004\n",
      "0 0.3598\n",
      "0 0.3198\n",
      "0 0.27980000000000005\n",
      "0 0.2398\n",
      "0 0.19979999999999998\n",
      "0 0.15980000000000005\n",
      "0 0.11980000000000002\n",
      "0 0.07979999999999998\n",
      "0 0.03979999999999995\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "for i,action in enumerate(agent):\n",
    "    test_info = dict(state=np.random.sample((1,4)),\n",
    "                 next_state=np.random.sample((1,4)),\n",
    "                 action=np.random.sample((1,4)))\n",
    "    agent.agent_base.iterator.append(test_info)\n",
    "    if i%200==0:print(action,agent_base.epislon_selector.epsilon)\n",
    "    if i>7000: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98904fbe-cf2e-454d-b6a0-90243f8e2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_info = dict(state=np.random.sample((1,4)),\n",
    "                 next_state=np.random.sample((1,4)),\n",
    "                 action=np.random.sample((1,4)))\n",
    "agent.agent_base.iterator.append(test_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbb6a95b-4634-476c-bdc9-51d65265803e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': array([[0.43078425, 0.53247456, 0.59616628, 0.81317171]]),\n",
       " 'next_state': array([[0.91338034, 0.79193859, 0.68524921, 0.48980343]]),\n",
       " 'action': array([[0.07863022, 0.79882702, 0.51724363, 0.35724013]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "869f1fc3-bf69-4310-9f36-8e4b64932621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def simple_iter_loader_loop(\n",
    "    items:Iterable,\n",
    "    cbs:Optional[List[Callback]]=None,\n",
    "    type_tfms:Optional[Transform]=None,\n",
    "    item_tfms:Optional[Transform]=None,\n",
    "    batch_tfms:Optional[Transform]=None,\n",
    "    bs:int=2,\n",
    "    n:int=1\n",
    "):\n",
    "    pipe = dp.map.SequenceWrapper(items)\n",
    "    pipe = TypeTransformLoop(pipe, type_tfms=ifnone(type_tfms,L()))\n",
    "    pipe = dp.map.InMemoryCacheHolder(pipe)\n",
    "    pipe = dp.iter.MapToIterConverter(pipe) # Will intialize the gym object, which will be an issue when doing multiproc\n",
    "    pipe = dp.iter.ShardingFilter(pipe)\n",
    "    pipe = pipe.cycle(count=n)\n",
    "    pipe = ItemTransformLoop(pipe, item_tfms=ifnone(item_tfms,L()))\n",
    "    pipe = dp.iter.Batcher(pipe,bs)\n",
    "    pipe = BatchTransformLoop(pipe, batch_tfms=ifnone(batch_tfms,L()))\n",
    "    \n",
    "    pipe = add_cbs_to_pipes(pipe,cbs)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1884a330-79a2-4c18-a97e-00693ebcdb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GymTransformBlock = TransformBlock(\n",
    "    type_tfms  = GymTypeTransform,\n",
    "    item_tfms  = (GymStepTransform(agent),DictToTensor),\n",
    "    batch_tfms = DictCollate,\n",
    "    cbs = NStepCallback(nsteps=1)\n",
    ")\n",
    "\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock,\n",
    "    loader_loop=simple_iter_loader_loop\n",
    ")\n",
    "pipes = block.datapipes(['CartPole-v1']*1,n=10,bs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30383a9f-7822-4e49-a23f-131f68a47700",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = block.dataloaders(['CartPole-v1']*1,n=4,n_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca430562-a8f6-4b8d-9bad-bd55f18e27d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.graph import traverse\n",
    "from torchdata.datapipes.utils import to_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1049ba2-4225-4f77-9c98-fd1baf48572e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"205pt\" height=\"632pt\"\n",
       " viewBox=\"0.00 0.00 205.00 632.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 628)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-628 201,-628 201,4 -4,4\"/>\n",
       "<!-- NStepPipe&#45;8781860419109 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>NStepPipe&#45;8781860419109</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"134,-184 63,-184 63,-165 134,-165 134,-184\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">NStepPipe</text>\n",
       "</g>\n",
       "<!-- Flattener&#45;8781860419117 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Flattener&#45;8781860419117</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"134,-129 63,-129 63,-110 134,-110 134,-129\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-117\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">Flattener</text>\n",
       "</g>\n",
       "<!-- NStepPipe&#45;8781860419109&#45;&gt;Flattener&#45;8781860419117 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>NStepPipe&#45;8781860419109&#45;&gt;Flattener&#45;8781860419117</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M98.5,-164.9197C98.5,-157.9083 98.5,-148.1442 98.5,-139.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.0001,-139.3408 98.5,-129.3408 95.0001,-139.3409 102.0001,-139.3408\"/>\n",
       "</g>\n",
       "<!-- Batcher&#45;8781860419165 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Batcher&#45;8781860419165</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"128,-74 69,-74 69,-55 128,-55 128,-74\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-62\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">Batcher</text>\n",
       "</g>\n",
       "<!-- Flattener&#45;8781860419117&#45;&gt;Batcher&#45;8781860419165 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Flattener&#45;8781860419117&#45;&gt;Batcher&#45;8781860419165</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M98.5,-109.9197C98.5,-102.9083 98.5,-93.1442 98.5,-84.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.0001,-84.3408 98.5,-74.3408 95.0001,-84.3409 102.0001,-84.3408\"/>\n",
       "</g>\n",
       "<!-- BatchTransformLoop&#45;8781860419145 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>BatchTransformLoop&#45;8781860419145</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"161,-19 36,-19 36,0 161,0 161,-19\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">BatchTransformLoop</text>\n",
       "</g>\n",
       "<!-- ItemTransformLoop&#45;8781860419081 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>ItemTransformLoop&#45;8781860419081</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"158,-294 39,-294 39,-275 158,-275 158,-294\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-282\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ItemTransformLoop</text>\n",
       "</g>\n",
       "<!-- NSkipPipe&#45;8781860419153 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>NSkipPipe&#45;8781860419153</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"134,-239 63,-239 63,-220 134,-220 134,-239\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-227\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">NSkipPipe</text>\n",
       "</g>\n",
       "<!-- ItemTransformLoop&#45;8781860419081&#45;&gt;NSkipPipe&#45;8781860419153 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>ItemTransformLoop&#45;8781860419081&#45;&gt;NSkipPipe&#45;8781860419153</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M98.5,-274.9197C98.5,-267.9083 98.5,-258.1442 98.5,-249.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.0001,-249.3408 98.5,-239.3408 95.0001,-249.3409 102.0001,-249.3408\"/>\n",
       "</g>\n",
       "<!-- NSkipPipe&#45;8781860419153&#45;&gt;NStepPipe&#45;8781860419109 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>NSkipPipe&#45;8781860419153&#45;&gt;NStepPipe&#45;8781860419109</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M98.5,-219.9197C98.5,-212.9083 98.5,-203.1442 98.5,-194.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.0001,-194.3408 98.5,-184.3408 95.0001,-194.3409 102.0001,-194.3408\"/>\n",
       "</g>\n",
       "<!-- Batcher&#45;8781860419165&#45;&gt;BatchTransformLoop&#45;8781860419145 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>Batcher&#45;8781860419165&#45;&gt;BatchTransformLoop&#45;8781860419145</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M98.5,-54.9197C98.5,-47.9083 98.5,-38.1442 98.5,-29.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.0001,-29.3408 98.5,-19.3408 95.0001,-29.3409 102.0001,-29.3408\"/>\n",
       "</g>\n",
       "<!-- ShardingFilter&#45;8781860324621 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>ShardingFilter&#45;8781860324621</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"149,-404 48,-404 48,-385 149,-385 149,-404\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-392\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ShardingFilter</text>\n",
       "</g>\n",
       "<!-- Cycler&#45;8781860324629 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>Cycler&#45;8781860324629</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"125.5,-349 71.5,-349 71.5,-330 125.5,-330 125.5,-349\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-337\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">Cycler</text>\n",
       "</g>\n",
       "<!-- ShardingFilter&#45;8781860324621&#45;&gt;Cycler&#45;8781860324629 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>ShardingFilter&#45;8781860324621&#45;&gt;Cycler&#45;8781860324629</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M98.5,-384.9197C98.5,-377.9083 98.5,-368.1442 98.5,-359.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.0001,-359.3408 98.5,-349.3408 95.0001,-359.3409 102.0001,-359.3408\"/>\n",
       "</g>\n",
       "<!-- Cycler&#45;8781860324629&#45;&gt;ItemTransformLoop&#45;8781860419081 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>Cycler&#45;8781860324629&#45;&gt;ItemTransformLoop&#45;8781860419081</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M98.5,-329.9197C98.5,-322.9083 98.5,-313.1442 98.5,-304.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.0001,-304.3408 98.5,-294.3408 95.0001,-304.3409 102.0001,-304.3408\"/>\n",
       "</g>\n",
       "<!-- InMemoryCacheHolderMapDataPipe&#45;8781860324625 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>InMemoryCacheHolderMapDataPipe&#45;8781860324625</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"197,-514 0,-514 0,-495 197,-495 197,-514\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-502\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">InMemoryCacheHolderMapDataPipe</text>\n",
       "</g>\n",
       "<!-- MapToIterConverter&#45;8781860324725 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>MapToIterConverter&#45;8781860324725</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"161,-459 36,-459 36,-440 161,-440 161,-459\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-447\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MapToIterConverter</text>\n",
       "</g>\n",
       "<!-- InMemoryCacheHolderMapDataPipe&#45;8781860324625&#45;&gt;MapToIterConverter&#45;8781860324725 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>InMemoryCacheHolderMapDataPipe&#45;8781860324625&#45;&gt;MapToIterConverter&#45;8781860324725</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M98.5,-494.9197C98.5,-487.9083 98.5,-478.1442 98.5,-469.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.0001,-469.3408 98.5,-459.3408 95.0001,-469.3409 102.0001,-469.3408\"/>\n",
       "</g>\n",
       "<!-- MapToIterConverter&#45;8781860324725&#45;&gt;ShardingFilter&#45;8781860324621 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>MapToIterConverter&#45;8781860324725&#45;&gt;ShardingFilter&#45;8781860324621</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M98.5,-439.9197C98.5,-432.9083 98.5,-423.1442 98.5,-414.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.0001,-414.3408 98.5,-404.3408 95.0001,-414.3409 102.0001,-414.3408\"/>\n",
       "</g>\n",
       "<!-- TypeTransformLoop&#45;8781860324817 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>TypeTransformLoop&#45;8781860324817</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"158,-569 39,-569 39,-550 158,-550 158,-569\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-557\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">TypeTransformLoop</text>\n",
       "</g>\n",
       "<!-- TypeTransformLoop&#45;8781860324817&#45;&gt;InMemoryCacheHolderMapDataPipe&#45;8781860324625 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>TypeTransformLoop&#45;8781860324817&#45;&gt;InMemoryCacheHolderMapDataPipe&#45;8781860324625</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M98.5,-549.9197C98.5,-542.9083 98.5,-533.1442 98.5,-524.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.0001,-524.3408 98.5,-514.3408 95.0001,-524.3409 102.0001,-524.3408\"/>\n",
       "</g>\n",
       "<!-- SequenceWrapperMapDataPipe&#45;8781860324753 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>SequenceWrapperMapDataPipe&#45;8781860324753</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"185,-624 12,-624 12,-605 185,-605 185,-624\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-612\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SequenceWrapperMapDataPipe</text>\n",
       "</g>\n",
       "<!-- SequenceWrapperMapDataPipe&#45;8781860324753&#45;&gt;TypeTransformLoop&#45;8781860324817 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>SequenceWrapperMapDataPipe&#45;8781860324753&#45;&gt;TypeTransformLoop&#45;8781860324817</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M98.5,-604.9197C98.5,-597.9083 98.5,-588.1442 98.5,-579.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.0001,-579.3408 98.5,-569.3408 95.0001,-579.3409 102.0001,-579.3408\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fcafaa45ed0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_graph(pipes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38da3c24-8809-4c68-b25b-5ee37cd9a397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking step\n",
      "taking step\n",
      "{'state': TensorBatch([[[ 1.3696e-02, -2.3021e-02, -4.5903e-02, -4.8347e-02],\n",
      "              [ 6.4906e-04, -6.0638e-01, -3.2139e-02,  7.8611e-01]]]), 'next_state': TensorBatch([[[ 6.4906e-04, -6.0638e-01, -3.2139e-02,  7.8611e-01],\n",
      "              [-1.1479e-02, -8.0105e-01, -1.6416e-02,  1.0685e+00]]]), 'done': TensorBatch([[[False],\n",
      "              [False]]]), 'reward': TensorBatch([[[1.],\n",
      "              [1.]]]), 'sum_reward': TensorBatch([[[3.],\n",
      "              [4.]]]), 'action': TensorBatch([[[0],\n",
      "              [0]]]), 'env_id': TensorBatch([[[140510454244752],\n",
      "              [140510454244752]]])}\n",
      "taking step\n",
      "taking step\n",
      "{'state': TensorBatch([[[-0.0115, -0.8010, -0.0164,  1.0685],\n",
      "              [-0.0275, -0.9959,  0.0050,  1.3560]]]), 'next_state': TensorBatch([[[-0.0275, -0.9959,  0.0050,  1.3560],\n",
      "              [-0.0474, -1.1911,  0.0321,  1.6502]]]), 'done': TensorBatch([[[False],\n",
      "              [False]]]), 'reward': TensorBatch([[[1.],\n",
      "              [1.]]]), 'sum_reward': TensorBatch([[[5.],\n",
      "              [6.]]]), 'action': TensorBatch([[[0],\n",
      "              [0]]]), 'env_id': TensorBatch([[[140510454244752],\n",
      "              [140510454244752]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:98: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  \"We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) \"\n"
     ]
    }
   ],
   "source": [
    "# from pprint import pprint\n",
    "for o in dls[0]:\n",
    "    print(o)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8d8e7-e153-41a3-ac31-22f936720d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
