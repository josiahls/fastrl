{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fastai.data.block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from typing import Any,Callable\n",
    "from inspect import isfunction,ismethod\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from fastai.torch_core import *\n",
    "from fastai.data.transforms import *\n",
    "import torchdata.datapipes as dp\n",
    "from collections import deque\n",
    "from fastai.imports import *\n",
    "# Local modules\n",
    "from fastrl.fastai.data.load import *\n",
    "from fastrl.fastai.data.pipes.core import *\n",
    "from fastrl.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Data Block\n",
    "> High level API to quickly get your data in a `DataLoader`s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63392058-2c52-4282-94f7-3c01400845d9",
   "metadata": {},
   "source": [
    "## Transform Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c189134b-414d-4a46-a7ce-5d7a75594655",
   "metadata": {},
   "source": [
    "> Note: We will first validate the lower level API on a dqn before making the data block. This is going to be a naive implimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c518d8b6-858c-41a3-a9cc-23fefea2ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _merge_grouper(o):\n",
    "    if isinstance(o, LambdaType): return id(o)\n",
    "    elif isinstance(o, type): return o\n",
    "    elif (isfunction(o) or ismethod(o)): return o.__qualname__\n",
    "    return o.__class__\n",
    "\n",
    "def _merge_tfms(*tfms):\n",
    "    \"Group the `tfms` in a single list, removing duplicates (from the same class) and instantiating\"\n",
    "    g = groupby(concat(*tfms), _merge_grouper)\n",
    "    return L(v[-1] for k,v in g.items()).map(instantiate)\n",
    "\n",
    "def _zip(x): return L(x).zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec802048-caeb-4149-adb5-e57592ded1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TransformBlock():\n",
    "    \"A basic wrapper that links defaults transforms for the data block API\"\n",
    "    def __init__(self, \n",
    "        type_tfms:list=None, # One or more `Transform`s for converting types. These will be re-called if workers!=0 for the dataloader.\n",
    "        item_tfms:list=None, # `ItemTransform`s, applied on an item\n",
    "        batch_tfms:list=None, # `Transform`s or `RandTransform`s, applied by batch\n",
    "        cbs:list=None, # `Callback`s for use in dataloaders\n",
    "        dl_type:DataLoader2=None, # Task specific `TfmdDL`, defaults to `TfmdDL`\n",
    "        dls_kwargs:dict=None, # Additional arguments to be passed to `DataLoaders`\n",
    "    ):\n",
    "        self.type_tfms  =            L(type_tfms)\n",
    "        self.item_tfms  =            L(item_tfms)\n",
    "        self.batch_tfms =            L(batch_tfms)\n",
    "        self.cbs        =            L(cbs)\n",
    "        self.dl_type,self.dls_kwargs = dl_type,({} if dls_kwargs is None else dls_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9c25da7-6dae-4f33-82fb-5ae633ded351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def simple_iter_loader_loop(\n",
    "    items:Iterable,\n",
    "    cbs:Optional[List[Callback]]=None,\n",
    "    type_tfms:Optional[Transform]=None,\n",
    "    item_tfms:Optional[Transform]=None,\n",
    "    batch_tfms:Optional[Transform]=None,\n",
    "    bs:int=2,\n",
    "    n:int=1\n",
    "):\n",
    "    pipe = dp.map.SequenceWrapper(items).add_cbs(cbs)\n",
    "    pipe = TypeTransformLoop(pipe, type_tfms=ifnone(type_tfms,L())).add_cbs(cbs)\n",
    "    pipe = dp.map.InMemoryCacheHolder(pipe).add_cbs(cbs)\n",
    "    pipe = dp.iter.MapToIterConverter(pipe).add_cbs(cbs) # Will intialize the gym object, which will be an issue when doing multiproc\n",
    "    pipe = dp.iter.ShardingFilter(pipe).add_cbs(cbs)\n",
    "    pipe = pipe.cycle(count=n).add_cbs(cbs)\n",
    "    pipe = ItemTransformLoop(pipe, item_tfms=ifnone(item_tfms,L())).add_cbs(cbs)\n",
    "    pipe = dp.iter.Batcher(pipe,bs).add_cbs(cbs)\n",
    "    pipe = BatchTransformLoop(pipe, batch_tfms=ifnone(batch_tfms,L())).add_cbs(cbs)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b69adc7-2512-450d-9dc3-c12c1d5901ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataBlock(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        blocks:List[TransformBlock]=None, # Transform blocks to use \n",
    "        loader_loop:Callable=None,\n",
    "        dl_type=None\n",
    "    ):\n",
    "        store_attr(but='loader_loop')\n",
    "        self.loader_loop = ifnone(loader_loop,default_loader_loop)\n",
    "        blocks = L(self.blocks if blocks is None else blocks)\n",
    "        blocks = L(b() if callable(b) else b for b in blocks)\n",
    "        self.type_tfms = blocks.attrgot('type_tfms', L())\n",
    "\n",
    "        self.cbs = blocks.attrgot('cbs', L())\n",
    "        self.item_tfms  = _merge_tfms(*blocks.attrgot('item_tfms',  L()))\n",
    "        self.batch_tfms = _merge_tfms(*blocks.attrgot('batch_tfms', L()))\n",
    "        for b in blocks:\n",
    "            if getattr(b, 'dl_type', None) is not None: self.dl_type = b.dl_type\n",
    "        if dl_type is not None: self.dl_type = dl_type\n",
    "        self.dataloaders = delegates(self.dl_type.__init__)(self.dataloaders)\n",
    "        self.dls_kwargs = merge(*blocks.attrgot('dls_kwargs', {}))\n",
    "\n",
    "    def datapipes(\n",
    "        self,\n",
    "        source:Any,\n",
    "        bs=2,\n",
    "        n=1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return L(self.loader_loop(\n",
    "            source,\n",
    "            cbs=cbs,\n",
    "            type_tfms=type_tfms,\n",
    "            item_tfms=self.item_tfms,\n",
    "            batch_tfms=self.batch_tfms,\n",
    "            bs=bs,\n",
    "            n=n,\n",
    "            **kwargs\n",
    "        ) for type_tfms,cbs in zip(self.type_tfms,self.cbs))\n",
    "        \n",
    "    def dataloaders(\n",
    "        self,\n",
    "        source:Any,\n",
    "        n_workers=0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        pipes = self.datapipes(source,**kwargs)\n",
    "        return L(pipes).map(DataLoader2,num_workers=n_workers,**self.dls_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d782b9-cc27-4e7c-a017-d7bd71fcb4b4",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb74ef4f-e4c8-4362-8db2-dca0a853ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import gym\n",
    "\n",
    "class Flattener(dp.iter.IterDataPipe):\n",
    "    \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for o in self.source_datapipe:\n",
    "            if not is_listy(o):\n",
    "                raise Exception(f'Expected listy object got {type(o)}\\n{o}')\n",
    "            for oo in o: yield oo\n",
    "            \n",
    "class NStepPipe(dp.iter.IterDataPipe):\n",
    "    \n",
    "    def __init__(self, source_datapipe, n=1, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.n = n\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        buffer = []\n",
    "        for o in self.source_datapipe:\n",
    "            if not type(o)==dict:\n",
    "                raise Exception(f'Expected dict object generated from `make_step` got {type(o)}\\n{o}')\n",
    "        \n",
    "            buffer.append(o)\n",
    "            if not o['done'] and len(buffer)<self.n: continue\n",
    "            \n",
    "            while o['done'] and len(buffer)!=0:\n",
    "                yield tuple(buffer)\n",
    "                buffer.pop(0)\n",
    "                \n",
    "            if not o['done']:\n",
    "                yield tuple(buffer)\n",
    "                buffer.pop(0)\n",
    "                \n",
    "class NSkipPipe(dp.iter.IterDataPipe):\n",
    "    \n",
    "    def __init__(self, source_datapipe, n=1, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.n = n\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        skip_idx = 0\n",
    "        for o in self.source_datapipe:\n",
    "            if not type(o)==dict:\n",
    "                raise Exception(f'Expected dict object generated from `make_step` got {type(o)}\\n{o}')\n",
    "            \n",
    "            skip_idx += 1 # Be aware of the ordering here. we want to always show the first step when we can. \n",
    "            if skip_idx%self.n==0 or o['done']: \n",
    "                yield o\n",
    "                if o['done']: skip_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14877e71-cc13-47a0-9d56-9c16e9849d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class NStepCallback(Callback):\n",
    "    \"A list of data pipes that have an associated job.\"\n",
    "    call_on=L(ItemTransformLoop)\n",
    "    exclude_under=L()\n",
    "    \n",
    "    def __init__(self,nsteps=1,nskip=1):\n",
    "        store_attr()\n",
    "        self.pipes = L(partial(NSkipPipe,n=nskip),\n",
    "                       partial(NStepPipe, n=nsteps),\n",
    "                       Flattener\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6517ff08-afc7-4990-acf0-bb05205e17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DictCollate(Transform):\n",
    "    def encodes(self,o): return L(o).map(BD).sum()\n",
    "    \n",
    "class DictToTensor(Transform):\n",
    "    def encodes(self,o:dict):\n",
    "        for k,v in o.items(): \n",
    "            v = TensorBatch(v)\n",
    "            if len(v.shape)==0: v = v.unsqueeze(0)\n",
    "            o[k] = v\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0a61a9a-a7ce-4960-ba95-ca387c0a5164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def make_step(\n",
    "    state,\n",
    "    next_state,\n",
    "    done,\n",
    "    reward,\n",
    "    sum_reward,\n",
    "    action,\n",
    "    env_id\n",
    "):\n",
    "    return dict(state=state,next_state=next_state,done=done,reward=reward,\n",
    "                sum_reward=sum_reward,action=action,env_id=env_id)\n",
    "\n",
    "class GymTypeTransform(Transform):\n",
    "    def encodes(self,o): return gym.make(o)\n",
    "    \n",
    "class GymStepTransform(Transform):\n",
    "    @delegates(Transform)\n",
    "    def __init__(self,agent=None,**kwargs):\n",
    "        self.agent = agent\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def encodes(self,o:gym.Env):\n",
    "        \n",
    "        if getattr(o,'is_done',True):\n",
    "            state = o.reset(seed=getattr(self,'seed',0))\n",
    "            o.is_done = False\n",
    "            o.sum_reward = 0\n",
    "            o.step_info = make_step(state,None,False,None,0,None,env_id=id(o))\n",
    "        else:\n",
    "            state = o.state\n",
    "            \n",
    "        self.agent.agent_base.iterator.append(o.step_info)\n",
    "        for action in self.agent:\n",
    "            next_state,reward,done,_ = o.step(action)\n",
    "            o.sum_reward += reward\n",
    "        \n",
    "        if done: o.is_done = True\n",
    "        o.step_info = make_step(state,next_state,done,reward,o.sum_reward,action,env_id=id(o))\n",
    "        \n",
    "        print('taking step')\n",
    "        \n",
    "        return o.step_info\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb48210f-aa14-4f18-812f-1b370c694cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)\n",
    "\n",
    "class Agent(dp.iter.IterDataPipe):\n",
    "    def __init__(self,model,iterator):\n",
    "        self.model = model\n",
    "        self.iterator = iterator\n",
    "        self.agent_base = self\n",
    "        \n",
    "    def __iter__(self):\n",
    "        while self.iterator:\n",
    "            yield self.iterator.pop(0)\n",
    "\n",
    "\n",
    "class RawOutOfStep(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,agent_base,key): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.key = key\n",
    "        self.agent_base = agent_base\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for o in self.source_datapipe:\n",
    "            x = tensor(o[self.key])\n",
    "            x = self.agent_base.model(x)\n",
    "            yield x\n",
    "            \n",
    "class ArgmaxOfStep(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,agent_base): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = agent_base\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for o in self.source_datapipe:\n",
    "            yield torch.argmax(o)\n",
    "            \n",
    "class ToDiscrete(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,agent_base): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = agent_base\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for x in self.source_datapipe:\n",
    "            if isinstance(x,Tensor):\n",
    "                if len(x.shape)==0:\n",
    "                    yield int(x)\n",
    "                else:\n",
    "                    yield x.long()\n",
    "            else:\n",
    "                raise Exception(f'Cant convert to discrete: {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7713f8f9-7e23-4433-9465-7eb637ab599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DiscreteEpsilonRandomSelect(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    def __init__(self,source_datapipe,agent_base,n_actions,idx=0,min_epsilon=0.2,max_epsilon=1,max_steps=5000):\n",
    "        self.n_actions = n_actions\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = agent_base\n",
    "        self.agent_base.epislon_selector = self \n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.epsilon = max_epsilon\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.max_steps = max_steps\n",
    "        self.idx = idx\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for action in self.source_datapipe:\n",
    "            mask = np.random.random(size=self.n_actions) < self.epsilon\n",
    "            rand_actions = np.random.choice(self.n_actions, sum(mask))\n",
    "            action = action.cpu().detach().numpy().reshape((-1,))\n",
    "            action[mask] = rand_actions\n",
    "            action=Tensor(action).long().reshape(-1,1)\n",
    "\n",
    "            if self.agent_base.model.training: \n",
    "                self.idx += 1\n",
    "                self.epsilon = max(self.min_epsilon,self.max_epsilon-self.idx/self.max_steps)\n",
    "            yield action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "456f581c-6266-4876-b970-da1c6ff059b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_info = dict(state=np.random.sample((1,4)),\n",
    "                 next_state=np.random.sample((1,4)),\n",
    "                 action=np.random.sample((1,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0072a93c-e0fe-45d4-bc13-26718ac32d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(4,2)\n",
    "agent_base = Agent(model,[test_info])\n",
    "agent = RawOutOfStep(agent_base,agent_base,'state')\n",
    "agent = DiscreteEpsilonRandomSelect(agent,agent_base,2,min_epsilon=0)\n",
    "agent = ArgmaxOfStep(agent,agent_base)\n",
    "agent = ToDiscrete(agent,agent_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10bc702-0183-41f9-b086-e34213839fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9998\n",
      "0 0.9598\n",
      "0 0.9198\n",
      "0 0.8798\n",
      "0 0.8398\n",
      "1 0.7998000000000001\n",
      "0 0.7598\n",
      "1 0.7198\n",
      "0 0.6798\n",
      "1 0.6397999999999999\n",
      "1 0.5998\n",
      "0 0.5598000000000001\n",
      "0 0.5198\n",
      "0 0.4798\n",
      "0 0.43979999999999997\n",
      "0 0.39980000000000004\n",
      "0 0.3598\n",
      "0 0.3198\n",
      "0 0.27980000000000005\n",
      "0 0.2398\n",
      "0 0.19979999999999998\n",
      "0 0.15980000000000005\n",
      "0 0.11980000000000002\n",
      "0 0.07979999999999998\n",
      "0 0.03979999999999995\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "for i,action in enumerate(agent):\n",
    "    test_info = dict(state=np.random.sample((1,4)),\n",
    "                 next_state=np.random.sample((1,4)),\n",
    "                 action=np.random.sample((1,4)))\n",
    "    agent.agent_base.iterator.append(test_info)\n",
    "    if i%200==0:print(action,agent_base.epislon_selector.epsilon)\n",
    "    if i>7000: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98904fbe-cf2e-454d-b6a0-90243f8e2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_info = dict(state=np.random.sample((1,4)),\n",
    "                 next_state=np.random.sample((1,4)),\n",
    "                 action=np.random.sample((1,4)))\n",
    "agent.agent_base.iterator.append(test_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbb6a95b-4634-476c-bdc9-51d65265803e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': array([[0.81997638, 0.62663011, 0.85674988, 0.38386031]]),\n",
       " 'next_state': array([[0.8615092 , 0.35864119, 0.248019  , 0.31837868]]),\n",
       " 'action': array([[0.4960577 , 0.15713401, 0.73006957, 0.66573211]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1884a330-79a2-4c18-a97e-00693ebcdb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GymTransformBlock = TransformBlock(\n",
    "    type_tfms  = GymTypeTransform,\n",
    "    item_tfms  = (GymStepTransform(agent),DictToTensor),\n",
    "    batch_tfms = DictCollate,\n",
    "    cbs = NStepCallback(nsteps=1)\n",
    ")\n",
    "\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock,\n",
    "    loader_loop=simple_iter_loader_loop\n",
    ")\n",
    "# pipes = block.datapipes(['CartPole-v1']*1,n=10,bs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7441d041-1654-460c-b2a4-2b360655eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data.graph import traverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30383a9f-7822-4e49-a23f-131f68a47700",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = block.dataloaders(['CartPole-v1']*1,n=4,n_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38da3c24-8809-4c68-b25b-5ee37cd9a397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking step\n",
      "taking step\n",
      "{'state': TensorBatch([[[-0.0990, -1.5824,  0.1041,  2.2648],\n",
      "              [-0.1306, -1.7783,  0.1494,  2.5877]]]), 'next_state': TensorBatch([[[-0.1306, -1.7783,  0.1494,  2.5877],\n",
      "              [-0.1662, -1.9742,  0.2012,  2.9221]]]), 'done': TensorBatch([[[False],\n",
      "              [False]]]), 'reward': TensorBatch([[[1.],\n",
      "              [1.]]]), 'sum_reward': TensorBatch([[[ 9.],\n",
      "              [10.]]]), 'action': TensorBatch([[[0],\n",
      "              [0]]]), 'env_id': TensorBatch([[[140669445366544],\n",
      "              [140669445366544]]])}\n",
      "taking step\n",
      "taking step\n",
      "{'state': TensorBatch([[[-0.1662, -1.9742,  0.2012,  2.9221],\n",
      "              [ 0.0137, -0.0230, -0.0459, -0.0483]]]), 'next_state': TensorBatch([[[-0.2057, -2.1699,  0.2596,  3.2685],\n",
      "              [ 0.0132, -0.2175, -0.0469,  0.2295]]]), 'done': TensorBatch([[[ True],\n",
      "              [False]]]), 'reward': TensorBatch([[[1.],\n",
      "              [1.]]]), 'sum_reward': TensorBatch([[[11.],\n",
      "              [ 1.]]]), 'action': TensorBatch([[[0],\n",
      "              [0]]]), 'env_id': TensorBatch([[[140669445366544],\n",
      "              [140669445366544]]])}\n",
      "taking step\n",
      "taking step\n",
      "{'state': TensorBatch([[[ 0.0132, -0.2175, -0.0469,  0.2295],\n",
      "              [ 0.0089, -0.4119, -0.0423,  0.5070]]]), 'next_state': TensorBatch([[[ 8.8866e-03, -4.1188e-01, -4.2279e-02,  5.0705e-01],\n",
      "              [ 6.4906e-04, -6.0638e-01, -3.2139e-02,  7.8611e-01]]]), 'done': TensorBatch([[[False],\n",
      "              [False]]]), 'reward': TensorBatch([[[1.],\n",
      "              [1.]]]), 'sum_reward': TensorBatch([[[2.],\n",
      "              [3.]]]), 'action': TensorBatch([[[0],\n",
      "              [0]]]), 'env_id': TensorBatch([[[140669445366544],\n",
      "              [140669445366544]]])}\n",
      "taking step\n",
      "taking step\n",
      "{'state': TensorBatch([[[ 6.4906e-04, -6.0638e-01, -3.2139e-02,  7.8611e-01],\n",
      "              [-1.1479e-02, -8.0105e-01, -1.6416e-02,  1.0685e+00]]]), 'next_state': TensorBatch([[[-0.0115, -0.8010, -0.0164,  1.0685],\n",
      "              [-0.0275, -0.9959,  0.0050,  1.3560]]]), 'done': TensorBatch([[[False],\n",
      "              [False]]]), 'reward': TensorBatch([[[1.],\n",
      "              [1.]]]), 'sum_reward': TensorBatch([[[4.],\n",
      "              [5.]]]), 'action': TensorBatch([[[0],\n",
      "              [0]]]), 'env_id': TensorBatch([[[140669445366544],\n",
      "              [140669445366544]]])}\n",
      "taking step\n",
      "taking step\n",
      "{'state': TensorBatch([[[-0.0275, -0.9959,  0.0050,  1.3560],\n",
      "              [-0.0474, -1.1911,  0.0321,  1.6502]]]), 'next_state': TensorBatch([[[-0.0474, -1.1911,  0.0321,  1.6502],\n",
      "              [-0.0712, -1.3866,  0.0651,  1.9527]]]), 'done': TensorBatch([[[False],\n",
      "              [False]]]), 'reward': TensorBatch([[[1.],\n",
      "              [1.]]]), 'sum_reward': TensorBatch([[[6.],\n",
      "              [7.]]]), 'action': TensorBatch([[[0],\n",
      "              [0]]]), 'env_id': TensorBatch([[[140669445366544],\n",
      "              [140669445366544]]])}\n",
      "taking step\n",
      "taking step\n",
      "{'state': TensorBatch([[[-0.0712, -1.3866,  0.0651,  1.9527],\n",
      "              [-0.0990, -1.5824,  0.1041,  2.2648]]]), 'next_state': TensorBatch([[[-0.0990, -1.5824,  0.1041,  2.2648],\n",
      "              [-0.1306, -1.7783,  0.1494,  2.5877]]]), 'done': TensorBatch([[[False],\n",
      "              [False]]]), 'reward': TensorBatch([[[1.],\n",
      "              [1.]]]), 'sum_reward': TensorBatch([[[8.],\n",
      "              [9.]]]), 'action': TensorBatch([[[0],\n",
      "              [0]]]), 'env_id': TensorBatch([[[140669445366544],\n",
      "              [140669445366544]]])}\n",
      "taking step\n",
      "taking step\n",
      "{'state': TensorBatch([[[-0.1306, -1.7783,  0.1494,  2.5877],\n",
      "              [-0.1662, -1.9742,  0.2012,  2.9221]]]), 'next_state': TensorBatch([[[-0.1662, -1.9742,  0.2012,  2.9221],\n",
      "              [-0.2057, -2.1699,  0.2596,  3.2685]]]), 'done': TensorBatch([[[False],\n",
      "              [ True]]]), 'reward': TensorBatch([[[1.],\n",
      "              [1.]]]), 'sum_reward': TensorBatch([[[10.],\n",
      "              [11.]]]), 'action': TensorBatch([[[0],\n",
      "              [0]]]), 'env_id': TensorBatch([[[140669445366544],\n",
      "              [140669445366544]]])}\n",
      "taking step\n",
      "taking step\n",
      "{'state': TensorBatch([[[ 0.0137, -0.0230, -0.0459, -0.0483],\n",
      "              [ 0.0132, -0.2175, -0.0469,  0.2295]]]), 'next_state': TensorBatch([[[ 0.0132, -0.2175, -0.0469,  0.2295],\n",
      "              [ 0.0089, -0.4119, -0.0423,  0.5070]]]), 'done': TensorBatch([[[False],\n",
      "              [False]]]), 'reward': TensorBatch([[[1.],\n",
      "              [1.]]]), 'sum_reward': TensorBatch([[[1.],\n",
      "              [2.]]]), 'action': TensorBatch([[[0],\n",
      "              [0]]]), 'env_id': TensorBatch([[[140669445366544],\n",
      "              [140669445366544]]])}\n"
     ]
    }
   ],
   "source": [
    "# from pprint import pprint\n",
    "for o in dls[0]:\n",
    "    print(o)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
