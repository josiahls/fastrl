{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python native modules\n",
    "import os\n",
    "from copy import deepcopy\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import numpy as np\n",
    "# Local modules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681dfae-2d75-4936-8ab3-eb1bf1727312",
   "metadata": {},
   "source": [
    "## MultiProcessing Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efbf0be-7a0c-4d7f-b876-df06e410dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchdata.datapipes as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139af462-4cee-42a0-9b8c-037f413ecf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting external_run_scripts/notes_multi_proc_82.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../external_run_scripts/notes_multi_proc_82.py\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "class AddABunch1(dp.iter.IterDataPipe):\n",
    "    def __init__(self,q):\n",
    "        super().__init__()\n",
    "        self.q = [q]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for o in range(10): \n",
    "            self.q[0].put(o)\n",
    "            yield o\n",
    "            \n",
    "class AddABunch2(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,q):\n",
    "        super().__init__()\n",
    "        self.q = q\n",
    "        print(id(self.q))\n",
    "        self.source_datapipe = source_datapipe\n",
    "\n",
    "    def __iter__(self):\n",
    "        for o in self.source_datapipe: \n",
    "            print(id(self.q))\n",
    "            self.q.put(o)\n",
    "            yield o\n",
    "            \n",
    "class AddABunch3(IterableDataset):\n",
    "    def __init__(self,q):\n",
    "        self.q = q\n",
    "\n",
    "    def __iter__(self):\n",
    "        for o in range(10): \n",
    "            print(id(self.q))\n",
    "            self.q.put(o)\n",
    "            yield o\n",
    "\n",
    "if __name__=='__main__':\n",
    "    from torch.multiprocessing import Pool,Process,set_start_method,Manager,get_start_method\n",
    "    import torch\n",
    "    \n",
    "    try: set_start_method('spawn')\n",
    "    except RuntimeError: pass\n",
    "    # from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "    from torchdata.dataloader2 import DataLoader2\n",
    "    from torchdata.dataloader2.reading_service import MultiProcessingReadingService\n",
    "\n",
    "    m = Manager()\n",
    "    q = m.Queue()\n",
    "    \n",
    "    pipe = AddABunch2(list(range(10)),q)\n",
    "    print(type(pipe))\n",
    "    dl = DataLoader2(pipe,\n",
    "        reading_service=MultiProcessingReadingService(num_workers=1)\n",
    "    ) # Will fail if num_workers>0\n",
    "    \n",
    "    # dl = DataLoader2(AddABunch1(q),num_workers=1) # Will fail if num_workers>0\n",
    "    # dl = DataLoader2(AddABunch2(q),num_workers=1) # Will fail if num_workers>0\n",
    "    # dl = DataLoader2(AddABunch3(q),num_workers=1) # Will succeed if num_workers>0\n",
    "    list(dl)\n",
    "    \n",
    "    while not q.empty():\n",
    "        print(q.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b223ee-40ab-4eea-a7cc-35d659301b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.multiprocessing import Pool,Process,set_start_method,Manager,get_start_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988390db-b284-494d-a413-2fc12b6fa032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fork'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_start_method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
