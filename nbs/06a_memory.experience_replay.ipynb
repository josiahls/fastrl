{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbverbose.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp memory.experience_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from typing import *\n",
    "from warnings import warn\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.callback.all import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# Local modules\n",
    "from fastrl.core import *\n",
    "from fastrl.callback.core import *\n",
    "from fastrl.data.block import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Experience Replay\n",
    "> Experience Replay is likely the simplest form of memory used by RL agents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "29951651-b9ff-4c02-859f-2528338ae8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceReplayException(Exception): pass\n",
    "\n",
    "class ExperienceReplay(object):\n",
    "    def __init__(self,\n",
    "                 bs:int=16,         # Number of entries to query from memory\n",
    "                 max_sz:int=200,    # Maximum number of entries to hold. Will start overwriting after.\n",
    "                 warmup_sz:int=100,  # Minimum number of entries needed to continue with a batch\n",
    "                 # Used for testing. Once the memory has reached max size, it will not\n",
    "                 # Add any more data. This is useful for checking whether a model is training correctly.\n",
    "                 freeze_at_max:bool=False, \n",
    "                 memory:Optional[BD]=None # Optionally, you can initialize a new `ExperienceReplay` with an existing dictionary\n",
    "                 ):\n",
    "        \"Stores `BD`s in a rotating list `self.memory`\"\n",
    "        store_attr()\n",
    "        test_lt(warmup_sz-1,max_sz)\n",
    "        self.memory=memory\n",
    "        self.pointer=0\n",
    "    \n",
    "    def __add__(self,other:BD):\n",
    "        \"In-place add `other` to memory, overwriting if len(self.memory)>self.max_sz\"\n",
    "        if isinstance(other,tuple) and len(other)==1: other=other[0]\n",
    "        elif isinstance(other,tuple):                 raise ExperienceReplayException('records need to be `BD`s or 1 element tuples')\n",
    "        if isinstance(other,dict):                    other=BD(other)\n",
    "        elif isinstance(other,list):                  other=sum(other)\n",
    "        \n",
    "        if 'td_error' not in other: other['td_error']=TensorBatch(torch.zeros((other.bs(),1)))\n",
    "        \n",
    "        if self.memory is None: \n",
    "            if other.bs()>self.max_sz: \n",
    "                self.memory=other[:self.max_sz]\n",
    "                self.pointer=0           # Keep the pointer 0 since we have basically replaced the memory\n",
    "                self+other[self.max_sz:] # Recursively add the rest of the batch\n",
    "            else:\n",
    "                self.memory=other\n",
    "                self.pointer=self.memory.bs() # remember that pointer is not an index but number of elements\n",
    "        else:\n",
    "            if self.freeze_at_max and self.memory.bs()>=self.max_sz: return self\n",
    "            n_over=(other.bs()+self.pointer)-self.max_sz\n",
    "            if n_over>0: # e.g.: max_sz 200, pointer 195, other is 5.\n",
    "                self.memory=self.memory[:self.pointer]+other[:-n_over]\n",
    "                self.pointer=0\n",
    "                self+other[other.bs()-n_over:]\n",
    "            else:\n",
    "                # If the number of elements is not over\n",
    "                next_pointer=self.pointer+other.bs()\n",
    "                self.memory=self.memory[:self.pointer]+other+self.memory[next_pointer:]\n",
    "                self.pointer=next_pointer\n",
    "        return self\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        return ExperienceReplay(bs=self.bs,max_sz=self.max_sz,\n",
    "                                warmup_sz=self.warmup_sz,memory=self.memory[i])\n",
    "    \n",
    "    def __radd__(self,other:BD): raise ExperienceReplayException('You can only do experience_reply+[some other element]')\n",
    "    \n",
    "    def __len__(self): return self.memory.bs() if self.memory is not None else 0\n",
    "        \n",
    "    def sample(self)->BD:\n",
    "        \"Returns a sample of size `self.bs`\"\n",
    "        with torch.no_grad():\n",
    "            idxs=np.random.randint(0,self.memory.bs(),self.bs).tolist()\n",
    "            samples=self.memory[idxs].mapv(to_device)\n",
    "        \n",
    "        if self.memory.bs()<self.warmup_sz: raise CancelBatchException\n",
    "        return samples,idxs\n",
    "    \n",
    "    def update_td(self,td_errors:Tensor,idxs:Tensor):\n",
    "        if not isinstance(idxs,list):\n",
    "            test_len(idxs.shape,1)\n",
    "        test_len(td_errors.shape,2)\n",
    "        self.memory['td_error'][idxs]=to_detach(td_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc88238c-b34e-40b2-8384-40e58e7b9dca",
   "metadata": {},
   "source": [
    "lets generate some batches to test with..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bec43770-af92-4f11-89ce-301f33c9bae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not do one pass in your dataloader, there is something wrong in it\n"
     ]
    }
   ],
   "source": [
    "from fastrl.data.gym import *\n",
    "source=Source(\n",
    "    cbs=[GymLoop(env_name='CartPole-v1',steps_delta=1,steps_count=1,seed=0),FirstLast]\n",
    ")\n",
    "source=Source(cbs=[GymLoop(env_name='CartPole-v1',steps_delta=1,steps_count=1,seed=0),FirstLast])\n",
    "learn=fake_gym_learner(source,n=1000,bs=5)\n",
    "batches=[BD(b[0]) for b in learn.dls[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "92ca156a-d774-413e-a0bb-505f60d4729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay=ExperienceReplay(max_sz=20,warmup_sz=19)\n",
    "test_len(experience_replay,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a714d-66cd-4660-b65f-578b87fdfba5",
   "metadata": {},
   "source": [
    "**what if we fill up ER?**\n",
    "Lets add the batches, this process will happen inplace..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "81db8e2b-3630-4445-90b7-457fbcc767cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[0]\n",
    "test_eq(experience_replay.pointer,5)\n",
    "test_len(experience_replay,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb4ee5-37fc-407a-bd8f-915556f6bcfc",
   "metadata": {},
   "source": [
    "If we add again, the total size should be 10..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d4b90529-0d8c-4964-abff-fe67de7ed6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[1]\n",
    "test_eq(experience_replay.pointer,10)\n",
    "test_len(experience_replay,10)\n",
    "test_eq(experience_replay.memory['step'],(batches[0]+batches[1])['step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "faab02dc-a33d-45fa-bfb9-291bca124844",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[2]\n",
    "test_len(experience_replay,15)\n",
    "test_eq(experience_replay.pointer,15)\n",
    "test_eq(experience_replay.memory['step'],(batches[0]+batches[1]+batches[2])['step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "870c422c-516f-43f3-973d-79966acca9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[3]\n",
    "test_len(experience_replay,20)\n",
    "test_eq(experience_replay.pointer,20)\n",
    "test_eq(experience_replay.memory['step'],(batches[0]+batches[1]+batches[2]+batches[3])['step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d227295b-11b5-4710-ac44-6a2d203b420e",
   "metadata": {},
   "source": [
    "Let's verify that the steps are what we expect..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c6679c-94c9-4b0e-a71c-c4e4ffad99da",
   "metadata": {},
   "source": [
    "**What if ER is full and we add batches? ** We are at the maximum memory size, we expect that the next batch added should completely\n",
    "overwrite the first 5 entries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ada8f82e-7236-48c9-b249-00d0f9397c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[4]\n",
    "test_len(experience_replay,20)\n",
    "test_eq(experience_replay.pointer,5)\n",
    "test_eq(experience_replay.memory['step'],(batches[4]+batches[1]+batches[2]+batches[3])['step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb9b4f4-2c2e-4a5f-b8cc-2395ef510908",
   "metadata": {},
   "source": [
    "This overwrite should properly overwrite the rest of the entries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0e02708c-0282-43b2-a42f-5f14b2f57992",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[5]+batches[6]+batches[7]\n",
    "test_eq(experience_replay.memory['step'],(batches[4]+batches[5]+batches[6]+batches[7])['step'])\n",
    "test_eq(experience_replay.pointer,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad837a0a-98f2-4cf0-8873-942421f18927",
   "metadata": {},
   "source": [
    "so we have fully overwritten the memory twice, and so far we can prove that the memory overwritting works. Let's \n",
    "see what happens when we append add numbered dictionaries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "662489e9-7ab9-4401-a2a8-ef24be6e1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[8]+batches[9]+batches[10]\n",
    "test_eq(experience_replay.pointer,15)\n",
    "test_eq(experience_replay.memory['step'],(batches[8]+batches[9]+batches[10]+batches[7])['step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6d9551-f9c7-4dc6-83dd-ae67a3c04dc9",
   "metadata": {},
   "source": [
    "**What if we need to split a batch to fit at the end and beginnging of the memory?** This is a possibly scary part where some of the dictionary needs to be split. Some needs to be allocated to the end of the memory, and\n",
    "some of it need to be allocated at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2a49dfab-308d-40a4-97b7-393f58f135f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_large_batch=batches[11]+batches[12]\n",
    "experience_replay+single_large_batch;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c1f47467-dd2f-4f0a-bb73-c491cf694937",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(experience_replay.pointer,5)\n",
    "test_eq(experience_replay.memory['step'],(batches[12]+batches[9]+batches[10]+batches[11])['step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3ae0a-fb90-41f9-997b-b538d6ff0491",
   "metadata": {},
   "source": [
    "**What if we sample the experience?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "296db44f-bdda-4876-bb41-ce6148c3f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_memory=(batches[12]+batches[9]+batches[10]+batches[11])\n",
    "entry_ids=[str(o) for o in torch.hstack((full_memory['step'],full_memory['episode_id']))]\n",
    "memory_hits=[False]*len(entry_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370e444-1088-4ea2-980d-d490f46e0bb9",
   "metadata": {},
   "source": [
    "We should be able to sample enough times that we have sampled **everything**. \n",
    "So we test this by sampling, check if that sample has been seen before, and then record that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "40561103-b40b-483f-ba17-c0d55af9b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    res,idxs=experience_replay.sample()\n",
    "    for o in torch.hstack((res['step'],res['episode_id'])):\n",
    "        memory_hits[entry_ids.index(str(o))]=True\n",
    "test_eq(all(memory_hits),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff82aa-af7c-4af4-9e58-9c0add6c3a22",
   "metadata": {},
   "source": [
    "**What happens when we index the experience replay?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f11d7d53-b80b-44dc-8f4d-736a71244be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(experience_replay[5:10].memory['step'],batches[9]['step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd22397-a935-4f6f-b1f7-0c83cc936ca8",
   "metadata": {},
   "source": [
    "**What happens when we try to update the td_errors?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5fb803c5-b0e1-48b8-83e0-02fb7eb26e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBatch([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorBatch(torch.full((5,1),1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "07746086-aa94-4999-bbb1-7bff353eaaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay.update_td(TensorBatch(torch.full((5,1),1.0)),torch.arange(5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1fe83f98-6117-421e-b45a-8c09f5c08b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(experience_replay.memory['td_error'].sum(),5)\n",
    "test_eq(experience_replay.memory['td_error'][torch.arange(5,10)].sum(),5)\n",
    "test_eq(experience_replay.memory['td_error'][torch.arange(6,11)].sum(),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab149d-bdbe-4482-80d8-e2d86113c41d",
   "metadata": {},
   "source": [
    "**What happens when we freeze the memory?**\n",
    "\n",
    "We should expect that we can fill up the memory, then once it is at its max, it will not accept anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c2f39252-defa-4d53-9f1d-93abb231d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay=ExperienceReplay(max_sz=20,warmup_sz=5,freeze_at_max=True)\n",
    "experience_replay+batches[0:4]\n",
    "test_eq(experience_replay.memory['step'],sum(batches[0:4])['step'])\n",
    "experience_replay+batches[4]\n",
    "test_eq(experience_replay.memory['step'],sum(batches[0:4])['step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c95b1cc6-4da6-4060-bb7b-35176883e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceReplayCallback(Callback):\n",
    "    @delegates(ExperienceReplay)\n",
    "    def __init__(self,\n",
    "                 verbose=False, # Will show warnings for recommended behavior.\n",
    "                 **kwargs):\n",
    "        \"Stores `BD`s in a rotating list `self.memory`\"\n",
    "        store_attr()\n",
    "        self._kwargs=kwargs\n",
    "        \n",
    "    def before_fit(self):\n",
    "        if not hasattr(self.learn,'experience_replay'):\n",
    "            self.learn.experience_replay=ExperienceReplay(**self._kwargs)\n",
    "    \n",
    "    def after_pred(self):\n",
    "        \"Adds `learn.xb` to memory, then sets `learn.xb=experience_replay.sample()`\"\n",
    "        xb=BD(self.learn.xb[0]).mapv(to_detach)\n",
    "        self.learn.experience_replay+xb\n",
    "        \n",
    "        self.learn.xb,self.learn.sample_indexes=self.experience_replay.sample()\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if hasattr(self.learn,'td_error'):\n",
    "            self.experience_replay.update_td(\n",
    "                self.td_error,\n",
    "                self.sample_indexes\n",
    "            )\n",
    "        elif self.verbose:\n",
    "            warn(\"\"\"The learner does not have a `td_error` field. Produced logs\n",
    "                    will not be useful unless `td_error` exists.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5b0add7d-8e48-4332-ba00-42a8c0828d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not do one pass in your dataloader, there is something wrong in it\n"
     ]
    }
   ],
   "source": [
    "from fastrl.data.gym import *\n",
    "source=Source(cbs=[GymLoop(env_name='CartPole-v1',steps_delta=1,steps_count=1,seed=0,mode='rgb_array'),\n",
    "                   ResReduce(reduce_by=4),\n",
    "                   FirstLast])\n",
    "learn=fake_gym_learner(source,n=30,bs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "56bdba18-35f2-4aa4-ade3-b9c7447d3b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay=ExperienceReplayCallback(bs=5,max_sz=20,warmup_sz=11,verbose=True)\n",
    "experience_replay.learn=learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "67054db9-eed9-4bfb-b96e-e01645b2199d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory is not full yet!\n",
      "memory sampled\n",
      "memory sampled\n"
     ]
    }
   ],
   "source": [
    "experience_replay.before_fit()\n",
    "for b in learn.dls[0]:\n",
    "    learn.xb=b\n",
    "    \n",
    "    try:\n",
    "        experience_replay.after_pred()\n",
    "        print('memory sampled')\n",
    "    except CancelBatchException:\n",
    "        print('memory is not full yet!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ebd82b31-c2c2-4688-af52-0f1ca929db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay.experience_replay.update_td(TensorBatch(torch.rand((5,1))),torch.arange(5,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caead713-c002-4865-86b3-b18ea60f1c64",
   "metadata": {},
   "source": [
    "## Memory Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "69cd6567-67a2-4193-92b9-62c9a4994bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def snapshot_memory(writer:SummaryWriter,epoch:int,experience_replay,prefix='experience_replay'):\n",
    "    if 'image' not in experience_replay.memory: \n",
    "        warn('image is missing from the experience replay. This is needed to produce understandble logs.')\n",
    "        return\n",
    "        \n",
    "    for i,frame in enumerate(experience_replay.memory['image'].permute(0,3, 1, 2)):\n",
    "        writer.add_video(f'{prefix}/{epoch}/video',frame.unsqueeze(0).unsqueeze(0),global_step=i)\n",
    "        \n",
    "    for i,v in enumerate(experience_replay.memory['td_error'].numpy().reshape(-1)):\n",
    "        writer.add_scalar(f'{prefix}/{epoch}/td_error',v,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4e6c111a-c9fd-4509-bc50-6369ef7dd255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceReplayTensorboard(Callback):\n",
    "    def __init__(self,writer=None,every_epoch=1):\n",
    "        store_attr()\n",
    "        self.writer=ifnone(writer,SummaryWriter())\n",
    "    \n",
    "    def before_fit(self):\n",
    "        if not hasattr(self.learn,'experience_replay'):\n",
    "            warn('Learner does not have `experience_replay`, nothing will be logged.')\n",
    "            \n",
    "    def after_epoch(self):\n",
    "        if self.epoch%self.every_epoch==0:\n",
    "            snapshot_memory(self.writer,epoch=self.epoch,\n",
    "                            experience_replay=self.learn.experience_replay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "eb1237ad-20bb-47cd-9310-b494a1d6a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# hide\n",
    "rm -r runs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9ce42251-1b26-4afb-aca5-48aa1b187208",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay_logger=ExperienceReplayTensorboard()\n",
    "experience_replay_logger.learn=learn\n",
    "learn.epoch=0\n",
    "experience_replay_logger.after_epoch()\n",
    "\n",
    "TENSOR_BOARD_STARTED=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a2a400d1-d241-490d-90a4-b75ecaeed879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def run_tensorboard(port=6006, # The port to run tensorboard on/connect on\n",
    "                    start_tag=None, # Starting regex e.g.: experience_replay/1\n",
    "                    samples_per_plugin=None, # Sampling freq such as  images=0 (keep all)\n",
    "                    extra_args=None, # Any additional arguments in the `--arg value` format\n",
    "                    rm_glob=None # Remove old logs via a parttern e.g.: '*' will remove all files: runs/* \n",
    "                   ):\n",
    "    if rm_glob is not None:\n",
    "        for p in Path('runs').glob(rm_glob): p.delete()\n",
    "    import socket\n",
    "    from tensorboard import notebook\n",
    "    a_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    if not a_socket.connect_ex(('127.0.0.1',6006)):\n",
    "        \n",
    "        notebook.display(port=port, height=1000)\n",
    "    else:\n",
    "        cmd=f'--logdir runs --port {port} --host=0.0.0.0'\n",
    "        if samples_per_plugin is not None: cmd+=f' --samples_per_plugin {samples_per_plugin}'\n",
    "        if start_tag is not None:          cmd+=f' --tag {start_tag}'\n",
    "        if extra_args is not None:         cmd+=f' {extra_args}'\n",
    "        notebook.start(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "344b1914-3d9a-4c02-92f6-712b25d51ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "SHOW_TENSOR_BOARD=False\n",
    "if not os.environ.get(\"IN_TEST\", None) and SHOW_TENSOR_BOARD:\n",
    "    run_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n",
      "Converted 00_core.ipynb.\n",
      "Converted 00_nbdev_extension.ipynb.\n",
      "Converted 03_callback.core.ipynb.\n",
      "Converted 04_agent.ipynb.\n",
      "Converted 05_data.test_async.ipynb.\n",
      "Converted 05a_data.block.ipynb.\n",
      "Converted 05b_data.gym.ipynb.\n",
      "Converted 06a_memory.experience_replay.ipynb.\n",
      "Converted 10a_agents.dqn.core.ipynb.\n",
      "Converted 10b_agents.dqn.targets.ipynb.\n",
      "Converted 10c_agents.dqn.double.ipynb.\n",
      "Converted 10d_agents.dqn.dueling.ipynb.\n",
      "Converted 10e_agents.dqn.categorical.ipynb.\n",
      "Converted 11a_agents.policy_gradient.ppo.ipynb.\n",
      "Converted 20_test_utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted nbdev_template.ipynb.\n",
      "converting: /home/fastrl_user/fastrl/nbs/06a_memory.experience_replay.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbverbose.cli import *\n",
    "    make_readme()\n",
    "    notebook2script()\n",
    "    notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4cb69-2a11-454f-be09-ff76b5251e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
