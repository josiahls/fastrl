{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp memory.experience_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from typing import *\n",
    "from warnings import warn\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "import torchdata.datapipes as dp\n",
    "# Local modules\n",
    "from fastrl.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Experience Replay\n",
    "> Experience Replay is likely the simplest form of memory used by RL agents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "29951651-b9ff-4c02-859f-2528338ae8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceReplay(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    def __init__(self,source_datapipe,learn=None,bs=1,max_sz=100,\n",
    "                 return_idxs=False):\n",
    "        self.memory = np.array([None]*max_sz)\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learn = learn\n",
    "        if learn is not None:\n",
    "            self.learn.experience_replay = self\n",
    "        self.bs = bs\n",
    "        self.max_sz = max_sz\n",
    "        self._sz_tracker = 0\n",
    "        self._idx_tracker = 0\n",
    "        self._cycle_tracker = 0\n",
    "        self.return_idxs = return_idxs\n",
    "    \n",
    "    def sample(self,bs=None):  \n",
    "        idxs = np.random.choice(range(self._sz_tracker),size=(ifnone(bs,self.bs),),replace=False)\n",
    "        if self.return_idxs: return self.memory[idxs],idxs\n",
    "        return self.memory[idxs]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str({k:v if k!='memory' else f'{len(self)} elements' for k,v in self.__dict__.items()})\n",
    "\n",
    "    def __len__(self): return self._sz_tracker\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i,b in enumerate(self.source_datapipe):\n",
    "            if self.debug: print('Experience Replay Adding: ',b)\n",
    "            \n",
    "            if not issubclass(b.__class__,(StepType,list,tuple)):\n",
    "                raise Exception(f'Expected typing.NamedTuple,list,tuple object got {type(step)}\\n{step}')\n",
    "            \n",
    "            if issubclass(b.__class__,StepType):   self.add(b)\n",
    "            elif issubclass(b.__class__,(list,tuple)): \n",
    "                for step in b: self.add(step)\n",
    "            else:\n",
    "                raise Exception(f'This should not have occured: {self.__dict__}')\n",
    "        \n",
    "            if self._sz_tracker<self.bs: continue\n",
    "            yield self.sample()\n",
    "\n",
    "    def add(self,step:StepType): \n",
    "        if self._sz_tracker==0: \n",
    "            self.memory[self._idx_tracker] = step\n",
    "            self._sz_tracker += 1\n",
    "            self._idx_tracker = 1\n",
    "        elif 0<self._sz_tracker<self.max_sz:\n",
    "            self.memory[self._idx_tracker] = step\n",
    "            self._sz_tracker += 1\n",
    "            self._idx_tracker += 1\n",
    "        elif self._sz_tracker>=self.max_sz:\n",
    "            if self._idx_tracker>=self.max_sz:\n",
    "                self._idx_tracker = 0\n",
    "                self._cycle_tracker += 1\n",
    "            self.memory[self._idx_tracker] = step\n",
    "            self._idx_tracker += 1\n",
    "        else:\n",
    "            raise Exception(f'This should not have occured: {self.__dict__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc88238c-b34e-40b2-8384-40e58e7b9dca",
   "metadata": {},
   "source": [
    "lets generate some batches to test with..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9bcd3740-c7e2-4c43-9061-87378ba3eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.fastai.data.pipes.core import *\n",
    "from fastrl.fastai.data.load import *\n",
    "from fastrl.fastai.data.block import *\n",
    "from fastrl.envs.gym import *\n",
    "\n",
    "def baseline_test(envs,total_steps,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformLoop(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle()\n",
    "    pipe = GymStepper(pipe,seed=seed)\n",
    "\n",
    "    steps = [step for _,step in zip(*(range(total_steps),pipe))]\n",
    "    return steps, pipe\n",
    "\n",
    "@delegates(ExperienceReplay)\n",
    "def exp_replay_test(envs,total_steps,seed=0,**kwargs):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformLoop(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle()\n",
    "    pipe = GymStepper(pipe,seed=seed)\n",
    "    pipe = ExperienceReplay(pipe,**kwargs)\n",
    "\n",
    "    steps = [step for _,step in zip(*(range(total_steps),pipe))]\n",
    "    return steps, pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "92ca156a-d774-413e-a0bb-505f60d4729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, experience_replay = exp_replay_test(['CartPole-v1'],0,bs=1)\n",
    "test_eq(len(experience_replay),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a714d-66cd-4660-b65f-578b87fdfba5",
   "metadata": {},
   "source": [
    "**what if we fill up ER?**\n",
    "Lets add the batches, this process will happen inplace..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "81db8e2b-3630-4445-90b7-457fbcc767cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, experience_replay = exp_replay_test(['CartPole-v1'],10,max_sz=20)\n",
    "test_eq(experience_replay._sz_tracker,10)\n",
    "test_eq(experience_replay._idx_tracker,10)\n",
    "test_eq(experience_replay._cycle_tracker,0)\n",
    "test_len(experience_replay,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb4ee5-37fc-407a-bd8f-915556f6bcfc",
   "metadata": {},
   "source": [
    "If we run 10 more times, the total size should be 20..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "659b6f62-972e-433c-8b59-fe05d939d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [step for step,_ in zip(*(range(10),experience_replay))]\n",
    "test_eq(experience_replay._sz_tracker,20)\n",
    "test_eq(experience_replay._idx_tracker,20)\n",
    "test_eq(experience_replay._cycle_tracker,0)\n",
    "test_len(experience_replay,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be82af3-ebe9-4a4e-a03c-4f102cec391f",
   "metadata": {},
   "source": [
    "`experience_replay` memory should contain identical steps to if we just run without it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1b66bde7-0c76-4f2b-8170-77b6d9bfe970",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, pipe = baseline_test(['CartPole-v1'],20,)\n",
    "\n",
    "for baseline_step,memory_step in zip(steps,experience_replay.memory):\n",
    "    test_eq(baseline_step.state,memory_step.state)\n",
    "    test_eq(baseline_step.next_state,memory_step.next_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1e995a-aa29-4a20-b59e-cb7ecff48ca2",
   "metadata": {},
   "source": [
    "Since the `max_sz` is 20, and so far we have run a total of 20 steps, if we run another 10 steps,\n",
    "the `_cycle_tracker` should be 1 (since this is a new cycle),`_idx_tracker` should be 10 since it should \n",
    "have reset and stopped half way in the memory. The `_sz_tracker` should still be 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "faab02dc-a33d-45fa-bfb9-291bca124844",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [step for step,_ in zip(*(range(10),experience_replay))]\n",
    "test_eq(experience_replay._sz_tracker,20)\n",
    "test_eq(experience_replay._idx_tracker,10)\n",
    "test_eq(experience_replay._cycle_tracker,1)\n",
    "test_len(experience_replay,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8f45a8-cc15-4c58-a538-8ad562e880aa",
   "metadata": {},
   "source": [
    "...and if we run the baseline, the last 10 steps in the baseline, should match the first 10 steps in memory\n",
    "since it is in the middle of re-writing the memory due to being at max size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a203118c-8986-4f96-a9ae-d35e43b1855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, pipe = baseline_test(['CartPole-v1'],30)\n",
    "\n",
    "for baseline_step,memory_step in zip(steps[20:],experience_replay.memory[:10]):\n",
    "    test_eq(baseline_step.state,memory_step.state)\n",
    "    test_eq(baseline_step.next_state,memory_step.next_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132c462a-43ed-45e0-ad47-72eb59dc919f",
   "metadata": {},
   "source": [
    "Finally we want to finish writing over the memory in its entirety. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "870c422c-516f-43f3-973d-79966acca9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [step for step,_ in zip(*(range(10),experience_replay))]\n",
    "test_eq(experience_replay._sz_tracker,20)\n",
    "test_eq(experience_replay._idx_tracker,20)\n",
    "test_eq(experience_replay._cycle_tracker,1)\n",
    "test_len(experience_replay,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ddf0a544-3393-498c-8838-e98d9c843f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, pipe = baseline_test(['CartPole-v1'],40)\n",
    "\n",
    "for baseline_step,memory_step in zip(steps[20:],experience_replay.memory):\n",
    "    test_eq(baseline_step.state,memory_step.state)\n",
    "    test_eq(baseline_step.next_state,memory_step.next_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d227295b-11b5-4710-ac44-6a2d203b420e",
   "metadata": {},
   "source": [
    "Let's verify that the steps are what we expect..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3ae0a-fb90-41f9-997b-b538d6ff0491",
   "metadata": {},
   "source": [
    "**What if we sample the experience?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "296db44f-bdda-4876-bb41-ce6148c3f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, experience_replay = exp_replay_test(['CartPole-v1'],1000,bs=300,max_sz=1000)\n",
    "memory = None\n",
    "for i,sample in enumerate(experience_replay):\n",
    "    for s in sample:\n",
    "        if memory is not None: test_ne(s,memory)\n",
    "        memory = copy(s)\n",
    "    if i>100:break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370e444-1088-4ea2-980d-d490f46e0bb9",
   "metadata": {},
   "source": [
    "We should be able to sample enough times that we have sampled **everything**. \n",
    "So we test this by sampling, check if that sample has been seen before, and then record that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "40561103-b40b-483f-ba17-c0d55af9b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, experience_replay = exp_replay_test(['CartPole-v1'],1000,bs=1,max_sz=30,return_idxs=True)\n",
    "memory_hits = [False]*30\n",
    "for i in range(150):\n",
    "    res,idxs = experience_replay.sample()\n",
    "    for idx in idxs: memory_hits[idx] = True\n",
    "test_eq(all(memory_hits),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "96648bad-32f5-41f9-8ea1-9df18cc54738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# ## Memory Exploration\n",
    "\n",
    "# # export\n",
    "# def snapshot_memory(writer:SummaryWriter,\n",
    "#                     main_writer:SummaryWriter,\n",
    "#                     img_idx:int,\n",
    "#                     epoch:Union[int,str],\n",
    "#                     experience_replay,\n",
    "#                     prefix='experience_replay'):\n",
    "#     for i,v in enumerate(experience_replay.memory['td_error'].numpy().reshape(-1)):\n",
    "#         writer.add_scalar(f'{prefix}/{epoch}/td_error',v,i)\n",
    "    \n",
    "#     if experience_replay.memory['expected_reward'].shape[-1]==1:\n",
    "#         for i,v in enumerate(experience_replay.memory['expected_reward'].numpy().reshape(-1)):\n",
    "#             writer.add_scalar(f'{prefix}/{epoch}/expected_reward',v,i)\n",
    "#     else:\n",
    "#         exp=experience_replay.memory['expected_reward'].numpy()\n",
    "#         for ii in range(0,experience_replay.memory['expected_reward'].shape[-1]):\n",
    "#             for i,v in enumerate(exp[:,ii]):\n",
    "#                 writer.add_scalar(f'{prefix}/{epoch}/expected_reward/action_dim_{ii}',v,i)\n",
    "    \n",
    "#     action_np=experience_replay.memory['action'].numpy()\n",
    "#     if action_np.shape[-1]==1:\n",
    "#         for i,v in enumerate(experience_replay.memory['action'].numpy().reshape(-1)):\n",
    "#             writer.add_scalar(f'{prefix}/{epoch}/action',v,i)\n",
    "#     else:\n",
    "#         for dim in range(action_np.shape[-1]):\n",
    "#             for i,v in enumerate(action_np[:,dim]):\n",
    "#                 writer.add_scalar(f'{prefix}/{epoch}/action_complex/{dim}',v,i)\n",
    "\n",
    "#     retrospective_action_np=experience_replay.memory['retrospective_action'].numpy()\n",
    "#     if retrospective_action_np.shape[-1]==1:\n",
    "#         for i,v in enumerate(experience_replay.memory['retrospective_action'].numpy().reshape(-1)):\n",
    "#             writer.add_scalar(f'{prefix}/{epoch}/retrospective_action',v,i)\n",
    "#     else:\n",
    "#         for dim in range(retrospective_action_np.shape[-1]):\n",
    "#             for i,v in enumerate(retrospective_action_np[:,dim]):\n",
    "#                 writer.add_scalar(f'{prefix}/{epoch}/retrospective_action_complex/{dim}',v,i)                \n",
    "\n",
    "#     if 'image' not in experience_replay.memory: \n",
    "#         warn('image is missing from the experience replay. Image section of the replay will not be logged.')\n",
    "#         return\n",
    "        \n",
    "#     i=0\n",
    "#     if img_idx<len(experience_replay):\n",
    "#         for i,frame in enumerate(experience_replay.memory[img_idx:]['image'].permute(0,3, 1, 2)):\n",
    "#             writer.add_video(f'{prefix}/{epoch}/video',frame.unsqueeze(0).unsqueeze(0),global_step=i+img_idx)\n",
    "#     else:\n",
    "#         warn(f'img_idx {img_idx} is more than the memory size {experience_replay}')\n",
    "                   \n",
    "#     return i+img_idx+1\n",
    "\n",
    "# # export\n",
    "# class ExperienceReplayTensorboard(Callback):\n",
    "#     def __init__(self,\n",
    "#                  writer:Optional[SummaryWriter]=None, # You can psas in an existing writer instead\n",
    "#                  comment='',                          # Comment to diff between training sessions\n",
    "#                  every_epoch=1,                       # How often/every-so-many epochs to write to tensorboard\n",
    "#                  overlay_epochs:bool=False            # Extremely useful if you want to compare epochs. While create separate log dirs to overlay\n",
    "#                 ):\n",
    "#         store_attr()\n",
    "#         self._comment=comment\n",
    "#         self.log_dir=None\n",
    "#         self.main_writer=None\n",
    "#         self.img_idx=0\n",
    "#         self.init_writer()\n",
    "        \n",
    "#     def init_writer(self,epoch=1):\n",
    "#         if self.writer is None or self.writer.file_writer is None:\n",
    "#             if self.log_dir is not None:\n",
    "#                 idx=self.log_dir.find(self._comment)\n",
    "#                 self.log_dir=self.log_dir[:self.log_dir.find(self._comment) if idx!=0 else None]\n",
    "                \n",
    "#                 self._comment=self.comment+f'_epoch_{epoch}' if self.overlay_epochs else self.comment \n",
    "#                 self.log_dir+=self._comment\n",
    "\n",
    "#             self.writer=SummaryWriter(comment=self._comment,log_dir=self.log_dir)\n",
    "#             if self.log_dir is None: \n",
    "#                 self.log_dir=self.writer.log_dir\n",
    "#         if self.main_writer is None:\n",
    "#             self.main_writer=SummaryWriter(comment=self._comment,log_dir=self.log_dir)      \n",
    "\n",
    "#     def before_fit(self):\n",
    "#         if not hasattr(self.learn,'experience_replay'):\n",
    "#             warn('Learner does not have `experience_replay`, nothing will be logged.')\n",
    "            \n",
    "#     def after_epoch(self):\n",
    "#         if self.epoch%self.every_epoch==0:\n",
    "#             if self.overlay_epochs:\n",
    "#                 self.writer.close()\n",
    "#                 self.init_writer(self.epoch)\n",
    "            \n",
    "#             img_idx=snapshot_memory(self.writer,\n",
    "#                             self.main_writer,\n",
    "#                             img_idx=self.img_idx,\n",
    "#                             epoch=self.epoch if not self.overlay_epochs else 'overlay',\n",
    "#                             experience_replay=self.learn.experience_replay)\n",
    "#             if img_idx is not None: self.img_idx=img_idx\n",
    "\n",
    "# %%bash \n",
    "# # hide\n",
    "# rm -r runs/*\n",
    "\n",
    "# experience_replay_logger=ExperienceReplayTensorboard(overlay_epochs=True)\n",
    "# experience_replay_logger.learn=learn\n",
    "# learn.epoch=1\n",
    "# experience_replay_logger.after_epoch()\n",
    "# learn.epoch=2\n",
    "# experience_replay_logger.after_epoch()\n",
    "# learn.epoch=3\n",
    "# experience_replay_logger.after_epoch()\n",
    "\n",
    "# TENSOR_BOARD_STARTED=False\n",
    "\n",
    "# # hide\n",
    "# SHOW_TENSOR_BOARD=True\n",
    "# if not os.environ.get(\"IN_TEST\", None) and SHOW_TENSOR_BOARD:\n",
    "#     run_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330bd054-e0ef-4918-aa57-1eff17a79eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
