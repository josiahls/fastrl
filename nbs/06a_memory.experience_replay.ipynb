{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbverbose.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp memory.experience_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1616554793803/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from typing import *\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.callback.all import *\n",
    "# Local modules\n",
    "from fastrl.core import *\n",
    "from fastrl.callback.core import *\n",
    "from fastrl.data.block import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Experience Replay\n",
    "> Experience Replay is likely the simplest form of memory used by RL agents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29951651-b9ff-4c02-859f-2528338ae8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceReplayException(Exception): pass\n",
    "\n",
    "class ExperienceReplay(object):\n",
    "    def __init__(self,\n",
    "                 bs=16,         # Number of entries to query from memory\n",
    "                 max_sz=200,    # Maximum number of entries to hold. Will start overwriting after.\n",
    "                 warmup_sz=100  # Minimum number of entries needed to continue with a batch\n",
    "                 ):\n",
    "        \"Stores `BD`s in a rotating list `self.memory`\"\n",
    "        store_attr()\n",
    "        test_lt(warmup_sz-1,max_sz)\n",
    "        self.memory=None\n",
    "        self.pointer=0\n",
    "    \n",
    "    def __add__(self,other:BD):\n",
    "        \"In-place add `other` to memory, overwriting if len(self.memory)>self.max_sz\"\n",
    "        if isinstance(other,tuple) and len(other)==1: other=other[0]\n",
    "        elif isinstance(other,tuple):                 raise ExperienceReplayException('records need to be `BD`s or 1 element tuples')\n",
    "        if isinstance(other,dict): other=BD(other)\n",
    "        \n",
    "        if self.memory is None: \n",
    "            if other.bs()>self.max_sz: \n",
    "                self.memory=other[:self.max_sz]\n",
    "                self.pointer=0           # Keep the pointer 0 since we have basically replaced the memory\n",
    "                self+other[self.max_sz:] # Recursively add the rest of the batch\n",
    "            else:\n",
    "                self.memory=other\n",
    "                self.pointer=self.memory.bs() # remember that pointer is not an index but number of elements\n",
    "        else:\n",
    "            n_over=(other.bs()+self.pointer)-self.max_sz\n",
    "            if n_over>0: # e.g.: max_sz 200, pointer 195, other is 5.\n",
    "                self.memory=self.memory[:self.pointer]+other[:-n_over]\n",
    "                self.pointer=0\n",
    "                self+other[other.bs()-n_over:]\n",
    "            else:\n",
    "                # If the number of elements is not over\n",
    "                next_pointer=self.pointer+other.bs()\n",
    "                self.memory=self.memory[:self.pointer]+other+self.memory[next_pointer:]\n",
    "                self.pointer=next_pointer\n",
    "        return self\n",
    "    \n",
    "    def __radd__(self,other:BD): raise ExperienceReplayException('You can only do experience_reply+[some other element]')\n",
    "    \n",
    "    def __len__(self): return self.memory.bs() if self.memory is not None else 0\n",
    "        \n",
    "    def sample(self)->BD:\n",
    "        \"Returns a sample of size `self.bs`\"\n",
    "        with torch.no_grad():\n",
    "            idxs=np.random.randint(0,self.memory.bs(),self.bs).tolist()\n",
    "            samples=self.memory[idxs].mapv(to_device)\n",
    "        \n",
    "        if self.memory.bs()<self.warmup_sz: raise CancelBatchException\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc88238c-b34e-40b2-8384-40e58e7b9dca",
   "metadata": {},
   "source": [
    "lets generate some batches to test with..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec43770-af92-4f11-89ce-301f33c9bae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not do one pass in your dataloader, there is something wrong in it\n"
     ]
    }
   ],
   "source": [
    "from fastrl.data.gym import *\n",
    "source=Source(\n",
    "    cbs=[GymLoop(env_name='CartPole-v1',steps_delta=1,steps_count=1,seed=0),FirstLast]\n",
    ")\n",
    "source=Source(cbs=[GymLoop(env_name='CartPole-v1',steps_delta=1,steps_count=1,seed=0),FirstLast])\n",
    "learn=fake_gym_learner(source,n=1000,bs=5)\n",
    "batches=[BD(b[0]) for b in learn.dls[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92ca156a-d774-413e-a0bb-505f60d4729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay=ExperienceReplay(max_sz=20,warmup_sz=19)\n",
    "test_len(experience_replay,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a714d-66cd-4660-b65f-578b87fdfba5",
   "metadata": {},
   "source": [
    "**what if we fill up ER?**\n",
    "Lets add the batches, this process will happen inplace..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81db8e2b-3630-4445-90b7-457fbcc767cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[0]\n",
    "test_eq(experience_replay.pointer,5)\n",
    "test_len(experience_replay,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb4ee5-37fc-407a-bd8f-915556f6bcfc",
   "metadata": {},
   "source": [
    "If we add again, the total size should be 10..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4b90529-0d8c-4964-abff-fe67de7ed6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[1]\n",
    "test_eq(experience_replay.pointer,10)\n",
    "test_len(experience_replay,10)\n",
    "test_eq(experience_replay.memory['step'],(batches[0]+batches[1])['step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faab02dc-a33d-45fa-bfb9-291bca124844",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[2]\n",
    "test_len(experience_replay,15)\n",
    "test_eq(experience_replay.pointer,15)\n",
    "test_eq(experience_replay.memory['step'],(batches[0]+batches[1]+batches[2])['step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "870c422c-516f-43f3-973d-79966acca9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[3]\n",
    "test_len(experience_replay,20)\n",
    "test_eq(experience_replay.pointer,20)\n",
    "test_eq(experience_replay.memory['step'],(batches[0]+batches[1]+batches[2]+batches[3])['step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d227295b-11b5-4710-ac44-6a2d203b420e",
   "metadata": {},
   "source": [
    "Let's verify that the steps are what we expect..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c6679c-94c9-4b0e-a71c-c4e4ffad99da",
   "metadata": {},
   "source": [
    "**What if ER is full and we add batches? ** We are at the maximum memory size, we expect that the next batch added should completely\n",
    "overwrite the first 5 entries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ada8f82e-7236-48c9-b249-00d0f9397c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[4]\n",
    "test_len(experience_replay,20)\n",
    "test_eq(experience_replay.pointer,5)\n",
    "test_eq(experience_replay.memory['step'],(batches[4]+batches[1]+batches[2]+batches[3])['step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb9b4f4-2c2e-4a5f-b8cc-2395ef510908",
   "metadata": {},
   "source": [
    "This overwrite should properly overwrite the rest of the entries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e02708c-0282-43b2-a42f-5f14b2f57992",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[5]+batches[6]+batches[7]\n",
    "test_eq(experience_replay.memory['step'],(batches[4]+batches[5]+batches[6]+batches[7])['step'])\n",
    "test_eq(experience_replay.pointer,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad837a0a-98f2-4cf0-8873-942421f18927",
   "metadata": {},
   "source": [
    "so we have fully overwritten the memory twice, and so far we can prove that the memory overwritting works. Let's \n",
    "see what happens when we append add numbered dictionaries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "662489e9-7ab9-4401-a2a8-ef24be6e1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay+batches[8]+batches[9]+batches[10]\n",
    "test_eq(experience_replay.pointer,15)\n",
    "test_eq(experience_replay.memory['step'],(batches[8]+batches[9]+batches[10]+batches[7])['step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6d9551-f9c7-4dc6-83dd-ae67a3c04dc9",
   "metadata": {},
   "source": [
    "**What if we need to split a batch to fit at the end and beginnging of the memory?** This is a possibly scary part where some of the dictionary needs to be split. Some needs to be allocated to the end of the memory, and\n",
    "some of it need to be allocated at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a49dfab-308d-40a4-97b7-393f58f135f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_large_batch=batches[11]+batches[12]\n",
    "experience_replay+single_large_batch;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1f47467-dd2f-4f0a-bb73-c491cf694937",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(experience_replay.pointer,5)\n",
    "test_eq(experience_replay.memory['step'],(batches[12]+batches[9]+batches[10]+batches[11])['step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3ae0a-fb90-41f9-997b-b538d6ff0491",
   "metadata": {},
   "source": [
    "**What if we sample the experience?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "296db44f-bdda-4876-bb41-ce6148c3f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_memory=(batches[12]+batches[9]+batches[10]+batches[11])\n",
    "entry_ids=[str(o) for o in torch.hstack((full_memory['step'],full_memory['episode_id']))]\n",
    "memory_hits=[False]*len(entry_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370e444-1088-4ea2-980d-d490f46e0bb9",
   "metadata": {},
   "source": [
    "We should be able to sample enough times that we have sampled **everything**. \n",
    "So we test this by sampling, check if that sample has been seen before, and then record that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40561103-b40b-483f-ba17-c0d55af9b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    res=experience_replay.sample()\n",
    "    for o in torch.hstack((res['step'],res['episode_id'])):\n",
    "        memory_hits[entry_ids.index(str(o))]=True\n",
    "test_eq(all(memory_hits),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c95b1cc6-4da6-4060-bb7b-35176883e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceReplayCallback(Callback):\n",
    "    @delegates(ExperienceReplay)\n",
    "    def __init__(self,**kwargs):\n",
    "        \"Stores `BD`s in a rotating list `self.memory`\"\n",
    "        store_attr()\n",
    "        self.experience_replay=ExperienceReplay(**kwargs)\n",
    "    \n",
    "    def after_pred(self):\n",
    "        \"Adds `learn.xb` to memory, then sets `learn.xb=experience_replay.sample()`\"\n",
    "        xb=BD(self.learn.xb[0]).mapv(to_detach)\n",
    "        self.experience_replay+xb\n",
    "        \n",
    "        self.learn.xb=self.experience_replay.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b0add7d-8e48-4332-ba00-42a8c0828d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not do one pass in your dataloader, there is something wrong in it\n"
     ]
    }
   ],
   "source": [
    "from fastrl.data.gym import *\n",
    "source=Source(cbs=[GymLoop(env_name='CartPole-v1',steps_delta=1,steps_count=1,seed=0),FirstLast])\n",
    "learn=fake_gym_learner(source,n=30,bs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56bdba18-35f2-4aa4-ade3-b9c7447d3b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_replay=ExperienceReplayCallback(bs=5,max_sz=20,warmup_sz=11)\n",
    "experience_replay.learn=learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67054db9-eed9-4bfb-b96e-e01645b2199d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory is not full yet!\n",
      "memory sampled\n",
      "memory sampled\n"
     ]
    }
   ],
   "source": [
    "for b in learn.dls[0]:\n",
    "    learn.xb=b\n",
    "    \n",
    "    try:\n",
    "        experience_replay.after_pred()\n",
    "        print('memory sampled')\n",
    "    except CancelBatchException:\n",
    "        print('memory is not full yet!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n",
      "Converted 00_core.ipynb.\n",
      "Converted 00_nbdev_extension.ipynb.\n",
      "Converted 03_callback.core.ipynb.\n",
      "Converted 04_agent.ipynb.\n",
      "Converted 05_data.test_async.ipynb.\n",
      "Converted 05a_data.block.ipynb.\n",
      "Converted 05b_data.gym.ipynb.\n",
      "Converted 06a_memory.experience_replay.ipynb.\n",
      "Converted 10a_agents.dqn.core.ipynb.\n",
      "Converted 10b_agents.dqn.targets.ipynb.\n",
      "Converted 10c_agents.dqn.double.ipynb.\n",
      "Converted 10d_agents.dqn.dueling.ipynb.\n",
      "Converted 10e_agents.dqn.categorical.ipynb.\n",
      "Converted 11a_agents.policy_gradient.ppo.ipynb.\n",
      "Converted 20_test_utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted nbdev_template.ipynb.\n",
      "converting: /home/fastrl_user/fastrl/nbs/06a_memory.experience_replay.ipynb\n",
      "converting: /home/fastrl_user/fastrl/nbs/10b_agents.dqn.targets.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbverbose.cli import *\n",
    "    make_readme()\n",
    "    notebook2script()\n",
    "    notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4cb69-2a11-454f-be09-ff76b5251e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
