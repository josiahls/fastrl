{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastrl.test_utils import initialize_notebook\n",
    "initialize_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "from torch.multiprocessing import Queue\n",
    "from typing import Tuple,NamedTuple\n",
    "# Third party libs\n",
    "from fastcore.all import add_docs\n",
    "import matplotlib.pyplot as plt\n",
    "import torchdata.datapipes as dp\n",
    "from IPython.core.display import clear_output\n",
    "import torch\n",
    "import numpy as np\n",
    "# Local modules\n",
    "from fastrl.core import Record\n",
    "from fastrl.loggers.core import LoggerBase,LogCollector,is_record\n",
    "# from fastrl.torch_core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp loggers.jupyter_visualizers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Visualizers \n",
    "> Iterable pipes for displaying environments as they run using `typing.NamedTuples` with `image` fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb488d2-41f1-4160-a938-e39003f1a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SimpleJupyterVideoPlayer(dp.iter.IterDataPipe):\n",
    "    def __init__(self, \n",
    "                 source_datapipe=None, \n",
    "                 between_frame_wait_seconds:float=0.1\n",
    "        ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.between_frame_wait_seconds = 0.1\n",
    "\n",
    "    def dequeue(self): \n",
    "        while self.buffer: yield self.buffer.pop(0)\n",
    "\n",
    "        \n",
    "    def __iter__(self) -> Tuple[NamedTuple]:\n",
    "        img = None\n",
    "        for record in self.source_datapipe:\n",
    "            # for o in self.dequeue():\n",
    "            if is_record(record):\n",
    "                if record.value is None: continue\n",
    "                if img is None: img = plt.imshow(record.value)\n",
    "                img.set_data(record.value) \n",
    "                plt.axis('off')\n",
    "                display(plt.gcf())\n",
    "                clear_output(wait=True)\n",
    "            yield record\n",
    "add_docs(\n",
    "    SimpleJupyterVideoPlayer,\n",
    "    \"\"\"Displays video from a `source_datapipe` that produces `typing.NamedTuples` that contain an `image` field.\n",
    "       This only can handle 1 env input.\"\"\",\n",
    "    dequeue=\"Grabs records from the `main_queue` and attempts to display them\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e46c41-f7f9-4168-b453-c43ec80377f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ImageCollector(dp.iter.IterDataPipe):\n",
    "    title:str='image'\n",
    "\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "\n",
    "    def convert_np(self,o):\n",
    "        if isinstance(o,torch.Tensor): return o.detach().numpy()\n",
    "        elif isinstance(o,np.ndarray): return o\n",
    "        else:                          raise ValueError(f'Expects Tensor or np.ndarray not {type(o)}')\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # for q in self.main_buffers: q.append(Record('image',None))\n",
    "        yield Record(self.title,None)\n",
    "        for steps in self.source_datapipe:\n",
    "            if isinstance(steps,dp.DataChunk):\n",
    "                for step in steps:\n",
    "                    yield Record(self.title,self.convert_np(step.image))\n",
    "            else:\n",
    "                yield Record(self.title,self.convert_np(steps.image))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.envs.gym import GymDataPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b9ca9-2027-40a1-ac97-4516d60479a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval:false\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead27188-7322-46c2-9300-59842af2386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = GymDataPipe(['CartPole-v1'],None,n=100,seed=0,include_images=True)\n",
    "pipe = ImageCollector(pipe)\n",
    "pipe = SimpleJupyterVideoPlayer(pipe)\n",
    "\n",
    "for o in pipe: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d82468-a2bf-4bfd-9ac7-e56db49b8476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
