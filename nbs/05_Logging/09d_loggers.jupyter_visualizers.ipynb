{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "from torch.multiprocessing import Queue\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torchdata.datapipes as dp\n",
    "from IPython.core.display import clear_output\n",
    "# Local modules\n",
    "from fastrl.core import *\n",
    "from fastrl.loggers.core import *\n",
    "from fastai.torch_basics import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp loggers.jupyter_visualizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Visualizers \n",
    "> Iterable pipes for displaying environments as they run using `typing.NamedTuples` with `image` fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb488d2-41f1-4160-a938-e39003f1a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SimpleJupyterVideoPlayer(LoggerBase):\n",
    "    def __init__(self, \n",
    "                 source_datapipe=None, \n",
    "                 between_frame_wait_seconds:float=0.1\n",
    "        ):\n",
    "        super().__init__(source_datapipe)\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.between_frame_wait_seconds = 0.1\n",
    "        \n",
    "    def __iter__(self) -> typing.Tuple[typing.NamedTuple]:\n",
    "        img = None\n",
    "        for record in self.source_datapipe:\n",
    "            for o in self.dequeue():\n",
    "                if o.value is None: continue\n",
    "                if img is None: img = plt.imshow(o.value)\n",
    "                img.set_data(o.value) \n",
    "                plt.axis('off')\n",
    "                display(plt.gcf())\n",
    "                clear_output(wait=True)\n",
    "            yield record\n",
    "add_docs(\n",
    "    SimpleJupyterVideoPlayer,\n",
    "    \"\"\"Displays video from a `source_datapipe` that produces `typing.NamedTuples` that contain an `image` field.\n",
    "       This only can handle 1 env input.\"\"\",\n",
    "    dequeue=\"Grabs records from the `main_queue` and attempts to display them\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b206cb2-4e6c-4bbe-81a2-2fe7de041425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4e46c41-f7f9-4168-b453-c43ec80377f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ImageCollector(LogCollector):\n",
    "    def convert_np(self,o):\n",
    "        if isinstance(o,Tensor):       return to_np(o)\n",
    "        elif isinstance(o,np.ndarray): return o\n",
    "        else:                          raise ValueError(f'Expects Tensor or np.ndarray not {type(o)}')\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for q in self.main_buffers: q.append(Record('image',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            if isinstance(steps,dp.DataChunk):\n",
    "                for step in steps:\n",
    "                    for q in self.main_buffers: \n",
    "                        q.append(Record('image',self.convert_np(step.image)))\n",
    "            else:\n",
    "                for q in self.main_buffers: q.append(Record('image',self.convert_np(steps.image)))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa66bd5-32bb-4b60-86f8-47a1474bceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.pipes.map.transforms import *\n",
    "from fastrl.envs.gym import GymTypeTransform,GymStepper\n",
    "\n",
    "def gym_pipe_base(envs,total_steps,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformer(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle(count=total_steps)\n",
    "    pipe = GymStepper(pipe,seed=seed,include_images=True)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a4b9ca9-2027-40a1-ac97-4516d60479a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead27188-7322-46c2-9300-59842af2386d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/core.py:44: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  \"The argument mode in render method is deprecated; \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "video_logger = SimpleJupyterVideoPlayer()\n",
    "\n",
    "pipe = gym_pipe_base(['CartPole-v1'],100)\n",
    "pipe = ImageCollector(pipe,[video_logger])\n",
    "\n",
    "pipe = video_logger.connect_source_datapipe(pipe)\n",
    "\n",
    "L(pipe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/astroid/node_classes.py:96: DeprecationWarning: The 'astroid.node_classes' module is deprecated and will be replaced by 'astroid.nodes' in astroid 3.0.0\n",
      "  DeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d82468-a2bf-4bfd-9ac7-e56db49b8476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
