{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fastai.learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from typing import *\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "import torchdata.datapipes as dp\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "\n",
    "# Local modules\n",
    "from fastrl.fastai.data.block import *\n",
    "from fastrl.fastai.data.pipes.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Learner\n",
    "> A revised fastai learner that uses DataPipe shimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbef7605-ff0f-470f-a45e-7973ea4819b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class XYSplit(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,learn,x_fld):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learn = learn\n",
    "        self.x_fld = x_fld\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            yield (batch[self.x_fld],batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb3a0d9-e008-4f23-8f66-fcb46561df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ModelPredict(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,learn):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learn = learn\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for xb,yb in self.source_datapipe:\n",
    "            self.learn.xb = xb\n",
    "            self.learn.yb = yb\n",
    "            self.learn.preds = self.learn.model(xb)\n",
    "            yield self.learn.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767117c0-54d6-442f-8ec6-cd596438753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LossCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,learn,y_target):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learn = learn\n",
    "        self.y_target = y_target\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            self.loss_grad = self.learn.loss_func(self.learn.preds, *self.learn.yb[self.y_target])\n",
    "            self.loss = self.loss_grad.clone()\n",
    "            yield self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b9ef1-fc90-47d5-96ed-2667111a458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "       # self._with_events(self._backward, 'backward', CancelBackwardException)\n",
    "       #  self._with_events(self._step, 'step', CancelStepException)\n",
    "       #  self.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc3f825d-8aec-4248-8ad9-a04cfa1584e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def default_train_loop(\n",
    "    dls:List[DataLoader2],\n",
    "    cbs:Optional[List[Callback]]=None,\n",
    "):\n",
    "    train_valid = L(dls).map(dp.iter.IterableWrapper).add_cbs(cbs)\n",
    "    \n",
    "    return train_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32bda196-1df6-4c02-b683-d3b62bb35326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def only_train_loop(\n",
    "    dls:List[DataLoader2],\n",
    "    cbs:Optional[List[Callback]]=None,\n",
    "):\n",
    "    train = dp.iter.IterableWrapper(dls,deepcopy=False).add_cbs(cbs)\n",
    "\n",
    "    # train = \n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73cd1116-de6f-4434-ace4-2ab38ce49a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Learner(dp.iter.IterDataPipe):\n",
    "    def __init__(self,model,dls,opt,loss_func,cbs,train_loop=None):\n",
    "        store_attr('model,dls,opt,loss_func')\n",
    "        self.cbs = L()\n",
    "        self.add_cbs(cbs)\n",
    "        self.train_loop = ifnone(train_loop,default_train_loop)\n",
    "        \n",
    "    def fit(self,epochs):\n",
    "        self.it = iter(self.dls[0])\n",
    "        train_pipe = only_train_loop(L(self.it),self.cbs) # Do not pass tuple, otherwise traverse will try to read the dl datapipes\n",
    "        for res in train_pipe:\n",
    "            print(res)\n",
    "\n",
    "    def add_cbs(self, cbs):\n",
    "        L(cbs).map(self.add_cb)\n",
    "        return self\n",
    "\n",
    "    def remove_cbs(self, cbs):\n",
    "        L(cbs).map(self.remove_cb)\n",
    "        return self\n",
    "\n",
    "    def add_cb(self, cb):\n",
    "        if isinstance(cb, type): cb = cb()\n",
    "        cb.learn = self\n",
    "        cb.init_pipes()\n",
    "        setattr(self, cb.name, cb)\n",
    "        self.cbs.append(cb)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e94004b7-2734-4d2e-b73a-2451632173e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e1c59d5-3490-4c45-b837-fd17769ebce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReinforcementLearningSimpleCallback(Callback):\n",
    "    call_on=L(dp.iter.IterableWrapper)\n",
    "    \n",
    "    def init_pipes(self):\n",
    "        self.pipes=L(\n",
    "            partial(XYSplit,learn=self.learn,x_fld='state'),\n",
    "            partial(ModelPredict,learn=self.learn),\n",
    "            partial(LossCalc,learn=self.learn,y_target='reward')\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e9430b9-5020-4cec-844e-84fc823d8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock,\n",
    "    loader_loop=simple_iter_loader_loop\n",
    ")\n",
    "ds = block.datapipes(['CartPole-v1']*4,n=10,bs=4)\n",
    "dls = block.dataloaders(['CartPole-v1']*4,n=20,n_workers=0,bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "981954a5-8593-4f91-bc88-8ff40ccabc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': TensorBatch([[ 0.0137, -0.0230, -0.0459, -0.0483],\n",
      "             [ 0.0137, -0.0230, -0.0459, -0.0483],\n",
      "             [ 0.0132, -0.2175, -0.0469,  0.2295],\n",
      "             [ 0.0137, -0.0230, -0.0459, -0.0483]]), 'next_state': TensorBatch([[ 0.0132, -0.2175, -0.0469,  0.2295],\n",
      "             [ 0.0132, -0.2175, -0.0469,  0.2295],\n",
      "             [ 0.0089, -0.4119, -0.0423,  0.5070],\n",
      "             [ 0.0132, -0.2175, -0.0469,  0.2295]]), 'done': TensorBatch([[False],\n",
      "             [False],\n",
      "             [False],\n",
      "             [False]]), 'reward': TensorBatch([[1.],\n",
      "             [1.],\n",
      "             [1.],\n",
      "             [1.]]), 'action': TensorBatch([[0],\n",
      "             [0],\n",
      "             [0],\n",
      "             [0]]), 'env_id': TensorBatch([[140030438722896],\n",
      "             [140030438616720],\n",
      "             [140030438722896],\n",
      "             [140030438616720]])}\n"
     ]
    }
   ],
   "source": [
    "for o in ds[0]:\n",
    "    print(o)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b8ba411-829a-48d0-817d-d7ddebeb910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b44c6eca-cc0c-4007-8086-69029f9de776",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model, dls, opt=AdamW(model.parameters()), loss_func=MSELoss(),train_loop=only_train_loop,\n",
    "               cbs=ReinforcementLearningSimpleCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47f79fdb-56e8-4785-990b-de77fd2e196a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBatch(0.9120, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.8932, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9198, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9282, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9267, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9327, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9373, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9454, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9558, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9631, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9745, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9935, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(1.0081, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(1.0330, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(1.0678, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(1.0391, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9057, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9020, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9198, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9277, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9287, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9327, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9400, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9488, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9558, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9669, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9809, grad_fn=<AliasBackward0>)\n",
      "TensorBatch(0.9914, grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:1121: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([1, 4, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  ret = func(*args, **kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:1121: UserWarning: Using a target size (torch.Size([3, 1])) that is different to the input size (torch.Size([1, 3, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "learn.fit(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef420c4d-6e5b-4814-a338-4058f33a4488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
