{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fastai.learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from typing import *\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "import torchdata.datapipes as dp\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "from torch.utils.data.graph import traverse\n",
    "\n",
    "# Local modules\n",
    "from fastrl.fastai.data.block import *\n",
    "from fastrl.fastai.data.pipes.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Learner\n",
    "> A revised fastai learner that uses DataPipe shimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef7605-ff0f-470f-a45e-7973ea4819b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50efeb1-5ded-417a-b6f7-56209ff98cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class XYSplit(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,learn,x_fld):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learn = learn\n",
    "        self.x_fld = x_fld\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.source_datapipe:\n",
    "            \n",
    "            for v in b.values():\n",
    "                if v.shape[0]==1 and len(v.shape)!=2: v.squeeze_(0)\n",
    "\n",
    "            yield (b[self.x_fld],b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb3a0d9-e008-4f23-8f66-fcb46561df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ModelPredict(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,learn):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learn = learn\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for xb,yb in self.source_datapipe:\n",
    "            self.learn.xb = xb\n",
    "            self.learn.yb = yb\n",
    "            self.learn.preds = self.learn.model(xb)\n",
    "            yield self.learn.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767117c0-54d6-442f-8ec6-cd596438753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LossCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,learn,y_target=None):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learn = learn\n",
    "        self.y_target = y_target\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            if self.y_target is None:\n",
    "                self.learn.loss_grad = self.learn.loss_func(self.learn.preds, *self.learn.yb)\n",
    "            else:\n",
    "                self.loss_grad = self.learn.loss_func(self.learn.preds, *self.learn.yb[self.y_target])\n",
    "            self.learn.loss = self.learn.loss_grad.clone()\n",
    "            yield self.learn.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc3f825d-8aec-4248-8ad9-a04cfa1584e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def default_train_loop(\n",
    "    dls:List[DataLoader2],\n",
    "    cbs:Optional[List[Callback]]=None,\n",
    "):\n",
    "    train_valid = L(dls).map(dp.iter.IterableWrapper).add_cbs(cbs)\n",
    "    \n",
    "    return train_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32bda196-1df6-4c02-b683-d3b62bb35326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def only_train_loop(\n",
    "    dls:List[DataLoader2],\n",
    "    cbs:Optional[List[Callback]]=None,\n",
    "):\n",
    "    train = dp.iter.IterableWrapper(dls,deepcopy=False).add_cbs(cbs)\n",
    "\n",
    "    # train = \n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73cd1116-de6f-4434-ace4-2ab38ce49a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Learner(dp.iter.IterDataPipe):\n",
    "    def __init__(self,model,dls,opt,loss_func,cbs,train_loop=None):\n",
    "        store_attr('model,dls,opt,loss_func')\n",
    "        self.cbs = L()\n",
    "        self.add_cbs(cbs)\n",
    "        self.train_loop = ifnone(train_loop,default_train_loop)\n",
    "        \n",
    "    def fit(self,epochs):\n",
    "        self.it = iter(self.dls[0])\n",
    "        train_pipe = only_train_loop(L(self.it),self.cbs) # Do not pass tuple, otherwise traverse will try to read the dl datapipes\n",
    "        for res in train_pipe:\n",
    "            print(res)\n",
    "\n",
    "    def add_cbs(self, cbs):\n",
    "        L(cbs).map(self.add_cb)\n",
    "        return self\n",
    "\n",
    "    def remove_cbs(self, cbs):\n",
    "        L(cbs).map(self.remove_cb)\n",
    "        return self\n",
    "\n",
    "    def add_cb(self, cb):\n",
    "        if isinstance(cb, type): cb = cb()\n",
    "        cb.learn = self\n",
    "        cb.init_pipes()\n",
    "        setattr(self, cb.name, cb)\n",
    "        self.cbs.append(cb)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e94004b7-2734-4d2e-b73a-2451632173e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "536e284f-302c-44de-b760-69818d13db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,learn,discount,nsteps):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learn = learn\n",
    "        self.discount = discount\n",
    "        self.nsteps = nsteps\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            \n",
    "            self.learn.done_mask = self.learn.yb['done'].reshape(-1,)\n",
    "            self.learn.next_q = self.learn.model(self.learn.yb['next_state'])\n",
    "            self.learn.next_q = self.learn.next_q.max(dim=1).values.reshape(-1,1)\n",
    "            self.learn.next_q[self.learn.done_mask] = 0 #xb[done_mask]['reward']\n",
    "            self.learn.targets = self.learn.yb['reward']+self.learn.next_q*(self.discount**self.nsteps)\n",
    "            self.learn.pred = self.learn.model(self.learn.yb['state'])\n",
    "            \n",
    "            \n",
    "            t_q=self.learn.pred.clone()\n",
    "            t_q.scatter_(1,self.learn.yb['action'],self.learn.targets)\n",
    "            # finalize the xb and yb\n",
    "            self.learn.yb=(t_q,)\n",
    "            yield batch\n",
    "            \n",
    "class ModelLearnCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,learn):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learn = learn\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learn.loss_grad.backward()\n",
    "            self.learn.opt.step()\n",
    "            self.learn.opt.zero_grad()\n",
    "            yield self.learn.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb5f8110-435e-4dfa-9283-7387b66048ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dict2TensorBatch(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,learn):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learn = learn\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            if not isinstance(batch,dict): \n",
    "                raise TypeError(f'Batch should be a dict, not {type(batch)}')\n",
    "            yield {k:tensor(v) for k,v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d568d3b5-519b-4d81-9b0a-ec35e0f6108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplay(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    def __init__(self,source_datapipe,learn,bs=1,maxsz=100):\n",
    "        self.memory = {}\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learn = learn\n",
    "        if learn is not None:\n",
    "            self.learn.experience_replay = self\n",
    "        self.bs = bs\n",
    "        self.maxsz = maxsz\n",
    "        self._sz_tracker = 0\n",
    "    \n",
    "    def sample(self,bs=None):  \n",
    "        idxs = np.random.choice(range(self._sz_tracker),size=(ifnone(bs,self.bs),),replace=False)\n",
    "        return {k:v[idxs] for k,v in self.memory.items()}\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.source_datapipe:\n",
    "\n",
    "            if self.debug: print('Experience Replay Adding: ',b)\n",
    "            for v in b.values():\n",
    "                if not isinstance(v,Tensor): continue\n",
    "                if v.shape[0]==1 and len(v.shape)!=2: v.squeeze_(0)\n",
    "            if isinstance(b,dict):   self.add(b)\n",
    "            elif isinstance(b,(list,tuple)): \n",
    "                for element in b: self.add(element)\n",
    "            yield self.sample()\n",
    "\n",
    "    def add(self,d:Dict): \n",
    "        d = {k:to_np(v) if isinstance(v,Tensor) else np.array(v) for k,v in d.items()}\n",
    "        if len(self.memory)==0: \n",
    "            self.memory = d\n",
    "            self._sz_tracker = 1\n",
    "        elif self._sz_tracker>self.maxsz:\n",
    "            for k,v in self.memory.items():\n",
    "                self.memory[k] = np.vstack((v[1:],d[k]))\n",
    "            self._sz_tracker+=1\n",
    "        else:\n",
    "            for k,v in self.memory.items():\n",
    "                self.memory[k] = np.vstack((v,d[k]))\n",
    "            self._sz_tracker+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e1c59d5-3490-4c45-b837-fd17769ebce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReinforcementLearningSimpleCallback(Callback):\n",
    "    call_on=L(dp.iter.IterableWrapper)\n",
    "    \n",
    "    def init_pipes(self):\n",
    "        self.pipes=L(\n",
    "            partial(ExperienceReplay,learn=self.learn),\n",
    "            partial(Dict2TensorBatch,learn=self.learn),\n",
    "            partial(XYSplit,learn=self.learn,x_fld='state'),\n",
    "            partial(ModelPredict,learn=self.learn),\n",
    "            partial(QCalc,learn=self.learn,discount=0.99,nsteps=3),\n",
    "            partial(LossCalc,learn=self.learn),\n",
    "            partial(ModelLearnCalc,learn=self.learn)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8064f78c-7482-4125-adc7-b93f36105a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = dp.iter.IterableWrapper([dict(test=np.array([i])) for i in range(10)])\n",
    "exp = ExperienceReplay(pipe,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e9430b9-5020-4cec-844e-84fc823d8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "model = DQN(4,2)\n",
    "# Setup the agent\n",
    "agent_base = Agent(model,[])\n",
    "agent = RawOutOfStep(agent_base,agent_base,'state')\n",
    "agent = DiscreteEpsilonRandomSelect(agent,agent_base,2,min_epsilon=0)\n",
    "agent = ArgmaxOfStep(agent,agent_base)\n",
    "agent = ToDiscrete(agent,agent_base)\n",
    "# Setup the data block \n",
    "GymTransformBlock = TransformBlock(\n",
    "    type_tfms  = GymTypeTransform,\n",
    "    item_tfms  = (GymStepTransform(agent),DictToTensor),\n",
    "    batch_tfms = DictCollate,\n",
    "    cbs = NStepCallback(nsteps=3)\n",
    ")\n",
    "# Init with supported loader loop\n",
    "block = DataBlock(\n",
    "    blocks=GymTransformBlock,\n",
    "    loader_loop=simple_iter_loader_loop\n",
    ")\n",
    "# Init the loader(s)\n",
    "dls = block.dataloaders(['CartPole-v1']*3,n=20,n_workers=0,bs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b44c6eca-cc0c-4007-8086-69029f9de776",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model, dls, opt=AdamW(model.parameters(),lr=0.01), \n",
    "                loss_func=MSELoss(),train_loop=only_train_loop,\n",
    "               cbs=ReinforcementLearningSimpleCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6764ebd8-8ada-4a0f-9bbf-91d44bf78e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Learner: {_IterDataPipeSerializationWrapper: {BatcherIterDataPipe: {BatchTransformLoop: {BatcherIterDataPipe: {Flattener: {NStepPipe: {NSkipPipe: {ItemTransformLoop: {ToDiscrete: {ArgmaxOfStep: {DiscreteEpsilonRandomSelect: {RawOutOfStep: {Agent: {}},\n",
       "             Agent: {RawOutOfStep: {}}},\n",
       "            Agent: {DiscreteEpsilonRandomSelect: {RawOutOfStep: {}}}},\n",
       "           Agent: {DiscreteEpsilonRandomSelect: {RawOutOfStep: {}}}},\n",
       "          CyclerIterDataPipe: {ShardingFilterIterDataPipe: {MapToIterConverterIterDataPipe: {InMemoryCacheHolderMapDataPipe: {TypeTransformLoop: {SequenceWrapperMapDataPipe: {}}}}}}}}}}}}}}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traverse(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "663a2a93-85b6-40cd-a6bb-f42e76371c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperienceReplay.debug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47f79fdb-56e8-4785-990b-de77fd2e196a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4057, grad_fn=<CloneBackward0>)\n",
      "tensor(0.2460, grad_fn=<CloneBackward0>)\n",
      "tensor(0.1467, grad_fn=<CloneBackward0>)\n",
      "tensor(0.0826, grad_fn=<CloneBackward0>)\n",
      "tensor(9.0700, grad_fn=<CloneBackward0>)\n",
      "tensor(6.4437, grad_fn=<CloneBackward0>)\n",
      "tensor(0.0281, grad_fn=<CloneBackward0>)\n",
      "tensor(0.6099, grad_fn=<CloneBackward0>)\n",
      "tensor(0.3778, grad_fn=<CloneBackward0>)\n",
      "tensor(0.6248, grad_fn=<CloneBackward0>)\n",
      "tensor(1.6429, grad_fn=<CloneBackward0>)\n",
      "tensor(1.4480, grad_fn=<CloneBackward0>)\n",
      "tensor(0.7320, grad_fn=<CloneBackward0>)\n",
      "tensor(0.5917, grad_fn=<CloneBackward0>)\n",
      "tensor(0.2401, grad_fn=<CloneBackward0>)\n",
      "tensor(0.8641, grad_fn=<CloneBackward0>)\n",
      "tensor(0.3782, grad_fn=<CloneBackward0>)\n",
      "tensor(0.3719, grad_fn=<CloneBackward0>)\n",
      "tensor(0.3894, grad_fn=<CloneBackward0>)\n",
      "tensor(0.3869, grad_fn=<CloneBackward0>)\n",
      "tensor(0.3677, grad_fn=<CloneBackward0>)\n",
      "tensor(0.9694, grad_fn=<CloneBackward0>)\n",
      "tensor(0.4739, grad_fn=<CloneBackward0>)\n",
      "tensor(0.2703, grad_fn=<CloneBackward0>)\n",
      "tensor(0.2282, grad_fn=<CloneBackward0>)\n",
      "tensor(0.8949, grad_fn=<CloneBackward0>)\n",
      "tensor(0.1541, grad_fn=<CloneBackward0>)\n",
      "tensor(0.8104, grad_fn=<CloneBackward0>)\n",
      "tensor(0.0763, grad_fn=<CloneBackward0>)\n",
      "tensor(0.0453, grad_fn=<CloneBackward0>)\n",
      "tensor(0.0284, grad_fn=<CloneBackward0>)\n",
      "tensor(10.8436, grad_fn=<CloneBackward0>)\n",
      "tensor(1.5730e-05, grad_fn=<CloneBackward0>)\n",
      "tensor(0.0597, grad_fn=<CloneBackward0>)\n",
      "tensor(0.0061, grad_fn=<CloneBackward0>)\n",
      "tensor(0.0016, grad_fn=<CloneBackward0>)\n",
      "tensor(2.2556, grad_fn=<CloneBackward0>)\n",
      "tensor(1.4601, grad_fn=<CloneBackward0>)\n",
      "tensor(3.0924, grad_fn=<CloneBackward0>)\n",
      "tensor(0.4279, grad_fn=<CloneBackward0>)\n",
      "tensor(0.2443, grad_fn=<CloneBackward0>)\n",
      "tensor(1.8434, grad_fn=<CloneBackward0>)\n",
      "tensor(0.1437, grad_fn=<CloneBackward0>)\n",
      "tensor(0.2301, grad_fn=<CloneBackward0>)\n",
      "tensor(0.1067, grad_fn=<CloneBackward0>)\n",
      "tensor(0.0130, grad_fn=<CloneBackward0>)\n",
      "tensor(0.8481, grad_fn=<CloneBackward0>)\n",
      "tensor(0.0117, grad_fn=<CloneBackward0>)\n",
      "tensor(4.5353, grad_fn=<CloneBackward0>)\n",
      "tensor(2.8304e-05, grad_fn=<CloneBackward0>)\n",
      "tensor(4.6469, grad_fn=<CloneBackward0>)\n",
      "tensor(0.0012, grad_fn=<CloneBackward0>)\n",
      "tensor(6.9151e-05, grad_fn=<CloneBackward0>)\n",
      "tensor(0.0002, grad_fn=<CloneBackward0>)\n",
      "tensor(0.0014, grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learn.fit(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef420c4d-6e5b-4814-a338-4058f33a4488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
