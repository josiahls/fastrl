{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp agents.dqn.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from collections import deque\n",
    "# Third party libs\n",
    "import torch\n",
    "from torch.nn import *\n",
    "from fastcore.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.callback.all import *\n",
    "# Local modules\n",
    "from fastrl.data.block import *\n",
    "from fastrl.data.gym import *\n",
    "from fastrl.agent import *\n",
    "from fastrl.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Core\n",
    "> Contains the minimum DQN API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adc270b5-35eb-4b19-8dd4-7b4572e1c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66fd7638-5e79-4e2f-9e05-72b723dafedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4089, -0.5149],\n",
       "        [-0.2000, -0.2720],\n",
       "        [-0.3605,  0.0190],\n",
       "        [-0.3379, -0.2817],\n",
       "        [-0.5743, -0.6477],\n",
       "        [-0.1879, -0.0895],\n",
       "        [-0.2231, -0.4661],\n",
       "        [-0.1841, -0.0873],\n",
       "        [-0.2543, -0.5512],\n",
       "        [-0.5217,  0.2658]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn=DQN(4,2)\n",
    "dqn(torch.randn((10,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10be0418-de9e-4935-bb46-a9d5fcb10a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ArgMaxFeed(AgentCallback):\n",
    "    def before_action(self): \n",
    "        raw_action=self.agent.model(self.experience['state'].to(default_device()))\n",
    "        self.agent.raw_action_shape=raw_action.shape\n",
    "        self.agent.action=torch.argmax(raw_action,dim=1).reshape(-1,1)\n",
    "        \n",
    "class DiscreteEpsilonRandomSelect(AgentCallback):\n",
    "    \n",
    "    def __init__(self,epsilon=0.5,idx=0,min_epsilon=0.2,max_epsilon=1,max_steps=5000):\n",
    "        store_attr()\n",
    "    \n",
    "    def before_noise(self): \n",
    "        self.mask=torch.randn(size=(self.agent.action.shape[0],))<self.epsilon\n",
    "        self.experience['randomly_selected']=self.mask.reshape(-1,1)\n",
    "        self.experience['epsilon']=torch.full(self.agent.action.shape,self.epsilon)\n",
    "        self.experience['orignal_actions']=self.agent.action.detach().clone()\n",
    "        self.agent.action[self.mask]=self.agent.action[self.mask].random_(0,self.agent.raw_action_shape[1])\n",
    "        self.agent.action=self.agent.action.detach().cpu().numpy()\n",
    "    \n",
    "        if self.agent.model.training: \n",
    "            self.idx+=1\n",
    "            self.epsilon=max(self.min_epsilon,self.max_epsilon-self.idx/self.max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "538ab88e-2315-4742-8064-2137d3daeb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1]]),\n",
       " {'state': tensor([[-0.2075, -0.2991, -0.0299,  0.8251],\n",
       "          [ 0.7072, -0.6476, -1.2632, -0.1896],\n",
       "          [ 0.1778, -1.0611,  1.0181, -0.4622],\n",
       "          [ 0.6031,  1.2278, -0.0281,  0.3100],\n",
       "          [-1.1645,  0.6733, -1.5055,  1.0855],\n",
       "          [ 0.1458,  0.0539, -2.0134, -0.2237],\n",
       "          [-1.6764,  0.2460,  1.2122, -0.7258],\n",
       "          [ 1.5572,  0.5758, -0.5163, -1.1471],\n",
       "          [-0.8150, -0.2210, -0.8654,  1.1129],\n",
       "          [ 1.1992,  1.5998,  0.0820,  0.6998]], device='cuda:0'),\n",
       "  'randomly_selected': tensor([[ True],\n",
       "          [ True],\n",
       "          [False],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [False],\n",
       "          [ True],\n",
       "          [False],\n",
       "          [False]]),\n",
       "  'epsilon': tensor([[0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000]]),\n",
       "  'orignal_actions': tensor([[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [1],\n",
       "          [0],\n",
       "          [1]], device='cuda:0')})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent=Agent(dqn,cbs=[ArgMaxFeed,DiscreteEpsilonRandomSelect(max_epsilon=0.5)]).to(default_device())\n",
    "agent.do_action(state=torch.randn((10,4)).to(default_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ef21b12-2568-4910-a1f1-0809a8706f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Action\n",
      "   - before_preprocess: []\n",
      "   - after_preprocess: []\n",
      "   - before_action  : [ArgMaxFeed]\n",
      "   - after_action   : []\n",
      "   - before_noise   : [DiscreteEpsilonRandomSelect]\n",
      "   - after_noise    : []\n",
      "End Action\n"
     ]
    }
   ],
   "source": [
    "agent.show_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0072ef1b-d81c-49d4-bbbd-74de1a5cdcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export        \n",
    "class Epsilon(Metric):\n",
    "    order=30\n",
    "    epsilon=0\n",
    "\n",
    "    @property\n",
    "    def value(self): return self.epsilon\n",
    "    def reset(self): self.epsilon=0\n",
    "    def accumulate(self,learn):\n",
    "        for cb in learn.model.cbs:\n",
    "            if type(cb)==DiscreteEpsilonRandomSelect:\n",
    "                self.epsilon=cb.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a955725f-6655-4879-b50d-49cb7ac2031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceReplay(Callback):\n",
    "    def __init__(self,*args,bs=16,max_sz=200,warmup_sz=100,**kwargs):\n",
    "        store_attr()\n",
    "        self.memory=None\n",
    "        self.pointer=0\n",
    "    \n",
    "    def after_pred(self):\n",
    "        xb=BD(self.learn.xb[0]).mapv(to_detach)\n",
    "        if self.memory is None:            self.memory=xb\n",
    "        elif self.memory.bs()<self.max_sz: self.memory+=xb\n",
    "        else:\n",
    "            self.memory=self.memory[:self.pointer]+xb+self.memory[self.pointer+xb.bs():]\n",
    "            self.pointer+=xb.bs()\n",
    "            if self.pointer>self.max_sz: self.pointer=0\n",
    "        with torch.no_grad():\n",
    "            idxs=np.random.randint(0,self.memory.bs(),self.bs).tolist()\n",
    "            self.learn.xb=(self.memory[idxs].mapv(to_device),)\n",
    "        \n",
    "        if self.memory.bs()<self.warmup_sz: raise CancelBatchException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaf6eb01-5449-4d5a-afd5-cc422bcac62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DQNTrainer(Callback):\n",
    "    \"Performs traditional training on `next_q`. Requires a callback such as `RegularNextQ`\"\n",
    "    def __init__(self,discount=0.99,n_steps=1):\n",
    "        store_attr()\n",
    "        self._xb=None  \n",
    "    \n",
    "    def after_pred(self): \n",
    "        self.learn.yb=self.xb\n",
    "        self.learn.xb=self.xb[0]\n",
    "        self._xb=({k:v.clone() for k,v in self.xb.items()},)\n",
    "        self.learn.done_mask=self.xb['done'].reshape(-1,)\n",
    "        self.learn.next_q=self.learn.model.model(self.xb['next_state']).max(dim=1).values.reshape(-1,1)\n",
    "        self.learn.next_q[self.done_mask]=0 #xb[done_mask]['reward']\n",
    "        self.learn.targets=self.xb['reward']+self.learn.next_q*(self.discount**self.n_steps)\n",
    "        self.learn.pred=self.learn.model.model(self.xb['state'])\n",
    "        t_q=self.pred.clone()\n",
    "        t_q.scatter_(1,self.xb['action'],self.targets)\n",
    "        # finalize the xb and yb\n",
    "        self.learn.yb=(t_q,)\n",
    "        \n",
    "    def before_backward(self): \n",
    "        self.learn.xb=self._xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2d91aec-d20d-4e28-83b1-5492915350fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not do one pass in your dataloader, there is something wrong in it\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "dqn=DQN(4,2)\n",
    "agent=Agent(dqn,cbs=[ArgMaxFeed,DiscreteEpsilonRandomSelect])\n",
    "source=Source(cbs=[GymLoop('CartPole-v1',agent,steps_count=3,seed=0,\n",
    "                           steps_delta=1,),FirstLast])\n",
    "\n",
    "dls=SourceDataBlock().dataloaders([source],n=1000,bs=1,num_workers=0)\n",
    "\n",
    "exp_replay=ExperienceReplay(bs=32,max_sz=100000,warmup_sz=32)\n",
    "\n",
    "learn=Learner(dls,agent,loss_func=MSELoss(),\n",
    "              cbs=[exp_replay,DQNTrainer],\n",
    "              metrics=[Reward,Epsilon,NEpisodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02127b39-3a0a-444a-a148-eaee6087de02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_reward</th>\n",
       "      <th>train_epsilon</th>\n",
       "      <th>train_n_episodes</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_reward</th>\n",
       "      <th>valid_epsilon</th>\n",
       "      <th>valid_n_episodes</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.866910</td>\n",
       "      <td>23.580000</td>\n",
       "      <td>0.599600</td>\n",
       "      <td>1215</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.564910</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2579</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.282163</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4030</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.147618</td>\n",
       "      <td>22.590000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5456</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.097573</td>\n",
       "      <td>21.170000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6938</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.032408</td>\n",
       "      <td>21.360000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8390</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.970809</td>\n",
       "      <td>22.270000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>9818</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.936549</td>\n",
       "      <td>23.460000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>11169</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.875266</td>\n",
       "      <td>22.490000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>12496</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.805818</td>\n",
       "      <td>25.710000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>13824</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.619585</td>\n",
       "      <td>25.090000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>15146</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.547933</td>\n",
       "      <td>23.990000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>16407</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.431727</td>\n",
       "      <td>25.070000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>17665</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.360617</td>\n",
       "      <td>23.520000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>18949</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.307233</td>\n",
       "      <td>27.870000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>20214</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.279744</td>\n",
       "      <td>25.110000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>21420</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.225894</td>\n",
       "      <td>27.610000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>22579</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.216485</td>\n",
       "      <td>27.230000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>23777</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.242735</td>\n",
       "      <td>26.180000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>24900</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.231283</td>\n",
       "      <td>27.230000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>26001</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.215271</td>\n",
       "      <td>28.390000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>27136</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.239262</td>\n",
       "      <td>29.180000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>28296</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.267721</td>\n",
       "      <td>28.180000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>29336</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.296692</td>\n",
       "      <td>29.050000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>30443</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.270544</td>\n",
       "      <td>31.110000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>31507</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.243794</td>\n",
       "      <td>28.560000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>32586</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.289188</td>\n",
       "      <td>28.670000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>33644</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.335407</td>\n",
       "      <td>28.160000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>34648</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.282880</td>\n",
       "      <td>31.390000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>35663</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.342316</td>\n",
       "      <td>30.350000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>36656</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.390511</td>\n",
       "      <td>31.340000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>37613</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.438693</td>\n",
       "      <td>32.690000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>38619</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.436564</td>\n",
       "      <td>31.210000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>39568</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.460253</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>40482</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.392400</td>\n",
       "      <td>33.910000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>41400</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.489936</td>\n",
       "      <td>36.980000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>42309</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.468581</td>\n",
       "      <td>37.510000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>43227</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>2.476106</td>\n",
       "      <td>29.810000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>44135</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2.510119</td>\n",
       "      <td>36.260000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>45038</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.505876</td>\n",
       "      <td>35.310000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>45893</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.540691</td>\n",
       "      <td>35.220000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>46778</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>2.535693</td>\n",
       "      <td>37.130000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>47630</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.556384</td>\n",
       "      <td>35.950000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>48490</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2.508524</td>\n",
       "      <td>37.620000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>49318</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.569147</td>\n",
       "      <td>34.360000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>50136</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.621363</td>\n",
       "      <td>37.390000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>50938</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2.575444</td>\n",
       "      <td>36.970000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>51807</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2.554861</td>\n",
       "      <td>39.570000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>52611</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.553591</td>\n",
       "      <td>36.710000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>53387</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>2.588190</td>\n",
       "      <td>33.910000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>54215</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(50,lr=0.0001,wd=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c531b-ae4b-459c-9ed4-94713d765254",
   "metadata": {},
   "source": [
    "> Note: This should work without a exp replay although will perform poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n",
      "Converted 00_core.ipynb.\n",
      "Converted 00_nbdev_extension.ipynb.\n",
      "Converted 03_callback.core.ipynb.\n",
      "Converted 04_agent.ipynb.\n",
      "Converted 05_data.test_async.ipynb.\n",
      "Converted 05a_data.block.ipynb.\n",
      "Converted 05b_data.block_simple.ipynb.\n",
      "Converted 05c_data.gym.ipynb.\n",
      "Converted 10a_agents.dqn.core.ipynb.\n",
      "Converted 10b_agents.dqn.targets.ipynb.\n",
      "Converted 10c_agents.dqn.double.ipynb.\n",
      "Converted 10d_agents.dqn.dueling.ipynb.\n",
      "Converted 10e_agents.dqn.categorical.ipynb.\n",
      "Converted 11a_agents.policy_gradient.ppo.ipynb.\n",
      "Converted 20_test_utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted nbdev_template.ipynb.\n",
      "No notebooks were modified\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import make_readme\n",
    "    make_readme()\n",
    "    notebook2script()\n",
    "    notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2104d-1cd0-4e35-91c6-c49d7a85454c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
