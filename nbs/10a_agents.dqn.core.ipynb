{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp agents.dqn.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from collections import deque\n",
    "# Third party libs\n",
    "import torch\n",
    "from torch.nn import *\n",
    "from fastcore.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.callback.all import *\n",
    "# Local modules\n",
    "from fastrl.data.block import *\n",
    "from fastrl.agent import *\n",
    "from fastrl.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Core\n",
    "> Contains the minimum DQN API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc270b5-35eb-4b19-8dd4-7b4572e1c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd7638-5e79-4e2f-9e05-72b723dafedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0043,  0.0131],\n",
       "        [-0.2317,  0.2354],\n",
       "        [-0.1468,  0.1337],\n",
       "        [-0.0957,  0.1546],\n",
       "        [-0.1007,  0.1002],\n",
       "        [-0.3004,  0.1560],\n",
       "        [-0.2387,  0.1041],\n",
       "        [-0.1160,  0.3274],\n",
       "        [-0.1999,  0.2108],\n",
       "        [-0.3804,  0.0979]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn=DQN(4,2)\n",
    "dqn(torch.randn((10,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be0418-de9e-4935-bb46-a9d5fcb10a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ArgMaxFeed(AgentCallback):\n",
    "    def before_action(self): \n",
    "        raw_action=self.agent.model(self.experience['state'].to(default_device()))\n",
    "        self.agent.raw_action_shape=raw_action.shape\n",
    "        self.agent.action=torch.argmax(raw_action,dim=1).reshape(-1,1)\n",
    "        \n",
    "class DiscreteEpsilonRandomSelect(AgentCallback):\n",
    "    \n",
    "    def __init__(self,epsilon=0.5,idx=0,min_epsilon=0.2,max_epsilon=1,max_steps=5000):\n",
    "        store_attr()\n",
    "    \n",
    "    def before_noise(self): \n",
    "        self.mask=torch.randn(size=(self.agent.action.shape[0],))<self.epsilon\n",
    "        self.experience['randomly_selected']=self.mask.reshape(-1,1)\n",
    "        self.experience['epsilon']=torch.full(self.agent.action.shape,self.epsilon)\n",
    "        self.experience['orignal_actions']=self.agent.action.detach().clone()\n",
    "        self.agent.action[self.mask]=self.agent.action[self.mask].random_(0,self.agent.raw_action_shape[1])\n",
    "        self.agent.action=self.agent.action.detach().cpu().numpy()\n",
    "    \n",
    "        if self.agent.model.training: \n",
    "            self.idx+=1\n",
    "            self.epsilon=max(self.min_epsilon,self.max_epsilon-self.idx/self.max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ab88e-2315-4742-8064-2137d3daeb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1]]),\n",
       " {'state': tensor([[ 0.6655,  0.1478, -1.0057,  0.0766],\n",
       "          [ 0.5459,  1.1897, -0.0463, -0.3098],\n",
       "          [-0.6644, -1.0284,  0.6910, -0.5376],\n",
       "          [ 0.0307, -0.4979,  0.4100,  0.4971],\n",
       "          [ 2.3816,  0.3332, -0.5500, -1.5564],\n",
       "          [-1.0884,  1.2270, -0.6541,  0.1153],\n",
       "          [ 1.1137,  1.8792, -0.5866,  1.6380],\n",
       "          [-0.5739,  0.3266,  1.4212, -1.5118],\n",
       "          [-0.3505,  1.8465,  1.8109, -0.7341],\n",
       "          [-0.7187,  0.7667,  0.9460, -0.6117]], device='cuda:0'),\n",
       "  'randomly_selected': tensor([[ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [False]]),\n",
       "  'epsilon': tensor([[0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000],\n",
       "          [0.5000]]),\n",
       "  'orignal_actions': tensor([[1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1]], device='cuda:0')})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent=Agent(dqn,cbs=[ArgMaxFeed,DiscreteEpsilonRandomSelect(max_epsilon=0.5)]).to(default_device())\n",
    "agent.do_action(state=torch.randn((10,4)).to(default_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef21b12-2568-4910-a1f1-0809a8706f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Action\n",
      "   - before_preprocess: []\n",
      "   - after_preprocess: []\n",
      "   - before_action  : [ArgMaxFeed]\n",
      "   - after_action   : []\n",
      "   - before_noise   : [DiscreteEpsilonRandomSelect]\n",
      "   - after_noise    : []\n",
      "End Action\n"
     ]
    }
   ],
   "source": [
    "agent.show_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329be5f3-ec00-4632-b9f7-c847513bb723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def _do_epoch_validate(self:Learner,*args,**kwargs): return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0072ef1b-d81c-49d4-bbbd-74de1a5cdcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export        \n",
    "class Epsilon(Metric):\n",
    "    order=30\n",
    "    epsilon=0\n",
    "\n",
    "    @property\n",
    "    def value(self): return self.epsilon\n",
    "    def reset(self): self.epsilon=0\n",
    "    def accumulate(self,learn):\n",
    "        for cb in learn.model.cbs:\n",
    "            if type(cb)==DiscreteEpsilonRandomSelect:\n",
    "                self.epsilon=cb.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955725f-6655-4879-b50d-49cb7ac2031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ExperienceReplay(Callback):\n",
    "    def __init__(self,*args,bs=16,max_sz=200,warmup_sz=100,**kwargs):\n",
    "        store_attr()\n",
    "        self.memory=None\n",
    "        self.pointer=0\n",
    "    \n",
    "    def after_pred(self):\n",
    "        yb=BD(self.learn.yb[0]).mapv(to_detach)\n",
    "        if self.memory is None:            self.memory=yb\n",
    "        elif self.memory.bs()<self.max_sz: self.memory+=yb\n",
    "        else:\n",
    "            self.memory=self.memory[:self.pointer]+yb+self.memory[self.pointer+yb.bs():]\n",
    "            self.pointer+=yb.bs()\n",
    "            if self.pointer>self.max_sz: self.pointer=0\n",
    "        with torch.no_grad():\n",
    "            idxs=np.random.randint(0,self.memory.bs(),self.bs).tolist()\n",
    "            self.learn.yb=(self.memory[idxs].mapv(to_device),)\n",
    "        \n",
    "        if self.memory.bs()<self.warmup_sz: raise CancelBatchException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf6eb01-5449-4d5a-afd5-cc422bcac62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def after_create(self:Callback): \n",
    "    for cb in self.learn.cbs: \n",
    "        if hasattr(cb,'train_metrics'): cb.train_metrics=True\n",
    "\n",
    "\n",
    "class DQNTrainer(Callback):\n",
    "    \"Performs traditional training on `next_q`. Requires a callback such as `RegularNextQ`\"\n",
    "    def __init__(self,discount=0.99,n_steps=1):\n",
    "        store_attr()\n",
    "        self._yb=None  \n",
    "    \n",
    "    def after_pred(self): \n",
    "        self.learn.yb=self.yb[0]\n",
    "        self._yb=({k:v.clone() for k,v in self.yb.items()},)\n",
    "        self.learn.done_mask=self.yb['done'].reshape(-1,)\n",
    "        self.learn.next_q=self.learn.model.model(self.yb['next_state']).max(dim=1).values.reshape(-1,1)\n",
    "        self.learn.next_q[self.done_mask]=0 #yb[done_mask]['reward']\n",
    "        self.learn.targets=self.yb['reward']+self.learn.next_q*(self.discount**self.n_steps)\n",
    "        self.learn.pred=self.learn.model.model(self.yb['state'])\n",
    "        t_q=self.pred.clone()\n",
    "        t_q.scatter_(1,self.yb['action'],self.targets)\n",
    "        self.learn.yb=(t_q,)\n",
    "        \n",
    "    def before_backward(self): self.learn.yb=self._yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d91aec-d20d-4e28-83b1-5492915350fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "dqn=DQN(4,2)\n",
    "agent=Agent(dqn,cbs=[ArgMaxFeed,DiscreteEpsilonRandomSelect])\n",
    "source=Src('CartPole-v1',agent,steps_count=1,n_envs=1,seed=0,\n",
    "           steps_delta=1,cbs=[GymSrc,FirstLast])\n",
    "\n",
    "dls=SourceDataBlock(\n",
    "    blocks=SourceBlock(source)\n",
    ").dataloaders([source],n=1000,bs=1,num_workers=0)\n",
    "\n",
    "exp_replay=ExperienceReplay(bs=32,max_sz=100000,warmup_sz=32)\n",
    "\n",
    "learn=Learner(dls,agent,loss_func=MSELoss(),\n",
    "              cbs=[exp_replay,DQNTrainer],\n",
    "              metrics=[Reward,Epsilon])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c531b-ae4b-459c-9ed4-94713d765254",
   "metadata": {},
   "source": [
    "> Note: This should work without a exp replay although will perform poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864bea5-39d1-498c-ba33-cf4cc756d391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_reward</th>\n",
       "      <th>train_epsilon</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_reward</th>\n",
       "      <th>valid_epsilon</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.476229</td>\n",
       "      <td>21.670000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.461504</td>\n",
       "      <td>23.090000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.452432</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.446137</td>\n",
       "      <td>22.620000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.443432</td>\n",
       "      <td>24.740000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(5,lr=0.0001,wd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n",
      "Converted 00_core.ipynb.\n",
      "Converted 00_nbdev_extension.ipynb.\n",
      "Converted 03_callback.core.ipynb.\n",
      "Converted 04_agent.ipynb.\n",
      "Converted 05_data.block.ipynb.\n",
      "Converted 05_data.test_async.ipynb.\n",
      "Converted 10a_agents.dqn.core.ipynb.\n",
      "Converted 10b_agents.dqn.targets.ipynb.\n",
      "Converted 10c_agents.dqn.double.ipynb.\n",
      "Converted 10d_agents.dqn.dueling.ipynb.\n",
      "Converted 10e_agents.dqn.categorical.ipynb.\n",
      "Converted 20_test_utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted nbdev_template.ipynb.\n",
      "converting: /home/fastrl_user/fastrl/nbs/10a_agents.dqn.core.ipynb\n",
      "converting: /home/fastrl_user/fastrl/nbs/10e_agents.dqn.categorical.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import make_readme\n",
    "    make_readme()\n",
    "    notebook2script()\n",
    "    notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2104d-1cd0-4e35-91c6-c49d7a85454c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
