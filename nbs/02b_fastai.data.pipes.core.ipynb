{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fastai.data.pipes.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "import logging\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.graph import traverse\n",
    "from torchdata.datapipes import functional_datapipe\n",
    "# Local modules\n",
    "\n",
    "\n",
    "_logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Pipes Core\n",
    "> Callback + DataPipe support for highly flexible looping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef4947e-37cf-4b16-bf5b-9e51a612bc4e",
   "metadata": {},
   "source": [
    "> Notes: about revising this one more time...\n",
    "\n",
    "I think that Callback call_on might be too limited. We want to have a callback that call add datapipes at different points in the loop.\n",
    "\n",
    "I think we can revise it to have for example:\n",
    "    \n",
    "```python\n",
    "\n",
    "class Recorder(Callback):\n",
    "    def initialize(self,on=None,before=Epocher,after=None):\n",
    "        class initialized_recorder_pipe(dp.iter.DataPipe):\n",
    "            def __iter__(self):\n",
    "                self.mbar = master_bar(self.learn.epochs)\n",
    "                yield from self.source_datapipe\n",
    "        return initialized_recorder_pipe\n",
    "        \n",
    "    def accumulate(self,on=None,before=None,after=Predictor):\n",
    "        class accumulated_recorder_pipe(dp.iter.DataPipe):\n",
    "            def __iter__(self):\n",
    "                for o in self.source_datapipe:\n",
    "                    self.smooth_loss.append(self.learn.loss)\n",
    "                    yield o   \n",
    "        return accumulated_recorder_pipe\n",
    "        \n",
    "    def batch_update(self,on=Batcher,before=None,after=None):\n",
    "        class batch_update_recorder_pipe(dp.iter.DataPipe):\n",
    "            def __iter__(self):\n",
    "                for o in self.source_datapipe:\n",
    "                    self.pbar.update(self.learn.nbatch)\n",
    "                    yield o   \n",
    "        return batch_update_recorder_pipe\n",
    "        \n",
    "    def epoch_update(self,on=Epocher,before=None,after=None):\n",
    "        class epoch_update_recorder_pipe(dp.iter.DataPipe):\n",
    "            def __iter__(self):\n",
    "                for o in self.source_datapipe:\n",
    "                    self.mbar.update(self.learn.epoch)\n",
    "                    yield o   \n",
    "        return epoch_update_recorder_pipe\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f2c63bf-6951-4266-9c66-3ab59dd99d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Callback():\n",
    "    \"A list of data pipes that have an associated job.\"\n",
    "    call_on = L()\n",
    "    exclude_under = L()\n",
    "    do_copy = False\n",
    "    immediate_parents = L()\n",
    "    root_parent = None\n",
    "    pipes = L()\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        \"Name of the `Callback`, camel-cased and with '*Callback*' removed\"\n",
    "        return class2attr(self, 'Callback')\n",
    "    \n",
    "    def init_pipes(self):pass\n",
    "    \n",
    "    def set_parents(self,immediate_parent):\n",
    "        if immediate_parent is not None: \n",
    "            self.immediate_parents.append(immediate_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f0c24d-c8cf-4fcb-8e65-69528ec4aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "dp.map.MapDataPipe.callbacks = L()\n",
    "dp.iter.IterDataPipe.callbacks = L()\n",
    "\n",
    "@patch\n",
    "def __repr__(self:dp.map.MapDataPipe):\n",
    "    if self.repr_hook is not None:\n",
    "        return self.repr_hook(self)\n",
    "    # Instead of showing <torch. ... .MapperMapDataPipe object at 0x.....>, return the class name\n",
    "    str_rep = str(self.__class__.__qualname__)\n",
    "    if self.callbacks: return str_rep + str(self.callbacks)\n",
    "    return str_rep\n",
    "\n",
    "@patch\n",
    "def __str__(self:dp.map.MapDataPipe):\n",
    "    if self.str_hook is not None:\n",
    "        return self.str_hook(self)\n",
    "    # Instead of showing <torch. ... .MapperMapDataPipe object at 0x.....>, return the class name\n",
    "    str_rep = str(self.__class__.__qualname__)\n",
    "    if self.callbacks: return str_rep + str(self.callbacks)\n",
    "    return str_rep\n",
    "\n",
    "@patch\n",
    "def __repr__(self:dp.iter.IterDataPipe):\n",
    "    if self.repr_hook is not None:\n",
    "        return self.repr_hook(self)\n",
    "    # Instead of showing <torch. ... .MapperMapDataPipe object at 0x.....>, return the class name\n",
    "    str_rep = str(self.__class__.__qualname__)\n",
    "    if self.callbacks: return str_rep + str(self.callbacks)\n",
    "    return str_rep\n",
    "\n",
    "@patch\n",
    "def __str__(self:dp.iter.IterDataPipe):\n",
    "    if self.str_hook is not None:\n",
    "        return self.str_hook(self)\n",
    "    # Instead of showing <torch. ... .MapperMapDataPipe object at 0x.....>, return the class name\n",
    "    str_rep = str(self.__class__.__qualname__)\n",
    "    if self.callbacks: return str_rep + str(self.callbacks)\n",
    "    return str_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb06254b-02ca-4af3-9467-bb93ea55c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def filter_call_on_cbs(obj, cbs): return tuple(cb for cb in cbs if obj.__class__ in cb.call_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d840592-3d7d-4db2-ba26-15117517f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def filter_exclude_under_cbs(\n",
    "    pipe:Union[dp.map.MapDataPipe,dp.iter.IterDataPipe], \n",
    "    cbs:List[Callback]\n",
    "):\n",
    "    cbs = tuple(cb for cb in cbs if pipe.__class__  not in cb.exclude_under)\n",
    "    for v in traverse(pipe,only_datapipe=True).values(): # We dont want to traverse non-dp objects.\n",
    "        for k,_ in v.items():\n",
    "            cbs = filter_exclude_under_cbs(k,cbs)\n",
    "    return cbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670fe378-ec5a-4ead-9495-63afc83d6300",
   "metadata": {},
   "source": [
    "Below is a simple example of a custom training setup. We will be re-defining these later. Below demonstrates a neive implimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f538e5-fd74-45da-bde8-5399d7bc1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.fastai.data.pipes.map.demux import *\n",
    "from fastrl.fastai.data.pipes.map.mux import *\n",
    "\n",
    "class Iterationer(dp.iter.IterDataPipe):\n",
    "        \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __iter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe: yield 0.5\n",
    "\n",
    "class Trainer(dp.iter.IterDataPipe):\n",
    "        \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __iter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe:\n",
    "            yield element\n",
    "                \n",
    "class Validater(dp.iter.IterDataPipe):\n",
    "        \n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def __iter__(self) -> Iterator[T_co]:\n",
    "        for element in self.source_datapipe:\n",
    "            yield element\n",
    "               \n",
    "class Epocher(dp.iter.IterDataPipe):\n",
    "    def __init__(self, source_datapipes:tuple, **kwargs) -> None:\n",
    "        test_eq(type(source_datapipes), tuple)\n",
    "        self.source_datapipes = source_datapipes\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __iter__(self) -> Iterator[T_co]:\n",
    "        for element in zip(*self.source_datapipes):\n",
    "            yield element\n",
    "                \n",
    "class TrainerShower(dp.iter.IterDataPipe):\n",
    "    \"Prints `on_trainer`.\"\n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for o in self.source_datapipe:\n",
    "            print('on_trainer')\n",
    "            yield o\n",
    "            \n",
    "class IterShower(dp.iter.IterDataPipe):\n",
    "    \"Prints `on_iter`.\"\n",
    "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
    "        print('show init')\n",
    "        self.source_datapipe = source_datapipe\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for o in self.source_datapipe:\n",
    "            print('on_iter')\n",
    "            yield o\n",
    "            \n",
    "class TrainerCallback(Callback):\n",
    "    call_on=L(Trainer)\n",
    "    exclude_under=L(Validater)\n",
    "    pipes=L(TrainerShower)\n",
    "    \n",
    "class IterCallback(Callback):\n",
    "    call_on=L(Iterationer)\n",
    "    exclude_under=L(Validater)\n",
    "    pipes=L(IterShower)\n",
    "\n",
    "class Fitter(dp.iter.IterDataPipe):\n",
    "    def __init__(self,iterable,cbs):\n",
    "                \n",
    "        trainer,validater = Trainer(iterable).add_cbs(cbs),Validater(iterable).add_cbs(cbs)\n",
    "        train_b,valid_b = L(trainer,validater).map(dp.iter.Batcher,batch_size=2).map(Self.add_cbs(cbs))\n",
    "        train_it,valid_it = L(train_b,valid_b).map(Iterationer).map(Self.add_cbs(cbs))\n",
    "        epocher = dp.iter.Zipper(train_it,valid_it).add_cbs(cbs)\n",
    "        self.source_datapipe = epocher\n",
    "            \n",
    "    def __iter__(self):\n",
    "        for epoch in self.source_datapipe: \n",
    "            yield epoch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2ce7460-06a0-4cec-a29d-bc08a142c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# @patch\n",
    "def add_cbs(self,cbs):\n",
    "    pipe = self\n",
    "    if cbs is None or len(cbs)==0: return pipe\n",
    "    cbs = filter_call_on_cbs(self,cbs)\n",
    "    cbs = filter_exclude_under_cbs(self,cbs)\n",
    "    for cb in cbs:\n",
    "        for dp in cb.pipes: pipe = dp(pipe)\n",
    "    return pipe\n",
    "\n",
    "\n",
    "patch_to(dp.map.MapDataPipe)(add_cbs)\n",
    "patch_to(dp.iter.IterDataPipe)(add_cbs)\n",
    "\n",
    "# @patch\n",
    "# def add_cbs(self:dp.iter.IterDataPipe,cbs):\n",
    "#     pipe = self\n",
    "#     if cbs is None or len(cbs)==0: return pipe\n",
    "#     cbs = filter_call_on_cbs(self,cbs)\n",
    "#     cbs = filter_exclude_under_cbs(self,cbs)\n",
    "#     for cb in cbs:\n",
    "#         for dp in cb.pipes: pipe = dp(pipe)\n",
    "#     return pipe\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14bf4db-165c-455d-a76b-577c5c0c2a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show init\n",
      "{Fitter: {ZipperIterDataPipe: {IterShower: {Iterationer: {BatcherIterDataPipe: {TrainerShower: {Trainer: {}}}}},\n",
      "                               Iterationer: {BatcherIterDataPipe: {Validater: {}}}}}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "base_pipe = Fitter([1,2,3,4,5,6],[TrainerCallback,IterCallback])\n",
    "pprint(traverse(base_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "598dee65-2600-40d0-a8b9-55bd77e87786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_trainer\n",
      "on_trainer\n",
      "on_iter\n",
      "on_trainer\n",
      "on_trainer\n",
      "on_iter\n",
      "on_trainer\n",
      "on_trainer\n",
      "on_iter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.5, 0.5), (0.5, 0.5), (0.5, 0.5)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(base_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c64d0-f9c6-4432-82f8-c171840afc55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
