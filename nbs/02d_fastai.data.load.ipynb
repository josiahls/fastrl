{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fastai.data.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from typing import Callable\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from torch.utils.data.graph import traverse\n",
    "# Local modules\n",
    "from fastrl.fastai.data.pipes.core import *\n",
    "\n",
    "from fastrl.fastai.data.pipes.map.mux import *\n",
    "from fastrl.fastai.data.pipes.map.demux import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Loading\n",
    "> Objects using the `Loop` and `DataPipe` API for DataLoading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b3d07-b0d1-44f8-8156-dbd6c392d5f8",
   "metadata": {},
   "source": [
    "We will replicate [fastai mnist loading](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22653cf8-a2ac-4a84-9f22-d8979ddbb113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/fastrl_user/.fastai/data/mnist_sample/train/7'),Path('/home/fastrl_user/.fastai/data/mnist_sample/train/3')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.all import get_image_files,PILImage,ToTensor,PILBase,untar_data,URLs,get_image_files\n",
    "\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f521f2-b226-4505-98f2-fb52c093cbb6",
   "metadata": {},
   "source": [
    "First we create the dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71f3b8e-5200-4374-aa94-666c020260ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TypeTransformLoop(dp.map.MapDataPipe):\n",
    "    def __init__(self,datapipe, type_tfms):\n",
    "        self.type_tfms,self.datapipe = Pipeline(type_tfms),datapipe\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.datapipe[index]\n",
    "        return self.type_tfms(data)\n",
    "            \n",
    "    def __len__(self): return len(self.datapipe)\n",
    "    \n",
    "class ItemTransformLoop(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe, item_tfms:List[Callable]): \n",
    "        self.item_tfms,self.source_datapipe = Pipeline(item_tfms),source_datapipe\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for data in self.source_datapipe:\n",
    "            yield self.item_tfms(data)\n",
    "    \n",
    "class BatchTransformLoop(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe, batch_tfms):\n",
    "        self.batch_tfms,self.source_datapipe = Pipeline(batch_tfms),source_datapipe\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for data in self.source_datapipe:\n",
    "            yield self.batch_tfms(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9323384d-c5b8-4918-9481-53119790a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def default_loader_loop(\n",
    "    items:Iterable,\n",
    "    splitter:Callable,\n",
    "    cbs:Optional[List[Callback]]=None,\n",
    "    type_tfms:Optional[Transform]=None,\n",
    "    item_tfms:Optional[Transform]=None,\n",
    "    batch_tfms:Optional[Transform]=None,\n",
    "    bs:int=2,\n",
    "    shuffler:Optional[Union[dp.iter.IterDataPipe,dp.map.MapDataPipe]]=None\n",
    "):\n",
    "    pipe = dp.map.SequenceWrapper(items).add_cbs(cbs)\n",
    "    train_vals = DemultiplexerMapDataPipe(\n",
    "        pipe,\n",
    "        num_instances=2,\n",
    "        classifier_fn=splitter,\n",
    "        drop_none=True\n",
    "    )\n",
    "    train_vals = L(train_vals).map(Self.add_cbs(cbs))\n",
    "    train_vals = L(train_vals).map(TypeTransformLoop,type_tfms=ifnone(type_tfms,L()))\n",
    "    train_vals = L(train_vals).map(Self.add_cbs(cbs))\n",
    "    if shuffler:\n",
    "        train_vals = train_vals.map(shuffler)\n",
    "    else:\n",
    "        train_vals = train_vals.map(Self.shuffle())\n",
    "    train_vals = L(train_vals).map(Self.add_cbs(cbs))\n",
    "    train_vals = train_vals.map(dp.iter.MapToIterConverter)\n",
    "    train_vals = L(train_vals).map(Self.add_cbs(cbs))\n",
    "    train_vals = L(train_vals).map(dp.iter.ShardingFilter).map(Self.add_cbs(cbs))\n",
    "    train_vals = train_vals.map(ItemTransformLoop, item_tfms=ifnone(item_tfms,L()))\n",
    "    train_vals = L(train_vals).map(Self.add_cbs(cbs))\n",
    "    train_vals = train_vals.map(Self.batch(batch_size=bs))\n",
    "    train_vals = L(train_vals).map(Self.add_cbs(cbs))\n",
    "    \n",
    "    return train_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3bf0711-9338-4e44-9d47-4a5c8af23654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def default_loader_loop(\n",
    "    items:Iterable,\n",
    "    splitter:Callable,\n",
    "    cbs:Optional[List[Callback]]=None,\n",
    "    type_tfms:Optional[Transform]=None,\n",
    "    item_tfms:Optional[Transform]=None,\n",
    "    batch_tfms:Optional[Transform]=None,\n",
    "    bs:int=2,\n",
    "    shuffler:Optional[Union[dp.iter.IterDataPipe,dp.map.MapDataPipe]]=None\n",
    "):\n",
    "    pipe = dp.map.SequenceWrapper(items) #.add_cbs(cbs)\n",
    "    train_vals = DemultiplexerMapDataPipe(\n",
    "        pipe,\n",
    "        num_instances=2,\n",
    "        classifier_fn=splitter,\n",
    "        drop_none=True\n",
    "    )\n",
    "    # train_vals = L(train_vals).map(Self.add_cbs(cbs))\n",
    "    train_vals = L(train_vals).map(TypeTransformLoop,type_tfms=ifnone(type_tfms,L()))\n",
    "    # train_vals = L(train_vals).map(Self.add_cbs(cbs))\n",
    "    if shuffler:\n",
    "        train_vals = train_vals.map(shuffler)\n",
    "    else:\n",
    "        train_vals = train_vals.map(Self.shuffle())\n",
    "    # train_vals = L(train_vals).map(Self.add_cbs(cbs))\n",
    "    train_vals = train_vals.map(dp.iter.MapToIterConverter)\n",
    "    # train_vals = L(train_vals).map(Self.add_cbs(cbs))\n",
    "    train_vals = L(train_vals).map(dp.iter.ShardingFilter) #.map(Self.add_cbs(cbs))\n",
    "    train_vals = train_vals.map(ItemTransformLoop, item_tfms=ifnone(item_tfms,L()))\n",
    "    # train_vals = L(train_vals).map(Self.add_cbs(cbs))\n",
    "    train_vals = train_vals.map(Self.batch(batch_size=bs))\n",
    "    # train_vals = L(train_vals).map(Self.add_cbs(cbs))\n",
    "    \n",
    "    \n",
    "    for _pipe in reversed(find_pipes(dp.iter.Zipper(*train_vals),lambda o:True)): pipe = _pipe.add_cbs_before(cbs)\n",
    "    for _pipe in reversed(find_pipes(dp.iter.Zipper(*train_vals),lambda o:True)): pipe = _pipe.add_cbs_after(cbs)\n",
    "    \n",
    "    return pipe.datapipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e09afb-c215-4e50-bfc3-3faa1974b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SayHi(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe): self.source_datapipe = source_datapipe\n",
    "    def __iter__(self):\n",
    "        for o in self.source_datapipe: \n",
    "            print(f'Hi! From {self.source_datapipe} {id(self.source_datapipe)}')\n",
    "            yield o\n",
    "\n",
    "class SayBye(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe): self.source_datapipe = source_datapipe\n",
    "    def __iter__(self):\n",
    "        for o in self.source_datapipe: \n",
    "            print(f'SayBye! From {self.source_datapipe} {id(self.source_datapipe)}')\n",
    "            yield o\n",
    "        \n",
    "class TestCallback(Callback):\n",
    "    \n",
    "    def not_a_hook(self): return 'this should not be processed as a hook!'\n",
    "    \n",
    "    def add_one(self,before=dp.iter.Batcher,after=None,not_under=None) -> List[dp.iter.IterDataPipe]:\n",
    "        return L(SayHi)\n",
    "    def add_point_zero_five(self,before=None,after=ItemTransformLoop,not_under=None) -> List[dp.iter.IterDataPipe]:\n",
    "        return L(SayBye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35f2d3a1-d5aa-4f32-8f6e-1257dc3421c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GrandparentSplitter(train='train',valid='valid'):\n",
    "    def splitter(item):\n",
    "        if all(s not in item.parts for s in (train,valid)): return None\n",
    "        if item.is_dir(): return None\n",
    "        # valid=1, train=0\n",
    "        return valid in item.parts \n",
    "    return splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c0e1f2b-084b-4b9a-83ca-7f63297ef321",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = default_loader_loop(\n",
    "    L(path.rglob('*'))[::700],\n",
    "    GrandparentSplitter(),\n",
    "    type_tfms = L(PILImage.create,ToTensor),\n",
    "    cbs = L(TestCallback())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25c0a4cb-146a-44e1-9223-e530b485be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastrl.fastai.data.pipes.map.demux import _DemultiplexerMapDataPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ebca564f-a2f8-498b-b117-b5dab5cedee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{BatcherIterDataPipe: {SayHi: {SayBye: {ItemTransformLoop: {ShardingFilterIterDataPipe: {MapToIterConverterIterDataPipe: {ShufflerMapDataPipe: {TypeTransformLoop: {_DemultiplexerChildMapDataPipe: {SequenceWrapperMapDataPipe: {}}}}}}}}}}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data.graph import traverse\n",
    "traverse(base[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "87eeb08e-0edf-430d-bb44-a223e2b04dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,valid_dl = DataLoader2(base[0],num_workers=0,batch_size=2),DataLoader2(base[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cdaa90c2-bcc9-4779-9607-06692c3c1a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "[torch.Size([2, 3, 28, 28]), torch.Size([2, 3, 28, 28])] x0\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "[torch.Size([2, 3, 28, 28]), torch.Size([2, 3, 28, 28])] x1\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "[torch.Size([2, 3, 28, 28]), torch.Size([2, 3, 28, 28])] x2\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "[torch.Size([2, 3, 28, 28]), torch.Size([2, 3, 28, 28])] x3\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "SayBye! From ItemTransformLoop 140303791967248\n",
      "Hi! From SayBye 140303791968144\n",
      "[torch.Size([1, 3, 28, 28]), torch.Size([1, 3, 28, 28])] x4\n"
     ]
    }
   ],
   "source": [
    "mod = 0 #len(L(path.rglob('*')))//10\n",
    "for i,element in enumerate(train_dl):\n",
    "    # if i%mod==0: print(L(element).map(Self.shape()), f'x{i}')\n",
    "    print(L(element).map(Self.shape()), f'x{i}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c4fb6-c6d4-437b-a86b-deba23121175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
