{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fastai.data.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from typing import Callable\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from torch.utils.data.graph import traverse\n",
    "# Local modules\n",
    "from fastrl.fastai.data.loop.core import *\n",
    "\n",
    "from fastrl.fastai.data.pipes.map.mux import *\n",
    "from fastrl.fastai.data.pipes.map.demux import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Loading\n",
    "> Objects using the `Loop` and `DataPipe` API for DataLoading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b3d07-b0d1-44f8-8156-dbd6c392d5f8",
   "metadata": {},
   "source": [
    "We will replicate [fastai mnist loading](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22653cf8-a2ac-4a84-9f22-d8979ddbb113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/fastrl_user/.fastai/data/mnist_sample/train/7'),Path('/home/fastrl_user/.fastai/data/mnist_sample/train/3')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.all import untar_data,URLs,get_image_files,PILImage,ToTensor,PILBase\n",
    "from fastrl.fastai.torch_core import *\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f521f2-b226-4505-98f2-fb52c093cbb6",
   "metadata": {},
   "source": [
    "First we create the dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71f3b8e-5200-4374-aa94-666c020260ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TypeTransformLoop(dp.map.MapDataPipe):\n",
    "    def __init__(self,datapipe, type_tfms):\n",
    "        self.type_tfms,self.datapipe = Pipeline(type_tfms),datapipe\n",
    "    \n",
    "    @callback_getitem\n",
    "    def __getitem__(self, index):\n",
    "        data = self.datapipe[index]\n",
    "        return self.type_tfms(data)\n",
    "            \n",
    "    def __len__(self): return len(self.datapipe)\n",
    "    \n",
    "class ItemTransformLoop(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe, item_tfms:List[Callable]): \n",
    "        self.item_tfms,self.source_datapipe = Pipeline(item_tfms),source_datapipe\n",
    "    @callback_iter\n",
    "    def __iter__(self):\n",
    "        for data in self.source_datapipe:\n",
    "            yield self.item_tfms(data)\n",
    "    \n",
    "    \n",
    "class BatchTransformLoop(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe, batch_tfms):\n",
    "        self.batch_tfms,self.source_datapipe = Pipeline(batch_tfms),source_datapipe\n",
    "    @callback_iter\n",
    "    def __iter__(self):\n",
    "        for data in self.source_datapipe:\n",
    "            yield self.batch_tfms(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9323384d-c5b8-4918-9481-53119790a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def default_loader_loop(\n",
    "    items:Iterable,\n",
    "    splitter:Callable,\n",
    "    cbs:Optional[List[Callback]]=None,\n",
    "    type_tfms:Optional[Transform]=None,\n",
    "    item_tfms:Optional[Transform]=None,\n",
    "    batch_tfms:Optional[Transform]=None,\n",
    "    bs:int=2,\n",
    "    shuffler:Optional[Union[dp.iter.IterDataPipe,dp.map.MapDataPipe]]=None\n",
    "):\n",
    "    type_tfms = ifnone(type_tfms,L())\n",
    "    pipe = dp.map.SequenceWrapper(items)\n",
    "    train_dp,valid_dp = DemultiplexerMapDataPipe(\n",
    "        pipe,\n",
    "        num_instances=2,\n",
    "        classifier_fn=splitter,\n",
    "        drop_none=True\n",
    "    )\n",
    "    train_dp,valid_dp = L(train_dp,valid_dp).map(TypeTransformLoop, type_tfms=type_tfms)\n",
    "    if shuffler:\n",
    "        train_dp,valid_dp = L(train_dp,valid_dp).map(shuffler)\n",
    "    else:\n",
    "        train_dp,valid_dp = L(train_dp,valid_dp).map(Self.shuffle())\n",
    "    train_dp,valid_dp = L(train_dp,valid_dp).map(dp.iter.MapToIterConverter)\n",
    "    train_dp,valid_dp = L(train_dp,valid_dp).map(ItemTransformLoop, item_tfms=ifnone(item_tfms,L()))\n",
    "    train_dp,valid_dp = train_dp.batch(bs),valid_dp.batch(bs)\n",
    "    return train_dp,valid_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35f2d3a1-d5aa-4f32-8f6e-1257dc3421c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GrandparentSplitter(train='train',valid='valid'):\n",
    "    def splitter(item):\n",
    "        if all(s not in item.parts for s in (train,valid)): return None\n",
    "        if item.is_dir(): return None\n",
    "        # valid=1, train=0\n",
    "        return valid in item.parts \n",
    "    return splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c0e1f2b-084b-4b9a-83ca-7f63297ef321",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = default_loader_loop(\n",
    "    L(path.rglob('*')),\n",
    "    GrandparentSplitter(),\n",
    "    type_tfms = L(PILImage.create,ToTensor)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50342410-1c9d-4a82-9ec1-52188fae4079",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "default_constructor(\n",
    "    dp.iter.Zipper(*base),   \n",
    "    cbs=L()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87eeb08e-0edf-430d-bb44-a223e2b04dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,valid_dl = DataLoader2(base[0]),DataLoader2(base[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdaa90c2-bcc9-4779-9607-06692c3c1a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorImage([[[[0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               ...,\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "              [[0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               ...,\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "              [[0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               ...,\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0]]]], dtype=torch.uint8), TensorImage([[[[0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               ...,\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "              [[0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               ...,\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "              [[0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               ...,\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0],\n",
      "               [0, 0, 0,  ..., 0, 0, 0]]]], dtype=torch.uint8)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py:141: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:295.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    }
   ],
   "source": [
    "for i,element in enumerate(train_dl):\n",
    "    print(element)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c4fb6-c6d4-437b-a86b-deba23121175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
