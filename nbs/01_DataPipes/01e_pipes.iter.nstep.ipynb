{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp pipes.iter.nstep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "import typing\n",
    "\n",
    "from fastrl.torch_core import *\n",
    "from torchdata.dataloader2.graph import find_dps,DataPipeGraph,Type,DataPipe,MapDataPipe,IterDataPipe\n",
    "# Local modules\n",
    "from fastrl.core import *\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.data.block import *\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.pipes.map.transforms import TypeTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# NStep\n",
    "> DataPipe for producing grouped steps env-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9bf8259-f901-4c0a-9c27-479e2e0c833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class NStepper(IterDataPipe):\n",
    "    def __init__(\n",
    "            self, \n",
    "            # The datapipe we are extracting from must produce `StepType`\n",
    "            source_datapipe:IterDataPipe[StepType], \n",
    "            # Maximum number of steps to produce per yield as a tuple. This is the *max* number\n",
    "            # and may be less if for example we are yielding terminal states.\n",
    "            # Default produces single steps\n",
    "            n:int=1\n",
    "        ) -> None:\n",
    "        self.source_datapipe:IterDataPipe[StepType] = source_datapipe\n",
    "        self.n:int = n\n",
    "        self.env_buffer:Dict = {}\n",
    "        \n",
    "    def __iter__(self) -> typing.Tuple[StepType]:\n",
    "        self.env_buffer = {}\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,StepType):\n",
    "                raise Exception(f'Expected typing.NamedTuple object got {type(step)}\\n{step}')\n",
    "    \n",
    "            env_id,terminated = int(step.env_id),bool(step.terminated)\n",
    "        \n",
    "            if env_id in self.env_buffer:\n",
    "                self.env_buffer[env_id].append(step)\n",
    "            else:\n",
    "                self.env_buffer[env_id] = [step]\n",
    "                \n",
    "            if not terminated and len(self.env_buffer[env_id])<self.n: continue\n",
    "            \n",
    "            while terminated and len(self.env_buffer[env_id])!=0:\n",
    "                yield tuple(self.env_buffer[env_id])\n",
    "                self.env_buffer[env_id].pop(0)\n",
    "                \n",
    "            if not terminated:\n",
    "                yield tuple(self.env_buffer[env_id])\n",
    "                self.env_buffer[env_id].pop(0)\n",
    "add_docs(\n",
    "NStepper,\n",
    "\"\"\"Accepts a `source_datapipe` or iterable whose `next()` produces a `StepType` of \n",
    "max size `n` that will contain steps from a single environment with \n",
    "a subset of fields from `SimpleStep`, namely `terminated` and `env_id`.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "04c5a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class NStepFlattener(IterDataPipe):\n",
    "    def __init__(\n",
    "            self, \n",
    "            # The datapipe we are extracting from must produce `StepType` or `Tuple[StepType]`\n",
    "            source_datapipe:IterDataPipe[Union[Tuple[StepType],Type[StepType]]], \n",
    "        ) -> None:\n",
    "        self.source_datapipe:IterDataPipe[Union[Tuple[StepType],Type[StepType]]] = source_datapipe\n",
    "        \n",
    "    def __iter__(self) -> StepType:\n",
    "        for step in self.source_datapipe:\n",
    "            if issubclass(step.__class__,StepType):\n",
    "                # print(step)\n",
    "                yield step\n",
    "            elif isinstance(step,tuple):\n",
    "                # print('got step: ',step)\n",
    "                yield from step \n",
    "            else:\n",
    "                raise Exception(f'Expected {StepType} or tuple object got {type(step)}\\n{step}')\n",
    "\n",
    "            \n",
    "add_docs(\n",
    "NStepFlattener,\n",
    "\"\"\"Handles unwrapping `StepTypes` in tuples better than `dp.iter.UnBatcher` and `dp.iter.Flattener`\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "13fbc336-7f21-4ff4-9277-7f077066556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# Used here to avoid UserWarnings related to gym complaining about bounding box / action space format.\n",
    "# There must be a bug in the CartPole-v1 env that is causing this to show. Also couldnt figure out the \n",
    "# regex, so instead we filter on the lineno, which is line 98.\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning,lineno=98)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d80222c-a450-4faf-9c72-c11122384460",
   "metadata": {},
   "source": [
    "Below we see an example where we collect 2 steps for each env, **then** yield them. This is useful for\n",
    "training models of larger chunks of env step output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281186d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastrl.envs.gym import GymTypeTransform,GymStepper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "731cae90-2f4d-44e1-a03c-5ba23f2f5323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchdata/datapipes/iter/util/header.py:60: UserWarning: The length of this HeaderIterDataPipe is inferred to be equal to its limit.The actual value may be smaller if the actual length of source_datapipe is smaller than the limit.\n",
      "  \"The length of this HeaderIterDataPipe is inferred to be equal to its limit.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>next_state</th>\n",
       "      <th>env_id</th>\n",
       "      <th>terminated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]</td>\n",
       "      <td>[tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]</td>\n",
       "      <td>tensor(140096952787408)</td>\n",
       "      <td>tensor(False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]</td>\n",
       "      <td>[tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]</td>\n",
       "      <td>tensor(140096952787408)</td>\n",
       "      <td>tensor(False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]</td>\n",
       "      <td>[tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]</td>\n",
       "      <td>tensor(140096952804368)</td>\n",
       "      <td>tensor(False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]</td>\n",
       "      <td>[tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]</td>\n",
       "      <td>tensor(140096952804368)</td>\n",
       "      <td>tensor(False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]</td>\n",
       "      <td>[tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]</td>\n",
       "      <td>tensor(140096952805136)</td>\n",
       "      <td>tensor(False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]</td>\n",
       "      <td>[tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]</td>\n",
       "      <td>tensor(140096952805136)</td>\n",
       "      <td>tensor(False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]</td>\n",
       "      <td>[tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]</td>\n",
       "      <td>tensor(140096952787408)</td>\n",
       "      <td>tensor(False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]</td>\n",
       "      <td>[tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]</td>\n",
       "      <td>tensor(140096952787408)</td>\n",
       "      <td>tensor(False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]</td>\n",
       "      <td>[tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]</td>\n",
       "      <td>tensor(140096952804368)</td>\n",
       "      <td>tensor(False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]</td>\n",
       "      <td>[tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]</td>\n",
       "      <td>tensor(140096952804368)</td>\n",
       "      <td>tensor(False)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 state  \\\n",
       "0  [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]   \n",
       "1   [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]   \n",
       "2  [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]   \n",
       "3   [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]   \n",
       "4  [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]   \n",
       "5   [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]   \n",
       "6   [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]   \n",
       "7   [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]   \n",
       "8   [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]   \n",
       "9   [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]   \n",
       "\n",
       "                                                           next_state  \\\n",
       "0  [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]   \n",
       "1  [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]   \n",
       "2  [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]   \n",
       "3  [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]   \n",
       "4  [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]   \n",
       "5  [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]   \n",
       "6  [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]   \n",
       "7  [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]   \n",
       "8  [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]   \n",
       "9  [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]   \n",
       "\n",
       "                    env_id     terminated  \n",
       "0  tensor(140096952787408)  tensor(False)  \n",
       "1  tensor(140096952787408)  tensor(False)  \n",
       "2  tensor(140096952804368)  tensor(False)  \n",
       "3  tensor(140096952804368)  tensor(False)  \n",
       "4  tensor(140096952805136)  tensor(False)  \n",
       "5  tensor(140096952805136)  tensor(False)  \n",
       "6  tensor(140096952787408)  tensor(False)  \n",
       "7  tensor(140096952787408)  tensor(False)  \n",
       "8  tensor(140096952804368)  tensor(False)  \n",
       "9  tensor(140096952804368)  tensor(False)  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def n_step_test(envs,total_steps,n=1,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformer(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle()\n",
    "    pipe = GymStepper(pipe,seed=seed)\n",
    "    pipe = NStepper(pipe,n=n)\n",
    "    pipe = NStepFlattener(pipe)\n",
    "    pipe = pipe.header(total_steps)\n",
    "    return list(pipe)\n",
    "\n",
    "steps = n_step_test(['CartPole-v1']*3,200,2,0)\n",
    "pd.DataFrame(steps)[['state','next_state','env_id','terminated']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d66ca-460b-44a8-b955-3fae8d594cc1",
   "metadata": {},
   "source": [
    "## NStepper Tests\n",
    "\n",
    "There are a couple properties that we expect from n-step output:\n",
    "- tuples should be `n` size at max, however can be smaller.\n",
    "- `done` n-steps unravel into multiple tuples yielded individually.\n",
    "\n",
    "    - In other words if `n=3`, meaning we want to yield 3 blocks of steps per env, then if we have\n",
    "      [step5,step6,step7] where step7 is `done` we will get individual tuples in the order:\n",
    "      \n",
    "          1. [step5,step6,step7]\n",
    "          2. [step6,step7]\n",
    "          3. [step7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c71c78-66e5-4929-9dea-b2894d7fb9e2",
   "metadata": {},
   "source": [
    "First, `NStepper(pipe,n=1)` when falttened should be identical to a pipelines that never used it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5a7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastrl.envs.gym import GymTypeTransform,GymStepper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a95076e6-8918-4b4b-8137-b9e0a50c1ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = dp.map.Mapper(['CartPole-v1']*3)\n",
    "pipe = TypeTransformer(pipe,[GymTypeTransform])\n",
    "pipe = dp.iter.MapToIterConverter(pipe)\n",
    "pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "pipe = pipe.cycle()\n",
    "pipe = GymStepper(pipe,seed=0)\n",
    "pipe = pipe.header(10)\n",
    "\n",
    "no_n_steps = list(pipe)\n",
    "steps = n_step_test(['CartPole-v1']*3,10,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf102f3-8208-44a8-a456-83d26fe0337b",
   "metadata": {},
   "source": [
    "If `n=1` we should expect that regardless of the number of envs, both n-step and simple environment\n",
    "pipelines should be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7ec6bf29-b775-4faa-ad26-adb2cd2eed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len(steps,no_n_steps)\n",
    "for field in ['next_state','state','terminated']:\n",
    "    for i,(step,no_n_step) in enumerate(zip(steps,no_n_steps)): \n",
    "        test_eq(getattr(step,field),getattr(no_n_step,field))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78267db7-b395-4f76-b964-a68caec85c22",
   "metadata": {},
   "source": [
    "We should expect n=1 -> 3 to have the same basic shape..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4cabda94-8bdb-4192-bba9-27aef284a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps1 = n_step_test(['CartPole-v1']*1,30,1,0)\n",
    "steps2 = n_step_test(['CartPole-v1']*1,30,2,0)\n",
    "steps3 = n_step_test(['CartPole-v1']*1,30,3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "54ddff38-8429-4a34-9d22-5f32f4ae864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in itertools.chain(steps1,steps2,steps3):\n",
    "    test_eq(len(o),12)\n",
    "    test_eq(isinstance(o,SimpleStep),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "46ee1e29-f09c-4c70-bcbe-c447498dade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def n_steps_expected(\n",
    "    default_steps:int, # The number of steps the episode would run without n_steps\n",
    "    n:int # The n-step value that we are planning ot use\n",
    "):\n",
    "    return (default_steps * n) - sum(range(n))\n",
    "    \n",
    "n_steps_expected.__doc__=r\"\"\"\n",
    "Produces the expected number of steps, assuming a fully deterministic episode based on `default_steps` and `n`\n",
    "\n",
    "Given `n=2`, given 1 envs, knowing that `CartPole-v1` when `seed=0` will always run 18 steps, the total \n",
    "steps will be:\n",
    "\n",
    "$$\n",
    "18 * n - \\sum_{0}^{n - 1}(i)\n",
    "$$\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ee621f23-5a97-4741-88ad-13b0db29fb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the above values, we expect a single episode to be  35  steps long\n"
     ]
    }
   ],
   "source": [
    "expected_n_steps = n_steps_expected(default_steps=18,n=2)\n",
    "print('Given the above values, we expect a single episode to be ',expected_n_steps,' steps long')\n",
    "steps = n_step_test(['CartPole-v1']*1,expected_n_steps+1,2,0)\n",
    "# The first episode should have ended on row 34, beign 35 steps long. The 36th row should be a new episode\n",
    "test_eq(steps[-2].terminated,tensor([True]))\n",
    "test_eq(steps[-2].episode_n,tensor([1]))\n",
    "test_eq(steps[-2].step_n,tensor([18]))\n",
    "test_eq(steps[-1].terminated,tensor([False]))\n",
    "test_eq(steps[-1].episode_n,tensor([2]))\n",
    "test_eq(steps[-1].step_n,tensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "478abe33-777c-4d96-869c-6ee7ff81d1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the above values, we expect a single episode to be  66  steps long\n"
     ]
    }
   ],
   "source": [
    "expected_n_steps = n_steps_expected(default_steps=18,n=4)\n",
    "print('Given the above values, we expect a single episode to be ',expected_n_steps,' steps long')\n",
    "steps = n_step_test(['CartPole-v1']*1,expected_n_steps+1,4,0)\n",
    "# The first episode should have ended on row 34, beign 35 steps long. The 36th row should be a new episode\n",
    "test_eq(steps[-2].terminated,tensor([True]))\n",
    "test_eq(steps[-2].episode_n,tensor([1]))\n",
    "test_eq(steps[-2].step_n,tensor([18]))\n",
    "test_eq(steps[-1].terminated,tensor([False]))\n",
    "test_eq(steps[-1].episode_n,tensor([2]))\n",
    "test_eq(steps[-1].step_n,tensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "829af9ec-2a38-4099-b73a-cbd170926c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the above values, we expect a single episode to be  35  steps long\n"
     ]
    }
   ],
   "source": [
    "expected_n_steps = n_steps_expected(default_steps=18,n=2)\n",
    "print('Given the above values, we expect a single episode to be ',expected_n_steps,' steps long')\n",
    "steps = n_step_test(['CartPole-v1']*3,expected_n_steps*3+1,2,0)\n",
    "# The first episode should have ended on row 34, beign 35 steps long. The 36th row should be a new episode\n",
    "test_eq(steps[-2].terminated,tensor([True]))\n",
    "test_eq(steps[-2].episode_n,tensor([1]))\n",
    "test_eq(steps[-2].step_n,tensor([18]))\n",
    "test_eq(steps[-1].terminated,tensor([False]))\n",
    "test_eq(steps[-1].episode_n,tensor([2]))\n",
    "test_eq(steps[-1].step_n,tensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/astroid/node_classes.py:96: DeprecationWarning: The 'astroid.node_classes' module is deprecated and will be replaced by 'astroid.nodes' in astroid 3.0.0\n",
      "  DeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfbdca1-0fdf-4f9b-b022-863f3ca92003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
