{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.dqn.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "from collections import deque\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from torch.utils.data.datapipes._typing import _DataPipeMeta, _IterDataPipeMeta\n",
    "from torchdata.dataloader2.graph import find_dps,traverse,DataPipe,replace_dp,remove_dp\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "# Local modules\n",
    "\n",
    "from fastrl.core import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.data.block import *\n",
    "from fastrl.memory.experience_replay import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.agents.discrete import *\n",
    "from fastrl.loggers.core import *\n",
    "from fastrl.loggers.jupyter_visualizers import *\n",
    "from fastrl.learner.core import *\n",
    "from fastrl.agents.dqn.basic import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Target\n",
    "> DQN that uses snapshots from the NN module to stabilize training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c98be0-6288-443a-b4ab-9390fbe3081c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Training DataPipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4fe4121b-df48-4845-b86f-dc72dd1c97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TargetModelUpdater(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe=None,target_sync=300):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        if source_datapipe is not None and type(source_datapipe)!=PassThroughIterPipe:\n",
    "            self.learner = find_dp(traverse(self),LearnerBase)\n",
    "            self.learner.target_model = deepcopy(self.learner.model)\n",
    "        self.target_sync = target_sync\n",
    "        self.n_batch = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.learner = find_dp(traverse(self),LearnerBase)\n",
    "        self.learner.target_model = deepcopy(self.learner.model)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        if self._snapshot_state.NotStarted: self.reset()\n",
    "        for batch in self.source_datapipe:\n",
    "            if self.n_batch%self.target_sync==0:\n",
    "                self.learner.target_model.load_state_dict(self.learner.model.state_dict())\n",
    "            self.n_batch+=1\n",
    "            yield batch\n",
    "\n",
    "    @classmethod\n",
    "    def insert_dp(cls,old_dp=ModelLearnCalc,target_sync=300) -> Callable[[DataPipe],DataPipe]:\n",
    "        def _insert_dp(pipe):\n",
    "            v = insert_dp(\n",
    "                traverse(pipe),\n",
    "                find_dp(traverse(pipe),old_dp),\n",
    "                cls(source_datapipe=PassThroughIterPipe(None),target_sync=target_sync)\n",
    "            )\n",
    "            return list(v.values())[0][0]\n",
    "        return _insert_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "cc8c66df-7063-4c77-915b-2c2c8c1b4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TargetModelQCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe=None):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        if source_datapipe is not None: self.learner = find_dp(traverse(self),LearnerBase)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.learner = find_dp(traverse(self),LearnerBase)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learner.done_mask = batch.terminated.reshape(-1,)\n",
    "            with torch.no_grad():\n",
    "                self.learner.next_q = self.learner.target_model(batch.next_state)\n",
    "            self.learner.next_q = self.learner.next_q.max(dim=1).values.reshape(-1,1)\n",
    "            self.learner.next_q[self.learner.done_mask] = 0 \n",
    "            yield batch\n",
    "            \n",
    "    @classmethod\n",
    "    def replace_dp(cls,old_dp=QCalc) -> Callable[[DataPipe],DataPipe]:\n",
    "        def _replace_dp(pipe):\n",
    "            old_dp_instance = find_dp(traverse(pipe),old_dp)\n",
    "            v = replace_dp(\n",
    "                traverse(pipe),\n",
    "                old_dp_instance,\n",
    "                cls(old_dp_instance.source_datapipe)\n",
    "            )\n",
    "            return list(v.values())[0][0]\n",
    "        return _replace_dp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f9ed8-fb05-40a1-ac0d-d4cafee8fa07",
   "metadata": {},
   "source": [
    "Try training with basic defaults..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "63d9b481-5998-472a-a2df-18d79bf07ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassThroughIterPipe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>episode</th>\n",
       "      <th>rolling_reward</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.017120052</td>\n",
       "      <td>54</td>\n",
       "      <td>18.603774</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.749500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.026505072</td>\n",
       "      <td>94</td>\n",
       "      <td>21.193548</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.499250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.06634918</td>\n",
       "      <td>113</td>\n",
       "      <td>27.580000</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.07020119</td>\n",
       "      <td>121</td>\n",
       "      <td>34.180000</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.114879206</td>\n",
       "      <td>124</td>\n",
       "      <td>44.810000</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.18819633</td>\n",
       "      <td>129</td>\n",
       "      <td>54.020000</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.14978153</td>\n",
       "      <td>134</td>\n",
       "      <td>62.080000</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.10781093</td>\n",
       "      <td>140</td>\n",
       "      <td>70.860000</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.25186944</td>\n",
       "      <td>146</td>\n",
       "      <td>80.510000</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.3126218</td>\n",
       "      <td>151</td>\n",
       "      <td>89.090000</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.1461959</td>\n",
       "      <td>156</td>\n",
       "      <td>98.230000</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5.129289</td>\n",
       "      <td>160</td>\n",
       "      <td>109.110000</td>\n",
       "      <td>12</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.21954563</td>\n",
       "      <td>166</td>\n",
       "      <td>118.270000</td>\n",
       "      <td>13</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.46689016</td>\n",
       "      <td>170</td>\n",
       "      <td>125.830000</td>\n",
       "      <td>14</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4.7093067</td>\n",
       "      <td>174</td>\n",
       "      <td>136.230000</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.39877427</td>\n",
       "      <td>179</td>\n",
       "      <td>145.130000</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.48806822</td>\n",
       "      <td>185</td>\n",
       "      <td>153.410000</td>\n",
       "      <td>17</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.91319084</td>\n",
       "      <td>187</td>\n",
       "      <td>162.460000</td>\n",
       "      <td>18</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.40610662</td>\n",
       "      <td>188</td>\n",
       "      <td>170.060000</td>\n",
       "      <td>19</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.5557756</td>\n",
       "      <td>192</td>\n",
       "      <td>180.230000</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.62125736</td>\n",
       "      <td>196</td>\n",
       "      <td>185.720000</td>\n",
       "      <td>21</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.36784676</td>\n",
       "      <td>197</td>\n",
       "      <td>192.500000</td>\n",
       "      <td>22</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.36487505</td>\n",
       "      <td>201</td>\n",
       "      <td>206.230000</td>\n",
       "      <td>23</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.51351684</td>\n",
       "      <td>206</td>\n",
       "      <td>212.530000</td>\n",
       "      <td>24</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.47843477</td>\n",
       "      <td>207</td>\n",
       "      <td>216.270000</td>\n",
       "      <td>24</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastrl.envs.gym import *\n",
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n",
    "                 batch_on_pipe=BatchCollector)\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,[logger_base],max_steps=4000)\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False)\n",
    ")\n",
    "# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1))\n",
    "# Setup the Learner\n",
    "learner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=100_000,\n",
    "                     batches=1000,\n",
    "                    dp_augmentation_fns=[\n",
    "                        TargetModelUpdater.insert_dp(),\n",
    "                        TargetModelQCalc.replace_dp()\n",
    "                    ]\n",
    ")\n",
    "# learner.fit(3)\n",
    "learner.fit(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0ed73-7bbf-415b-9ee7-9a95de31d638",
   "metadata": {},
   "source": [
    "The DQN learners, but I wonder if we can get it to learn faster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d510e-38c1-458c-9830-df5a68e6a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n",
    "                 batch_on_pipe=BatchCollector)\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,[logger_base],max_steps=10000)\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True) # We basically merge 2 steps into 1 and skip. \n",
    ")\n",
    "# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1))\n",
    "# Setup the Learner\n",
    "learner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=20_000,nsteps=2,lr=0.001,\n",
    "                     batches=1000,\n",
    "                    dp_augmentation_fns=[\n",
    "                        TargetModelUpdater.insert_dp(),\n",
    "                        TargetModelQCalc.replace_dp()\n",
    "                    ])\n",
    "# learner.fit(3)\n",
    "learner.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de0f41e-2eda-4227-9fa8-f2e0b920754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.loggers.jupyter_visualizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15937f36-8efa-4163-bc67-20019d18c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482490a-475e-4c46-b1fa-193bf68b7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.envs.gym import GymTypeTransform,GymStepper\n",
    "\n",
    "def gym_pipe_base(envs,total_steps,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformLoop(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle(count=total_steps)\n",
    "    pipe = GymStepper(pipe,agent=agent,seed=seed,include_images=True)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc10e61-4f65-4a17-a5a9-489bb466af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8784650-6f5c-42b7-9a72-68a0d37d8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_logger = SimpleJupyterVideoPlayer()\n",
    "\n",
    "pipe = gym_pipe_base(['CartPole-v1'],1000,seed=None)\n",
    "pipe = ImageCollector(pipe,[video_logger])\n",
    "\n",
    "pipe = video_logger.connect_source_datapipe(pipe)\n",
    "\n",
    "for o in pipe:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d3626-1702-4f22-ae15-bb93a75bec68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
