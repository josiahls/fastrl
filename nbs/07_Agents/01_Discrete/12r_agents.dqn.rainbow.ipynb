{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastrl.test_utils import initialize_notebook\n",
    "initialize_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.dqn.rainbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "from copy import deepcopy\n",
    "from typing import Optional,Callable,Tuple\n",
    "# Third party libs\n",
    "import torchdata.datapipes as dp\n",
    "from torchdata.dataloader2.graph import traverse_dps,DataPipe\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from fastcore.all import store_attr,ifnone\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "# Local modulesf\n",
    "from fastrl.torch_core import default_device,to_detach,evaluating\n",
    "from fastrl.pipes.core import find_dp\n",
    "from fastrl.agents.core import StepFieldSelector,SimpleModelRunner,NumpyConverter\n",
    "from fastrl.agents.discrete import EpsilonCollector,PyPrimativeConverter,ArgMaxer,EpsilonSelector\n",
    "from fastrl.memory.experience_replay import ExperienceReplay\n",
    "from fastrl.loggers.core import BatchCollector,EpochCollector\n",
    "from fastrl.learner.core import LearnerBase,LearnerHead\n",
    "from fastrl.agents.core import AgentHead,AgentBase\n",
    "from fastrl.loggers.vscode_visualizers import VSCodeDataPipe\n",
    "from fastrl.loggers.core import ProgressBarLogger\n",
    "from fastrl.agents.dqn.basic import (\n",
    "    LossCollector,\n",
    "    RollingTerminatedRewardCollector,\n",
    "    EpisodeCollector,\n",
    "    StepBatcher,\n",
    "    TargetCalc,\n",
    "    LossCalc,\n",
    "    ModelLearnCalc,\n",
    "    DQN,\n",
    "    DQNAgent\n",
    ")\n",
    "from fastrl.agents.dqn.target import (\n",
    "    TargetModelUpdater,\n",
    "    TargetModelQCalc\n",
    ")\n",
    "from fastrl.agents.dqn.dueling import DuelingHead \n",
    "from fastrl.agents.dqn.categorical import (\n",
    "    CategoricalDQNAgent,\n",
    "    CategoricalDQN,\n",
    "    CategoricalTargetQCalc,\n",
    "    PartialCrossEntropy\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Rainbow\n",
    "> Combines target, dueling, double, categorical dqns\n",
    "\n",
    "> Important: I think this also needs special exploration layers also to be officially a rainbow implimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DQNRainbowLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    do_logging:bool=True,\n",
    "    loss_func=PartialCrossEntropy,\n",
    "    opt=optim.AdamW,\n",
    "    lr=0.005,\n",
    "    bs=128,\n",
    "    max_sz=10000,\n",
    "    nsteps=1,\n",
    "    device=None,\n",
    "    batches=None,\n",
    "    target_sync=300,\n",
    "    # Use DoubleDQN target strategy\n",
    "    double_dqn_strategy=True\n",
    ") -> LearnerHead:\n",
    "    learner = LearnerBase(model,dls=dls[0])\n",
    "    learner = BatchCollector(learner,batches=batches)\n",
    "    learner = EpochCollector(learner)\n",
    "    if do_logging: \n",
    "        learner = learner.dump_records()\n",
    "        learner = ProgressBarLogger(learner)\n",
    "        learner = RollingTerminatedRewardCollector(learner)\n",
    "        learner = EpisodeCollector(learner).catch_records()\n",
    "    learner = ExperienceReplay(learner,bs=bs,max_sz=max_sz)\n",
    "    learner = StepBatcher(learner,device=device)\n",
    "    learner = CategoricalTargetQCalc(learner,nsteps=nsteps,double_dqn_strategy=double_dqn_strategy).to(device=device)\n",
    "    learner = LossCalc(learner,loss_func=loss_func)\n",
    "    learner = ModelLearnCalc(learner,opt=opt(model.parameters(),lr=lr))\n",
    "    learner = TargetModelUpdater(learner,target_sync=target_sync)\n",
    "    if do_logging: \n",
    "        learner = LossCollector(learner).catch_records()\n",
    "\n",
    "    if len(dls)==2:\n",
    "        val_learner = LearnerBase(model,dls[1]).visualize_vscode()\n",
    "        val_learner = BatchCollector(val_learner,batches=batches)\n",
    "        val_learner = EpochCollector(val_learner).catch_records(drop=True)\n",
    "        return LearnerHead((learner,val_learner))\n",
    "    else:\n",
    "        return LearnerHead(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73013fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.envs.gym import GymDataPipe\n",
    "from fastrl.dataloading.core import dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6828da-23ae-4762-8e33-a3a7f123fed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval:false\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "# Rainbow uses a CategoricalDQN with a DuelingHead (DuealingDQN)\n",
    "model = CategoricalDQN(4,2,head_layer=DuelingHead)\n",
    "# Setup the Agent\n",
    "agent = CategoricalDQNAgent(model,do_logging=True,min_epsilon=0.02,max_epsilon=1,max_steps=5000)\n",
    "# Setup the Dataloaders\n",
    "params = dict(\n",
    "    source=['CartPole-v1']*1,\n",
    "    agent=agent,\n",
    "    nsteps=2,\n",
    "    nskips=2,\n",
    "    firstlast=True\n",
    ")\n",
    "dls = dataloaders((GymDataPipe(**params),GymDataPipe(**params,include_images=True).unbatch()))\n",
    "# Setup the Learner\n",
    "learner = DQNRainbowLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    bs=128,\n",
    "    max_sz=100_000,\n",
    "    nsteps=2,\n",
    "    lr=0.001,\n",
    "    batches=1000,\n",
    "    target_sync=300\n",
    ")\n",
    "learner.fit(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87fc47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval:false\n",
    "learner.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d3626-1702-4f22-ae15-bb93a75bec68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
