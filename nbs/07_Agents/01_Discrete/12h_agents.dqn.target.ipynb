{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastrl.test_utils import initialize_notebook\n",
    "initialize_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.dqn.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "from copy import deepcopy\n",
    "from typing import Optional,Callable\n",
    "# Third party libs\n",
    "import torchdata.datapipes as dp\n",
    "from torchdata.dataloader2.graph import traverse_dps,DataPipe\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "# Local modules\n",
    "from fastrl.pipes.core import find_dp\n",
    "from fastrl.memory.experience_replay import ExperienceReplay\n",
    "from fastrl.loggers.core import BatchCollector,EpochCollector\n",
    "from fastrl.learner.core import LearnerBase,LearnerHead\n",
    "from fastrl.agents.dqn.basic import (\n",
    "    LossCollector,\n",
    "    RollingTerminatedRewardCollector,\n",
    "    EpisodeCollector,\n",
    "    StepBatcher,\n",
    "    TargetCalc,\n",
    "    LossCalc,\n",
    "    ModelLearnCalc,\n",
    "    DQN,\n",
    "    DQNAgent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Target\n",
    "> DQN that uses snapshots from the NN module to stabilize training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c98be0-6288-443a-b4ab-9390fbe3081c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Training DataPipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fe4121b-df48-4845-b86f-dc72dd1c97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TargetModelUpdater(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe=None,target_sync=300):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        if source_datapipe is not None:\n",
    "            self.learner = find_dp(traverse_dps(self),LearnerBase)\n",
    "            self.learner.target_model = deepcopy(self.learner.model)\n",
    "        self.target_sync = target_sync\n",
    "        self.n_batch = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.learner = find_dp(traverse_dps(self),LearnerBase)\n",
    "        self.learner.target_model = deepcopy(self.learner.model)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        if self._snapshot_state.NotStarted: \n",
    "            self.reset()\n",
    "        for batch in self.source_datapipe:\n",
    "            if self.n_batch%self.target_sync==0:\n",
    "                self.learner.target_model.load_state_dict(self.learner.model.state_dict())\n",
    "            self.n_batch+=1\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc8c66df-7063-4c77-915b-2c2c8c1b4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TargetModelQCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe=None):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.learner = find_dp(traverse_dps(self),LearnerBase)\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learner.done_mask = batch.terminated.reshape(-1,)\n",
    "            with torch.no_grad():\n",
    "                self.learner.next_q = self.learner.target_model(batch.next_state)\n",
    "            self.learner.next_q = self.learner.next_q.max(dim=1).values.reshape(-1,1)\n",
    "            self.learner.next_q[self.learner.done_mask] = 0 \n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1de0e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DQNTargetLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    logger_bases:Optional[Callable]=None,\n",
    "    loss_func=nn.MSELoss(),\n",
    "    opt=optim.AdamW,\n",
    "    lr=0.005,\n",
    "    bs=128,\n",
    "    max_sz=10000,\n",
    "    nsteps=1,\n",
    "    device=None,\n",
    "    batches=None\n",
    ") -> LearnerHead:\n",
    "    learner = LearnerBase(\n",
    "        model,\n",
    "        fit_dls=dls[0],\n",
    "        val_dls=dls[1]\n",
    "    )\n",
    "    learner = BatchCollector(learner,batches=batches)\n",
    "    learner = EpochCollector(learner).catch_records()\n",
    "    if logger_bases: \n",
    "        learner = logger_bases(learner)\n",
    "        learner = RollingTerminatedRewardCollector(learner).catch_records()\n",
    "        learner = EpisodeCollector(learner).catch_records()\n",
    "    exp_replay = ExperienceReplay(learner,bs=bs,max_sz=max_sz)\n",
    "    learner = StepBatcher(exp_replay,device=device)\n",
    "    learner = TargetModelQCalc(learner)\n",
    "    learner = TargetCalc(learner,nsteps=nsteps)\n",
    "    learner = LossCalc(learner,loss_func=loss_func)\n",
    "    learner = ModelLearnCalc(learner,opt=opt(model.parameters(),lr=lr))\n",
    "    learner = TargetModelUpdater(learner)\n",
    "    if logger_bases: \n",
    "        learner = LossCollector(learner).catch_records()\n",
    "    learner = LearnerHead(learner)\n",
    "    return learner,exp_replay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f9ed8-fb05-40a1-ac0d-d4cafee8fa07",
   "metadata": {},
   "source": [
    "Try training with basic defaults..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4917308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.envs.gym import GymDataPipe\n",
    "from fastrl.loggers.core import ProgressBarLogger\n",
    "from fastrl.dataloading.core import dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63d9b481-5998-472a-a2df-18d79bf07ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clearing _RECORD_CATCH_LIST since it is not empty: 4 elements\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 24\u001b[0m\n\u001b[1;32m     13\u001b[0m dls \u001b[39m=\u001b[39m dataloaders(\n\u001b[1;32m     14\u001b[0m     GymDataPipe(\n\u001b[1;32m     15\u001b[0m         [\u001b[39m'\u001b[39m\u001b[39mCartPole-v1\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[39m# Setup the Learner\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m learner,exp_replay \u001b[39m=\u001b[39m DQNTargetLearner(\n\u001b[1;32m     25\u001b[0m     model,\n\u001b[1;32m     26\u001b[0m     dls,\n\u001b[1;32m     27\u001b[0m     logger_bases\u001b[39m=\u001b[39;49mlogger_bases,\n\u001b[1;32m     28\u001b[0m     bs\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m     29\u001b[0m     max_sz\u001b[39m=\u001b[39;49m\u001b[39m100_000\u001b[39;49m,\n\u001b[1;32m     30\u001b[0m     batches\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m learner\u001b[39m.\u001b[39mfit(\u001b[39m3\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[39m# learner.fit(25)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m, in \u001b[0;36mDQNTargetLearner\u001b[0;34m(model, dls, logger_bases, loss_func, opt, lr, bs, max_sz, nsteps, device, batches)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mDQNTargetLearner\u001b[39m(\n\u001b[1;32m      3\u001b[0m     model,\n\u001b[1;32m      4\u001b[0m     dls,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     batches\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m     14\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LearnerHead:\n\u001b[1;32m     15\u001b[0m     learner \u001b[39m=\u001b[39m LearnerBase(\n\u001b[1;32m     16\u001b[0m         model,\n\u001b[1;32m     17\u001b[0m         fit_dls\u001b[39m=\u001b[39mdls[\u001b[39m0\u001b[39m],\n\u001b[0;32m---> 18\u001b[0m         val_dls\u001b[39m=\u001b[39mdls[\u001b[39m1\u001b[39;49m]\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m     learner \u001b[39m=\u001b[39m BatchCollector(learner,batches\u001b[39m=\u001b[39mbatches)\n\u001b[1;32m     21\u001b[0m     learner \u001b[39m=\u001b[39m EpochCollector(learner)\u001b[39m.\u001b[39mcatch_records()\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#|eval:false\n",
    "# Setup Loggers\n",
    "def logger_bases(pipe):\n",
    "    pipe = pipe.dump_records()\n",
    "    pipe = ProgressBarLogger(pipe)\n",
    "    return pipe\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,do_logging=True,max_steps=4000)\n",
    "# Setup the DataBlock\n",
    "dls = dataloaders(\n",
    "    GymDataPipe(\n",
    "        ['CartPole-v1']*1,\n",
    "        agent=agent,\n",
    "        nsteps=1,\n",
    "        nskips=1,\n",
    "        firstlast=False,\n",
    "        bs=1\n",
    "    )\n",
    ")\n",
    "# Setup the Learner\n",
    "learner,exp_replay = DQNTargetLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    logger_bases=logger_bases,\n",
    "    bs=128,\n",
    "    max_sz=100_000,\n",
    "    batches=1000\n",
    ")\n",
    "learner.fit(3)\n",
    "# learner.fit(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0ed73-7bbf-415b-9ee7-9a95de31d638",
   "metadata": {},
   "source": [
    "The DQN learns, but I wonder if we can get it to learn faster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f0f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.loggers.vscode_visualizers import VSCodeDataPipe\n",
    "from fastrl.dataloading.core import dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d510e-38c1-458c-9830-df5a68e6a53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clearing _RECORD_CATCH_LIST since it is not empty: 2 elements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>episode</th>\n",
       "      <th>rolling_reward</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.13191189</td>\n",
       "      <td>103</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>0.539000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.60782194</td>\n",
       "      <td>256</td>\n",
       "      <td>10.480000</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0.093000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.2860094</td>\n",
       "      <td>435</td>\n",
       "      <td>9.480000</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.8917716</td>\n",
       "      <td>618</td>\n",
       "      <td>9.320000</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.9597063</td>\n",
       "      <td>799</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.7231499</td>\n",
       "      <td>981</td>\n",
       "      <td>9.380000</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.9072262</td>\n",
       "      <td>1160</td>\n",
       "      <td>9.520000</td>\n",
       "      <td>6</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.130864</td>\n",
       "      <td>1342</td>\n",
       "      <td>9.480000</td>\n",
       "      <td>7</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.3850579</td>\n",
       "      <td>1523</td>\n",
       "      <td>9.560000</td>\n",
       "      <td>8</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|eval:false\n",
    "# Setup Loggers\n",
    "def logger_bases(pipe):\n",
    "    pipe = pipe.dump_records()\n",
    "    pipe = ProgressBarLogger(pipe)\n",
    "    return pipe\n",
    "# Setup up the core NNa\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,do_logging=True,max_steps=4000)\n",
    "# Setup the DataBlock\n",
    "train_pipe = GymDataPipe(\n",
    "    ['CartPole-v1']*1,\n",
    "    agent=agent,\n",
    "    nsteps=2,\n",
    "    nskips=2,\n",
    "    firstlast=True,\n",
    "    bs=1\n",
    ")\n",
    "valid_pipe = GymDataPipe(\n",
    "    ['CartPole-v1']*1,\n",
    "    agent=agent,\n",
    "    nsteps=2,\n",
    "    nskips=2,\n",
    "    firstlast=True,\n",
    "    bs=1,\n",
    "    n=100,\n",
    "    include_images=True\n",
    ")\n",
    "valid_pipe = VSCodeDataPipe(valid_pipe)\n",
    "dls = dataloaders((train_pipe,valid_pipe))\n",
    "# Setup the Learner\n",
    "learner,exp_replay = DQNTargetLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    logger_bases=logger_bases,\n",
    "    bs=128,\n",
    "    max_sz=100_000,\n",
    "    nsteps=2,\n",
    "    lr=0.001,\n",
    "    batches=1000\n",
    ")\n",
    "# learner.fit(3)\n",
    "learner.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab57ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fe9822c9504b75a211bf6cbb1658bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Number of Elements in Memory: 10000'), HBox(children=(Button(description='Previous…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<fastrl.memory.memory_visualizer.MemoryBufferViewer at 0x7fb844efbf10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_replay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5b57c4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.TargetModelUpdater'>: it's not the same object as __main__.TargetModelUpdater",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#|hide\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#|eval:false\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m learner\u001b[39m.\u001b[39;49mvalidate(\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[0;32m~/fastrl/fastrl/learner/core.py:103\u001b[0m, in \u001b[0;36mLearnerHead.validate\u001b[0;34m(self, epochs, show)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearner_base\u001b[39m.\u001b[39m_validating \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     epocher \u001b[39m=\u001b[39m find_dp(traverse_dps(\u001b[39mself\u001b[39;49m),EpochCollector)\n\u001b[1;32m    104\u001b[0m     epocher\u001b[39m.\u001b[39mepochs \u001b[39m=\u001b[39m epochs\n\u001b[1;32m    105\u001b[0m     \u001b[39mfor\u001b[39;00m iteration \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m: \n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/graph.py:98\u001b[0m, in \u001b[0;36mtraverse_dps\u001b[0;34m(datapipe)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39mTraverse the DataPipes and their attributes to extract the DataPipe graph.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mThis only looks into the attribute from each DataPipe that is either a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39m    and values are tuples of DataPipe instance and the sub-graph\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m cache: Set[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m _traverse_helper(datapipe, only_datapipe\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, cache\u001b[39m=\u001b[39;49mcache)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/graph.py:145\u001b[0m, in \u001b[0;36m_traverse_helper\u001b[0;34m(datapipe, only_datapipe, cache)\u001b[0m\n\u001b[1;32m    141\u001b[0m d: DataPipeGraph \u001b[39m=\u001b[39m {dp_id: (datapipe, {})}\n\u001b[1;32m    142\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m items:\n\u001b[1;32m    143\u001b[0m     \u001b[39m# Using cache.copy() here is to prevent recursion on a single path rather than global graph\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[39m# Single DataPipe can present multiple times in different paths in graph\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     d[dp_id][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mupdate(_traverse_helper(item, only_datapipe, cache\u001b[39m.\u001b[39;49mcopy()))\n\u001b[1;32m    146\u001b[0m \u001b[39mreturn\u001b[39;00m d\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/graph.py:145\u001b[0m, in \u001b[0;36m_traverse_helper\u001b[0;34m(datapipe, only_datapipe, cache)\u001b[0m\n\u001b[1;32m    141\u001b[0m d: DataPipeGraph \u001b[39m=\u001b[39m {dp_id: (datapipe, {})}\n\u001b[1;32m    142\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m items:\n\u001b[1;32m    143\u001b[0m     \u001b[39m# Using cache.copy() here is to prevent recursion on a single path rather than global graph\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[39m# Single DataPipe can present multiple times in different paths in graph\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     d[dp_id][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mupdate(_traverse_helper(item, only_datapipe, cache\u001b[39m.\u001b[39;49mcopy()))\n\u001b[1;32m    146\u001b[0m \u001b[39mreturn\u001b[39;00m d\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/graph.py:145\u001b[0m, in \u001b[0;36m_traverse_helper\u001b[0;34m(datapipe, only_datapipe, cache)\u001b[0m\n\u001b[1;32m    141\u001b[0m d: DataPipeGraph \u001b[39m=\u001b[39m {dp_id: (datapipe, {})}\n\u001b[1;32m    142\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m items:\n\u001b[1;32m    143\u001b[0m     \u001b[39m# Using cache.copy() here is to prevent recursion on a single path rather than global graph\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[39m# Single DataPipe can present multiple times in different paths in graph\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     d[dp_id][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mupdate(_traverse_helper(item, only_datapipe, cache\u001b[39m.\u001b[39;49mcopy()))\n\u001b[1;32m    146\u001b[0m \u001b[39mreturn\u001b[39;00m d\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/graph.py:140\u001b[0m, in \u001b[0;36m_traverse_helper\u001b[0;34m(datapipe, only_datapipe, cache)\u001b[0m\n\u001b[1;32m    138\u001b[0m cache\u001b[39m.\u001b[39madd(dp_id)\n\u001b[1;32m    139\u001b[0m \u001b[39m# Using cache.copy() here is to prevent the same DataPipe pollutes the cache on different paths\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m items \u001b[39m=\u001b[39m _list_connected_datapipes(datapipe, only_datapipe, cache\u001b[39m.\u001b[39;49mcopy())\n\u001b[1;32m    141\u001b[0m d: DataPipeGraph \u001b[39m=\u001b[39m {dp_id: (datapipe, {})}\n\u001b[1;32m    142\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m items:\n\u001b[1;32m    143\u001b[0m     \u001b[39m# Using cache.copy() here is to prevent recursion on a single path rather than global graph\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[39m# Single DataPipe can present multiple times in different paths in graph\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/graph.py:67\u001b[0m, in \u001b[0;36m_list_connected_datapipes\u001b[0;34m(scan_obj, only_datapipe, cache)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset_getstate_hook(getstate_hook)\n\u001b[1;32m     66\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     p\u001b[39m.\u001b[39;49mdump(scan_obj)\n\u001b[1;32m     68\u001b[0m \u001b[39mexcept\u001b[39;00m (pickle\u001b[39m.\u001b[39mPickleError, \u001b[39mAttributeError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m DILL_AVAILABLE:\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class '__main__.TargetModelUpdater'>: it's not the same object as __main__.TargetModelUpdater"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "#|eval:false\n",
    "learner.validate(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/nbdev/export.py:54: UserWarning: Notebook '/home/fastrl_user/fastrl/nbs/07_Agents/02_Continuous/12u_agents.ppo.ipynb' uses `#|export` without `#|default_exp` cell.\n",
      "Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\n",
      "See https://nbdev.fast.ai/getting_started.html for more information.\n",
      "  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\"\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dd827a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
