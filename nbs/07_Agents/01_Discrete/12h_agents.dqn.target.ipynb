{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastrl.test_utils import initialize_notebook\n",
    "initialize_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.dqn.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "from copy import deepcopy\n",
    "from typing import Optional,Callable,Tuple\n",
    "# Third party libs\n",
    "import torchdata.datapipes as dp\n",
    "from torchdata.dataloader2.graph import traverse_dps,DataPipe\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "# Local modulesf\n",
    "from fastrl.pipes.core import find_dp\n",
    "from fastrl.memory.experience_replay import ExperienceReplay\n",
    "from fastrl.loggers.core import BatchCollector,EpochCollector\n",
    "from fastrl.learner.core import LearnerBase,LearnerHead\n",
    "from fastrl.loggers.vscode_visualizers import VSCodeDataPipe\n",
    "from fastrl.agents.dqn.basic import (\n",
    "    LossCollector,\n",
    "    RollingTerminatedRewardCollector,\n",
    "    EpisodeCollector,\n",
    "    StepBatcher,\n",
    "    TargetCalc,\n",
    "    LossCalc,\n",
    "    ModelLearnCalc,\n",
    "    DQN,\n",
    "    DQNAgent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import logging\n",
    "from fastrl.core import default_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "logging.basicConfig(**default_logging())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Target\n",
    "> DQN that uses snapshots from the NN module to stabilize training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c98be0-6288-443a-b4ab-9390fbe3081c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Training DataPipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4121b-df48-4845-b86f-dc72dd1c97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TargetModelUpdater(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe=None,target_sync=300):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        if source_datapipe is not None:\n",
    "            self.learner = find_dp(traverse_dps(self),LearnerBase)\n",
    "            with torch.no_grad():\n",
    "                self.learner.target_model = deepcopy(self.learner.model)\n",
    "        self.target_sync = target_sync\n",
    "        self.n_batch = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        print('resetting')\n",
    "        self.learner = find_dp(traverse_dps(self),LearnerBase)\n",
    "        with torch.no_grad():\n",
    "            self.learner.target_model = deepcopy(self.learner.model)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        if self._snapshot_state.NotStarted: \n",
    "            self.reset()\n",
    "        for batch in self.source_datapipe:\n",
    "            if self.n_batch%self.target_sync==0:\n",
    "                with torch.no_grad():\n",
    "                    self.learner.target_model.load_state_dict(self.learner.model.state_dict())\n",
    "            self.n_batch+=1\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c66df-7063-4c77-915b-2c2c8c1b4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TargetModelQCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe=None):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.learner = find_dp(traverse_dps(self),LearnerBase)\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learner.done_mask = batch.terminated.reshape(-1,)\n",
    "            with torch.no_grad():\n",
    "                self.learner.next_q = self.learner.target_model(batch.next_state)\n",
    "            self.learner.next_q = self.learner.next_q.max(dim=1).values.reshape(-1,1)\n",
    "            self.learner.next_q[self.learner.done_mask] = 0 \n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DQNTargetLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    logger_bases:Optional[Callable]=None,\n",
    "    loss_func=nn.MSELoss(),\n",
    "    opt=optim.AdamW,\n",
    "    lr=0.005,\n",
    "    bs=128,\n",
    "    max_sz=10000,\n",
    "    nsteps=1,\n",
    "    device=None,\n",
    "    batches=None,\n",
    "    target_sync=300\n",
    ") -> LearnerHead:\n",
    "    learner = LearnerBase(model,dls=dls[0])\n",
    "    learner = BatchCollector(learner,batches=batches)\n",
    "    learner = EpochCollector(learner)\n",
    "    if logger_bases: \n",
    "        learner = logger_bases(learner)\n",
    "        learner = RollingTerminatedRewardCollector(learner)\n",
    "        learner = EpisodeCollector(learner)\n",
    "    learner = learner.catch_records()\n",
    "    learner = ExperienceReplay(learner,bs=bs,max_sz=max_sz)\n",
    "    learner = StepBatcher(learner,device=device)\n",
    "    learner = TargetModelQCalc(learner)\n",
    "    learner = TargetCalc(learner,nsteps=nsteps)\n",
    "    learner = LossCalc(learner,loss_func=loss_func)\n",
    "    learner = ModelLearnCalc(learner,opt=opt(model.parameters(),lr=lr))\n",
    "    learner = TargetModelUpdater(learner,target_sync=target_sync)\n",
    "    if logger_bases: \n",
    "        learner = LossCollector(learner).catch_records()\n",
    "\n",
    "    if len(dls)==2:\n",
    "        val_learner = LearnerBase(model,dls[1])\n",
    "        val_learner = BatchCollector(val_learner,batches=batches)\n",
    "        val_learner = EpochCollector(val_learner).catch_records(drop=True)\n",
    "        val_learner = VSCodeDataPipe(val_learner)\n",
    "        return LearnerHead((learner,val_learner),model)\n",
    "    else:\n",
    "        return LearnerHead(learner,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f9ed8-fb05-40a1-ac0d-d4cafee8fa07",
   "metadata": {},
   "source": [
    "Try training with basic defaults..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4917308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.loggers.vscode_visualizers import VSCodeDataPipe\n",
    "from fastrl.envs.gym import GymDataPipe\n",
    "from fastrl.loggers.core import ProgressBarLogger\n",
    "from fastrl.dataloading.core import dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0ed73-7bbf-415b-9ee7-9a95de31d638",
   "metadata": {},
   "source": [
    "The DQN learns, but I wonder if we can get it to learn faster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d510e-38c1-458c-9830-df5a68e6a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval:false\n",
    "# Setup Loggers\n",
    "def logger_bases(pipe):\n",
    "    pipe = pipe.dump_records()\n",
    "    pipe = ProgressBarLogger(pipe)\n",
    "    return pipe\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "model.train()\n",
    "model = model.share_memory()\n",
    "agent = DQNAgent(model,do_logging=True,min_epsilon=0.02,max_epsilon=1,max_steps=5000)\n",
    "# Setup the DataBlock\n",
    "train_pipe = GymDataPipe(\n",
    "    ['CartPole-v1']*1,\n",
    "    agent=agent,\n",
    "    nsteps=2,\n",
    "    nskips=2,\n",
    "    firstlast=True,\n",
    "    bs=1\n",
    ")\n",
    "dls = dataloaders(train_pipe)\n",
    "# Setup the Learner\n",
    "learner = DQNTargetLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    logger_bases=logger_bases,\n",
    "    bs=128,\n",
    "    max_sz=100_000,\n",
    "    nsteps=2,\n",
    "    lr=0.01,\n",
    "    batches=1000,\n",
    "    target_sync=300\n",
    ")\n",
    "learner.fit(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6eefa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_replay = find_dp(traverse_dps(learner),ExperienceReplay)\n",
    "# exp_replay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cbfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.agents.core import AgentHead,AgentBase\n",
    "from fastrl.agents.core import SimpleModelRunner,NumpyConverter\n",
    "from fastrl.agents.discrete import ArgMaxer\n",
    "from fastrl.memory.memory_visualizer import MemoryBufferViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f88a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_agent = DQNAgent(model,min_epsilon=0,max_epsilon=0)\n",
    "valid_pipe = GymDataPipe(\n",
    "    ['CartPole-v1']*1,\n",
    "    agent=val_agent,\n",
    "    nsteps=2,\n",
    "    nskips=2,\n",
    "    firstlast=True,\n",
    "    bs=1,\n",
    "    n=100,\n",
    "    include_images=False\n",
    ")\n",
    "# valid_pipe = VSCodeDataPipe(valid_pipe)\n",
    "sample_run = [o[0] for o in valid_pipe.catch_records(drop=True)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "model.eval()\n",
    "\n",
    "pipe = GymDataPipe(['CartPole-v1']*1,agent=agent,n=1000,seed=0,include_images=True)\n",
    "pipe = VSCodeDataPipe(pipe)\n",
    "\n",
    "list(pipe);\n",
    "pipe.show()\n",
    "# list(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.agents.core import StepFieldSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692662d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DQNValAgent(\n",
    "    model,\n",
    "    device='cpu'\n",
    ")->AgentHead:\n",
    "    agent_base = AgentBase(model)\n",
    "    agent = StepFieldSelector(agent_base,field='state')\n",
    "    agent = SimpleModelRunner(agent).to(device=device)\n",
    "    # agent = ArgMaxer(agent,only_idx=True)\n",
    "    # agent = NumpyConverter(agent)\n",
    "    # agent = PyPrimativeConverter(agent)\n",
    "    agent = AgentHead(agent)\n",
    "    return agent\n",
    "\n",
    "val_agent = DQNValAgent(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab57ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MemoryBufferViewer(sample_run,val_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b57c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval:false\n",
    "# learner.validate(epochs=1,batches=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dd827a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
