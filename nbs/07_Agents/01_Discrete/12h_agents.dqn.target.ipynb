{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastrl.test_utils import initialize_notebook\n",
    "initialize_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.dqn.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "from copy import deepcopy\n",
    "from typing import Optional,Callable,Tuple\n",
    "# Third party libs\n",
    "import torchdata.datapipes as dp\n",
    "from torchdata.dataloader2.graph import traverse_dps,DataPipe\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "# Local modulesf\n",
    "from fastrl.pipes.core import find_dp\n",
    "from fastrl.memory.experience_replay import ExperienceReplay\n",
    "from fastrl.loggers.core import BatchCollector,EpochCollector\n",
    "from fastrl.learner.core import LearnerBase,LearnerHead\n",
    "from fastrl.loggers.vscode_visualizers import VSCodeDataPipe\n",
    "from fastrl.loggers.core import ProgressBarLogger\n",
    "from fastrl.agents.dqn.basic import (\n",
    "    LossCollector,\n",
    "    RollingTerminatedRewardCollector,\n",
    "    EpisodeCollector,\n",
    "    StepBatcher,\n",
    "    TargetCalc,\n",
    "    LossCalc,\n",
    "    ModelLearnCalc,\n",
    "    DQN,\n",
    "    DQNAgent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import logging\n",
    "from fastrl.core import default_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "logging.basicConfig(**default_logging())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Target\n",
    "> DQN that uses snapshots from the NN module to stabilize training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c98be0-6288-443a-b4ab-9390fbe3081c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Training DataPipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4121b-df48-4845-b86f-dc72dd1c97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TargetModelUpdater(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,target_sync=300):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.target_sync = target_sync\n",
    "        self.n_batch = 0\n",
    "        self.learner = find_dp(traverse_dps(self),LearnerBase)\n",
    "        with torch.no_grad():\n",
    "            self.learner.target_model = deepcopy(self.learner.model)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.learner = find_dp(traverse_dps(self),LearnerBase)\n",
    "        with torch.no_grad():\n",
    "            self.learner.target_model = deepcopy(self.learner.model)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        if self._snapshot_state.NotStarted: \n",
    "            self.reset()\n",
    "        for batch in self.source_datapipe:\n",
    "            if self.n_batch%self.target_sync==0:\n",
    "                with torch.no_grad():\n",
    "                    self.learner.target_model.load_state_dict(self.learner.model.state_dict())\n",
    "            self.n_batch+=1\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c66df-7063-4c77-915b-2c2c8c1b4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TargetModelQCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe=None):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.learner = find_dp(traverse_dps(self),LearnerBase)\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learner.done_mask = batch.terminated.reshape(-1,)\n",
    "            with torch.no_grad():\n",
    "                self.learner.next_q = self.learner.target_model(batch.next_state)\n",
    "            self.learner.next_q = self.learner.next_q.max(dim=1).values.reshape(-1,1)\n",
    "            self.learner.next_q[self.learner.done_mask] = 0 \n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DQNTargetLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    do_logging:bool=True,\n",
    "    loss_func=nn.MSELoss(),\n",
    "    opt=optim.AdamW,\n",
    "    lr=0.005,\n",
    "    bs=128,\n",
    "    max_sz=10000,\n",
    "    nsteps=1,\n",
    "    device=None,\n",
    "    batches=None,\n",
    "    target_sync=300\n",
    ") -> LearnerHead:\n",
    "    learner = LearnerBase(model,dls=dls[0])\n",
    "    learner = BatchCollector(learner,batches=batches)\n",
    "    learner = EpochCollector(learner)\n",
    "    if do_logging: \n",
    "        learner = learner.dump_records()\n",
    "        learner = ProgressBarLogger(learner)\n",
    "        learner = RollingTerminatedRewardCollector(learner)\n",
    "        learner = EpisodeCollector(learner).catch_records()\n",
    "    learner = ExperienceReplay(learner,bs=bs,max_sz=max_sz)\n",
    "    learner = StepBatcher(learner,device=device)\n",
    "    learner = TargetModelQCalc(learner)\n",
    "    learner = TargetCalc(learner,nsteps=nsteps)\n",
    "    learner = LossCalc(learner,loss_func=loss_func)\n",
    "    learner = ModelLearnCalc(learner,opt=opt(model.parameters(),lr=lr))\n",
    "    learner = TargetModelUpdater(learner,target_sync=target_sync)\n",
    "    if do_logging: \n",
    "        learner = LossCollector(learner).catch_records()\n",
    "\n",
    "    if len(dls)==2:\n",
    "        val_learner = LearnerBase(model,dls[1]).visualize_vscode()\n",
    "        val_learner = BatchCollector(val_learner,batches=batches)\n",
    "        val_learner = EpochCollector(val_learner).catch_records(drop=True)\n",
    "        return LearnerHead((learner,val_learner))\n",
    "    else:\n",
    "        return LearnerHead(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4917308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.envs.gym import GymDataPipe\n",
    "from fastrl.dataloading.core import dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d510e-38c1-458c-9830-df5a68e6a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval:false\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,do_logging=True,min_epsilon=0.02,max_epsilon=1,max_steps=5000)\n",
    "# Setup the DataLoader\n",
    "params = dict(\n",
    "    source=['CartPole-v1']*1,\n",
    "    agent=agent,\n",
    "    nsteps=2,\n",
    "    nskips=2,\n",
    "    firstlast=True\n",
    ")\n",
    "dls = dataloaders((GymDataPipe(**params),GymDataPipe(**params,include_images=True).unbatch()))\n",
    "# Setup the Learner\n",
    "learner = DQNTargetLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    bs=128,\n",
    "    max_sz=100_000,\n",
    "    nsteps=2,\n",
    "    lr=0.01,\n",
    "    batches=1000,\n",
    "    target_sync=300\n",
    ")\n",
    "# learner.fit(7)\n",
    "learner.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6888519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval:false\n",
    "learner.validate(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval:false\n",
    "sample_run = learner.validate(2,show=False,return_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.agents.core import AgentHead,AgentBase\n",
    "from fastrl.agents.core import SimpleModelRunner\n",
    "from fastrl.memory.memory_visualizer import MemoryBufferViewer\n",
    "from fastrl.agents.core import StepFieldSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692662d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval:false\n",
    "def DQNValAgent(\n",
    "    model,\n",
    "    device='cpu'\n",
    ")->AgentHead:\n",
    "    agent_base = AgentBase(model)\n",
    "    agent = StepFieldSelector(agent_base,field='state')\n",
    "    agent = SimpleModelRunner(agent).to(device=device)\n",
    "    agent = AgentHead(agent)\n",
    "    return agent\n",
    "\n",
    "val_agent = DQNValAgent(model)\n",
    "MemoryBufferViewer(sample_run,val_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dd827a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
