{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastrl.test_utils import initialize_notebook\n",
    "initialize_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.dqn.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "from copy import deepcopy\n",
    "from typing import Optional,Callable,Tuple\n",
    "# Third party libs\n",
    "import torchdata.datapipes as dp\n",
    "from torchdata.dataloader2.graph import traverse_dps,DataPipe\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "# Local modulesf\n",
    "from fastrl.pipes.core import find_dp\n",
    "from fastrl.memory.experience_replay import ExperienceReplay\n",
    "from fastrl.loggers.core import BatchCollector,EpochCollector\n",
    "from fastrl.learner.core import LearnerBase,LearnerHead\n",
    "from fastrl.loggers.vscode_visualizers import VSCodeDataPipe\n",
    "from fastrl.agents.dqn.basic import (\n",
    "    LossCollector,\n",
    "    RollingTerminatedRewardCollector,\n",
    "    EpisodeCollector,\n",
    "    StepBatcher,\n",
    "    TargetCalc,\n",
    "    LossCalc,\n",
    "    ModelLearnCalc,\n",
    "    DQN,\n",
    "    DQNAgent\n",
    ")\n",
    "from fastrl.agents.dqn.target import (\n",
    "    TargetModelUpdater,\n",
    "    TargetModelQCalc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Double\n",
    "> Instead of using the actions from memory to train on, use the actions chosen by the current model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c98be0-6288-443a-b4ab-9390fbe3081c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Training DataPipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c66df-7063-4c77-915b-2c2c8c1b4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DoubleQCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe=None):\n",
    "        self.source_datapipe = source_datapipe\n",
    "                \n",
    "    def __iter__(self):\n",
    "        self.learner = find_dp(traverse_dps(self),LearnerBase)\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learner.done_mask = batch.terminated.reshape(-1,)\n",
    "            with torch.no_grad():\n",
    "                chosen_actions = self.learner.model(batch.next_state).argmax(dim=1).reshape(-1,1)\n",
    "                self.learner.next_q = self.learner.target_model(batch.next_state).gather(1,chosen_actions)\n",
    "            self.learner.next_q[self.learner.done_mask] = 0\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DoubleDQNLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    logger_bases:Optional[Callable]=None,\n",
    "    loss_func=nn.MSELoss(),\n",
    "    opt=optim.AdamW,\n",
    "    lr=0.005,\n",
    "    bs=128,\n",
    "    max_sz=10000,\n",
    "    nsteps=1,\n",
    "    device=None,\n",
    "    batches=None,\n",
    "    target_sync=300\n",
    ") -> LearnerHead:\n",
    "    learner = LearnerBase(model,dls=dls[0])\n",
    "    learner = BatchCollector(learner,batches=batches)\n",
    "    learner = EpochCollector(learner)\n",
    "    if logger_bases: \n",
    "        learner = logger_bases(learner)\n",
    "        learner = RollingTerminatedRewardCollector(learner)\n",
    "        learner = EpisodeCollector(learner)\n",
    "    learner = learner.catch_records()\n",
    "    learner = ExperienceReplay(learner,bs=bs,max_sz=max_sz)\n",
    "    learner = StepBatcher(learner,device=device)\n",
    "    # learner = TargetModelQCalc(learner)\n",
    "    learner = DoubleQCalc(learner)\n",
    "    learner = TargetCalc(learner,nsteps=nsteps)\n",
    "    learner = LossCalc(learner,loss_func=loss_func)\n",
    "    learner = ModelLearnCalc(learner,opt=opt(model.parameters(),lr=lr))\n",
    "    learner = TargetModelUpdater(learner,target_sync=target_sync)\n",
    "    if logger_bases: \n",
    "        learner = LossCollector(learner).catch_records()\n",
    "\n",
    "    if len(dls)==2:\n",
    "        val_learner = LearnerBase(model,dls[1])\n",
    "        val_learner = BatchCollector(val_learner,batches=batches)\n",
    "        val_learner = EpochCollector(val_learner).catch_records(drop=True)\n",
    "        val_learner = VSCodeDataPipe(val_learner)\n",
    "        return LearnerHead((learner,val_learner),model)\n",
    "    else:\n",
    "        return LearnerHead(learner,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f9ed8-fb05-40a1-ac0d-d4cafee8fa07",
   "metadata": {},
   "source": [
    "Try training with basic defaults..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.envs.gym import GymDataPipe\n",
    "from fastrl.loggers.core import ProgressBarLogger\n",
    "from fastrl.dataloading.core import dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9b481-5998-472a-a2df-18d79bf07ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval:false\n",
    "# Setup Loggers\n",
    "def logger_bases(pipe):\n",
    "    pipe = pipe.dump_records()\n",
    "    pipe = ProgressBarLogger(pipe)\n",
    "    return pipe\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,do_logging=True,min_epsilon=0.02,max_epsilon=1,max_steps=5000)\n",
    "# Setup the DataBlock\n",
    "train_pipe = GymDataPipe(\n",
    "    ['CartPole-v1']*1,\n",
    "    agent=agent,\n",
    "    nsteps=2,\n",
    "    nskips=2,\n",
    "    firstlast=True,\n",
    "    bs=1\n",
    ")\n",
    "dls = dataloaders(train_pipe)\n",
    "# Setup the Learner\n",
    "learner = DoubleDQNLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    logger_bases=logger_bases,\n",
    "    bs=128,\n",
    "    max_sz=100_000,\n",
    "    nsteps=2,\n",
    "    lr=0.01,\n",
    "    batches=1000,\n",
    "    target_sync=300\n",
    ")\n",
    "learner.fit(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0ed73-7bbf-415b-9ee7-9a95de31d638",
   "metadata": {},
   "source": [
    "The DQN learners, but I wonder if we can get it to learn faster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdef5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipe = GymDataPipe(\n",
    "    ['CartPole-v1']*1,\n",
    "    agent=agent,\n",
    "    nsteps=2,\n",
    "    nskips=2,\n",
    "    firstlast=True,\n",
    "    bs=1\n",
    ")\n",
    "dls = dataloaders([train_pipe,train_pipe])\n",
    "# Setup the Learner\n",
    "learner = DoubleDQNLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    logger_bases=logger_bases,\n",
    "    bs=128,\n",
    "    max_sz=100_000,\n",
    "    nsteps=2,\n",
    "    lr=0.01,\n",
    "    batches=1000,\n",
    "    target_sync=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de0f41e-2eda-4227-9fa8-f2e0b920754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval:false\n",
    "learner.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d3626-1702-4f22-ae15-bb93a75bec68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
