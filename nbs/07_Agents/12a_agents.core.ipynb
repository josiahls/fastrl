{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "from typing import List\n",
    "# Third party libs\n",
    "from fastcore.all import add_docs,ifnone\n",
    "import torchdata.datapipes as dp\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchdata.dataloader2.graph import find_dps,traverse_dps\n",
    "# Local modules\n",
    "from fastrl.core import *\n",
    "from fastrl.torch_core import *\n",
    "from fastrl.pipes.core import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Agent Core\n",
    "> Minimum Agent DataPipes, objects, and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a53f1-93ee-4540-8b8d-50071090280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class AgentBase(dp.iter.IterDataPipe):\n",
    "    def __init__(self,\n",
    "            model:nn.Module, # The base NN that we getting raw action values out of.\n",
    "            action_iterator:list=None, # A reference to an iterator that contains actions to process.\n",
    "            logger_bases=None\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.iterable = ifnone(action_iterator,[])\n",
    "        self.agent_base = self\n",
    "        self.logger_bases = logger_bases\n",
    "        \n",
    "    def to(self,*args,**kwargs):\n",
    "        self.model.to(**kwargs)\n",
    "\n",
    "    def __iter__(self):\n",
    "        while self.iterable:\n",
    "            yield self.iterable.pop(0)\n",
    "            \n",
    "add_docs(\n",
    "AgentBase,\n",
    "\"\"\"Acts as the footer of the Agent pipeline. \n",
    "Maintains important state such as the `model` being used for get actions from.\n",
    "Also optionally allows passing a reference list of `action_iterator` which is a\n",
    "persistent list of actions for the entire agent pipeline to process through.\n",
    "\n",
    "> Important: Must be at the start of the pipeline, and be used with AgentHead at the end.\n",
    "\n",
    "> Important: `action_iterator` is stored in the `iterable` field. However the recommended\n",
    "way of passing actions to the pipeline is to call an `AgentHead` instance.\n",
    "\"\"\",\n",
    "to=torch.Tensor.to.__doc__\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c9cc6-4be3-4606-b07d-12d30da2144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export               \n",
    "class AgentHead(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = find_dp(traverse_dps(self.source_datapipe),AgentBase)\n",
    "\n",
    "    def __call__(self,steps:list):\n",
    "        if issubclass(steps.__class__,StepType):\n",
    "            raise Exception(f'Expected List[{StepType}] object got {type(steps)}\\n{steps}')\n",
    "        self.agent_base.iterable.extend(steps)\n",
    "        return self\n",
    "\n",
    "    def __iter__(self): yield from self.source_datapipe\n",
    "    \n",
    "    def augment_actions(self,actions): return actions\n",
    "\n",
    "    def create_step(self,**kwargs): return SimpleStep(**kwargs)\n",
    "    \n",
    "add_docs(\n",
    "    AgentHead,\n",
    "    \"\"\"Acts as the head of the Agent pipeline. \n",
    "    Used for conveniently adding actions to the pipeline to process.\n",
    "    \n",
    "    > Important: Must be paired with `AgentBase`\n",
    "    \"\"\",\n",
    "    augment_actions=\"\"\"Called right before being fed into the env. \n",
    "    \n",
    "    > Important: The results of this function will not be kept / used in the step or forwarded to \n",
    "    any training code.\n",
    "\n",
    "    There are cases where either the entire action shouldn't be fed into the env,\n",
    "    or the version of the action that we want to train on would be compat with the env.\n",
    "    \n",
    "    This is also useful if we want to train on the original raw values of the action prior to argmax being run on it for example.\n",
    "    \"\"\",\n",
    "    create_step=\"Creates the step used by the env for running, and used by the model for training.\"\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b0d60-0d54-4cff-a5d1-7c0bbdeff571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SimpleModelRunner(dp.iter.IterDataPipe):\n",
    "    \"Takes input from `source_datapipe` and pushes through the agent bases model assuming there is only one model field.\"\n",
    "    def __init__(self,\n",
    "                 source_datapipe\n",
    "                ): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = find_dp(traverse_dps(self.source_datapipe),AgentBase)\n",
    "        self.device = None\n",
    "\n",
    "    def to(self,*args,**kwargs):\n",
    "        if 'device' in kwargs: self.device = kwargs.get('device',None)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for x in self.source_datapipe:\n",
    "            if self.device is not None: x = x.to(self.device)\n",
    "            if len(x.shape)==1: x = x.unsqueeze(0)\n",
    "            with evaluating(self.agent_base.model):\n",
    "                res = self.agent_base.model(x)\n",
    "            yield res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "177664aa-5b6d-4fe3-a1dd-7c261045dd84",
   "metadata": {},
   "source": [
    "Check that the 1x4 tensor assuccessfully pushes through the model can get expected outputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6291148-914f-4d2b-b924-f4a02a83d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Linear(state_sz,hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca892b7c-f36a-43d7-92eb-ceffc4b3b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastrl.agents.dqn.basic import DQN\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the agent\n",
    "agent = AgentBase(model)\n",
    "agent = SimpleModelRunner(agent)\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d6639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b9d8b-c2d1-461d-bad9-583c757fd9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = tensor([1,2,3,4]).float()\n",
    "\n",
    "for action in agent([input_tensor]):\n",
    "    print(action)\n",
    "    \n",
    "test_eq(input_tensor,tensor([1., 2., 3., 4.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae8542-7c38-41e2-8f7c-3259ebfb8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class StepFieldSelector(dp.iter.IterDataPipe):\n",
    "    \"Grabs `field` from `source_datapipe` to push to the rest of the pipeline.\"\n",
    "    def __init__(self,\n",
    "         source_datapipe, # datapipe whose next(source_datapipe) -> `StepType`\n",
    "         field='state' # A field in `StepType` to grab\n",
    "        ): \n",
    "        # TODO: support multi-fields\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.field = field\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,StepType):\n",
    "                raise Exception(f'Expected typing.NamedTuple object got {type(step)}\\n{step}')\n",
    "            yield getattr(step,self.field)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63928e34-7f29-4182-942a-a5edf444fb7e",
   "metadata": {},
   "source": [
    "Check that using `StepFieldSelector`, we can grab the `state` field from the `Simplestep` to push through the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b65fb9-e92c-4098-a1cf-8680b220367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = SimpleModelRunner(agent)\n",
    "agent = AgentHead(agent)\n",
    "\n",
    "for action in agent([SimpleStep.random(state=tensor([1.,2.,3.,4.]))]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48ec65-b385-4dea-87c8-f58c202d2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the agent\n",
    "agent = AgentBase(model,[])\n",
    "# All the things that make this agent unique and special\n",
    "# In this instance, all this module does is pass the action directly through to the model.\n",
    "agent = SimpleModelRunner(agent)\n",
    "# Bring everything together into the AgentHead where actions will be passed and then run through the pipeline\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc2bb26b-2ade-44d2-970c-7fff000d0ed6",
   "metadata": {},
   "source": [
    "If we pass a list of tensors, we will get a list of actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330318f5-4423-4174-b9fe-499bcbb9de85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for action in agent([tensor([1,2,3,4]).float()]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e1141-4961-45dd-ad4e-2d8f049f5294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for action in agent([tensor([1,2,3,4]).float()]*3):\n",
    "    print(action)\n",
    "traverse_dps(agent); # Check that we can traverse it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e74c7bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Type' from 'torchdata.dataloader2.graph' (/usr/local/lib/python3.8/dist-packages/torchdata/dataloader2/graph/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmap\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblock\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgym\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/fastrl/fastrl/pipes/map/transforms.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdp\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmap\u001b[39;00m \u001b[39mimport\u001b[39;00m MapDataPipe\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataloader2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph\u001b[39;00m \u001b[39mimport\u001b[39;00m find_dps,DataPipeGraph,Type,DataPipe\n\u001b[1;32m     14\u001b[0m \u001b[39m# Local modules\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[39m# %% ../../../nbs/01_DataPipes/01h_pipes.map.transforms.ipynb 5\u001b[39;00m\n\u001b[1;32m     17\u001b[0m T_co \u001b[39m=\u001b[39m TypeVar(\u001b[39m\"\u001b[39m\u001b[39mT_co\u001b[39m\u001b[39m\"\u001b[39m, covariant\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Type' from 'torchdata.dataloader2.graph' (/usr/local/lib/python3.8/dist-packages/torchdata/dataloader2/graph/__init__.py)"
     ]
    }
   ],
   "source": [
    "from fastrl.pipes.core import *\n",
    "from fastrl.pipes.map.transforms import *\n",
    "from fastrl.data.block import *\n",
    "from fastrl.envs.gym import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7496dbff-cda7-4826-8d2e-f4663d46430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def baseline_test(envs,total_steps,seed=0):\n",
    "#     pipe = dp.map.Mapper(envs)\n",
    "#     pipe = TypeTransformer(pipe,[GymTypeTransform])\n",
    "#     pipe = dp.iter.MapToIterConverter(pipe)\n",
    "#     pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "#     pipe = pipe.cycle()\n",
    "#     pipe = GymStepper(pipe,seed=seed)\n",
    "\n",
    "#     steps = [step for _,step in zip(*(range(total_steps),pipe))]\n",
    "#     return steps, pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e00ef9-f09d-475a-b28f-6878044feb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps, pipe = baseline_test(['CartPole-v1'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5dd6a2-fd98-49f1-beee-fa5ed97e2764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class StepModelFeeder(dp.iter.IterDataPipe):\n",
    "    def __init__(self,\n",
    "                 source_datapipe, # next() must produce a `StepType`,\n",
    "                 keys:List[str] # A list of field names to grab and push into `self.agent_base.model`\n",
    "                ): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.keys = keys\n",
    "        self.agent_base = find_dp(traverse_dps(self.source_datapipe),AgentBase)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for step in self.source_datapipe: \n",
    "            \n",
    "            if not issubclass(step.__class__,StepType):\n",
    "                raise Exception(f'Expected {StepType} object got {type(step)}\\n{step}')\n",
    "            \n",
    "            tensors = tuple(getattr(step,k) for k in self.keys)\n",
    "            \n",
    "            try: yield self.agent_base.model(tensors)\n",
    "            except Exception:\n",
    "                print('Failed on ',step)\n",
    "                raise\n",
    "        \n",
    "add_docs(\n",
    "    StepModelFeeder,\n",
    "    \"\"\"Converts `StepTypes` into unified tensors using `keys` and feeds them into `self.agent_base.model`\n",
    "    \"\"\"\n",
    ")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff29b3a-9c5f-415b-a102-f8d41d275447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class NumpyConverter(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "\n",
    "    def __init__(self,source_datapipe): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        \n",
    "    def debug_display(self,step):\n",
    "        print(f'Step: {step}')\n",
    "    \n",
    "    def __iter__(self) -> torch.LongTensor:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,torch.Tensor):\n",
    "                raise Exception(f'Expected Tensor to  convert to numpy, got {type(step)}\\n{step}')\n",
    "            if self.debug: self.debug_display(step)\n",
    "            yield step.detach().cpu().numpy()\n",
    "\n",
    "add_docs(\n",
    "NumpyConverter,\n",
    "\"\"\"Given input `Tensor` from `source_datapipe` returns a numpy array of same shape with argmax set to 1.\"\"\",\n",
    "debug_display=\"Display the step being processed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41a38b6-3849-450a-88f7-b4e6300ba5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = [tensor([4]) for _ in range(10)]\n",
    "pipe = NumpyConverter(tensors)\n",
    "list(pipe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20feb80b-2418-4bc2-b552-d0d0cad660c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#|eval:false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tensors \u001b[38;5;241m=\u001b[39m [tensor([\u001b[38;5;241m4\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)]\n\u001b[1;32m      3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m NumpyConverter(tensors)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mlist\u001b[39m(pipe);\n",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#|eval:false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tensors \u001b[38;5;241m=\u001b[39m [\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)]\n\u001b[1;32m      3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m NumpyConverter(tensors)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mlist\u001b[39m(pipe);\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:264\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    263\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 264\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    265\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    268\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "#|eval:false\n",
    "tensors = [tensor([4]).to(device='cuda') for _ in range(10)]\n",
    "pipe = NumpyConverter(tensors)\n",
    "list(pipe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/nbdev/export.py:54: UserWarning: Notebook '/home/fastrl_user/fastrl/nbs/07_Agents/02_Continuous/12u_agents.ppo.ipynb' uses `#|export` without `#|default_exp` cell.\n",
      "Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\n",
      "See https://nbdev.fast.ai/getting_started.html for more information.\n",
      "  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\"\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8d259e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
