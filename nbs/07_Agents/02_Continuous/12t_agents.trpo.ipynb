{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.trpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "\n",
    "# Third party libs\n",
    "\n",
    "# Local modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a258abcf",
   "metadata": {},
   "source": [
    "# TRPO\n",
    "> Trust Region Policy Optimization via online-learning for continuous action domains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5b8f6",
   "metadata": {},
   "source": [
    "[(Schulman et al., 2017) [TRPO] Trust Region Policy Optimization](https://arxiv.org/abs/1502.05477)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d62d5ed",
   "metadata": {},
   "source": [
    "## Memory\n",
    "> Policy gradient online models use short term trajectory samples instead of\n",
    "ER / iid memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class A:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed71a089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
