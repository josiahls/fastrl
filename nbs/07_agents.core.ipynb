{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "import torch\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "# Local modules\n",
    "from fastrl.core import *\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.pipes.map.demux import *\n",
    "from fastrl.pipes.map.mux import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Agent Core\n",
    "> Minimum Agent DataPipes, objects, and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "984a53f1-93ee-4540-8b8d-50071090280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class AgentBase(dp.iter.IterDataPipe):\n",
    "    def __init__(self,\n",
    "            model:Module, # The base NN that we getting raw action values out of.\n",
    "            action_iterator:list=None # A reference to an iterator that contains actions to process.\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.iterable = ifnone(action_iterator,[])\n",
    "        self.agent_base = self\n",
    "        \n",
    "    def __iter__(self):\n",
    "        while self.iterable:\n",
    "            yield self.iterable.pop(0)\n",
    "            \n",
    "add_docs(\n",
    "    AgentBase,\n",
    "    \"\"\"Acts as the footer of the Agent pipeline. \n",
    "    Maintains important state such as the `model` being used for get actions from.\n",
    "    Also optionally allows passing a reference list of `action_iterator` which is a\n",
    "    persistent list of actions for the entire agent pipeline to process through.\n",
    "    \n",
    "    > Important: Must be at the start of the pipeline, and be used with AgentHead at the end.\n",
    "    \n",
    "    > Important: `action_iterator` is stored in the `iterable` field. However the recommended\n",
    "    way of passing actions to the pipeline is to call an `AgentHead` instance.\n",
    "    \"\"\"\n",
    "    \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742c9cc6-4be3-4606-b07d-12d30da2144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export               \n",
    "def is_agent_base(pipe): return isinstance(pipe,AgentBase)\n",
    "def find_agent_base(pipe):\n",
    "    \"Basically just find_pipes+is_agent_base with exception handling\"\n",
    "    agent_base = find_pipes(pipe,is_agent_base)\n",
    "    if not agent_base:\n",
    "        raise Exception('`AgentBase` must be at the start of the pipeline, but it seems to be missing.')\n",
    "    return agent_base[0]\n",
    "\n",
    "class AgentHead(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = find_agent_base(self.source_datapipe)\n",
    "\n",
    "    def __call__(self,steps:list):\n",
    "        if issubclass(steps.__class__,StepType):\n",
    "            raise Exception(f'Expected List[{StepType}] object got {type(steps)}\\n{steps}')\n",
    "        self.agent_base.iterable.extend(steps)\n",
    "        return self\n",
    "\n",
    "    def __iter__(self): yield from self.source_datapipe\n",
    "    \n",
    "add_docs(\n",
    "    AgentHead,\n",
    "    \"\"\"Acts as the head of the Agent pipeline. \n",
    "    Used for conveniently adding actions to the pipeline to process.\n",
    "    \n",
    "    > Important: Must be paired with `AgentBase`\n",
    "    \"\"\"\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a967a3-e169-4253-908f-0bce2dff16fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)\n",
    "\n",
    "class SimpleModelRunner(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = find_agent_base(self.source_datapipe)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for o in self.source_datapipe: \n",
    "            try: yield self.agent_base.model(o)\n",
    "            except Exception:\n",
    "                print('Failed on ',o)\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a48ec65-b385-4dea-87c8-f58c202d2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the agent\n",
    "agent = AgentBase(model,[])\n",
    "# All the things that make this agent unique and special\n",
    "# In this instance, all this module does is pass the action directly through to the model.\n",
    "agent = SimpleModelRunner(agent)\n",
    "# Bring everything together into the AgentHead where actions will be passed and then run through the pipeline\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bb26b-2ade-44d2-970c-7fff000d0ed6",
   "metadata": {},
   "source": [
    "If we pass a list of tensors, we will get a list of actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "330318f5-4423-4174-b9fe-499bcbb9de85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2909, -1.0357], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for action in agent([tensor([1,2,3,4]).float()]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "385e1141-4961-45dd-ad4e-2d8f049f5294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2909, -1.0357], grad_fn=<AddBackward0>)\n",
      "tensor([-0.2909, -1.0357], grad_fn=<AddBackward0>)\n",
      "tensor([-0.2909, -1.0357], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for action in agent([tensor([1,2,3,4]).float()]*3):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81907bf7-dab1-4908-a82f-35842cf66b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchdata.datapipes.utils import to_graph\n",
    "# to_graph(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7496dbff-cda7-4826-8d2e-f4663d46430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.fastai.data.pipes.core import *\n",
    "from fastrl.fastai.data.load import *\n",
    "from fastrl.fastai.data.block import *\n",
    "from fastrl.envs.gym import *\n",
    "\n",
    "def baseline_test(envs,total_steps,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformLoop(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle()\n",
    "    pipe = GymStepper(pipe,seed=seed)\n",
    "\n",
    "    steps = [step for _,step in zip(*(range(total_steps),pipe))]\n",
    "    return steps, pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30e00ef9-f09d-475a-b28f-6878044feb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, pipe = baseline_test(['CartPole-v1'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da5dd6a2-fd98-49f1-beee-fa5ed97e2764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class StepModelFeeder(dp.iter.IterDataPipe):\n",
    "    def __init__(self,\n",
    "                 source_datapipe, # next() must produce a `StepType`,\n",
    "                 keys:List[str] # A list of field names to grab and push into `self.agent_base.model`\n",
    "                ): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.keys = keys\n",
    "        self.agent_base = find_agent_base(self.source_datapipe)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for o in self.source_datapipe: \n",
    "            \n",
    "            if not issubclass(b.__class__,StepType):\n",
    "                raise Exception(f'Expected {StepType} object got {type(step)}\\n{step}')\n",
    "            \n",
    "            tensors = tuple(getattr(o,k) for k in self.keys)\n",
    "            \n",
    "            try: yield self.agent_base.model(tensors)\n",
    "            except Exception:\n",
    "                print('Failed on ',o)\n",
    "                raise\n",
    "        \n",
    "add_docs(\n",
    "    StepModelFeeder,\n",
    "    \"\"\"Converts `StepTypes` into unified tensors using `keys` and feeds them into `self.agent_base.model`\n",
    "    \"\"\"\n",
    ")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caf56ffb-9200-4a0c-ae77-3fd2d11a3146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# #|export\n",
    "# class DiscreteEpsilonRandomSelect(dp.iter.IterDataPipe):\n",
    "#     debug=False\n",
    "#     def __init__(self,source_datapipe,agent_base,n_actions,idx=0,min_epsilon=0.2,max_epsilon=1,max_steps=5000):\n",
    "#         self.n_actions = n_actions\n",
    "#         self.source_datapipe = source_datapipe\n",
    "#         self.agent_base = agent_base\n",
    "#         self.agent_base.epislon_selector = self \n",
    "#         self.min_epsilon = min_epsilon\n",
    "#         self.epsilon = max_epsilon\n",
    "#         self.max_epsilon = max_epsilon\n",
    "#         self.max_steps = max_steps\n",
    "#         self.idx = idx\n",
    "    \n",
    "#     def __iter__(self):\n",
    "#         for action in self.source_datapipe:\n",
    "#             mask = np.random.random(size=self.n_actions) < self.epsilon\n",
    "#             rand_actions = np.random.choice(self.n_actions, sum(mask))\n",
    "#             action = action.cpu().detach().numpy().reshape((-1,))\n",
    "#             action[mask] = rand_actions\n",
    "#             action=Tensor(action).long().reshape(-1,1)\n",
    "\n",
    "#             if self.agent_base.model.training: \n",
    "#                 self.idx += 1\n",
    "#                 self.epsilon = max(self.min_epsilon,self.max_epsilon-self.idx/self.max_steps)\n",
    "#             yield action\n",
    "\n",
    "# #|export\n",
    "# from torch.nn import *\n",
    "# from torch.optim import *\n",
    "# from fastai.torch_basics import *\n",
    "# from fastai.torch_core import *\n",
    "\n",
    "# class DQN(Module):\n",
    "#     def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "#         self.layers=Sequential(\n",
    "#             Linear(state_sz,hidden),\n",
    "#             ReLU(),\n",
    "#             Linear(hidden,action_sz),\n",
    "#         )\n",
    "#     def forward(self,x): return self.layers(x)\n",
    "\n",
    "\n",
    "# class RawOutOfStep(dp.iter.IterDataPipe):\n",
    "#     def __init__(self,source_datapipe,agent_base,key): \n",
    "#         self.source_datapipe = source_datapipe\n",
    "#         self.key = key\n",
    "#         self.agent_base = agent_base\n",
    "        \n",
    "#     def __iter__(self):\n",
    "#         for o in self.source_datapipe:\n",
    "#             x = tensor(o[self.key])\n",
    "#             x = self.agent_base.model(x)\n",
    "#             yield x\n",
    "            \n",
    "# class ArgmaxOfStep(dp.iter.IterDataPipe):\n",
    "#     def __init__(self,source_datapipe,agent_base): \n",
    "#         self.source_datapipe = source_datapipe\n",
    "#         self.agent_base = agent_base\n",
    "        \n",
    "#     def __iter__(self):\n",
    "#         for o in self.source_datapipe:\n",
    "#             yield torch.argmax(o)\n",
    "            \n",
    "# class ToDiscrete(dp.iter.IterDataPipe):\n",
    "#     def __init__(self,source_datapipe,agent_base): \n",
    "#         self.source_datapipe = source_datapipe\n",
    "#         self.agent_base = agent_base\n",
    "        \n",
    "#     def __iter__(self):\n",
    "#         for x in self.source_datapipe:\n",
    "#             if isinstance(x,Tensor):\n",
    "#                 if len(x.shape)==0:\n",
    "#                     yield int(x)\n",
    "#                 else:\n",
    "#                     yield x.long()\n",
    "#             else:\n",
    "#                 raise Exception(f'Cant convert to discrete: {x}')\n",
    "\n",
    "# # Setup up the core NN\n",
    "# model = DQN(4,2)\n",
    "# # Setup the agent\n",
    "# agent_base = Agent(model,[])\n",
    "# agent = RawOutOfStep(agent_base,agent_base,'state')\n",
    "# agent_ep = DiscreteEpsilonRandomSelect(agent,agent_base,2,min_epsilon=0)\n",
    "# agent = ArgmaxOfStep(agent_ep,agent_base)\n",
    "# agent = ToDiscrete(agent,agent_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5f7311-f9ea-4a67-b504-427cb509f5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
