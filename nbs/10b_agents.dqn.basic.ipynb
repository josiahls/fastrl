{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp agents.dqn.basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "# Local modules\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "\n",
    "from fastrl.core import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.fastai.data.load import *\n",
    "from fastrl.fastai.data.block import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Basic\n",
    "> Core DQN modules, pipes, and tooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4fb528-cd3d-4dbe-87ff-cf06c60b1168",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6241ea68-611d-4cdf-abdb-4e2a58af23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0f4eb63-65c9-4226-a033-ecbb097f616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BasicModelForwarder(dp.iter.IterDataPipe):\n",
    "    \"Takes input from `source_datapipe` and pushes through the agent bases model assuming there is only one model field.\"\n",
    "    def __init__(self,source_datapipe): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = find_agent_base(self.source_datapipe)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        yield from map(self.agent_base.model,self.source_datapipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5dff0-4b6f-4513-9565-f363c5087cdc",
   "metadata": {},
   "source": [
    "Check that the 1x4 tensor assuccessfully pushes through the model can get expected outputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "498f7b8c-1de3-442e-94d6-7fb2a1f5baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the agent\n",
    "agent = AgentBase(model)\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d8e8699-c6b2-4bef-98c9-9057a190bfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2909, -1.0357], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for action in agent([tensor([1,2,3,4]).float()]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a3558a6-eb99-4f68-983c-9b25532a5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class StepFieldSelector(dp.iter.IterDataPipe):\n",
    "    \"Grabs `field` from `source_datapipe` to push to the rest of the pipeline.\"\n",
    "    def __init__(self,\n",
    "         source_datapipe, # datapipe whose next(source_datapipe) -> `StepType`\n",
    "         field='state' # A field in `StepType` to grab\n",
    "        ): \n",
    "        # TODO: support multi-fields\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.field = field\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,StepType):\n",
    "                raise Exception(f'Expected typing.NamedTuple object got {type(step)}\\n{step}')\n",
    "            yield getattr(step,self.field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382f58d7-3f2f-4c1e-b2f3-1906e9c64a2b",
   "metadata": {},
   "source": [
    "Check that using `StepFieldSelector`, we can grab the `state` field from the `Simplestep` to push through the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e46e30b-757f-472f-86ae-ccbe2cf11932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2909, -1.0357], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = AgentHead(agent)\n",
    "\n",
    "for action in agent([SimpleStep.random(state=tensor([1.,2.,3.,4.]))]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a55397ec-c070-4d14-a6ab-c1202284eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ArgMaxer(dp.iter.IterDataPipe):\n",
    "    \"Given input `Tensor` from `source_datapipe` returns a tensor of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe): \n",
    "        self.source_datapipe = source_datapipe\n",
    "    \n",
    "    def __iter__(self) -> torch.LongTensor:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor to take the argmax, got {type(step)}\\n{step}')\n",
    "            # Might want to support simple tuples also depending on if we are processing multiple fields.\n",
    "            idx = torch.argmax(step)\n",
    "            step[:] = 0\n",
    "            step[idx] = 1\n",
    "            yield step.long()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bb8e39ab-45fd-4e71-96c1-24bdfdff10aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "agent = AgentHead(agent)\n",
    "\n",
    "for action in agent([SimpleStep.random(state=tensor([1.,2.,3.,4.]))]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "29a4ba91-a6f7-4c31-906d-6d1a88d0ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EpsilonSelector(dp.iter.IterDataPipe):\n",
    "    \"Given input `Tensor` from `source_datapipe`.\"\n",
    "    def __init__(self,\n",
    "            source_datapipe, # a datapipe whose next(source_datapipe) -> `Tensor` \n",
    "            min_epsilon:float=0.2, # The minimum epsilon to drop to\n",
    "            # The max/starting epsilon if `epsilon` is None and used for calculating epislon decrease speed.\n",
    "            max_epsilon:float=1, \n",
    "            # Determines how fast the episilon should drop to `min_epsilon`. This should be the number\n",
    "            # of steps that the agent was run through.\n",
    "            max_steps:int=100,\n",
    "            # The starting epsilon\n",
    "            epsilon:float=None,\n",
    "            # Based on the `base_agent.model.training`, by default no decrement or step tracking will\n",
    "            # occur during validation steps.\n",
    "            decrement_on_val:bool=False,\n",
    "            # Based on the `base_agent.model.training`, by default random actions will not be attempted\n",
    "            select_on_val:bool=False,\n",
    "            # Also return the mask that, where True, the action should be randomly selected.\n",
    "            ret_mask:bool=False\n",
    "        ): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.max_steps = max_steps\n",
    "        self.epsilon = epsilon\n",
    "        self.decrement_on_val = decrement_on_val\n",
    "        self.select_on_val = select_on_val\n",
    "        self.ret_mask = ret_mask\n",
    "        self.agent_base = find_agent_base(self.source_datapipe)\n",
    "        self.step = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for action in self.source_datapipe:\n",
    "            # TODO: Support tuples of actions also\n",
    "            if not issubclass(action.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor, got {type(action)}\\n{action}')\n",
    "            if action.dtype!=torch.int64:\n",
    "                raise ValueError(f'Expected Tensor of dtype int64, got: {action.dtype} from {self.source_datapipe}')\n",
    "                \n",
    "            if self.agent_base.model.training or self.decrement_on_val:\n",
    "                self.step+=1\n",
    "                \n",
    "            self.epsilon=max(self.min_epsilon,self.max_epsilon-self.step/self.max_steps)\n",
    "            # Add a batch dim if missing\n",
    "            if len(action.shape)==1: action.unsqueeze_(0)\n",
    "            mask = None\n",
    "            if self.agent_base.model.training or self.select_on_val:\n",
    "                # Given N(action.shape[0]) actions, select the ones we want to randomly assign... \n",
    "                mask = torch.rand(action.shape[0],)<self.epsilon\n",
    "                # Get random actions as their indexes\n",
    "                rand_action_idxs = torch.LongTensor(mask.sum().long(),).random_(action.shape[1])\n",
    "                print(torch.LongTensor(mask.sum().long(),).random_(action.shape[1]))\n",
    "                print(action.shape[1],mask.sum().long())\n",
    "                # If the input action is [[0,1],[1,0]] and...\n",
    "                # If mask is [True,False] and...\n",
    "                # if rand_action_idxs is [0]\n",
    "                # the action[mask] will have [[1,0]] assigned to it resulting in... \n",
    "                # an action with [[1,0],[1,0]]\n",
    "                # print(action.shape[1])\n",
    "                print(rand_action_idxs)#,F.one_hot(rand_action_idxs,action.shape[1]))\n",
    "                action[mask] = F.one_hot(rand_action_idxs,action.shape[1])\n",
    "            \n",
    "            yield ((action,mask) if self.ret_mask else action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b8808a-9b40-4887-81ee-cc95cca5471f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "123c1428-c145-4fff-aebe-7f2a230df49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "        1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "        1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "        0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(200,).random_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "384fa4e5-649b-4357-ac2a-278eaa8a5d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "2 tensor(200)\n",
      "tensor(0)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=1,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n",
    "    test_eq(mask.sum(),200)\n",
    "    print(action)\n",
    "    print(selector.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "88a3f86b-e035-43e0-a8c5-b354cf38152a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor(1) tensor([0, 1])\n",
      "tensor([[0, 1]])\n"
     ]
    }
   ],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "agent = EpsilonSelector(agent)\n",
    "agent = AgentHead(agent)\n",
    "\n",
    "for action in agent([SimpleStep.random(state=tensor([1.,2.,3.,4.]))]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f9d78f-6828-4b6a-87ce-675f0fef9509",
   "metadata": {},
   "source": [
    "Check that if min_epsilon=1, actions are randomly selected 100% of the time..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d75d83e-718a-4c8f-910d-e142f2188a70",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cfe338-de27-4c61-a18d-d74ea33fde37",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f18bb6-1e74-4a17-be8f-a1b36c4f2253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
