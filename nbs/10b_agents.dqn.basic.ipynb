{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp agents.dqn.basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from collections import deque\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from torch.utils.data.datapipes._typing import _DataPipeMeta, _IterDataPipeMeta\n",
    "# Local modules\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "\n",
    "from fastrl.core import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.fastai.data.load import *\n",
    "from fastrl.fastai.data.block import *\n",
    "from fastrl.memory.experience_replay import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Basic\n",
    "> Core DQN modules, pipes, and tooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4fb528-cd3d-4dbe-87ff-cf06c60b1168",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6241ea68-611d-4cdf-abdb-4e2a58af23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f4eb63-65c9-4226-a033-ecbb097f616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BasicModelForwarder(dp.iter.IterDataPipe):\n",
    "    \"Takes input from `source_datapipe` and pushes through the agent bases model assuming there is only one model field.\"\n",
    "    def __init__(self,source_datapipe): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = find_agent_base(self.source_datapipe)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for state in self.source_datapipe:\n",
    "            if len(state.shape)==1:\n",
    "                state.unsqueeze_(0)\n",
    "            yield self.agent_base.model(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5dff0-4b6f-4513-9565-f363c5087cdc",
   "metadata": {},
   "source": [
    "Check that the 1x4 tensor assuccessfully pushes through the model can get expected outputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498f7b8c-1de3-442e-94d6-7fb2a1f5baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the agent\n",
    "agent = AgentBase(model)\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d8e8699-c6b2-4bef-98c9-9057a190bfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for action in agent([tensor([1,2,3,4]).float()]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a3558a6-eb99-4f68-983c-9b25532a5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class StepFieldSelector(dp.iter.IterDataPipe):\n",
    "    \"Grabs `field` from `source_datapipe` to push to the rest of the pipeline.\"\n",
    "    def __init__(self,\n",
    "         source_datapipe, # datapipe whose next(source_datapipe) -> `StepType`\n",
    "         field='state' # A field in `StepType` to grab\n",
    "        ): \n",
    "        # TODO: support multi-fields\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.field = field\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,StepType):\n",
    "                raise Exception(f'Expected typing.NamedTuple object got {type(step)}\\n{step}')\n",
    "            yield getattr(step,self.field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382f58d7-3f2f-4c1e-b2f3-1906e9c64a2b",
   "metadata": {},
   "source": [
    "Check that using `StepFieldSelector`, we can grab the `state` field from the `Simplestep` to push through the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e46e30b-757f-472f-86ae-ccbe2cf11932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = AgentHead(agent)\n",
    "\n",
    "for action in agent([SimpleStep.random(state=tensor([1.,2.,3.,4.]))]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a55397ec-c070-4d14-a6ab-c1202284eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ArgMaxer(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \n",
    "    \"Given input `Tensor` from `source_datapipe` returns a tensor of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe,axis=1): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.axis = axis\n",
    "        \n",
    "    def debug_display(self,step,idx):\n",
    "        print(f'Step: {step}\\n{idx}')\n",
    "    \n",
    "    def __iter__(self) -> torch.LongTensor:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor to take the argmax, got {type(step)}\\n{step}')\n",
    "            # Might want to support simple tuples also depending on if we are processing multiple fields.\n",
    "            idx = torch.argmax(step,axis=self.axis).reshape(-1,1)\n",
    "            step[:] = 0\n",
    "            if self.debug: self.debug_display(step,idx)\n",
    "            step.scatter_(1,idx,1)\n",
    "            yield step.long()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb8e39ab-45fd-4e71-96c1-24bdfdff10aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0]])\n"
     ]
    }
   ],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "agent = AgentHead(agent)\n",
    "\n",
    "for action in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a4ba91-a6f7-4c31-906d-6d1a88d0ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EpsilonSelector(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \"Given input `Tensor` from `source_datapipe`.\"\n",
    "    def __init__(self,\n",
    "            source_datapipe, # a datapipe whose next(source_datapipe) -> `Tensor` \n",
    "            min_epsilon:float=0.2, # The minimum epsilon to drop to\n",
    "            # The max/starting epsilon if `epsilon` is None and used for calculating epislon decrease speed.\n",
    "            max_epsilon:float=1, \n",
    "            # Determines how fast the episilon should drop to `min_epsilon`. This should be the number\n",
    "            # of steps that the agent was run through.\n",
    "            max_steps:int=100,\n",
    "            # The starting epsilon\n",
    "            epsilon:float=None,\n",
    "            # Based on the `base_agent.model.training`, by default no decrement or step tracking will\n",
    "            # occur during validation steps.\n",
    "            decrement_on_val:bool=False,\n",
    "            # Based on the `base_agent.model.training`, by default random actions will not be attempted\n",
    "            select_on_val:bool=False,\n",
    "            # Also return the mask that, where True, the action should be randomly selected.\n",
    "            ret_mask:bool=False\n",
    "        ): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.max_steps = max_steps\n",
    "        self.epsilon = epsilon\n",
    "        self.decrement_on_val = decrement_on_val\n",
    "        self.select_on_val = select_on_val\n",
    "        self.ret_mask = ret_mask\n",
    "        self.agent_base = find_agent_base(self.source_datapipe)\n",
    "        self.step = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for action in self.source_datapipe:\n",
    "            # TODO: Support tuples of actions also\n",
    "            if not issubclass(action.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor, got {type(action)}\\n{action}')\n",
    "            if action.dtype!=torch.int64:\n",
    "                raise ValueError(f'Expected Tensor of dtype int64, got: {action.dtype} from {self.source_datapipe}')\n",
    "                \n",
    "            if self.agent_base.model.training or self.decrement_on_val:\n",
    "                self.step+=1\n",
    "                \n",
    "            self.epsilon=max(self.min_epsilon,self.max_epsilon-self.step/self.max_steps)\n",
    "            # Add a batch dim if missing\n",
    "            if len(action.shape)==1: action.unsqueeze_(0)\n",
    "            mask = None\n",
    "            if self.agent_base.model.training or self.select_on_val:\n",
    "                # Given N(action.shape[0]) actions, select the ones we want to randomly assign... \n",
    "                mask = torch.rand(action.shape[0],)<self.epsilon\n",
    "                # Get random actions as their indexes\n",
    "                rand_action_idxs = torch.LongTensor(int(mask.sum().long()),).random_(action.shape[1])\n",
    "                # If the input action is [[0,1],[1,0]] and...\n",
    "                # If mask is [True,False] and...\n",
    "                # if rand_action_idxs is [0]\n",
    "                # the action[mask] will have [[1,0]] assigned to it resulting in... \n",
    "                # an action with [[1,0],[1,0]]\n",
    "                # print(action.shape[1])\n",
    "                if self.debug: print(f'Mask: {mask}\\nRandom Actions: {rand_action_idxs}\\nPre-random Actions: {action}')\n",
    "                action[mask] = F.one_hot(rand_action_idxs,action.shape[1])\n",
    "            \n",
    "            yield ((action,mask) if self.ret_mask else action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859ecb6-9849-4240-a617-d75fc7070b03",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=1`, that the actions have 100% likihood of randomness applied \n",
    "(even though some might not change due to the random action matching the chosen action). Check that this \n",
    "works on a large batch of `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "384fa4e5-649b-4357-ac2a-278eaa8a5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=1,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n",
    "    test_eq(mask.sum(),200)\n",
    "    test_ne(action.sum(0)[0],200) # Only some of the actions should 1\n",
    "    test_ne(action.sum(0)[1],0) # Only some of the actions should be 0\n",
    "    test_eq(selector.epsilon,1)\n",
    "    test_eq(selector.step,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a711ee-333b-49d7-b849-c3f517079478",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=1`, that the actions have 100% likihood of randomness applied \n",
    "(even though some might not change due to the random action matching the chosen action). Check that this \n",
    "works on single batches over `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56415726-46c2-47a1-88c9-37a0f0af452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ArgMaxer.debug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "030017f4-f373-40ef-978e-fe0c9d2ace06",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent,axis=1)\n",
    "selector = EpsilonSelector(agent,min_epsilon=1,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "        test_eq(mask.sum(),1)\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "test_ne(actions.sum(0)[0],200) # Only some of the actions should 1\n",
    "test_ne(actions.sum(0)[1],0) # Only some of the actions should be 0\n",
    "test_eq(selector.epsilon,1)\n",
    "test_eq(selector.step,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bda9f9-5aaf-427a-b7ae-e61bf0bcc194",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=0`, that the actions have 0% likihood of randomness applied. Check that this \n",
    "works on a large batch of `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c790b227-fc40-49fd-9e0f-4e792a000962",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=0,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n",
    "    test_eq(mask.sum(),0)\n",
    "    test_eq(action.sum(0)[0],200) # All the \"left\" actions should be 1\n",
    "    test_eq(action.sum(0)[1],0) # All the \"right\" actions should be 0\n",
    "    test_eq(selector.epsilon,0)\n",
    "    test_eq(selector.step,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521693a5-8d31-42ee-ad47-566f35f00649",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=0`, that the actions have 0% likihood of randomness applied. Check that this \n",
    "works on single batches over `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4dbb3cb-ddc1-4d77-aad6-05c7510948fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=0,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "        test_eq(mask.sum(),0)\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "test_eq(actions.sum(0)[0],200) # All the \"left\" actions should be 1\n",
    "test_eq(actions.sum(0)[1],0) # All the \"right\" actions should be 0\n",
    "test_eq(selector.epsilon,0)\n",
    "test_eq(selector.step,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee0a64-d23c-472b-a8f5-7b6ea8099e9c",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=1`, the actions should become less random\n",
    "as the steps go on. Check that this works on a large batch of `200 steps`...\n",
    "\n",
    "`epislon` should be 0 at the end of this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dca194b-aae5-4c3d-b18b-d94e00c623f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "masks = None\n",
    "epsilons = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "        if masks is None: masks = mask\n",
    "        else:             masks = torch.hstack((masks,mask))\n",
    "        if epsilons is None: epsilons = tensor([selector.epsilon])\n",
    "        else:                epsilons = torch.hstack((epsilons,tensor([selector.epsilon])))\n",
    "        \n",
    "test_ne(masks[:((200*200)//2)].sum(),200) # We do not expect this to equal a perfect 200...\n",
    "test_ne(masks[:((200*200)//2)].sum(),0)   # ... but we also dont expect it to be 0\n",
    "assert 1000<masks[:((200*200)//2)].sum()<10_000,\\\n",
    "        \"\"\"We expect this to be somewhere between 1000 and 10,000, generally in the 9000 range since \n",
    "           for 200 steps, we are running 200 inputs\"\"\"\n",
    "test_eq(masks[((200*200)//2):].sum(),0) # We fully expect this to be 0 after the half way point\n",
    "test_ne(actions.sum(0)[0],200) # All the \"left\" generally shouldnt be 1\n",
    "test_ne(actions.sum(0)[1],0) # All the \"right\"  generally shouldnt be 0\n",
    "test_eq(selector.epsilon,0)\n",
    "test_eq(selector.step,200)\n",
    "# Since the max steps are 100, and we go for 200 steps, the first 100 epislon entries shouldnt be 0\n",
    "test_ne(epsilons[:100].sum(),0) \n",
    "# In fact the first 100 should sum up to somewhere between 40 and 50. (expected 49.5)\n",
    "test_eq(40<epsilons[:100].sum()<50,True) \n",
    "# Everything after 100 should be 0\n",
    "test_eq(epsilons[100:].sum(),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b6922-bb36-4628-81f3-4fd24272bac5",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=0`, that the actions have 0% likihood of randomness applied. Check that this \n",
    "works on single batches over `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ae2796f-5a7c-4146-9237-5c8f771a05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "masks = None\n",
    "epsilons = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "        if masks is None: masks = mask\n",
    "        else:             masks = torch.hstack((masks,mask))\n",
    "        if epsilons is None: epsilons = tensor([selector.epsilon])\n",
    "        else:                epsilons = torch.hstack((epsilons,tensor([selector.epsilon])))\n",
    "        \n",
    "test_ne(masks[:(200//2)].sum(),200) # We do not expect this to equal a perfect 200...\n",
    "test_ne(masks[:(200//2)].sum(),0)   # ... but we also dont expect it to be 0\n",
    "assert 40<masks[:(200//2)].sum()<60,'We expect this to be somewhere between 60, generally in the ~50 range'\n",
    "test_eq(masks[(200//2):].sum(),0) # We fully expect this to be 0 after the half way point\n",
    "test_ne(actions.sum(0)[0],200) # All the \"left\" generally shouldnt be 1\n",
    "test_ne(actions.sum(0)[1],0) # All the \"right\"  generally shouldnt be 0\n",
    "test_eq(selector.epsilon,0)\n",
    "test_eq(selector.step,200)\n",
    "# Since the max steps are 100, and we go for 200 steps, the first 100 epislon entries shouldnt be 0\n",
    "test_ne(epsilons[:100].sum(),0) \n",
    "# In fact the first 100 should sum up to somewhere between 40 and 50. (expected 49.5)\n",
    "test_eq(40<epsilons[:100].sum()<50,True) \n",
    "# Everything after 100 should be 0\n",
    "test_eq(epsilons[100:].sum(),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d75d83e-718a-4c8f-910d-e142f2188a70",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e3b8453-bb94-416d-9336-06652612c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.envs.gym import *\n",
    "from fastrl.fastai.data.block import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce389bd2-bdda-463b-a653-c9857aef1e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b9405f5-ca51-4e39-b996-f20dcaa900c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ArgMaxer(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \n",
    "    \"Given input `Tensor` from `source_datapipe` returns a tensor of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe,axis=1,only_idx=False): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.axis = axis\n",
    "        self.only_idx = only_idx\n",
    "        \n",
    "    def debug_display(self,step,idx):\n",
    "        print(f'Step: {step}\\n{idx}')\n",
    "    \n",
    "    def __iter__(self) -> torch.LongTensor:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor to take the argmax, got {type(step)}\\n{step}')\n",
    "            # Might want to support simple tuples also depending on if we are processing multiple fields.\n",
    "            idx = torch.argmax(step,axis=self.axis).reshape(-1,1)\n",
    "            if self.only_idx: \n",
    "                yield idx.long()\n",
    "                continue\n",
    "            step[:] = 0\n",
    "            if self.debug: self.debug_display(step,idx)\n",
    "            step.scatter_(1,idx,1)\n",
    "            yield step.long()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4779a26a-28bd-4963-9f02-b018bfbc1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class NumpyConverter(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \n",
    "    \"Given input `Tensor` from `source_datapipe` returns a numpy array of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        \n",
    "    def debug_display(self,step,idx):\n",
    "        print(f'Step: {step}\\n{idx}')\n",
    "    \n",
    "    def __iter__(self) -> torch.LongTensor:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor to  convert to numpy, got {type(step)}\\n{step}')\n",
    "            if self.debug: self.debug_display(step,idx)\n",
    "            yield step.numpy()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14ac4a8c-8a67-45e1-90bf-f35d3bd1cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PyPrimativeConverter(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \n",
    "    \"Given input `Tensor` from `source_datapipe` returns a numpy array of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe,remove_batch_dim=True): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.remove_batch_dim = remove_batch_dim\n",
    "        \n",
    "    def debug_display(self,step): print(f'Step: {step}')\n",
    "    \n",
    "    def __iter__(self) -> Union[float,bool,int]:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,(np.ndarray)):\n",
    "                raise Exception(f'Expected list or np.ndarray to  convert to python primitive, got {type(step)}\\n{step}')\n",
    "            if self.debug: self.debug_display(step)\n",
    "            \n",
    "            if len(step)>1 or len(step)==0:\n",
    "                raise Exception(f'`step` from {self.source_datapipe} needs to be len 1, not {len(step)}')\n",
    "            else:\n",
    "                step = step[0]\n",
    "                \n",
    "            if np.issubdtype(step.dtype,np.integer):\n",
    "                yield int(step)\n",
    "            elif np.issubdtype(step.dtype,np.floating):\n",
    "                yield float(step)\n",
    "            elif np.issubdtype(step.dtype,np.bool8):\n",
    "                yield bool(step)\n",
    "            else:\n",
    "                raise Exception(f'`step` from {self.source_datapipe} must be one of the 3 python types: bool,int,float, not {step.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23ec79a4-bbdf-41b0-94a9-b4490322527e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [0.5]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = PyPrimativeConverter([np.array([0.5])])\n",
    "L(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d90da02-7778-4f87-88d9-aac89a5ffdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = PyPrimativeConverter([np.array([1])])\n",
    "L(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9025097e-beeb-47f2-a8c1-15fc55e8a540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [True]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = PyPrimativeConverter([np.array([True])])\n",
    "L(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e9adfba-0424-4e39-a29a-b98f9f744e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "\n",
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100)\n",
    "agent = ArgMaxer(selector,only_idx=True)\n",
    "agent = NumpyConverter(agent)\n",
    "agent = PyPrimativeConverter(agent)\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b66738f1-7e53-4097-9846-421d4cd56d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GymTransformBlock(\n",
    "    agent,\n",
    "    seed=None,\n",
    "    nsteps=1,\n",
    "    nskips=1,\n",
    "    dl_type = DataLoader2,\n",
    "    pipe_fn_kwargs=None,\n",
    "    type_tfms=None,\n",
    "    **kwargs\n",
    "):\n",
    "    pipe_fn_kwargs = ifnone(pipe_fn_kwargs,{})\n",
    "    type_tfms = ifnone(type_tfms,GymTypeTransform)\n",
    "    \n",
    "    def pipe_fn(source:List[str],bs,n,seed,nsteps,nskips,\n",
    "                type_tfms=None,item_tfms=None,batch_tfms=None,cbs=None):\n",
    "        pipe = dp.map.Mapper(source)\n",
    "        pipe = TypeTransformLoop(pipe,type_tfms)\n",
    "        pipe = dp.iter.MapToIterConverter(pipe)\n",
    "        pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "        pipe = pipe.cycle(count=n)\n",
    "        pipe = GymStepper(pipe,agent=agent,seed=seed)\n",
    "        if nskips!=1: pipe = NSkipper(pipe,n=nskips)\n",
    "        if nsteps!=1:\n",
    "            pipe = NStepper(pipe,n=nsteps)\n",
    "            pipe = Flattener(pipe)\n",
    "        pipe = ItemTransformLoop(pipe,item_tfms)\n",
    "        pipe  = pipe.batch(batch_size=bs)\n",
    "        pipe = BatchTransformLoop(pipe,batch_tfms)\n",
    "        pipe = add_cbs_to_pipes(pipe,cbs)\n",
    "        return pipe\n",
    "\n",
    "    return TransformBlock(\n",
    "        pipe_fn = pipe_fn,\n",
    "        dl_type = dl_type,\n",
    "        pipe_fn_kwargs = merge(pipe_fn_kwargs,kwargs,dict(nsteps=nsteps,nskips=nskips,seed=seed,type_tfms=type_tfms))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71d30240-b234-4cba-af7c-4e05684d92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.pipes.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d852ef9e-864d-4b45-8bc6-863b7968dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataBlock(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Each transform block will have its own dataloader. \n",
    "        blocks:List[TransformBlock]=None, \n",
    "    ):\n",
    "        store_attr(but='blocks')\n",
    "        self.blocks = L(blocks)\n",
    "\n",
    "    def datapipes(\n",
    "        self,\n",
    "        source:Any,\n",
    "        bs=1,\n",
    "        n=1,\n",
    "        return_blocks:bool=False\n",
    "    ) -> Generator[Union[Tuple[_DataPipeMeta,TransformBlock],_DataPipeMeta],None,None]:\n",
    "        for b in self.blocks:\n",
    "            pipe = b.pipe_fn(source,bs=bs,n=n,**b.pipe_fn_kwargs)\n",
    "            yield (pipe,b) if return_blocks else pipe\n",
    "        \n",
    "    def dataloaders(\n",
    "        self,\n",
    "        source:Any,\n",
    "        bs=1,\n",
    "        n=1,\n",
    "        n_workers=0,\n",
    "        **kwargs\n",
    "    ) -> Generator[DataLoader2,None,None]:\n",
    "        for pipe,block in self.datapipes(source,bs=bs,n=n,return_blocks=True,**kwargs):\n",
    "            yield block.dl_type(pipe,**merge(kwargs,block.dls_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e6c7e55-4fc8-461c-bfcb-af735521b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent)\n",
    ")\n",
    "pipes = L(block.datapipes(['CartPole-v1']*1,n=10,bs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4282e91-635c-475b-953b-b93ab3281e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleStep(state=tensor([0.0059, 0.0479, 0.0246, 0.0382]), action=tensor(1.), next_state=tensor([ 0.0069,  0.2427,  0.0254, -0.2466]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(1.), env_id=tensor(139723029015184), proc_id=tensor(432), step_n=tensor(1), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([ 0.0069,  0.2427,  0.0254, -0.2466]), action=tensor(0.), next_state=tensor([0.0118, 0.0472, 0.0205, 0.0540]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(2.), env_id=tensor(139723029015184), proc_id=tensor(432), step_n=tensor(2), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([0.0118, 0.0472, 0.0205, 0.0540]), action=tensor(1.), next_state=tensor([ 0.0127,  0.2420,  0.0215, -0.2322]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(3.), env_id=tensor(139723029015184), proc_id=tensor(432), step_n=tensor(3), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([ 0.0127,  0.2420,  0.0215, -0.2322]), action=tensor(0.), next_state=tensor([0.0175, 0.0466, 0.0169, 0.0672]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(4.), env_id=tensor(139723029015184), proc_id=tensor(432), step_n=tensor(4), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([0.0175, 0.0466, 0.0169, 0.0672]), action=tensor(1.), next_state=tensor([ 0.0185,  0.2415,  0.0182, -0.2201]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(5.), env_id=tensor(139723029015184), proc_id=tensor(432), step_n=tensor(5), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([ 0.0185,  0.2415,  0.0182, -0.2201]), action=tensor(0.), next_state=tensor([0.0233, 0.0461, 0.0138, 0.0783]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(6.), env_id=tensor(139723029015184), proc_id=tensor(432), step_n=tensor(6), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([0.0233, 0.0461, 0.0138, 0.0783]), action=tensor(1.), next_state=tensor([ 0.0242,  0.2410,  0.0154, -0.2100]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(7.), env_id=tensor(139723029015184), proc_id=tensor(432), step_n=tensor(7), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([ 0.0242,  0.2410,  0.0154, -0.2100]), action=tensor(0.), next_state=tensor([0.0290, 0.0457, 0.0112, 0.0875]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(8.), env_id=tensor(139723029015184), proc_id=tensor(432), step_n=tensor(8), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([0.0290, 0.0457, 0.0112, 0.0875]), action=tensor(0.), next_state=tensor([ 0.0300, -0.1496,  0.0129,  0.3837]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(9.), env_id=tensor(139723029015184), proc_id=tensor(432), step_n=tensor(9), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([ 0.0300, -0.1496,  0.0129,  0.3837]), action=tensor(0.), next_state=tensor([ 0.0270, -0.3449,  0.0206,  0.6804]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(10.), env_id=tensor(139723029015184), proc_id=tensor(432), step_n=tensor(10), episode_n=tensor(1))]\n"
     ]
    }
   ],
   "source": [
    "for p in pipes[0]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7c1dca2-dc5e-4d4e-95fa-d57441643d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent)\n",
    ")\n",
    "pipes = L(block.dataloaders(['CartPole-v1']*1,n=10,bs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b83d32e-a034-45a9-b963-cc8da2677cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleStep(state=tensor([[ 0.0316,  0.0182,  0.0052, -0.0221]]), action=tensor([1.]), next_state=tensor([[ 0.0319,  0.2133,  0.0048, -0.3132]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([1.]), env_id=tensor([139723029077584]), proc_id=tensor([432]), step_n=tensor([1]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0319,  0.2133,  0.0048, -0.3132]]), action=tensor([0.]), next_state=tensor([[ 0.0362,  0.0181, -0.0015, -0.0190]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([2.]), env_id=tensor([139723029077584]), proc_id=tensor([432]), step_n=tensor([2]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0362,  0.0181, -0.0015, -0.0190]]), action=tensor([1.]), next_state=tensor([[ 0.0366,  0.2132, -0.0019, -0.3122]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([3.]), env_id=tensor([139723029077584]), proc_id=tensor([432]), step_n=tensor([3]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0366,  0.2132, -0.0019, -0.3122]]), action=tensor([1.]), next_state=tensor([[ 0.0408,  0.4084, -0.0081, -0.6054]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([4.]), env_id=tensor([139723029077584]), proc_id=tensor([432]), step_n=tensor([4]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0408,  0.4084, -0.0081, -0.6054]]), action=tensor([1.]), next_state=tensor([[ 0.0490,  0.6036, -0.0202, -0.9007]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([5.]), env_id=tensor([139723029077584]), proc_id=tensor([432]), step_n=tensor([5]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0490,  0.6036, -0.0202, -0.9007]]), action=tensor([0.]), next_state=tensor([[ 0.0611,  0.4088, -0.0383, -0.6144]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([6.]), env_id=tensor([139723029077584]), proc_id=tensor([432]), step_n=tensor([6]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0611,  0.4088, -0.0383, -0.6144]]), action=tensor([0.]), next_state=tensor([[ 0.0692,  0.2142, -0.0505, -0.3340]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([7.]), env_id=tensor([139723029077584]), proc_id=tensor([432]), step_n=tensor([7]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0692,  0.2142, -0.0505, -0.3340]]), action=tensor([0.]), next_state=tensor([[ 0.0735,  0.0198, -0.0572, -0.0577]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([8.]), env_id=tensor([139723029077584]), proc_id=tensor([432]), step_n=tensor([8]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0735,  0.0198, -0.0572, -0.0577]]), action=tensor([0.]), next_state=tensor([[ 0.0739, -0.1744, -0.0584,  0.2164]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([9.]), env_id=tensor([139723029077584]), proc_id=tensor([432]), step_n=tensor([9]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0739, -0.1744, -0.0584,  0.2164]]), action=tensor([0.]), next_state=tensor([[ 0.0704, -0.3687, -0.0540,  0.4901]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([10.]), env_id=tensor([139723029077584]), proc_id=tensor([432]), step_n=tensor([10]), episode_n=tensor([1]))]\n"
     ]
    }
   ],
   "source": [
    "for p in pipes[0]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cfe338-de27-4c61-a18d-d74ea33fde37",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03f01296-fd3c-41c8-935b-859cc48fc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LearnerBase(dp.iter.IterDataPipe):\n",
    "    def __init__(self,\n",
    "            model:Module, # The base NN that we getting raw action values out of.\n",
    "            dls:List[DataLoader2], # The dataloaders to read data from for training\n",
    "            loss_func=None, # The loss function to use\n",
    "            opt=None, # The optimizer to use\n",
    "            # LearnerBase will yield each dl individually by default. If `zipwise=True`\n",
    "            # next() will be called on `dls` and will `yield next(dl1),next(dl2),next(dl1)...`\n",
    "            zipwise:bool=False\n",
    "    ):\n",
    "        self.loss_func = loss_func\n",
    "        self.opt = opt\n",
    "        self.model = model\n",
    "        self.iterable = dls\n",
    "        self.zipwise = zipwise\n",
    "        self.learner_base = self\n",
    "        self.batches = find_pipe_instance(dls[0].dataset,dp.iter.Cycler).count\n",
    "\n",
    "    def __iter__(self):\n",
    "        dls = [iter(dl) for dl in self.iterable]\n",
    "        exhausted = []\n",
    "        if self.zipwise:\n",
    "            yield from [next(dl) for i,dl in enumerate(dls) if i not in exhausted]\n",
    "        else:\n",
    "            while not exhausted:\n",
    "                for i,dl in enumerate(dls): \n",
    "                    print('iteratign through dl:',i)\n",
    "                    while i not in exhausted:\n",
    "                        try:\n",
    "                            yield next(dl)\n",
    "                        except StopIteration:\n",
    "                            print('iterating',exhausted)\n",
    "                            exhausted.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d162eca-d930-49af-abf6-8f6af5064938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_epocher(pipe): return isinstance(pipe,Epocher)\n",
    "\n",
    "class Epocher(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.epochs = 0\n",
    "        self.epoch = 0\n",
    "\n",
    "    def __iter__(self): \n",
    "        for i in range(self.epochs):\n",
    "            yield from self.source_datapipe    \n",
    "            self.epoch = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d83e2f9-59d7-45bf-bf34-6f5ea27d864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_learner_base(pipe): return isinstance(pipe,LearnerBase)\n",
    "\n",
    "def find_learner_base(pipe):\n",
    "    \"Basically just find_pipes+is_learner_base with exception handling\"\n",
    "    learner_base = find_pipes(pipe,is_learner_base)\n",
    "    if not learner_base:\n",
    "        raise Exception('`LearnerBase` must be at the start of the pipeline, but it seems to be missing.')\n",
    "    return learner_base[0]\n",
    "\n",
    "class LearnerHead(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learner_base = find_learner_base(self.source_datapipe)\n",
    "\n",
    "    def __iter__(self): yield from self.source_datapipe\n",
    "    \n",
    "    def fit(self,epochs):\n",
    "        epocher = find_pipes(self,is_epocher)[0]\n",
    "        epocher.epochs = epochs\n",
    "        \n",
    "        for iteration in self: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5604841-5938-4359-b60e-491796772384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loggers\n",
    "from fastrl.loggers.core import *\n",
    "\n",
    "logger_base = ProgressBarLogger(\n",
    "     epoch_on_pipe=Epocher,\n",
    "     batch_on_pipe=LearnerBase\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c531706-903d-46fa-acd0-f43a5c3046b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EpsilonCollector(LogCollector):\n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('epsilon',None))\n",
    "        for action in self.source_datapipe:\n",
    "            for q in self.main_queues: \n",
    "                q.put(Record('epsilon',self.source_datapipe.epsilon))\n",
    "            yield action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31f18bb6-1e74-4a17-be8f-a1b36c4f2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "\n",
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100)\n",
    "agent = EpsilonCollector(selector,[logger_base])\n",
    "agent = ArgMaxer(agent,only_idx=True)\n",
    "agent = NumpyConverter(agent)\n",
    "agent = PyPrimativeConverter(agent)\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97a3e6b7-e1fd-40c5-996d-9b8de93da06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent)\n",
    ")\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=10,bs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75847cc7-5647-4ade-8a8d-e0535cef0c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SimpleStep(state=tensor([[-0.0223, -0.0025, -0.0061,  0.0036]]), action=tensor([1.]), next_state=tensor([[-0.0224,  0.1927, -0.0060, -0.2909]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([1.]), env_id=tensor([139723029074576]), proc_id=tensor([432]), step_n=tensor([1]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[-0.0224,  0.1927, -0.0060, -0.2909]]), action=tensor([0.]), next_state=tensor([[-0.0185, -0.0023, -0.0118, -0.0002]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([2.]), env_id=tensor([139723029074576]), proc_id=tensor([432]), step_n=tensor([2]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[-0.0185, -0.0023, -0.0118, -0.0002]]), action=tensor([1.]), next_state=tensor([[-0.0186,  0.1929, -0.0118, -0.2965]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([3.]), env_id=tensor([139723029074576]), proc_id=tensor([432]), step_n=tensor([3]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[-0.0186,  0.1929, -0.0118, -0.2965]]), action=tensor([0.]), next_state=tensor([[-0.0147, -0.0020, -0.0177, -0.0076]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([4.]), env_id=tensor([139723029074576]), proc_id=tensor([432]), step_n=tensor([4]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[-0.0147, -0.0020, -0.0177, -0.0076]]), action=tensor([1.]), next_state=tensor([[-0.0148,  0.1934, -0.0179, -0.3058]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([5.]), env_id=tensor([139723029074576]), proc_id=tensor([432]), step_n=tensor([5]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[-0.0148,  0.1934, -0.0179, -0.3058]]), action=tensor([0.]), next_state=tensor([[-0.0109, -0.0015, -0.0240, -0.0189]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([6.]), env_id=tensor([139723029074576]), proc_id=tensor([432]), step_n=tensor([6]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[-0.0109, -0.0015, -0.0240, -0.0189]]), action=tensor([0.]), next_state=tensor([[-0.0109, -0.1963, -0.0244,  0.2662]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([7.]), env_id=tensor([139723029074576]), proc_id=tensor([432]), step_n=tensor([7]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[-0.0109, -0.1963, -0.0244,  0.2662]]), action=tensor([0.]), next_state=tensor([[-0.0148, -0.3910, -0.0191,  0.5510]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([8.]), env_id=tensor([139723029074576]), proc_id=tensor([432]), step_n=tensor([8]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[-0.0148, -0.3910, -0.0191,  0.5510]]), action=tensor([1.]), next_state=tensor([[-0.0227, -0.1957, -0.0080,  0.2524]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([9.]), env_id=tensor([139723029074576]), proc_id=tensor([432]), step_n=tensor([9]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[-0.0227, -0.1957, -0.0080,  0.2524]]), action=tensor([1.]), next_state=tensor([[-0.0266, -0.0004, -0.0030, -0.0428]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([10.]), env_id=tensor([139723029074576]), proc_id=tensor([432]), step_n=tensor([10]), episode_n=tensor([1]))]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9eea139c-52c0-4005-9101-a45c25c2d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,discount=0.99,nsteps=1):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.discount = discount\n",
    "        self.nsteps = nsteps\n",
    "        self.learner = find_learner_base(self.source_datapipe)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learner.done_mask = batch.terminated.reshape(-1,)\n",
    "            \n",
    "            self.learner.next_q = self.learner.model(batch.next_state)\n",
    "            # print(self.learner.next_q,self.learner.done_mask)\n",
    "            self.learner.next_q = self.learner.next_q.max(dim=1).values.reshape(-1,1)\n",
    "            self.learner.next_q[self.learner.done_mask] = 0 #xb[done_mask]['reward']\n",
    "            self.learner.targets = batch.reward+self.learner.next_q*(self.discount**self.nsteps)\n",
    "            self.learner.pred = self.learner.model(batch.state)\n",
    "            \n",
    "            t_q=self.learner.pred.clone()\n",
    "            t_q.scatter_(1,batch.action.long(),self.learner.targets)\n",
    "            \n",
    "            self.learner.loss_grad = self.learner.loss_func(self.learner.pred, t_q)\n",
    "            yield batch\n",
    "            \n",
    "class ModelLearnCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learner = find_learner_base(self.source_datapipe)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learner.loss_grad.backward()\n",
    "            self.learner.opt.step()\n",
    "            self.learner.opt.zero_grad()\n",
    "            self.learner.loss = self.learner.loss_grad.clone()\n",
    "            yield self.learner.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fdb1161a-26de-4f73-b052-dfefbb8bc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class StepBatcher(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        \"Converts multiple `StepType` into a single `StepType` with the fields concated.\"\n",
    "        self.source_datapipe = source_datapipe\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            # print(batch)\n",
    "            cls = batch[0].__class__\n",
    "            yield cls(\n",
    "                **{\n",
    "                    fld:torch.vstack(tuple(getattr(step,fld) for step in batch)) for fld in cls._fields\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a793dc72-c14a-48aa-bc7a-9bd8e865458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EpisodeCollector(LogCollector):\n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('episode',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            if isinstance(steps,dp.DataChunk):\n",
    "                for step in steps:\n",
    "                    for q in self.main_queues: q.put(Record('episode',step.episode_n.detach().numpy()[0]))\n",
    "            else:\n",
    "                for q in self.main_queues: q.put(Record('episode',steps.episode_n.detach().numpy()[0]))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28aa721c-22fc-49e6-8bc4-fc01b20e6df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LossCollector(LogCollector):\n",
    "    def __init__(self,\n",
    "         source_datapipe, # The parent datapipe, likely the one to collect metrics from\n",
    "         logger_bases:List[LoggerBase] # `LoggerBase`s that we want to send metrics to\n",
    "        ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queues = [o.main_queue for o in logger_bases]\n",
    "        self.learner = find_learner_base(self.source_datapipe)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('loss',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            for q in self.main_queues: q.put(Record('loss',self.learner.loss.detach().numpy()))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "576be92f-0a44-459b-a3a4-3db191cca95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class RollingTerminatedRewardCollector(LogCollector):\n",
    "    def __init__(self,\n",
    "         source_datapipe, # The parent datapipe, likely the one to collect metrics from\n",
    "         logger_bases:List[LoggerBase], # `LoggerBase`s that we want to send metrics to\n",
    "         rolling_length:int=100\n",
    "        ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queues = [o.main_queue for o in logger_bases]\n",
    "        self.rolling_rewards = deque([],maxlen=rolling_length)\n",
    "        \n",
    "    def step2terminated(self,step): return bool(step.terminated)\n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('rolling_reward',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            if isinstance(steps,dp.DataChunk):\n",
    "                for step in steps:\n",
    "                    if self.step2terminated(step):\n",
    "                        self.rolling_rewards.append(step.total_reward.detach().numpy()[0])\n",
    "                        for q in self.main_queues: q.put(Record('rolling_reward',np.average(self.rolling_rewards)))\n",
    "            elif self.step2terminated(steps):\n",
    "                self.rolling_rewards.append(steps.total_reward.detach().numpy()[0])\n",
    "                for q in self.main_queues: q.put(Record('rolling_reward',np.average(self.rolling_rewards)))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1cf27848-ef37-4bf2-aec5-9770090908b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EpochCollector(LogCollector):\n",
    "    def __init__(self,\n",
    "         source_datapipe, # The parent datapipe, likely the one to collect metrics from\n",
    "         logger_bases:List[LoggerBase] # `LoggerBase`s that we want to send metrics to\n",
    "        ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queues = [o.main_queue for o in logger_bases]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.epocher = find_pipe_instance(self.source_datapipe,pipe_cls=Epocher)\n",
    "        for q in self.main_queues: q.put(Record('epoch',None))\n",
    "        epoch = None\n",
    "        for steps in self.source_datapipe:\n",
    "            if self.epocher.epoch!=epoch:\n",
    "                epoch = self.epocher.epoch\n",
    "                for q in self.main_queues: q.put(Record('epoch',epoch))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b8e798d-e03a-4e8f-ad8f-7b214c1591c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_epocher(pipe): return isinstance(pipe,Epocher)\n",
    "\n",
    "class Epocher(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.epochs = 0\n",
    "        self.epoch = 0\n",
    "\n",
    "    def __iter__(self): \n",
    "        print('Start epocher')\n",
    "        for i in range(self.epochs): \n",
    "            self.epoch = i\n",
    "            print(self.epoch,self.epochs)\n",
    "            yield from self.source_datapipe   \n",
    "        print('End epocher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98b525dc-0b4f-46be-8241-56c08c056494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loggers\n",
    "from fastrl.loggers.core import *\n",
    "\n",
    "logger_base = ProgressBarLogger(\n",
    "     epoch_on_pipe=Epocher,\n",
    "     batch_on_pipe=LearnerBase\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "730a2df7-ab63-4ccf-be14-4702823c408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "\n",
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0.02,max_epsilon=1,max_steps=10000)\n",
    "agent = EpsilonCollector(selector,[logger_base])\n",
    "agent = ArgMaxer(agent,only_idx=True)\n",
    "agent = NumpyConverter(agent)\n",
    "agent = PyPrimativeConverter(agent)\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30c8aa23-ce25-4b1e-a5b0-3cada7802069",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent)\n",
    ")\n",
    "# dls = L(block.dataloaders(['CartPole-v1']*1,n=1000,bs=1))\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=100,bs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd0f3282-c6f7-4157-a983-1e24f641b313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epocher\n",
      "0 3\n",
      "iteratign through dl: 0\n",
      "iterating []\n",
      "1 3\n",
      "iteratign through dl: 0\n",
      "iterating []\n",
      "2 3\n",
      "iteratign through dl: 0\n",
      "iterating []\n",
      "End epocher\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learner = LearnerBase(model,dls,loss_func=MSELoss(),opt=AdamW(model.parameters(),lr=0.005))\n",
    "\n",
    "learner = Epocher(learner)\n",
    "learner = EpochCollector(learner,[logger_base])\n",
    "# learner = RollingTerminatedRewardCollector(learner,[logger_base])\n",
    "# learner = EpisodeCollector(learner,[logger_base])\n",
    "\n",
    "# learner = ExperienceReplay(learner,bs=128,max_sz=10000)\n",
    "# learner = StepBatcher(learner)\n",
    "# learner = QCalc(learner)\n",
    "# learner = ModelLearnCalc(learner)\n",
    "# learner = LossCollector(learner,[logger_base])\n",
    "\n",
    "# learner = logger_base.connect_source_datapipe(learner)\n",
    "\n",
    "learner = LearnerHead(learner)\n",
    "\n",
    "learner.fit(3)\n",
    "# learner.fit(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d3626-1702-4f22-ae15-bb93a75bec68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
