{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp agents.dqn.basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from torch.utils.data.datapipes._typing import _DataPipeMeta, _IterDataPipeMeta\n",
    "# Local modules\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "\n",
    "from fastrl.core import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.fastai.data.load import *\n",
    "from fastrl.fastai.data.block import *\n",
    "from fastrl.memory.experience_replay import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Basic\n",
    "> Core DQN modules, pipes, and tooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4fb528-cd3d-4dbe-87ff-cf06c60b1168",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6241ea68-611d-4cdf-abdb-4e2a58af23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0f4eb63-65c9-4226-a033-ecbb097f616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BasicModelForwarder(dp.iter.IterDataPipe):\n",
    "    \"Takes input from `source_datapipe` and pushes through the agent bases model assuming there is only one model field.\"\n",
    "    def __init__(self,source_datapipe): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = find_agent_base(self.source_datapipe)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for state in self.source_datapipe:\n",
    "            if len(state.shape)==1:\n",
    "                state.unsqueeze_(0)\n",
    "            yield self.agent_base.model(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5dff0-4b6f-4513-9565-f363c5087cdc",
   "metadata": {},
   "source": [
    "Check that the 1x4 tensor assuccessfully pushes through the model can get expected outputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "498f7b8c-1de3-442e-94d6-7fb2a1f5baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the agent\n",
    "agent = AgentBase(model)\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d8e8699-c6b2-4bef-98c9-9057a190bfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for action in agent([tensor([1,2,3,4]).float()]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a3558a6-eb99-4f68-983c-9b25532a5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class StepFieldSelector(dp.iter.IterDataPipe):\n",
    "    \"Grabs `field` from `source_datapipe` to push to the rest of the pipeline.\"\n",
    "    def __init__(self,\n",
    "         source_datapipe, # datapipe whose next(source_datapipe) -> `StepType`\n",
    "         field='state' # A field in `StepType` to grab\n",
    "        ): \n",
    "        # TODO: support multi-fields\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.field = field\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,StepType):\n",
    "                raise Exception(f'Expected typing.NamedTuple object got {type(step)}\\n{step}')\n",
    "            yield getattr(step,self.field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382f58d7-3f2f-4c1e-b2f3-1906e9c64a2b",
   "metadata": {},
   "source": [
    "Check that using `StepFieldSelector`, we can grab the `state` field from the `Simplestep` to push through the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e46e30b-757f-472f-86ae-ccbe2cf11932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = AgentHead(agent)\n",
    "\n",
    "for action in agent([SimpleStep.random(state=tensor([1.,2.,3.,4.]))]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a55397ec-c070-4d14-a6ab-c1202284eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ArgMaxer(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \n",
    "    \"Given input `Tensor` from `source_datapipe` returns a tensor of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe,axis=1): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.axis = axis\n",
    "        \n",
    "    def debug_display(self,step,idx):\n",
    "        print(f'Step: {step}\\n{idx}')\n",
    "    \n",
    "    def __iter__(self) -> torch.LongTensor:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor to take the argmax, got {type(step)}\\n{step}')\n",
    "            # Might want to support simple tuples also depending on if we are processing multiple fields.\n",
    "            idx = torch.argmax(step,axis=self.axis).reshape(-1,1)\n",
    "            step[:] = 0\n",
    "            if self.debug: self.debug_display(step,idx)\n",
    "            step.scatter_(1,idx,1)\n",
    "            yield step.long()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb8e39ab-45fd-4e71-96c1-24bdfdff10aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0]])\n"
     ]
    }
   ],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "agent = AgentHead(agent)\n",
    "\n",
    "for action in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29a4ba91-a6f7-4c31-906d-6d1a88d0ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EpsilonSelector(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \"Given input `Tensor` from `source_datapipe`.\"\n",
    "    def __init__(self,\n",
    "            source_datapipe, # a datapipe whose next(source_datapipe) -> `Tensor` \n",
    "            min_epsilon:float=0.2, # The minimum epsilon to drop to\n",
    "            # The max/starting epsilon if `epsilon` is None and used for calculating epislon decrease speed.\n",
    "            max_epsilon:float=1, \n",
    "            # Determines how fast the episilon should drop to `min_epsilon`. This should be the number\n",
    "            # of steps that the agent was run through.\n",
    "            max_steps:int=100,\n",
    "            # The starting epsilon\n",
    "            epsilon:float=None,\n",
    "            # Based on the `base_agent.model.training`, by default no decrement or step tracking will\n",
    "            # occur during validation steps.\n",
    "            decrement_on_val:bool=False,\n",
    "            # Based on the `base_agent.model.training`, by default random actions will not be attempted\n",
    "            select_on_val:bool=False,\n",
    "            # Also return the mask that, where True, the action should be randomly selected.\n",
    "            ret_mask:bool=False\n",
    "        ): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.max_steps = max_steps\n",
    "        self.epsilon = epsilon\n",
    "        self.decrement_on_val = decrement_on_val\n",
    "        self.select_on_val = select_on_val\n",
    "        self.ret_mask = ret_mask\n",
    "        self.agent_base = find_agent_base(self.source_datapipe)\n",
    "        self.step = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for action in self.source_datapipe:\n",
    "            # TODO: Support tuples of actions also\n",
    "            if not issubclass(action.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor, got {type(action)}\\n{action}')\n",
    "            if action.dtype!=torch.int64:\n",
    "                raise ValueError(f'Expected Tensor of dtype int64, got: {action.dtype} from {self.source_datapipe}')\n",
    "                \n",
    "            if self.agent_base.model.training or self.decrement_on_val:\n",
    "                self.step+=1\n",
    "                \n",
    "            self.epsilon=max(self.min_epsilon,self.max_epsilon-self.step/self.max_steps)\n",
    "            # Add a batch dim if missing\n",
    "            if len(action.shape)==1: action.unsqueeze_(0)\n",
    "            mask = None\n",
    "            if self.agent_base.model.training or self.select_on_val:\n",
    "                # Given N(action.shape[0]) actions, select the ones we want to randomly assign... \n",
    "                mask = torch.rand(action.shape[0],)<self.epsilon\n",
    "                # Get random actions as their indexes\n",
    "                rand_action_idxs = torch.LongTensor(int(mask.sum().long()),).random_(action.shape[1])\n",
    "                # If the input action is [[0,1],[1,0]] and...\n",
    "                # If mask is [True,False] and...\n",
    "                # if rand_action_idxs is [0]\n",
    "                # the action[mask] will have [[1,0]] assigned to it resulting in... \n",
    "                # an action with [[1,0],[1,0]]\n",
    "                # print(action.shape[1])\n",
    "                if self.debug: print(f'Mask: {mask}\\nRandom Actions: {rand_action_idxs}\\nPre-random Actions: {action}')\n",
    "                action[mask] = F.one_hot(rand_action_idxs,action.shape[1])\n",
    "            \n",
    "            yield ((action,mask) if self.ret_mask else action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859ecb6-9849-4240-a617-d75fc7070b03",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=1`, that the actions have 100% likihood of randomness applied \n",
    "(even though some might not change due to the random action matching the chosen action). Check that this \n",
    "works on a large batch of `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "384fa4e5-649b-4357-ac2a-278eaa8a5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=1,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n",
    "    test_eq(mask.sum(),200)\n",
    "    test_ne(action.sum(0)[0],200) # Only some of the actions should 1\n",
    "    test_ne(action.sum(0)[1],0) # Only some of the actions should be 0\n",
    "    test_eq(selector.epsilon,1)\n",
    "    test_eq(selector.step,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a711ee-333b-49d7-b849-c3f517079478",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=1`, that the actions have 100% likihood of randomness applied \n",
    "(even though some might not change due to the random action matching the chosen action). Check that this \n",
    "works on single batches over `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56415726-46c2-47a1-88c9-37a0f0af452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ArgMaxer.debug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "030017f4-f373-40ef-978e-fe0c9d2ace06",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent,axis=1)\n",
    "selector = EpsilonSelector(agent,min_epsilon=1,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "        test_eq(mask.sum(),1)\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "test_ne(actions.sum(0)[0],200) # Only some of the actions should 1\n",
    "test_ne(actions.sum(0)[1],0) # Only some of the actions should be 0\n",
    "test_eq(selector.epsilon,1)\n",
    "test_eq(selector.step,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bda9f9-5aaf-427a-b7ae-e61bf0bcc194",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=0`, that the actions have 0% likihood of randomness applied. Check that this \n",
    "works on a large batch of `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c790b227-fc40-49fd-9e0f-4e792a000962",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=0,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n",
    "    test_eq(mask.sum(),0)\n",
    "    test_eq(action.sum(0)[0],200) # All the \"left\" actions should be 1\n",
    "    test_eq(action.sum(0)[1],0) # All the \"right\" actions should be 0\n",
    "    test_eq(selector.epsilon,0)\n",
    "    test_eq(selector.step,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521693a5-8d31-42ee-ad47-566f35f00649",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=0`, that the actions have 0% likihood of randomness applied. Check that this \n",
    "works on single batches over `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4dbb3cb-ddc1-4d77-aad6-05c7510948fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=0,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "        test_eq(mask.sum(),0)\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "test_eq(actions.sum(0)[0],200) # All the \"left\" actions should be 1\n",
    "test_eq(actions.sum(0)[1],0) # All the \"right\" actions should be 0\n",
    "test_eq(selector.epsilon,0)\n",
    "test_eq(selector.step,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee0a64-d23c-472b-a8f5-7b6ea8099e9c",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=1`, the actions should become less random\n",
    "as the steps go on. Check that this works on a large batch of `200 steps`...\n",
    "\n",
    "`epislon` should be 0 at the end of this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3dca194b-aae5-4c3d-b18b-d94e00c623f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "masks = None\n",
    "epsilons = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "        if masks is None: masks = mask\n",
    "        else:             masks = torch.hstack((masks,mask))\n",
    "        if epsilons is None: epsilons = tensor([selector.epsilon])\n",
    "        else:                epsilons = torch.hstack((epsilons,tensor([selector.epsilon])))\n",
    "        \n",
    "test_ne(masks[:((200*200)//2)].sum(),200) # We do not expect this to equal a perfect 200...\n",
    "test_ne(masks[:((200*200)//2)].sum(),0)   # ... but we also dont expect it to be 0\n",
    "assert 1000<masks[:((200*200)//2)].sum()<10_000,\\\n",
    "        \"\"\"We expect this to be somewhere between 1000 and 10,000, generally in the 9000 range since \n",
    "           for 200 steps, we are running 200 inputs\"\"\"\n",
    "test_eq(masks[((200*200)//2):].sum(),0) # We fully expect this to be 0 after the half way point\n",
    "test_ne(actions.sum(0)[0],200) # All the \"left\" generally shouldnt be 1\n",
    "test_ne(actions.sum(0)[1],0) # All the \"right\"  generally shouldnt be 0\n",
    "test_eq(selector.epsilon,0)\n",
    "test_eq(selector.step,200)\n",
    "# Since the max steps are 100, and we go for 200 steps, the first 100 epislon entries shouldnt be 0\n",
    "test_ne(epsilons[:100].sum(),0) \n",
    "# In fact the first 100 should sum up to somewhere between 40 and 50. (expected 49.5)\n",
    "test_eq(40<epsilons[:100].sum()<50,True) \n",
    "# Everything after 100 should be 0\n",
    "test_eq(epsilons[100:].sum(),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b6922-bb36-4628-81f3-4fd24272bac5",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=0`, that the actions have 0% likihood of randomness applied. Check that this \n",
    "works on single batches over `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ae2796f-5a7c-4146-9237-5c8f771a05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "masks = None\n",
    "epsilons = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "        if masks is None: masks = mask\n",
    "        else:             masks = torch.hstack((masks,mask))\n",
    "        if epsilons is None: epsilons = tensor([selector.epsilon])\n",
    "        else:                epsilons = torch.hstack((epsilons,tensor([selector.epsilon])))\n",
    "        \n",
    "test_ne(masks[:(200//2)].sum(),200) # We do not expect this to equal a perfect 200...\n",
    "test_ne(masks[:(200//2)].sum(),0)   # ... but we also dont expect it to be 0\n",
    "assert 40<masks[:(200//2)].sum()<60,'We expect this to be somewhere between 60, generally in the ~50 range'\n",
    "test_eq(masks[(200//2):].sum(),0) # We fully expect this to be 0 after the half way point\n",
    "test_ne(actions.sum(0)[0],200) # All the \"left\" generally shouldnt be 1\n",
    "test_ne(actions.sum(0)[1],0) # All the \"right\"  generally shouldnt be 0\n",
    "test_eq(selector.epsilon,0)\n",
    "test_eq(selector.step,200)\n",
    "# Since the max steps are 100, and we go for 200 steps, the first 100 epislon entries shouldnt be 0\n",
    "test_ne(epsilons[:100].sum(),0) \n",
    "# In fact the first 100 should sum up to somewhere between 40 and 50. (expected 49.5)\n",
    "test_eq(40<epsilons[:100].sum()<50,True) \n",
    "# Everything after 100 should be 0\n",
    "test_eq(epsilons[100:].sum(),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d75d83e-718a-4c8f-910d-e142f2188a70",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e3b8453-bb94-416d-9336-06652612c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.envs.gym import *\n",
    "from fastrl.fastai.data.block import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce389bd2-bdda-463b-a653-c9857aef1e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b9405f5-ca51-4e39-b996-f20dcaa900c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ArgMaxer(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \n",
    "    \"Given input `Tensor` from `source_datapipe` returns a tensor of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe,axis=1,only_idx=False): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.axis = axis\n",
    "        self.only_idx = only_idx\n",
    "        \n",
    "    def debug_display(self,step,idx):\n",
    "        print(f'Step: {step}\\n{idx}')\n",
    "    \n",
    "    def __iter__(self) -> torch.LongTensor:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor to take the argmax, got {type(step)}\\n{step}')\n",
    "            # Might want to support simple tuples also depending on if we are processing multiple fields.\n",
    "            idx = torch.argmax(step,axis=self.axis).reshape(-1,1)\n",
    "            if self.only_idx: \n",
    "                yield idx.long()\n",
    "                continue\n",
    "            step[:] = 0\n",
    "            if self.debug: self.debug_display(step,idx)\n",
    "            step.scatter_(1,idx,1)\n",
    "            yield step.long()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4779a26a-28bd-4963-9f02-b018bfbc1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class NumpyConverter(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \n",
    "    \"Given input `Tensor` from `source_datapipe` returns a numpy array of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        \n",
    "    def debug_display(self,step,idx):\n",
    "        print(f'Step: {step}\\n{idx}')\n",
    "    \n",
    "    def __iter__(self) -> torch.LongTensor:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor to  convert to numpy, got {type(step)}\\n{step}')\n",
    "            if self.debug: self.debug_display(step,idx)\n",
    "            yield step.numpy()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14ac4a8c-8a67-45e1-90bf-f35d3bd1cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PyPrimativeConverter(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \n",
    "    \"Given input `Tensor` from `source_datapipe` returns a numpy array of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe,remove_batch_dim=True): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.remove_batch_dim = remove_batch_dim\n",
    "        \n",
    "    def debug_display(self,step): print(f'Step: {step}')\n",
    "    \n",
    "    def __iter__(self) -> Union[float,bool,int]:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,(np.ndarray)):\n",
    "                raise Exception(f'Expected list or np.ndarray to  convert to python primitive, got {type(step)}\\n{step}')\n",
    "            if self.debug: self.debug_display(step)\n",
    "            \n",
    "            if len(step)>1 or len(step)==0:\n",
    "                raise Exception(f'`step` from {self.source_datapipe} needs to be len 1, not {len(step)}')\n",
    "            else:\n",
    "                step = step[0]\n",
    "                \n",
    "            if np.issubdtype(step.dtype,np.integer):\n",
    "                yield int(step)\n",
    "            elif np.issubdtype(step.dtype,np.floating):\n",
    "                yield float(step)\n",
    "            elif np.issubdtype(step.dtype,np.bool8):\n",
    "                yield bool(step)\n",
    "            else:\n",
    "                raise Exception(f'`step` from {self.source_datapipe} must be one of the 3 python types: bool,int,float, not {step.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23ec79a4-bbdf-41b0-94a9-b4490322527e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [0.5]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = PyPrimativeConverter([np.array([0.5])])\n",
    "L(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d90da02-7778-4f87-88d9-aac89a5ffdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [1]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = PyPrimativeConverter([np.array([1])])\n",
    "L(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9025097e-beeb-47f2-a8c1-15fc55e8a540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [True]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = PyPrimativeConverter([np.array([True])])\n",
    "L(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e9adfba-0424-4e39-a29a-b98f9f744e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "\n",
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100)\n",
    "agent = ArgMaxer(selector,only_idx=True)\n",
    "agent = NumpyConverter(agent)\n",
    "agent = PyPrimativeConverter(agent)\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b66738f1-7e53-4097-9846-421d4cd56d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GymTransformBlock(\n",
    "    agent,\n",
    "    seed=None,\n",
    "    nsteps=1,\n",
    "    nskips=1,\n",
    "    dl_type = DataLoader2,\n",
    "    pipe_fn_kwargs=None,\n",
    "    type_tfms=None,\n",
    "    **kwargs\n",
    "):\n",
    "    pipe_fn_kwargs = ifnone(pipe_fn_kwargs,{})\n",
    "    type_tfms = ifnone(type_tfms,GymTypeTransform)\n",
    "    \n",
    "    def pipe_fn(source:List[str],bs,n,seed,nsteps,nskips,\n",
    "                type_tfms=None,item_tfms=None,batch_tfms=None,cbs=None):\n",
    "        pipe = dp.map.Mapper(source)\n",
    "        pipe = TypeTransformLoop(pipe,type_tfms)\n",
    "        pipe = dp.iter.MapToIterConverter(pipe)\n",
    "        pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "        pipe = pipe.cycle(count=n)\n",
    "        pipe = GymStepper(pipe,agent=agent,seed=seed)\n",
    "        if nskips!=1: pipe = NSkipper(pipe,n=nskips)\n",
    "        if nsteps!=1:\n",
    "            pipe = NStepper(pipe,n=nsteps)\n",
    "            pipe = Flattener(pipe)\n",
    "        pipe = ItemTransformLoop(pipe,item_tfms)\n",
    "        pipe  = pipe.batch(batch_size=bs)\n",
    "        pipe = BatchTransformLoop(pipe,batch_tfms)\n",
    "        pipe = add_cbs_to_pipes(pipe,cbs)\n",
    "        return pipe\n",
    "\n",
    "    return TransformBlock(\n",
    "        pipe_fn = pipe_fn,\n",
    "        dl_type = dl_type,\n",
    "        pipe_fn_kwargs = merge(pipe_fn_kwargs,kwargs,dict(nsteps=nsteps,nskips=nskips,seed=seed,type_tfms=type_tfms))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71d30240-b234-4cba-af7c-4e05684d92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.pipes.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d852ef9e-864d-4b45-8bc6-863b7968dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataBlock(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Each transform block will have its own dataloader. \n",
    "        blocks:List[TransformBlock]=None, \n",
    "    ):\n",
    "        store_attr(but='blocks')\n",
    "        self.blocks = L(blocks)\n",
    "\n",
    "    def datapipes(\n",
    "        self,\n",
    "        source:Any,\n",
    "        bs=1,\n",
    "        n=1,\n",
    "        return_blocks:bool=False\n",
    "    ) -> Generator[Union[Tuple[_DataPipeMeta,TransformBlock],_DataPipeMeta],None,None]:\n",
    "        for b in self.blocks:\n",
    "            pipe = b.pipe_fn(source,bs=bs,n=n,**b.pipe_fn_kwargs)\n",
    "            yield (pipe,b) if return_blocks else pipe\n",
    "        \n",
    "    def dataloaders(\n",
    "        self,\n",
    "        source:Any,\n",
    "        bs=1,\n",
    "        n=1,\n",
    "        n_workers=0,\n",
    "        **kwargs\n",
    "    ) -> Generator[DataLoader2,None,None]:\n",
    "        for pipe,block in self.datapipes(source,bs=bs,n=n,return_blocks=True,**kwargs):\n",
    "            yield block.dl_type(pipe,**merge(kwargs,block.dls_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e6c7e55-4fc8-461c-bfcb-af735521b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent)\n",
    ")\n",
    "pipes = L(block.datapipes(['CartPole-v1']*1,n=10,bs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d4282e91-635c-475b-953b-b93ab3281e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleStep(state=tensor([-0.0295,  0.0351,  0.0443,  0.0104]), action=tensor(1.), next_state=tensor([-0.0288,  0.2296,  0.0445, -0.2680]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(1.), env_id=tensor(140401505813712), proc_id=tensor(1022), step_n=tensor(1), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([-0.0288,  0.2296,  0.0445, -0.2680]), action=tensor(0.), next_state=tensor([-0.0242,  0.0338,  0.0391,  0.0384]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(2.), env_id=tensor(140401505813712), proc_id=tensor(1022), step_n=tensor(2), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([-0.0242,  0.0338,  0.0391,  0.0384]), action=tensor(1.), next_state=tensor([-0.0235,  0.2284,  0.0399, -0.2417]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(3.), env_id=tensor(140401505813712), proc_id=tensor(1022), step_n=tensor(3), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([-0.0235,  0.2284,  0.0399, -0.2417]), action=tensor(0.), next_state=tensor([-0.0189,  0.0327,  0.0351,  0.0633]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(4.), env_id=tensor(140401505813712), proc_id=tensor(1022), step_n=tensor(4), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([-0.0189,  0.0327,  0.0351,  0.0633]), action=tensor(1.), next_state=tensor([-0.0183,  0.2273,  0.0363, -0.2181]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(5.), env_id=tensor(140401505813712), proc_id=tensor(1022), step_n=tensor(5), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([-0.0183,  0.2273,  0.0363, -0.2181]), action=tensor(0.), next_state=tensor([-0.0137,  0.0317,  0.0320,  0.0858]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(6.), env_id=tensor(140401505813712), proc_id=tensor(1022), step_n=tensor(6), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([-0.0137,  0.0317,  0.0320,  0.0858]), action=tensor(1.), next_state=tensor([-0.0131,  0.2263,  0.0337, -0.1966]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(7.), env_id=tensor(140401505813712), proc_id=tensor(1022), step_n=tensor(7), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([-0.0131,  0.2263,  0.0337, -0.1966]), action=tensor(0.), next_state=tensor([-0.0086,  0.0308,  0.0298,  0.1065]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(8.), env_id=tensor(140401505813712), proc_id=tensor(1022), step_n=tensor(8), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([-0.0086,  0.0308,  0.0298,  0.1065]), action=tensor(0.), next_state=tensor([-0.0079, -0.1648,  0.0319,  0.4084]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(9.), env_id=tensor(140401505813712), proc_id=tensor(1022), step_n=tensor(9), episode_n=tensor(1))]\n",
      "[SimpleStep(state=tensor([-0.0079, -0.1648,  0.0319,  0.4084]), action=tensor(0.), next_state=tensor([-0.0112, -0.3603,  0.0401,  0.7110]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(10.), env_id=tensor(140401505813712), proc_id=tensor(1022), step_n=tensor(10), episode_n=tensor(1))]\n"
     ]
    }
   ],
   "source": [
    "for p in pipes[0]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b7c1dca2-dc5e-4d4e-95fa-d57441643d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent)\n",
    ")\n",
    "pipes = L(block.dataloaders(['CartPole-v1']*1,n=10,bs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b83d32e-a034-45a9-b963-cc8da2677cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleStep(state=tensor([[ 0.0484, -0.0215,  0.0088,  0.0104]]), action=tensor([1.]), next_state=tensor([[ 0.0480,  0.1735,  0.0090, -0.2795]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([1.]), env_id=tensor([140401505542992]), proc_id=tensor([1022]), step_n=tensor([1]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0480,  0.1735,  0.0090, -0.2795]]), action=tensor([0.]), next_state=tensor([[ 0.0514, -0.0218,  0.0034,  0.0160]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([2.]), env_id=tensor([140401505542992]), proc_id=tensor([1022]), step_n=tensor([2]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0514, -0.0218,  0.0034,  0.0160]]), action=tensor([1.]), next_state=tensor([[ 0.0510,  0.1733,  0.0037, -0.2756]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([3.]), env_id=tensor([140401505542992]), proc_id=tensor([1022]), step_n=tensor([3]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0510,  0.1733,  0.0037, -0.2756]]), action=tensor([1.]), next_state=tensor([[ 0.0545,  0.3684, -0.0018, -0.5671]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([4.]), env_id=tensor([140401505542992]), proc_id=tensor([1022]), step_n=tensor([4]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0545,  0.3684, -0.0018, -0.5671]]), action=tensor([1.]), next_state=tensor([[ 0.0618,  0.5635, -0.0131, -0.8603]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([5.]), env_id=tensor([140401505542992]), proc_id=tensor([1022]), step_n=tensor([5]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0618,  0.5635, -0.0131, -0.8603]]), action=tensor([0.]), next_state=tensor([[ 0.0731,  0.3686, -0.0303, -0.5718]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([6.]), env_id=tensor([140401505542992]), proc_id=tensor([1022]), step_n=tensor([6]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0731,  0.3686, -0.0303, -0.5718]]), action=tensor([0.]), next_state=tensor([[ 0.0805,  0.1739, -0.0418, -0.2888]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([7.]), env_id=tensor([140401505542992]), proc_id=tensor([1022]), step_n=tensor([7]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0805,  0.1739, -0.0418, -0.2888]]), action=tensor([0.]), next_state=tensor([[ 0.0839, -0.0206, -0.0475, -0.0096]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([8.]), env_id=tensor([140401505542992]), proc_id=tensor([1022]), step_n=tensor([8]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0839, -0.0206, -0.0475, -0.0096]]), action=tensor([0.]), next_state=tensor([[ 0.0835, -0.2150, -0.0477,  0.2677]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([9.]), env_id=tensor([140401505542992]), proc_id=tensor([1022]), step_n=tensor([9]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([[ 0.0835, -0.2150, -0.0477,  0.2677]]), action=tensor([0.]), next_state=tensor([[ 0.0792, -0.4094, -0.0424,  0.5450]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([10.]), env_id=tensor([140401505542992]), proc_id=tensor([1022]), step_n=tensor([10]), episode_n=tensor([1]))]\n"
     ]
    }
   ],
   "source": [
    "for p in pipes[0]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cfe338-de27-4c61-a18d-d74ea33fde37",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03f01296-fd3c-41c8-935b-859cc48fc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LearnerBase(dp.iter.IterDataPipe):\n",
    "    def __init__(self,\n",
    "            model:Module, # The base NN that we getting raw action values out of.\n",
    "            dls:List[DataLoader2], # The dataloaders to read data from for training\n",
    "            loss_func=None, # The loss function to use\n",
    "            opt=None, # The optimizer to use\n",
    "            # LearnerBase will yield each dl individually by default. If `zipwise=True`\n",
    "            # next() will be called on `dls` and will `yield next(dl1),next(dl2),next(dl1)...`\n",
    "            zipwise:bool=False\n",
    "    ):\n",
    "        self.loss_func = loss_func\n",
    "        self.opt = opt\n",
    "        self.model = model\n",
    "        self.iterable = dls\n",
    "        self.zipwise = zipwise\n",
    "        self.learner_base = self\n",
    "        self.batches = find_pipe_instance(dls[0].dataset,dp.iter.Cycler).count\n",
    "\n",
    "    def __iter__(self):\n",
    "        dls = [iter(dl) for dl in self.iterable]\n",
    "        exhausted = []\n",
    "        if self.zipwise:\n",
    "            yield from [next(dl) for i,dl in enumerate(dls) if i not in exhausted]\n",
    "        else:\n",
    "            while not exhausted:\n",
    "                for i,dl in enumerate(dls): \n",
    "                    if i not in exhausted:\n",
    "                        try:\n",
    "                            yield next(dl)\n",
    "                        except StopIteration:\n",
    "                            exhausted.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d162eca-d930-49af-abf6-8f6af5064938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_epocher(pipe): return isinstance(pipe,Epocher)\n",
    "\n",
    "class Epocher(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.epochs = 0\n",
    "\n",
    "    def __iter__(self): \n",
    "        for i in range(self.epochs):\n",
    "            yield from self.source_datapipe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d83e2f9-59d7-45bf-bf34-6f5ea27d864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_learner_base(pipe): return isinstance(pipe,LearnerBase)\n",
    "\n",
    "def find_learner_base(pipe):\n",
    "    \"Basically just find_pipes+is_learner_base with exception handling\"\n",
    "    learner_base = find_pipes(pipe,is_learner_base)\n",
    "    if not learner_base:\n",
    "        raise Exception('`LearnerBase` must be at the start of the pipeline, but it seems to be missing.')\n",
    "    return learner_base[0]\n",
    "\n",
    "class LearnerHead(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learner_base = find_learner_base(self.source_datapipe)\n",
    "\n",
    "    def __iter__(self): yield from self.source_datapipe\n",
    "    \n",
    "    def fit(self,epochs):\n",
    "        epocher = find_pipes(self,is_epocher)[0]\n",
    "        epocher.epochs = epochs\n",
    "        \n",
    "        for iteration in self: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c5604841-5938-4359-b60e-491796772384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loggers\n",
    "from fastrl.loggers.core import *\n",
    "\n",
    "logger_base = ProgressBarLogger(\n",
    "     epoch_on_pipe=Epocher,\n",
    "     batch_on_pipe=LearnerBase\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9c531706-903d-46fa-acd0-f43a5c3046b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EpsilonCollector(LogCollector):\n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('epsilon',None))\n",
    "        for action in self.source_datapipe:\n",
    "            for q in self.main_queues: \n",
    "                q.put(Record('epsilon',self.source_datapipe.epsilon))\n",
    "            yield action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31f18bb6-1e74-4a17-be8f-a1b36c4f2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "\n",
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100)\n",
    "agent = EpsilonCollector(selector,[logger_base])\n",
    "agent = ArgMaxer(agent,only_idx=True)\n",
    "agent = NumpyConverter(agent)\n",
    "agent = PyPrimativeConverter(agent)\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "97a3e6b7-e1fd-40c5-996d-9b8de93da06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent)\n",
    ")\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=10,bs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "75847cc7-5647-4ade-8a8d-e0535cef0c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SimpleStep(state=tensor([[ 0.0196, -0.0241,  0.0392, -0.0182]]), action=tensor([1.]), next_state=tensor([[ 0.0192,  0.1705,  0.0389, -0.2983]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([1.]), env_id=tensor([140401550457424]), proc_id=tensor([1022]), step_n=tensor([1]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[ 0.0192,  0.1705,  0.0389, -0.2983]]), action=tensor([0.]), next_state=tensor([[ 0.0226, -0.0252,  0.0329,  0.0064]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([2.]), env_id=tensor([140401550457424]), proc_id=tensor([1022]), step_n=tensor([2]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[ 0.0226, -0.0252,  0.0329,  0.0064]]), action=tensor([1.]), next_state=tensor([[ 0.0221,  0.1695,  0.0330, -0.2757]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([3.]), env_id=tensor([140401550457424]), proc_id=tensor([1022]), step_n=tensor([3]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[ 0.0221,  0.1695,  0.0330, -0.2757]]), action=tensor([0.]), next_state=tensor([[ 0.0255, -0.0261,  0.0275,  0.0272]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([4.]), env_id=tensor([140401550457424]), proc_id=tensor([1022]), step_n=tensor([4]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[ 0.0255, -0.0261,  0.0275,  0.0272]]), action=tensor([1.]), next_state=tensor([[ 0.0249,  0.1686,  0.0281, -0.2567]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([5.]), env_id=tensor([140401550457424]), proc_id=tensor([1022]), step_n=tensor([5]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[ 0.0249,  0.1686,  0.0281, -0.2567]]), action=tensor([0.]), next_state=tensor([[ 0.0283, -0.0269,  0.0229,  0.0447]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([6.]), env_id=tensor([140401550457424]), proc_id=tensor([1022]), step_n=tensor([6]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[ 0.0283, -0.0269,  0.0229,  0.0447]]), action=tensor([0.]), next_state=tensor([[ 0.0278, -0.2224,  0.0238,  0.3445]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([7.]), env_id=tensor([140401550457424]), proc_id=tensor([1022]), step_n=tensor([7]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[ 0.0278, -0.2224,  0.0238,  0.3445]]), action=tensor([0.]), next_state=tensor([[ 0.0233, -0.4178,  0.0307,  0.6446]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([8.]), env_id=tensor([140401550457424]), proc_id=tensor([1022]), step_n=tensor([8]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[ 0.0233, -0.4178,  0.0307,  0.6446]]), action=tensor([1.]), next_state=tensor([[ 0.0150, -0.2231,  0.0436,  0.3618]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([9.]), env_id=tensor([140401550457424]), proc_id=tensor([1022]), step_n=tensor([9]), episode_n=tensor([1]))],\n",
       " [SimpleStep(state=tensor([[ 0.0150, -0.2231,  0.0436,  0.3618]]), action=tensor([1.]), next_state=tensor([[ 0.0105, -0.0286,  0.0508,  0.0832]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([10.]), env_id=tensor([140401550457424]), proc_id=tensor([1022]), step_n=tensor([10]), episode_n=tensor([1]))]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9eea139c-52c0-4005-9101-a45c25c2d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,discount=0.99,nsteps=1):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.discount = discount\n",
    "        self.nsteps = nsteps\n",
    "        self.learner = find_learner_base(self.source_datapipe)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learner.done_mask = batch.terminated.reshape(-1,)\n",
    "            \n",
    "            self.learner.next_q = self.learner.model(batch.next_state)\n",
    "            # print(self.learner.next_q,self.learner.done_mask)\n",
    "            self.learner.next_q = self.learner.next_q.max(dim=1).values.reshape(-1,1)\n",
    "            self.learner.next_q[self.learner.done_mask] = 0 #xb[done_mask]['reward']\n",
    "            self.learner.targets = batch.reward+self.learner.next_q*(self.discount**self.nsteps)\n",
    "            self.learner.pred = self.learner.model(batch.state)\n",
    "            \n",
    "            \n",
    "            t_q=self.learner.pred.clone()\n",
    "            t_q.scatter_(1,batch.action.long(),self.learner.targets)\n",
    "            \n",
    "            self.learner.loss_grad = self.learner.loss_func(self.learner.pred, self.learner.targets)\n",
    "            yield batch\n",
    "            \n",
    "class ModelLearnCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learner = find_learner_base(self.source_datapipe)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learner.loss_grad.backward()\n",
    "            self.learner.opt.step()\n",
    "            self.learner.opt.zero_grad()\n",
    "            self.learner.loss = self.learner.loss_grad.clone()\n",
    "            yield self.learner.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fdb1161a-26de-4f73-b052-dfefbb8bc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class StepBatcher(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        \"Converts multiple `StepType` into a single `StepType` with the fields concated.\"\n",
    "        self.source_datapipe = source_datapipe\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            # print(batch)\n",
    "            cls = batch[0].__class__\n",
    "            yield cls(\n",
    "                **{\n",
    "                    fld:torch.vstack(tuple(getattr(step,fld) for step in batch)) for fld in cls._fields\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fd0f3282-c6f7-4157-a983-1e24f641b313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>reward</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "learner = LearnerBase(model,dls,loss_func=MSELoss(),opt=AdamW(model.parameters(),lr=0.001))\n",
    "\n",
    "learner = Epocher(learner)\n",
    "learner = RewardCollector(learner,[logger_base])\n",
    "\n",
    "\n",
    "learner = ExperienceReplay(learner)\n",
    "learner = StepBatcher(learner)\n",
    "learner = QCalc(learner)\n",
    "learner = ModelLearnCalc(learner)\n",
    "\n",
    "learner = logger_base.connect_source_datapipe(learner)\n",
    "\n",
    "learner = LearnerHead(learner)\n",
    "\n",
    "learner.fit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e4591-4dbf-4772-92cb-a9dbdeaf2646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
