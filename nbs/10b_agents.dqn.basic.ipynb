{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.dqn.basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "from collections import deque\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from torch.utils.data.datapipes._typing import _DataPipeMeta, _IterDataPipeMeta\n",
    "# Local modules\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "\n",
    "from fastrl.core import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.fastai.data.block import *\n",
    "from fastrl.memory.experience_replay import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Basic\n",
    "> Core DQN modules, pipes, and tooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4fb528-cd3d-4dbe-87ff-cf06c60b1168",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6241ea68-611d-4cdf-abdb-4e2a58af23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f4eb63-65c9-4226-a033-ecbb097f616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class BasicModelForwarder(dp.iter.IterDataPipe):\n",
    "    \"Takes input from `source_datapipe` and pushes through the agent bases model assuming there is only one model field.\"\n",
    "    def __init__(self,source_datapipe): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = find_agent_base(self.source_datapipe)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for state in self.source_datapipe:\n",
    "            if len(state.shape)==1:\n",
    "                state.unsqueeze_(0)\n",
    "            yield self.agent_base.model(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5dff0-4b6f-4513-9565-f363c5087cdc",
   "metadata": {},
   "source": [
    "Check that the 1x4 tensor assuccessfully pushes through the model can get expected outputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498f7b8c-1de3-442e-94d6-7fb2a1f5baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the agent\n",
    "agent = AgentBase(model)\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d8e8699-c6b2-4bef-98c9-9057a190bfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for action in agent([tensor([1,2,3,4]).float()]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a3558a6-eb99-4f68-983c-9b25532a5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class StepFieldSelector(dp.iter.IterDataPipe):\n",
    "    \"Grabs `field` from `source_datapipe` to push to the rest of the pipeline.\"\n",
    "    def __init__(self,\n",
    "         source_datapipe, # datapipe whose next(source_datapipe) -> `StepType`\n",
    "         field='state' # A field in `StepType` to grab\n",
    "        ): \n",
    "        # TODO: support multi-fields\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.field = field\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,StepType):\n",
    "                raise Exception(f'Expected typing.NamedTuple object got {type(step)}\\n{step}')\n",
    "            yield getattr(step,self.field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382f58d7-3f2f-4c1e-b2f3-1906e9c64a2b",
   "metadata": {},
   "source": [
    "Check that using `StepFieldSelector`, we can grab the `state` field from the `Simplestep` to push through the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e46e30b-757f-472f-86ae-ccbe2cf11932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = AgentHead(agent)\n",
    "\n",
    "for action in agent([SimpleStep.random(state=tensor([1.,2.,3.,4.]))]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a55397ec-c070-4d14-a6ab-c1202284eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ArgMaxer(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \n",
    "    \"Given input `Tensor` from `source_datapipe` returns a tensor of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe,axis=1): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.axis = axis\n",
    "        \n",
    "    def debug_display(self,step,idx):\n",
    "        print(f'Step: {step}\\n{idx}')\n",
    "    \n",
    "    def __iter__(self) -> torch.LongTensor:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor to take the argmax, got {type(step)}\\n{step}')\n",
    "            # Might want to support simple tuples also depending on if we are processing multiple fields.\n",
    "            idx = torch.argmax(step,axis=self.axis).reshape(-1,1)\n",
    "            step[:] = 0\n",
    "            if self.debug: self.debug_display(step,idx)\n",
    "            step.scatter_(1,idx,1)\n",
    "            yield step.long()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb8e39ab-45fd-4e71-96c1-24bdfdff10aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0]])\n"
     ]
    }
   ],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "agent = AgentHead(agent)\n",
    "\n",
    "for action in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a4ba91-a6f7-4c31-906d-6d1a88d0ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class EpsilonSelector(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \"Given input `Tensor` from `source_datapipe`.\"\n",
    "    def __init__(self,\n",
    "            source_datapipe, # a datapipe whose next(source_datapipe) -> `Tensor` \n",
    "            min_epsilon:float=0.2, # The minimum epsilon to drop to\n",
    "            # The max/starting epsilon if `epsilon` is None and used for calculating epislon decrease speed.\n",
    "            max_epsilon:float=1, \n",
    "            # Determines how fast the episilon should drop to `min_epsilon`. This should be the number\n",
    "            # of steps that the agent was run through.\n",
    "            max_steps:int=100,\n",
    "            # The starting epsilon\n",
    "            epsilon:float=None,\n",
    "            # Based on the `base_agent.model.training`, by default no decrement or step tracking will\n",
    "            # occur during validation steps.\n",
    "            decrement_on_val:bool=False,\n",
    "            # Based on the `base_agent.model.training`, by default random actions will not be attempted\n",
    "            select_on_val:bool=False,\n",
    "            # Also return the mask that, where True, the action should be randomly selected.\n",
    "            ret_mask:bool=False\n",
    "        ): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.max_steps = max_steps\n",
    "        self.epsilon = epsilon\n",
    "        self.decrement_on_val = decrement_on_val\n",
    "        self.select_on_val = select_on_val\n",
    "        self.ret_mask = ret_mask\n",
    "        self.agent_base = find_agent_base(self.source_datapipe)\n",
    "        self.step = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for action in self.source_datapipe:\n",
    "            # TODO: Support tuples of actions also\n",
    "            if not issubclass(action.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor, got {type(action)}\\n{action}')\n",
    "            if action.dtype!=torch.int64:\n",
    "                raise ValueError(f'Expected Tensor of dtype int64, got: {action.dtype} from {self.source_datapipe}')\n",
    "                \n",
    "            if self.agent_base.model.training or self.decrement_on_val:\n",
    "                self.step+=1\n",
    "                \n",
    "            self.epsilon=max(self.min_epsilon,self.max_epsilon-self.step/self.max_steps)\n",
    "            # Add a batch dim if missing\n",
    "            if len(action.shape)==1: action.unsqueeze_(0)\n",
    "            mask = None\n",
    "            if self.agent_base.model.training or self.select_on_val:\n",
    "                # Given N(action.shape[0]) actions, select the ones we want to randomly assign... \n",
    "                mask = torch.rand(action.shape[0],)<self.epsilon\n",
    "                # Get random actions as their indexes\n",
    "                rand_action_idxs = torch.LongTensor(int(mask.sum().long()),).random_(action.shape[1])\n",
    "                # If the input action is [[0,1],[1,0]] and...\n",
    "                # If mask is [True,False] and...\n",
    "                # if rand_action_idxs is [0]\n",
    "                # the action[mask] will have [[1,0]] assigned to it resulting in... \n",
    "                # an action with [[1,0],[1,0]]\n",
    "                # print(action.shape[1])\n",
    "                if self.debug: print(f'Mask: {mask}\\nRandom Actions: {rand_action_idxs}\\nPre-random Actions: {action}')\n",
    "                action[mask] = F.one_hot(rand_action_idxs,action.shape[1])\n",
    "            \n",
    "            yield ((action,mask) if self.ret_mask else action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859ecb6-9849-4240-a617-d75fc7070b03",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=1`, that the actions have 100% likihood of randomness applied \n",
    "(even though some might not change due to the random action matching the chosen action). Check that this \n",
    "works on a large batch of `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "384fa4e5-649b-4357-ac2a-278eaa8a5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=1,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n",
    "    test_eq(mask.sum(),200)\n",
    "    test_ne(action.sum(0)[0],200) # Only some of the actions should 1\n",
    "    test_ne(action.sum(0)[1],0) # Only some of the actions should be 0\n",
    "    test_eq(selector.epsilon,1)\n",
    "    test_eq(selector.step,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a711ee-333b-49d7-b849-c3f517079478",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=1`, that the actions have 100% likihood of randomness applied \n",
    "(even though some might not change due to the random action matching the chosen action). Check that this \n",
    "works on single batches over `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56415726-46c2-47a1-88c9-37a0f0af452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ArgMaxer.debug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "030017f4-f373-40ef-978e-fe0c9d2ace06",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent,axis=1)\n",
    "selector = EpsilonSelector(agent,min_epsilon=1,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "        test_eq(mask.sum(),1)\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "test_ne(actions.sum(0)[0],200) # Only some of the actions should 1\n",
    "test_ne(actions.sum(0)[1],0) # Only some of the actions should be 0\n",
    "test_eq(selector.epsilon,1)\n",
    "test_eq(selector.step,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bda9f9-5aaf-427a-b7ae-e61bf0bcc194",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=0`, that the actions have 0% likihood of randomness applied. Check that this \n",
    "works on a large batch of `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c790b227-fc40-49fd-9e0f-4e792a000962",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=0,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n",
    "    test_eq(mask.sum(),0)\n",
    "    test_eq(action.sum(0)[0],200) # All the \"left\" actions should be 1\n",
    "    test_eq(action.sum(0)[1],0) # All the \"right\" actions should be 0\n",
    "    test_eq(selector.epsilon,0)\n",
    "    test_eq(selector.step,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521693a5-8d31-42ee-ad47-566f35f00649",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=0`, that the actions have 0% likihood of randomness applied. Check that this \n",
    "works on single batches over `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4dbb3cb-ddc1-4d77-aad6-05c7510948fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=0,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "        test_eq(mask.sum(),0)\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "test_eq(actions.sum(0)[0],200) # All the \"left\" actions should be 1\n",
    "test_eq(actions.sum(0)[1],0) # All the \"right\" actions should be 0\n",
    "test_eq(selector.epsilon,0)\n",
    "test_eq(selector.step,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee0a64-d23c-472b-a8f5-7b6ea8099e9c",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=1`, the actions should become less random\n",
    "as the steps go on. Check that this works on a large batch of `200 steps`...\n",
    "\n",
    "`epislon` should be 0 at the end of this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dca194b-aae5-4c3d-b18b-d94e00c623f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "masks = None\n",
    "epsilons = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "        if masks is None: masks = mask\n",
    "        else:             masks = torch.hstack((masks,mask))\n",
    "        if epsilons is None: epsilons = tensor([selector.epsilon])\n",
    "        else:                epsilons = torch.hstack((epsilons,tensor([selector.epsilon])))\n",
    "        \n",
    "test_ne(masks[:((200*200)//2)].sum(),200) # We do not expect this to equal a perfect 200...\n",
    "test_ne(masks[:((200*200)//2)].sum(),0)   # ... but we also dont expect it to be 0\n",
    "assert 1000<masks[:((200*200)//2)].sum()<10_000,\\\n",
    "        \"\"\"We expect this to be somewhere between 1000 and 10,000, generally in the 9000 range since \n",
    "           for 200 steps, we are running 200 inputs\"\"\"\n",
    "test_eq(masks[((200*200)//2):].sum(),0) # We fully expect this to be 0 after the half way point\n",
    "test_ne(actions.sum(0)[0],200) # All the \"left\" generally shouldnt be 1\n",
    "test_ne(actions.sum(0)[1],0) # All the \"right\"  generally shouldnt be 0\n",
    "test_eq(selector.epsilon,0)\n",
    "test_eq(selector.step,200)\n",
    "# Since the max steps are 100, and we go for 200 steps, the first 100 epislon entries shouldnt be 0\n",
    "test_ne(epsilons[:100].sum(),0) \n",
    "# In fact the first 100 should sum up to somewhere between 40 and 50. (expected 49.5)\n",
    "test_eq(40<epsilons[:100].sum()<50,True) \n",
    "# Everything after 100 should be 0\n",
    "test_eq(epsilons[100:].sum(),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b6922-bb36-4628-81f3-4fd24272bac5",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=0`, that the actions have 0% likihood of randomness applied. Check that this \n",
    "works on single batches over `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ae2796f-5a7c-4146-9237-5c8f771a05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "masks = None\n",
    "epsilons = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "        if masks is None: masks = mask\n",
    "        else:             masks = torch.hstack((masks,mask))\n",
    "        if epsilons is None: epsilons = tensor([selector.epsilon])\n",
    "        else:                epsilons = torch.hstack((epsilons,tensor([selector.epsilon])))\n",
    "        \n",
    "test_ne(masks[:(200//2)].sum(),200) # We do not expect this to equal a perfect 200...\n",
    "test_ne(masks[:(200//2)].sum(),0)   # ... but we also dont expect it to be 0\n",
    "assert 40<masks[:(200//2)].sum()<60,'We expect this to be somewhere between 60, generally in the ~50 range'\n",
    "test_eq(masks[(200//2):].sum(),0) # We fully expect this to be 0 after the half way point\n",
    "test_ne(actions.sum(0)[0],200) # All the \"left\" generally shouldnt be 1\n",
    "test_ne(actions.sum(0)[1],0) # All the \"right\"  generally shouldnt be 0\n",
    "test_eq(selector.epsilon,0)\n",
    "test_eq(selector.step,200)\n",
    "# Since the max steps are 100, and we go for 200 steps, the first 100 epislon entries shouldnt be 0\n",
    "test_ne(epsilons[:100].sum(),0) \n",
    "# In fact the first 100 should sum up to somewhere between 40 and 50. (expected 49.5)\n",
    "test_eq(40<epsilons[:100].sum()<50,True) \n",
    "# Everything after 100 should be 0\n",
    "test_eq(epsilons[100:].sum(),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d75d83e-718a-4c8f-910d-e142f2188a70",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e3b8453-bb94-416d-9336-06652612c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.envs.gym import *\n",
    "from fastrl.fastai.data.block import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce389bd2-bdda-463b-a653-c9857aef1e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b9405f5-ca51-4e39-b996-f20dcaa900c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ArgMaxer(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \n",
    "    \"Given input `Tensor` from `source_datapipe` returns a tensor of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe,axis=1,only_idx=False): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.axis = axis\n",
    "        self.only_idx = only_idx\n",
    "        \n",
    "    def debug_display(self,step,idx):\n",
    "        print(f'Step: {step}\\n{idx}')\n",
    "    \n",
    "    def __iter__(self) -> torch.LongTensor:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor to take the argmax, got {type(step)}\\n{step}')\n",
    "            # Might want to support simple tuples also depending on if we are processing multiple fields.\n",
    "            idx = torch.argmax(step,axis=self.axis).reshape(-1,1)\n",
    "            if self.only_idx: \n",
    "                yield idx.long()\n",
    "                continue\n",
    "            step[:] = 0\n",
    "            if self.debug: self.debug_display(step,idx)\n",
    "            step.scatter_(1,idx,1)\n",
    "            yield step.long()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4779a26a-28bd-4963-9f02-b018bfbc1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class NumpyConverter(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \n",
    "    \"Given input `Tensor` from `source_datapipe` returns a numpy array of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        \n",
    "    def debug_display(self,step,idx):\n",
    "        print(f'Step: {step}\\n{idx}')\n",
    "    \n",
    "    def __iter__(self) -> torch.LongTensor:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor to  convert to numpy, got {type(step)}\\n{step}')\n",
    "            if self.debug: self.debug_display(step,idx)\n",
    "            yield step.numpy()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14ac4a8c-8a67-45e1-90bf-f35d3bd1cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class PyPrimativeConverter(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \n",
    "    \"Given input `Tensor` from `source_datapipe` returns a numpy array of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe,remove_batch_dim=True): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.remove_batch_dim = remove_batch_dim\n",
    "        \n",
    "    def debug_display(self,step): print(f'Step: {step}')\n",
    "    \n",
    "    def __iter__(self) -> Union[float,bool,int]:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,(np.ndarray)):\n",
    "                raise Exception(f'Expected list or np.ndarray to  convert to python primitive, got {type(step)}\\n{step}')\n",
    "            if self.debug: self.debug_display(step)\n",
    "            \n",
    "            if len(step)>1 or len(step)==0:\n",
    "                raise Exception(f'`step` from {self.source_datapipe} needs to be len 1, not {len(step)}')\n",
    "            else:\n",
    "                step = step[0]\n",
    "                \n",
    "            if np.issubdtype(step.dtype,np.integer):\n",
    "                yield int(step)\n",
    "            elif np.issubdtype(step.dtype,np.floating):\n",
    "                yield float(step)\n",
    "            elif np.issubdtype(step.dtype,np.bool8):\n",
    "                yield bool(step)\n",
    "            else:\n",
    "                raise Exception(f'`step` from {self.source_datapipe} must be one of the 3 python types: bool,int,float, not {step.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23ec79a4-bbdf-41b0-94a9-b4490322527e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [0.5]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = PyPrimativeConverter([np.array([0.5])])\n",
    "L(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d90da02-7778-4f87-88d9-aac89a5ffdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = PyPrimativeConverter([np.array([1])])\n",
    "L(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9025097e-beeb-47f2-a8c1-15fc55e8a540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [True]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = PyPrimativeConverter([np.array([True])])\n",
    "L(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e9adfba-0424-4e39-a29a-b98f9f744e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "\n",
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100)\n",
    "agent = ArgMaxer(selector,only_idx=True)\n",
    "agent = NumpyConverter(agent)\n",
    "agent = PyPrimativeConverter(agent)\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d30240-b234-4cba-af7c-4e05684d92e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4cfe338-de27-4c61-a18d-d74ea33fde37",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03f01296-fd3c-41c8-935b-859cc48fc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LearnerBase(dp.iter.IterDataPipe):\n",
    "    def __init__(self,\n",
    "            model:Module, # The base NN that we getting raw action values out of.\n",
    "            dls:List[DataLoader2], # The dataloaders to read data from for training\n",
    "            loss_func=None, # The loss function to use\n",
    "            opt=None, # The optimizer to use\n",
    "            # LearnerBase will yield each dl individually by default. If `zipwise=True`\n",
    "            # next() will be called on `dls` and will `yield next(dl1),next(dl2),next(dl1)...`\n",
    "            zipwise:bool=False\n",
    "    ):\n",
    "        self.loss_func = loss_func\n",
    "        self.opt = opt\n",
    "        self.model = model\n",
    "        self.iterable = dls\n",
    "        self.zipwise = zipwise\n",
    "        self.learner_base = self\n",
    "        self.batches = find_pipe_instance(dls[0].dataset,dp.iter.Cycler).count\n",
    "\n",
    "    def __iter__(self):\n",
    "        dls = [iter(dl) for dl in self.iterable]\n",
    "        exhausted = []\n",
    "        if self.zipwise:\n",
    "            yield from [next(dl) for i,dl in enumerate(dls) if i not in exhausted]\n",
    "        else:\n",
    "            while not exhausted:\n",
    "                for i,dl in enumerate(dls): \n",
    "                    while i not in exhausted:\n",
    "                        try:\n",
    "                            yield next(dl)\n",
    "                        except StopIteration:\n",
    "                            exhausted.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d83e2f9-59d7-45bf-bf34-6f5ea27d864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def is_learner_base(pipe): return isinstance(pipe,LearnerBase)\n",
    "\n",
    "def find_learner_base(pipe):\n",
    "    \"Basically just find_pipes+is_learner_base with exception handling\"\n",
    "    learner_base = find_pipes(pipe,is_learner_base)\n",
    "    if not learner_base:\n",
    "        raise Exception('`LearnerBase` must be at the start of the pipeline, but it seems to be missing.')\n",
    "    return learner_base[0]\n",
    "\n",
    "class LearnerHead(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learner_base = find_learner_base(self.source_datapipe)\n",
    "\n",
    "    def __iter__(self): yield from self.source_datapipe\n",
    "    \n",
    "    def fit(self,epochs):\n",
    "        epocher = find_pipes(self,is_epocher)[0]\n",
    "        epocher.epochs = epochs\n",
    "        \n",
    "        for iteration in self: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d162eca-d930-49af-abf6-8f6af5064938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def is_epocher(pipe): return isinstance(pipe,EpocherCollector)\n",
    "\n",
    "from fastrl.loggers.core import *\n",
    "def is_epocher(pipe): return isinstance(pipe,EpocherCollector)\n",
    "\n",
    "class EpocherCollector(dp.iter.IterDataPipe):\n",
    "    def __init__(self,\n",
    "            source_datapipe,\n",
    "            logger_bases:List[LoggerBase]=None # `LoggerBase`s that we want to send metrics to\n",
    "        ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queues = [o.main_queue for o in logger_bases] if logger_bases is not None else None\n",
    "        self.iteration_started = False\n",
    "        self.epochs = 0\n",
    "        self.epoch = 0\n",
    "\n",
    "    def __iter__(self): \n",
    "        if self.main_queues is not None and not self.iteration_started:\n",
    "            for q in self.main_queues: q.put(Record('epoch',None))\n",
    "            self.iteration_started = True\n",
    "            \n",
    "        for i in range(self.epochs): \n",
    "            self.epoch = i\n",
    "            if self.main_queues is not None:\n",
    "                for q in self.main_queues: q.put(Record('epoch',self.epoch))\n",
    "            yield from self.source_datapipe   \n",
    "        \n",
    "class BatchCollector(dp.iter.IterDataPipe):\n",
    "    def __init__(self,\n",
    "            source_datapipe,\n",
    "            logger_bases:List[LoggerBase], # `LoggerBase`s that we want to send metrics to\n",
    "            batches:Optional[int]=None\n",
    "        ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queues = [o.main_queue for o in logger_bases] if logger_bases is not None else None\n",
    "        self.iteration_started = False\n",
    "        self.batches = ifnone(\n",
    "            batches,\n",
    "            find_pipe_instance(self.source_datapipe,pipe_cls=LearnerBase).batches\n",
    "        )\n",
    "        self.batch = 0\n",
    "\n",
    "    def __iter__(self): \n",
    "        if self.main_queues is not None and not self.iteration_started:\n",
    "            for q in self.main_queues: q.put(Record('batch',None))\n",
    "            self.iteration_started = True\n",
    "            \n",
    "        self.batch = 0\n",
    "        for batch,record in enumerate(self.source_datapipe): \n",
    "            yield record\n",
    "            self.batch = batch\n",
    "            if self.main_queues is not None:\n",
    "                for q in self.main_queues: q.put(Record('batch',batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55a05bc2-1dbe-4896-838b-d705ebbea82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ProgressBarLogger(LoggerBase):\n",
    "    def __init__(self,\n",
    "                 # This does not need to be immediately set since we need the `LogCollectors` to \n",
    "                 # first be able to reference its queues.\n",
    "                 source_datapipe=None, \n",
    "                 # For automatic pipe attaching, we can designate which pipe this should be\n",
    "                 # referneced for information on which epoch we are on\n",
    "                 epoch_on_pipe:dp.iter.IterDataPipe=EpocherCollector,\n",
    "                 # For automatic pipe attaching, we can designate which pipe this should be\n",
    "                 # referneced for information on which batch we are on\n",
    "                 batch_on_pipe:dp.iter.IterDataPipe=BatchCollector\n",
    "                ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queue = Queue()\n",
    "        self.epoch_on_pipe = epoch_on_pipe\n",
    "        self.batch_on_pipe = batch_on_pipe\n",
    "        \n",
    "        self.collector_keys = None\n",
    "        self.attached_collectors = None\n",
    "    \n",
    "    def dequeue(self): \n",
    "        while not self.main_queue.empty(): yield self.main_queue.get()\n",
    "        \n",
    "    def __iter__(self):\n",
    "        epocher = find_pipe_instance(self,self.epoch_on_pipe)\n",
    "        batcher = find_pipe_instance(self,self.batch_on_pipe)\n",
    "        mbar = master_bar(range(epocher.epochs)) \n",
    "        pbar = progress_bar(range(batcher.batches),parent=mbar,leave=False)\n",
    "\n",
    "        mbar.update(0)\n",
    "        for i,record in enumerate(self.source_datapipe):\n",
    "            if i==0:\n",
    "                self.attached_collectors = {o.name:o.value for o in self.dequeue()}\n",
    "                mbar.write(self.attached_collectors, table=True)\n",
    "                self.collector_keys = list(self.attached_collectors)\n",
    "                    \n",
    "            attached_collectors = {o.name:o.value for o in self.dequeue()}\n",
    "            \n",
    "            if attached_collectors:\n",
    "                self.attached_collectors = merge(self.attached_collectors,attached_collectors)\n",
    "            \n",
    "            if 'batch' in attached_collectors:\n",
    "                pbar.update(attached_collectors['batch'])\n",
    "                \n",
    "            if 'epoch' in attached_collectors:\n",
    "                mbar.update(attached_collectors['epoch'])\n",
    "                collector_values = {k:self.attached_collectors.get(k,None) for k in self.collector_keys}\n",
    "                mbar.write([f'{l:.6f}' if isinstance(l, float) else str(l) for l in collector_values.values()], table=True)\n",
    "            \n",
    "\n",
    "            yield record\n",
    "\n",
    "        attached_collectors = {o.name:o.value for o in self.dequeue()}\n",
    "        if attached_collectors: self.attached_collectors = merge(self.attached_collectors,attached_collectors)\n",
    "\n",
    "        collector_values = {k:self.attached_collectors.get(k,None) for k in self.collector_keys}\n",
    "        mbar.write([f'{l:.6f}' if isinstance(l, float) else str(l) for l in collector_values.values()], table=True)\n",
    "\n",
    "        pbar.on_iter_end()\n",
    "        mbar.on_iter_end()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5604841-5938-4359-b60e-491796772384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup Loggers\n",
    "\n",
    "logger_base = ProgressBarLogger(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c531706-903d-46fa-acd0-f43a5c3046b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class EpsilonCollector(LogCollector):\n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('epsilon',None))\n",
    "        for action in self.source_datapipe:\n",
    "            for q in self.main_queues: \n",
    "                q.put(Record('epsilon',self.source_datapipe.epsilon))\n",
    "            yield action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31f18bb6-1e74-4a17-be8f-a1b36c4f2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "\n",
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100)\n",
    "agent = EpsilonCollector(selector,[logger_base])\n",
    "agent = ArgMaxer(agent,only_idx=True)\n",
    "agent = NumpyConverter(agent)\n",
    "agent = PyPrimativeConverter(agent)\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97a3e6b7-e1fd-40c5-996d-9b8de93da06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent)\n",
    ")\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=10,bs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75847cc7-5647-4ade-8a8d-e0535cef0c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SimpleStep(state=tensor([[ 0.0418, -0.0168,  0.0160, -0.0054]]), action=tensor([1.]), next_state=tensor([[ 0.0415,  0.1781,  0.0159, -0.2930]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([1.]), env_id=tensor([139899300056528]), proc_id=tensor([315]), step_n=tensor([1]), episode_n=tensor([1]), image=tensor([[0.]]))],\n",
       " [SimpleStep(state=tensor([[ 0.0415,  0.1781,  0.0159, -0.2930]]), action=tensor([0.]), next_state=tensor([[ 0.0450, -0.0172,  0.0100,  0.0046]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([2.]), env_id=tensor([139899300056528]), proc_id=tensor([315]), step_n=tensor([2]), episode_n=tensor([1]), image=tensor([[0.]]))],\n",
       " [SimpleStep(state=tensor([[ 0.0450, -0.0172,  0.0100,  0.0046]]), action=tensor([1.]), next_state=tensor([[ 0.0447,  0.1777,  0.0101, -0.2849]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([3.]), env_id=tensor([139899300056528]), proc_id=tensor([315]), step_n=tensor([3]), episode_n=tensor([1]), image=tensor([[0.]]))],\n",
       " [SimpleStep(state=tensor([[ 0.0447,  0.1777,  0.0101, -0.2849]]), action=tensor([0.]), next_state=tensor([[ 0.0483, -0.0175,  0.0044,  0.0110]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([4.]), env_id=tensor([139899300056528]), proc_id=tensor([315]), step_n=tensor([4]), episode_n=tensor([1]), image=tensor([[0.]]))],\n",
       " [SimpleStep(state=tensor([[ 0.0483, -0.0175,  0.0044,  0.0110]]), action=tensor([1.]), next_state=tensor([[ 0.0479,  0.1775,  0.0046, -0.2803]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([5.]), env_id=tensor([139899300056528]), proc_id=tensor([315]), step_n=tensor([5]), episode_n=tensor([1]), image=tensor([[0.]]))],\n",
       " [SimpleStep(state=tensor([[ 0.0479,  0.1775,  0.0046, -0.2803]]), action=tensor([0.]), next_state=tensor([[ 0.0515, -0.0177, -0.0010,  0.0138]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([6.]), env_id=tensor([139899300056528]), proc_id=tensor([315]), step_n=tensor([6]), episode_n=tensor([1]), image=tensor([[0.]]))],\n",
       " [SimpleStep(state=tensor([[ 0.0515, -0.0177, -0.0010,  0.0138]]), action=tensor([0.]), next_state=tensor([[ 0.0511, -0.2128, -0.0007,  0.3062]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([7.]), env_id=tensor([139899300056528]), proc_id=tensor([315]), step_n=tensor([7]), episode_n=tensor([1]), image=tensor([[0.]]))],\n",
       " [SimpleStep(state=tensor([[ 0.0511, -0.2128, -0.0007,  0.3062]]), action=tensor([0.]), next_state=tensor([[ 0.0468, -0.4079,  0.0054,  0.5987]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([8.]), env_id=tensor([139899300056528]), proc_id=tensor([315]), step_n=tensor([8]), episode_n=tensor([1]), image=tensor([[0.]]))],\n",
       " [SimpleStep(state=tensor([[ 0.0468, -0.4079,  0.0054,  0.5987]]), action=tensor([1.]), next_state=tensor([[ 0.0387, -0.2128,  0.0174,  0.3077]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([9.]), env_id=tensor([139899300056528]), proc_id=tensor([315]), step_n=tensor([9]), episode_n=tensor([1]), image=tensor([[0.]]))],\n",
       " [SimpleStep(state=tensor([[ 0.0387, -0.2128,  0.0174,  0.3077]]), action=tensor([1.]), next_state=tensor([[ 0.0344, -0.0180,  0.0235,  0.0205]]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([10.]), env_id=tensor([139899300056528]), proc_id=tensor([315]), step_n=tensor([10]), episode_n=tensor([1]), image=tensor([[0.]]))]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9eea139c-52c0-4005-9101-a45c25c2d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class QCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,discount=0.99,nsteps=1):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.discount = discount\n",
    "        self.nsteps = nsteps\n",
    "        self.learner = find_learner_base(self.source_datapipe)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learner.done_mask = batch.terminated.reshape(-1,)\n",
    "            \n",
    "            self.learner.next_q = self.learner.model(batch.next_state)\n",
    "            # print(self.learner.next_q,self.learner.done_mask)\n",
    "            self.learner.next_q = self.learner.next_q.max(dim=1).values.reshape(-1,1)\n",
    "            self.learner.next_q[self.learner.done_mask] = 0 #xb[done_mask]['reward']\n",
    "            self.learner.targets = batch.reward+self.learner.next_q*(self.discount**self.nsteps)\n",
    "            self.learner.pred = self.learner.model(batch.state)\n",
    "            \n",
    "            t_q=self.learner.pred.clone()\n",
    "            t_q.scatter_(1,batch.action.long(),self.learner.targets)\n",
    "            \n",
    "            self.learner.loss_grad = self.learner.loss_func(self.learner.pred, t_q)\n",
    "            yield batch\n",
    "            \n",
    "class ModelLearnCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learner = find_learner_base(self.source_datapipe)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learner.loss_grad.backward()\n",
    "            self.learner.opt.step()\n",
    "            self.learner.opt.zero_grad()\n",
    "            self.learner.loss = self.learner.loss_grad.clone()\n",
    "            yield self.learner.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fdb1161a-26de-4f73-b052-dfefbb8bc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class StepBatcher(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        \"Converts multiple `StepType` into a single `StepType` with the fields concated.\"\n",
    "        self.source_datapipe = source_datapipe\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            # print(batch)\n",
    "            cls = batch[0].__class__\n",
    "            yield cls(\n",
    "                **{\n",
    "                    fld:torch.vstack(tuple(getattr(step,fld) for step in batch)) for fld in cls._fields\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a793dc72-c14a-48aa-bc7a-9bd8e865458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class EpisodeCollector(LogCollector):\n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('episode',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            if isinstance(steps,dp.DataChunk):\n",
    "                for step in steps:\n",
    "                    for q in self.main_queues: q.put(Record('episode',step.episode_n.detach().numpy()[0]))\n",
    "            else:\n",
    "                for q in self.main_queues: q.put(Record('episode',steps.episode_n.detach().numpy()[0]))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28aa721c-22fc-49e6-8bc4-fc01b20e6df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LossCollector(LogCollector):\n",
    "    def __init__(self,\n",
    "         source_datapipe, # The parent datapipe, likely the one to collect metrics from\n",
    "         logger_bases:List[LoggerBase] # `LoggerBase`s that we want to send metrics to\n",
    "        ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queues = [o.main_queue for o in logger_bases]\n",
    "        self.learner = find_learner_base(self.source_datapipe)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('loss',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            for q in self.main_queues: q.put(Record('loss',self.learner.loss.detach().numpy()))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "576be92f-0a44-459b-a3a4-3db191cca95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class RollingTerminatedRewardCollector(LogCollector):\n",
    "    def __init__(self,\n",
    "         source_datapipe, # The parent datapipe, likely the one to collect metrics from\n",
    "         logger_bases:List[LoggerBase], # `LoggerBase`s that we want to send metrics to\n",
    "         rolling_length:int=100\n",
    "        ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queues = [o.main_queue for o in logger_bases]\n",
    "        self.rolling_rewards = deque([],maxlen=rolling_length)\n",
    "        \n",
    "    def step2terminated(self,step): return bool(step.terminated)\n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('rolling_reward',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            if isinstance(steps,dp.DataChunk):\n",
    "                for step in steps:\n",
    "                    if self.step2terminated(step):\n",
    "                        self.rolling_rewards.append(step.total_reward.detach().numpy()[0])\n",
    "                        for q in self.main_queues: q.put(Record('rolling_reward',np.average(self.rolling_rewards)))\n",
    "            elif self.step2terminated(steps):\n",
    "                self.rolling_rewards.append(steps.total_reward.detach().numpy()[0])\n",
    "                for q in self.main_queues: q.put(Record('rolling_reward',np.average(self.rolling_rewards)))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e798d-e03a-4e8f-ad8f-7b214c1591c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7f8d6-1ad3-45e2-ab60-153def2826ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71bc3355-376e-4743-90b0-c5f9a0b48310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprogress import fastprogress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63d9b481-5998-472a-a2df-18d79bf07ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>episode</th>\n",
       "      <th>rolling_reward</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.294591</td>\n",
       "      <td>41</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0.899900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.23077747</td>\n",
       "      <td>79</td>\n",
       "      <td>25.602564</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0.799900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.24024382</td>\n",
       "      <td>112</td>\n",
       "      <td>27.33</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0.699900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.23441581</td>\n",
       "      <td>135</td>\n",
       "      <td>32.15</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0.599900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.24172296</td>\n",
       "      <td>155</td>\n",
       "      <td>36.69</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0.499900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.25344092</td>\n",
       "      <td>170</td>\n",
       "      <td>42.62</td>\n",
       "      <td>6</td>\n",
       "      <td>999</td>\n",
       "      <td>0.399900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.284737</td>\n",
       "      <td>181</td>\n",
       "      <td>49.37</td>\n",
       "      <td>7</td>\n",
       "      <td>999</td>\n",
       "      <td>0.299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.30140695</td>\n",
       "      <td>190</td>\n",
       "      <td>56.82</td>\n",
       "      <td>8</td>\n",
       "      <td>999</td>\n",
       "      <td>0.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.3079363</td>\n",
       "      <td>197</td>\n",
       "      <td>64.36</td>\n",
       "      <td>9</td>\n",
       "      <td>999</td>\n",
       "      <td>0.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.2763259</td>\n",
       "      <td>201</td>\n",
       "      <td>72.26</td>\n",
       "      <td>10</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.2910457</td>\n",
       "      <td>206</td>\n",
       "      <td>81.48</td>\n",
       "      <td>11</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.3132371</td>\n",
       "      <td>210</td>\n",
       "      <td>89.7</td>\n",
       "      <td>12</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.30576438</td>\n",
       "      <td>213</td>\n",
       "      <td>99.53</td>\n",
       "      <td>13</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.3694377</td>\n",
       "      <td>216</td>\n",
       "      <td>107.75</td>\n",
       "      <td>14</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.2925566</td>\n",
       "      <td>219</td>\n",
       "      <td>115.66</td>\n",
       "      <td>15</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.26451784</td>\n",
       "      <td>223</td>\n",
       "      <td>124.17</td>\n",
       "      <td>16</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.30956095</td>\n",
       "      <td>226</td>\n",
       "      <td>130.12</td>\n",
       "      <td>17</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.22527483</td>\n",
       "      <td>228</td>\n",
       "      <td>136.47</td>\n",
       "      <td>18</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.22211279</td>\n",
       "      <td>230</td>\n",
       "      <td>151.48</td>\n",
       "      <td>19</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.18329658</td>\n",
       "      <td>233</td>\n",
       "      <td>159.34</td>\n",
       "      <td>20</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.18310589</td>\n",
       "      <td>234</td>\n",
       "      <td>169.48</td>\n",
       "      <td>21</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.18026872</td>\n",
       "      <td>234</td>\n",
       "      <td>169.48</td>\n",
       "      <td>22</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.19133674</td>\n",
       "      <td>238</td>\n",
       "      <td>188.25</td>\n",
       "      <td>23</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.22108816</td>\n",
       "      <td>242</td>\n",
       "      <td>196.16</td>\n",
       "      <td>24</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.2952142</td>\n",
       "      <td>248</td>\n",
       "      <td>202.7</td>\n",
       "      <td>25</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.30475733</td>\n",
       "      <td>252</td>\n",
       "      <td>210.47</td>\n",
       "      <td>26</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.2972348</td>\n",
       "      <td>257</td>\n",
       "      <td>219.01</td>\n",
       "      <td>27</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.3361781</td>\n",
       "      <td>261</td>\n",
       "      <td>224.63</td>\n",
       "      <td>28</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.33909246</td>\n",
       "      <td>267</td>\n",
       "      <td>231.28</td>\n",
       "      <td>29</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.29568154</td>\n",
       "      <td>271</td>\n",
       "      <td>236.24</td>\n",
       "      <td>29</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger()\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0.02,max_epsilon=1,max_steps=10000)\n",
    "agent = EpsilonCollector(selector,[logger_base])\n",
    "agent = ArgMaxer(agent,only_idx=True)\n",
    "agent = NumpyConverter(agent)\n",
    "agent = PyPrimativeConverter(agent)\n",
    "agent = AgentHead(agent)\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent)\n",
    ")\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=1000,bs=1))\n",
    "# Setup the Learner\n",
    "learner = LearnerBase(model,dls,loss_func=MSELoss(),opt=AdamW(model.parameters(),lr=0.005))\n",
    "learner = BatchCollector(learner,[logger_base])\n",
    "learner = EpocherCollector(learner,[logger_base])\n",
    "learner = logger_base.connect_source_datapipe(learner)\n",
    "learner = RollingTerminatedRewardCollector(learner,[logger_base])\n",
    "learner = EpisodeCollector(learner,[logger_base])\n",
    "learner = ExperienceReplay(learner,bs=128,max_sz=10000)\n",
    "learner = StepBatcher(learner)\n",
    "learner = QCalc(learner)\n",
    "learner = ModelLearnCalc(learner)\n",
    "learner = LossCollector(learner,[logger_base])\n",
    "learner = LearnerHead(learner)\n",
    "\n",
    "learner.fit(3)\n",
    "# learner.fit(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6de0f41e-2eda-4227-9fa8-f2e0b920754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.loggers.jupyter_visualizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15937f36-8efa-4163-bc67-20019d18c98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7482490a-475e-4c46-b1fa-193bf68b7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.envs.gym import GymTypeTransform,GymStepper\n",
    "\n",
    "def gym_pipe_base(envs,total_steps,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformLoop(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle(count=total_steps)\n",
    "    pipe = GymStepper(pipe,agent=agent,seed=seed,include_images=True)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7dc10e61-4f65-4a17-a5a9-489bb466af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c8784650-6f5c-42b7-9a72-68a0d37d8983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "video_logger = SimpleJupyterVideoPlayer()\n",
    "\n",
    "pipe = gym_pipe_base(['CartPole-v1'],1000,seed=None)\n",
    "pipe = ImageCollector(pipe,[video_logger])\n",
    "\n",
    "pipe = video_logger.connect_source_datapipe(pipe)\n",
    "\n",
    "L(pipe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "05a2c42c-6f47-467f-b758-7f491d4a211e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>episode</th>\n",
       "      <th>rolling_reward</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1.5962886</td>\n",
       "      <td>10</td>\n",
       "      <td>-236.47035</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0.899900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.295194</td>\n",
       "      <td>20</td>\n",
       "      <td>-174.32756</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0.799900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.3210166</td>\n",
       "      <td>29</td>\n",
       "      <td>-172.74147</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0.699900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.0403426</td>\n",
       "      <td>38</td>\n",
       "      <td>-155.03424</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0.599900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.4872072</td>\n",
       "      <td>45</td>\n",
       "      <td>-147.71843</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0.499900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4.567928</td>\n",
       "      <td>50</td>\n",
       "      <td>-144.54634</td>\n",
       "      <td>6</td>\n",
       "      <td>999</td>\n",
       "      <td>0.399900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5700434</td>\n",
       "      <td>53</td>\n",
       "      <td>-143.87135</td>\n",
       "      <td>7</td>\n",
       "      <td>999</td>\n",
       "      <td>0.299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.61638325</td>\n",
       "      <td>56</td>\n",
       "      <td>-139.21907</td>\n",
       "      <td>8</td>\n",
       "      <td>999</td>\n",
       "      <td>0.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.7877886</td>\n",
       "      <td>60</td>\n",
       "      <td>-131.72797</td>\n",
       "      <td>9</td>\n",
       "      <td>999</td>\n",
       "      <td>0.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.2660519</td>\n",
       "      <td>61</td>\n",
       "      <td>-132.82907</td>\n",
       "      <td>10</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5186723</td>\n",
       "      <td>62</td>\n",
       "      <td>-135.85945</td>\n",
       "      <td>11</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.4942812</td>\n",
       "      <td>63</td>\n",
       "      <td>-134.28824</td>\n",
       "      <td>12</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.7345578</td>\n",
       "      <td>63</td>\n",
       "      <td>-134.28824</td>\n",
       "      <td>13</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.46523243</td>\n",
       "      <td>63</td>\n",
       "      <td>-134.28824</td>\n",
       "      <td>14</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.38168797</td>\n",
       "      <td>63</td>\n",
       "      <td>-134.28824</td>\n",
       "      <td>15</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.38190186</td>\n",
       "      <td>63</td>\n",
       "      <td>-134.28824</td>\n",
       "      <td>16</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.30465055</td>\n",
       "      <td>63</td>\n",
       "      <td>-134.28824</td>\n",
       "      <td>17</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.42095584</td>\n",
       "      <td>63</td>\n",
       "      <td>-134.28824</td>\n",
       "      <td>18</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.16994831</td>\n",
       "      <td>63</td>\n",
       "      <td>-134.28824</td>\n",
       "      <td>19</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.10339489</td>\n",
       "      <td>63</td>\n",
       "      <td>-134.28824</td>\n",
       "      <td>20</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.09491216</td>\n",
       "      <td>63</td>\n",
       "      <td>-134.28824</td>\n",
       "      <td>21</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.026964568</td>\n",
       "      <td>63</td>\n",
       "      <td>-134.28824</td>\n",
       "      <td>22</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.9032413</td>\n",
       "      <td>70</td>\n",
       "      <td>-179.59862</td>\n",
       "      <td>23</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.11814615</td>\n",
       "      <td>71</td>\n",
       "      <td>-181.99051</td>\n",
       "      <td>24</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.112917215</td>\n",
       "      <td>71</td>\n",
       "      <td>-181.99051</td>\n",
       "      <td>25</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.14841089</td>\n",
       "      <td>71</td>\n",
       "      <td>-181.99051</td>\n",
       "      <td>26</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.091609694</td>\n",
       "      <td>71</td>\n",
       "      <td>-181.99051</td>\n",
       "      <td>27</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.3686006</td>\n",
       "      <td>71</td>\n",
       "      <td>-181.99051</td>\n",
       "      <td>28</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.3033772</td>\n",
       "      <td>71</td>\n",
       "      <td>-181.99051</td>\n",
       "      <td>29</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.16751838</td>\n",
       "      <td>71</td>\n",
       "      <td>-181.99051</td>\n",
       "      <td>29</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger()\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(8,4)\n",
    "# Setup the Agent\n",
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0.02,max_epsilon=1,max_steps=10000)\n",
    "agent = EpsilonCollector(selector,[logger_base])\n",
    "agent = ArgMaxer(agent,only_idx=True)\n",
    "agent = NumpyConverter(agent)\n",
    "agent = PyPrimativeConverter(agent)\n",
    "agent = AgentHead(agent)\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent)\n",
    ")\n",
    "dls = L(block.dataloaders(['LunarLander-v2']*1,n=1000,bs=1))\n",
    "# Setup the Learner\n",
    "learner = LearnerBase(model,dls,loss_func=MSELoss(),opt=AdamW(model.parameters(),lr=0.005))\n",
    "learner = BatchCollector(learner,[logger_base])\n",
    "learner = EpocherCollector(learner,[logger_base])\n",
    "learner = logger_base.connect_source_datapipe(learner)\n",
    "learner = RollingTerminatedRewardCollector(learner,[logger_base])\n",
    "learner = EpisodeCollector(learner,[logger_base])\n",
    "learner = ExperienceReplay(learner,bs=128,max_sz=10000)\n",
    "learner = StepBatcher(learner)\n",
    "learner = QCalc(learner)\n",
    "learner = ModelLearnCalc(learner)\n",
    "learner = LossCollector(learner,[logger_base])\n",
    "learner = LearnerHead(learner)\n",
    "\n",
    "learner.fit(3)\n",
    "# learner.fit(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "55e84a7d-9583-485d-8e16-3958c72b526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.envs.gym import GymTypeTransform,GymStepper\n",
    "\n",
    "def gym_pipe_base(envs,total_steps,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformLoop(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle(count=total_steps)\n",
    "    pipe = GymStepper(pipe,agent=agent,seed=seed,include_images=True)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "723a8a98-5091-4e31-9cca-9220c64ecdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "video_logger = SimpleJupyterVideoPlayer()\n",
    "\n",
    "pipe = gym_pipe_base(['LunarLander-v2'],1000,seed=None)\n",
    "pipe = ImageCollector(pipe,[video_logger])\n",
    "\n",
    "pipe = video_logger.connect_source_datapipe(pipe)\n",
    "\n",
    "L(pipe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d3626-1702-4f22-ae15-bb93a75bec68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
