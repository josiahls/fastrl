{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.greedy=True\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp agents.dqn.basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from torch.utils.data.datapipes._typing import _DataPipeMeta, _IterDataPipeMeta\n",
    "# Local modules\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "\n",
    "from fastrl.core import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.fastai.data.load import *\n",
    "from fastrl.fastai.data.block import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Basic\n",
    "> Core DQN modules, pipes, and tooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4fb528-cd3d-4dbe-87ff-cf06c60b1168",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6241ea68-611d-4cdf-abdb-4e2a58af23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f4eb63-65c9-4226-a033-ecbb097f616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BasicModelForwarder(dp.iter.IterDataPipe):\n",
    "    \"Takes input from `source_datapipe` and pushes through the agent bases model assuming there is only one model field.\"\n",
    "    def __init__(self,source_datapipe): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.agent_base = find_agent_base(self.source_datapipe)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        yield from map(self.agent_base.model,self.source_datapipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5dff0-4b6f-4513-9565-f363c5087cdc",
   "metadata": {},
   "source": [
    "Check that the 1x4 tensor assuccessfully pushes through the model can get expected outputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498f7b8c-1de3-442e-94d6-7fb2a1f5baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the agent\n",
    "agent = AgentBase(model)\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d8e8699-c6b2-4bef-98c9-9057a190bfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2909, -1.0357], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for action in agent([tensor([1,2,3,4]).float()]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a3558a6-eb99-4f68-983c-9b25532a5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class StepFieldSelector(dp.iter.IterDataPipe):\n",
    "    \"Grabs `field` from `source_datapipe` to push to the rest of the pipeline.\"\n",
    "    def __init__(self,\n",
    "         source_datapipe, # datapipe whose next(source_datapipe) -> `StepType`\n",
    "         field='state' # A field in `StepType` to grab\n",
    "        ): \n",
    "        # TODO: support multi-fields\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.field = field\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,StepType):\n",
    "                raise Exception(f'Expected typing.NamedTuple object got {type(step)}\\n{step}')\n",
    "            yield getattr(step,self.field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382f58d7-3f2f-4c1e-b2f3-1906e9c64a2b",
   "metadata": {},
   "source": [
    "Check that using `StepFieldSelector`, we can grab the `state` field from the `Simplestep` to push through the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e46e30b-757f-472f-86ae-ccbe2cf11932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2909, -1.0357], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = AgentHead(agent)\n",
    "\n",
    "for action in agent([SimpleStep.random(state=tensor([1.,2.,3.,4.]))]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a55397ec-c070-4d14-a6ab-c1202284eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ArgMaxer(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \n",
    "    \"Given input `Tensor` from `source_datapipe` returns a tensor of same shape with argmax set to 1.\"\n",
    "    def __init__(self,source_datapipe,axis=1): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.axis = axis\n",
    "        \n",
    "    def debug_display(self,step,idx):\n",
    "        print(f'Step: {step}\\n{idx}')\n",
    "    \n",
    "    def __iter__(self) -> torch.LongTensor:\n",
    "        for step in self.source_datapipe:\n",
    "            if not issubclass(step.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor to take the argmax, got {type(step)}\\n{step}')\n",
    "            # Might want to support simple tuples also depending on if we are processing multiple fields.\n",
    "            idx = torch.argmax(step,axis=self.axis).reshape(-1,1)\n",
    "            step[:] = 0\n",
    "            if self.debug: self.debug_display(step,idx)\n",
    "            step.scatter_(1,idx,1)\n",
    "            yield step.long()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb8e39ab-45fd-4e71-96c1-24bdfdff10aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0]])\n"
     ]
    }
   ],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "agent = AgentHead(agent)\n",
    "\n",
    "for action in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a4ba91-a6f7-4c31-906d-6d1a88d0ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EpsilonSelector(dp.iter.IterDataPipe):\n",
    "    debug=False\n",
    "    \"Given input `Tensor` from `source_datapipe`.\"\n",
    "    def __init__(self,\n",
    "            source_datapipe, # a datapipe whose next(source_datapipe) -> `Tensor` \n",
    "            min_epsilon:float=0.2, # The minimum epsilon to drop to\n",
    "            # The max/starting epsilon if `epsilon` is None and used for calculating epislon decrease speed.\n",
    "            max_epsilon:float=1, \n",
    "            # Determines how fast the episilon should drop to `min_epsilon`. This should be the number\n",
    "            # of steps that the agent was run through.\n",
    "            max_steps:int=100,\n",
    "            # The starting epsilon\n",
    "            epsilon:float=None,\n",
    "            # Based on the `base_agent.model.training`, by default no decrement or step tracking will\n",
    "            # occur during validation steps.\n",
    "            decrement_on_val:bool=False,\n",
    "            # Based on the `base_agent.model.training`, by default random actions will not be attempted\n",
    "            select_on_val:bool=False,\n",
    "            # Also return the mask that, where True, the action should be randomly selected.\n",
    "            ret_mask:bool=False\n",
    "        ): \n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.max_steps = max_steps\n",
    "        self.epsilon = epsilon\n",
    "        self.decrement_on_val = decrement_on_val\n",
    "        self.select_on_val = select_on_val\n",
    "        self.ret_mask = ret_mask\n",
    "        self.agent_base = find_agent_base(self.source_datapipe)\n",
    "        self.step = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for action in self.source_datapipe:\n",
    "            # TODO: Support tuples of actions also\n",
    "            if not issubclass(action.__class__,Tensor):\n",
    "                raise Exception(f'Expected Tensor, got {type(action)}\\n{action}')\n",
    "            if action.dtype!=torch.int64:\n",
    "                raise ValueError(f'Expected Tensor of dtype int64, got: {action.dtype} from {self.source_datapipe}')\n",
    "                \n",
    "            if self.agent_base.model.training or self.decrement_on_val:\n",
    "                self.step+=1\n",
    "                \n",
    "            self.epsilon=max(self.min_epsilon,self.max_epsilon-self.step/self.max_steps)\n",
    "            # Add a batch dim if missing\n",
    "            if len(action.shape)==1: action.unsqueeze_(0)\n",
    "            mask = None\n",
    "            if self.agent_base.model.training or self.select_on_val:\n",
    "                # Given N(action.shape[0]) actions, select the ones we want to randomly assign... \n",
    "                mask = torch.rand(action.shape[0],)<self.epsilon\n",
    "                # Get random actions as their indexes\n",
    "                rand_action_idxs = torch.LongTensor(int(mask.sum().long()),).random_(action.shape[1])\n",
    "                # If the input action is [[0,1],[1,0]] and...\n",
    "                # If mask is [True,False] and...\n",
    "                # if rand_action_idxs is [0]\n",
    "                # the action[mask] will have [[1,0]] assigned to it resulting in... \n",
    "                # an action with [[1,0],[1,0]]\n",
    "                # print(action.shape[1])\n",
    "                if self.debug: print(f'Mask: {mask}\\nRandom Actions: {rand_action_idxs}\\nPre-random Actions: {action}')\n",
    "                action[mask] = F.one_hot(rand_action_idxs,action.shape[1])\n",
    "            \n",
    "            yield ((action,mask) if self.ret_mask else action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859ecb6-9849-4240-a617-d75fc7070b03",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=1`, that the actions have 100% likihood of randomness applied \n",
    "(even though some might not change due to the random action matching the chosen action). Check that this \n",
    "works on a large batch of `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "384fa4e5-649b-4357-ac2a-278eaa8a5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=1,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n",
    "    test_eq(mask.sum(),200)\n",
    "    test_ne(action.sum(0)[0],200) # Only some of the actions should 1\n",
    "    test_ne(action.sum(0)[1],0) # Only some of the actions should be 0\n",
    "    test_eq(selector.epsilon,1)\n",
    "    test_eq(selector.step,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a711ee-333b-49d7-b849-c3f517079478",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=1`, that the actions have 100% likihood of randomness applied \n",
    "(even though some might not change due to the random action matching the chosen action). Check that this \n",
    "works on single batches over `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56415726-46c2-47a1-88c9-37a0f0af452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ArgMaxer.debug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "030017f4-f373-40ef-978e-fe0c9d2ace06",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent,axis=1)\n",
    "selector = EpsilonSelector(agent,min_epsilon=1,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "        test_eq(mask.sum(),1)\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "test_ne(actions.sum(0)[0],200) # Only some of the actions should 1\n",
    "test_ne(actions.sum(0)[1],0) # Only some of the actions should be 0\n",
    "test_eq(selector.epsilon,1)\n",
    "test_eq(selector.step,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bda9f9-5aaf-427a-b7ae-e61bf0bcc194",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=0`, that the actions have 0% likihood of randomness applied. Check that this \n",
    "works on a large batch of `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c790b227-fc40-49fd-9e0f-4e792a000962",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=0,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n",
    "    test_eq(mask.sum(),0)\n",
    "    test_eq(action.sum(0)[0],200) # All the \"left\" actions should be 1\n",
    "    test_eq(action.sum(0)[1],0) # All the \"right\" actions should be 0\n",
    "    test_eq(selector.epsilon,0)\n",
    "    test_eq(selector.step,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521693a5-8d31-42ee-ad47-566f35f00649",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=0`, that the actions have 0% likihood of randomness applied. Check that this \n",
    "works on single batches over `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4dbb3cb-ddc1-4d77-aad6-05c7510948fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=0,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "        test_eq(mask.sum(),0)\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "test_eq(actions.sum(0)[0],200) # All the \"left\" actions should be 1\n",
    "test_eq(actions.sum(0)[1],0) # All the \"right\" actions should be 0\n",
    "test_eq(selector.epsilon,0)\n",
    "test_eq(selector.step,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee0a64-d23c-472b-a8f5-7b6ea8099e9c",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=1`, the actions should become less random\n",
    "as the steps go on. Check that this works on a large batch of `200 steps`...\n",
    "\n",
    "`epislon` should be 0 at the end of this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dca194b-aae5-4c3d-b18b-d94e00c623f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "masks = None\n",
    "epsilons = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "        if masks is None: masks = mask\n",
    "        else:             masks = torch.hstack((masks,mask))\n",
    "        if epsilons is None: epsilons = tensor([selector.epsilon])\n",
    "        else:                epsilons = torch.hstack((epsilons,tensor([selector.epsilon])))\n",
    "        \n",
    "test_ne(masks[:((200*200)//2)].sum(),200) # We do not expect this to equal a perfect 200...\n",
    "test_ne(masks[:((200*200)//2)].sum(),0)   # ... but we also dont expect it to be 0\n",
    "assert 1000<masks[:((200*200)//2)].sum()<10_000,\\\n",
    "        \"\"\"We expect this to be somewhere between 1000 and 10,000, generally in the 9000 range since \n",
    "           for 200 steps, we are running 200 inputs\"\"\"\n",
    "test_eq(masks[((200*200)//2):].sum(),0) # We fully expect this to be 0 after the half way point\n",
    "test_ne(actions.sum(0)[0],200) # All the \"left\" generally shouldnt be 1\n",
    "test_ne(actions.sum(0)[1],0) # All the \"right\"  generally shouldnt be 0\n",
    "test_eq(selector.epsilon,0)\n",
    "test_eq(selector.step,200)\n",
    "# Since the max steps are 100, and we go for 200 steps, the first 100 epislon entries shouldnt be 0\n",
    "test_ne(epsilons[:100].sum(),0) \n",
    "# In fact the first 100 should sum up to somewhere between 40 and 50. (expected 49.5)\n",
    "test_eq(40<epsilons[:100].sum()<50,True) \n",
    "# Everything after 100 should be 0\n",
    "test_eq(epsilons[100:].sum(),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b6922-bb36-4628-81f3-4fd24272bac5",
   "metadata": {},
   "source": [
    "Check that when `min_epsilon=0 and max_epsilon=0`, that the actions have 0% likihood of randomness applied. Check that this \n",
    "works on single batches over `200 steps`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ae2796f-5a7c-4146-9237-5c8f771a05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100,ret_mask=True)\n",
    "agent = AgentHead(selector)\n",
    "\n",
    "actions = None\n",
    "masks = None\n",
    "epsilons = None\n",
    "for i in range(200):\n",
    "    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n",
    "        if actions is None: actions = action\n",
    "        else:               actions = torch.vstack((actions,action))\n",
    "        if masks is None: masks = mask\n",
    "        else:             masks = torch.hstack((masks,mask))\n",
    "        if epsilons is None: epsilons = tensor([selector.epsilon])\n",
    "        else:                epsilons = torch.hstack((epsilons,tensor([selector.epsilon])))\n",
    "        \n",
    "test_ne(masks[:(200//2)].sum(),200) # We do not expect this to equal a perfect 200...\n",
    "test_ne(masks[:(200//2)].sum(),0)   # ... but we also dont expect it to be 0\n",
    "assert 40<masks[:(200//2)].sum()<60,'We expect this to be somewhere between 60, generally in the ~50 range'\n",
    "test_eq(masks[(200//2):].sum(),0) # We fully expect this to be 0 after the half way point\n",
    "test_ne(actions.sum(0)[0],200) # All the \"left\" generally shouldnt be 1\n",
    "test_ne(actions.sum(0)[1],0) # All the \"right\"  generally shouldnt be 0\n",
    "test_eq(selector.epsilon,0)\n",
    "test_eq(selector.step,200)\n",
    "# Since the max steps are 100, and we go for 200 steps, the first 100 epislon entries shouldnt be 0\n",
    "test_ne(epsilons[:100].sum(),0) \n",
    "# In fact the first 100 should sum up to somewhere between 40 and 50. (expected 49.5)\n",
    "test_eq(40<epsilons[:100].sum()<50,True) \n",
    "# Everything after 100 should be 0\n",
    "test_eq(epsilons[100:].sum(),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d75d83e-718a-4c8f-910d-e142f2188a70",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e3b8453-bb94-416d-9336-06652612c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.envs.gym import *\n",
    "from fastrl.fastai.data.block import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e9adfba-0424-4e39-a29a-b98f9f744e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "\n",
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100,ret_mask=True)\n",
    "agent = AgentHead(selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b66738f1-7e53-4097-9846-421d4cd56d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GymTransformBlock(\n",
    "    agent,\n",
    "    seed=None,\n",
    "    nsteps=1,\n",
    "    nskips=1,\n",
    "    dl_type = DataLoader2,\n",
    "    pipe_fn_kwargs=None,\n",
    "    type_tfms=None,\n",
    "    **kwargs\n",
    "):\n",
    "    pipe_fn_kwargs = ifnone(pipe_fn_kwargs,{})\n",
    "    type_tfms = ifnone(type_tfms,GymTypeTransform)\n",
    "    \n",
    "    def pipe_fn(source:List[str],bs,n,seed,nsteps,nskips,\n",
    "                type_tfms=None,item_tfms=None,batch_tfms=None,cbs=None):\n",
    "        pipe = dp.map.Mapper(source)\n",
    "        pipe = TypeTransformLoop(pipe,type_tfms)\n",
    "        pipe = dp.iter.MapToIterConverter(pipe)\n",
    "        pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "        pipe = pipe.cycle(count=n)\n",
    "        pipe = GymStepper(pipe,seed=seed)\n",
    "        if nskips!=1: pipe = NSkipper(pipe,n=nskips)\n",
    "        if nsteps!=1:\n",
    "            pipe = NStepper(pipe,n=nsteps)\n",
    "            pipe = Flattener(pipe)\n",
    "        pipe = ItemTransformLoop(pipe,item_tfms)\n",
    "        pipe  = pipe.batch(batch_size=bs)\n",
    "        pipe = BatchTransformLoop(pipe,batch_tfms)\n",
    "        pipe = add_cbs_to_pipes(pipe,cbs)\n",
    "        return pipe\n",
    "\n",
    "    return TransformBlock(\n",
    "        pipe_fn = pipe_fn,\n",
    "        dl_type = dl_type,\n",
    "        pipe_fn_kwargs = merge(pipe_fn_kwargs,kwargs,dict(nsteps=nsteps,nskips=nskips,seed=seed,type_tfms=type_tfms))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71d30240-b234-4cba-af7c-4e05684d92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.pipes.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d852ef9e-864d-4b45-8bc6-863b7968dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataBlock(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Each transform block will have its own dataloader. \n",
    "        blocks:List[TransformBlock]=None, \n",
    "    ):\n",
    "        store_attr(but='blocks')\n",
    "        self.blocks = L(blocks)\n",
    "\n",
    "    def datapipes(\n",
    "        self,\n",
    "        source:Any,\n",
    "        bs=1,\n",
    "        n=1,\n",
    "        return_blocks:bool=False\n",
    "    ) -> Generator[Union[Tuple[_DataPipeMeta,TransformBlock],_DataPipeMeta],None,None]:\n",
    "        for b in self.blocks:\n",
    "            pipe = b.pipe_fn(source,bs=bs,n=n,**b.pipe_fn_kwargs)\n",
    "            yield (pipe,b) if return_blocks else pipe\n",
    "        \n",
    "    def dataloaders(\n",
    "        self,\n",
    "        source:Any,\n",
    "        bs=1,\n",
    "        n=1,\n",
    "        n_workers=0,\n",
    "        **kwargs\n",
    "    ) -> Generator[DataLoader2,None,None]:\n",
    "        for pipe,block in self.datapipes(source,bs=bs,n=n,return_blocks=True,**kwargs):\n",
    "            yield block.dl_type(pipe,**merge(kwargs,block.dls_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e6c7e55-4fc8-461c-bfcb-af735521b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent)\n",
    ")\n",
    "pipes = L(block.datapipes(['CartPole-v1']*1,n=10,bs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4282e91-635c-475b-953b-b93ab3281e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleStep(state=tensor([-0.0240, -0.0074, -0.0099,  0.0254]), action=tensor([1.]), next_state=tensor([-0.0242,  0.1879, -0.0094, -0.2704]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([1.]), env_id=tensor([140235705537616]), proc_id=tensor([96]), step_n=tensor([1]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([-0.0242,  0.1879, -0.0094, -0.2704]), action=tensor([1.]), next_state=tensor([-0.0204,  0.3831, -0.0148, -0.5660]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([2.]), env_id=tensor([140235705537616]), proc_id=tensor([96]), step_n=tensor([2]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([-0.0204,  0.3831, -0.0148, -0.5660]), action=tensor([1.]), next_state=tensor([-0.0128,  0.5784, -0.0262, -0.8633]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([3.]), env_id=tensor([140235705537616]), proc_id=tensor([96]), step_n=tensor([3]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([-0.0128,  0.5784, -0.0262, -0.8633]), action=tensor([1.]), next_state=tensor([-0.0012,  0.7739, -0.0434, -1.1641]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([4.]), env_id=tensor([140235705537616]), proc_id=tensor([96]), step_n=tensor([4]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([-0.0012,  0.7739, -0.0434, -1.1641]), action=tensor([0.]), next_state=tensor([ 0.0143,  0.5794, -0.0667, -0.8854]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([5.]), env_id=tensor([140235705537616]), proc_id=tensor([96]), step_n=tensor([5]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([ 0.0143,  0.5794, -0.0667, -0.8854]), action=tensor([1.]), next_state=tensor([ 0.0259,  0.7753, -0.0844, -1.1983]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([6.]), env_id=tensor([140235705537616]), proc_id=tensor([96]), step_n=tensor([6]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([ 0.0259,  0.7753, -0.0844, -1.1983]), action=tensor([0.]), next_state=tensor([ 0.0414,  0.5814, -0.1084, -0.9332]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([7.]), env_id=tensor([140235705537616]), proc_id=tensor([96]), step_n=tensor([7]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([ 0.0414,  0.5814, -0.1084, -0.9332]), action=tensor([1.]), next_state=tensor([ 0.0530,  0.7778, -0.1270, -1.2579]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([8.]), env_id=tensor([140235705537616]), proc_id=tensor([96]), step_n=tensor([8]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([ 0.0530,  0.7778, -0.1270, -1.2579]), action=tensor([0.]), next_state=tensor([ 0.0686,  0.5845, -0.1522, -1.0075]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([9.]), env_id=tensor([140235705537616]), proc_id=tensor([96]), step_n=tensor([9]), episode_n=tensor([1]))]\n",
      "[SimpleStep(state=tensor([ 0.0686,  0.5845, -0.1522, -1.0075]), action=tensor([0.]), next_state=tensor([ 0.0803,  0.3917, -0.1724, -0.7662]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([1.]), total_reward=tensor([10.]), env_id=tensor([140235705537616]), proc_id=tensor([96]), step_n=tensor([10]), episode_n=tensor([1]))]\n"
     ]
    }
   ],
   "source": [
    "for p in pipes[0]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7c1dca2-dc5e-4d4e-95fa-d57441643d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent)\n",
    ")\n",
    "pipes = L(block.dataloaders(['CartPole-v1']*1,n=10,bs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b83d32e-a034-45a9-b963-cc8da2677cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleStep(state=tensor([[-0.0378, -0.0020, -0.0261, -0.0370]]), action=tensor([[1.]]), next_state=tensor([[-0.0379,  0.1935, -0.0269, -0.3378]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[1.]]), env_id=tensor([[140235041323536]]), proc_id=tensor([[96]]), step_n=tensor([[1]]), episode_n=tensor([[1]]))]\n",
      "[SimpleStep(state=tensor([[-0.0379,  0.1935, -0.0269, -0.3378]]), action=tensor([[1.]]), next_state=tensor([[-0.0340,  0.3890, -0.0336, -0.6389]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[2.]]), env_id=tensor([[140235041323536]]), proc_id=tensor([[96]]), step_n=tensor([[2]]), episode_n=tensor([[1]]))]\n",
      "[SimpleStep(state=tensor([[-0.0340,  0.3890, -0.0336, -0.6389]]), action=tensor([[1.]]), next_state=tensor([[-0.0262,  0.5846, -0.0464, -0.9419]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[3.]]), env_id=tensor([[140235041323536]]), proc_id=tensor([[96]]), step_n=tensor([[3]]), episode_n=tensor([[1]]))]\n",
      "[SimpleStep(state=tensor([[-0.0262,  0.5846, -0.0464, -0.9419]]), action=tensor([[1.]]), next_state=tensor([[-0.0145,  0.7803, -0.0653, -1.2488]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[4.]]), env_id=tensor([[140235041323536]]), proc_id=tensor([[96]]), step_n=tensor([[4]]), episode_n=tensor([[1]]))]\n",
      "[SimpleStep(state=tensor([[-0.0145,  0.7803, -0.0653, -1.2488]]), action=tensor([[1.]]), next_state=tensor([[ 1.0638e-03,  9.7619e-01, -9.0233e-02, -1.5612e+00]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[5.]]), env_id=tensor([[140235041323536]]), proc_id=tensor([[96]]), step_n=tensor([[5]]), episode_n=tensor([[1]]))]\n",
      "[SimpleStep(state=tensor([[ 1.0638e-03,  9.7619e-01, -9.0233e-02, -1.5612e+00]]), action=tensor([[0.]]), next_state=tensor([[ 0.0206,  0.7823, -0.1215, -1.2980]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[6.]]), env_id=tensor([[140235041323536]]), proc_id=tensor([[96]]), step_n=tensor([[6]]), episode_n=tensor([[1]]))]\n",
      "[SimpleStep(state=tensor([[ 0.0206,  0.7823, -0.1215, -1.2980]]), action=tensor([[0.]]), next_state=tensor([[ 0.0362,  0.5889, -0.1474, -1.0457]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[7.]]), env_id=tensor([[140235041323536]]), proc_id=tensor([[96]]), step_n=tensor([[7]]), episode_n=tensor([[1]]))]\n",
      "[SimpleStep(state=tensor([[ 0.0362,  0.5889, -0.1474, -1.0457]]), action=tensor([[1.]]), next_state=tensor([[ 0.0480,  0.7856, -0.1683, -1.3808]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[8.]]), env_id=tensor([[140235041323536]]), proc_id=tensor([[96]]), step_n=tensor([[8]]), episode_n=tensor([[1]]))]\n",
      "[SimpleStep(state=tensor([[ 0.0480,  0.7856, -0.1683, -1.3808]]), action=tensor([[1.]]), next_state=tensor([[ 0.0637,  0.9824, -0.1959, -1.7210]]), terminated=tensor([[False]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[9.]]), env_id=tensor([[140235041323536]]), proc_id=tensor([[96]]), step_n=tensor([[9]]), episode_n=tensor([[1]]))]\n",
      "[SimpleStep(state=tensor([[ 0.0637,  0.9824, -0.1959, -1.7210]]), action=tensor([[1.]]), next_state=tensor([[ 0.0834,  1.1791, -0.2304, -2.0677]]), terminated=tensor([[True]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[10.]]), env_id=tensor([[140235041323536]]), proc_id=tensor([[96]]), step_n=tensor([[10]]), episode_n=tensor([[1]]))]\n"
     ]
    }
   ],
   "source": [
    "for p in pipes[0]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cfe338-de27-4c61-a18d-d74ea33fde37",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "03f01296-fd3c-41c8-935b-859cc48fc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LearnerBase(dp.iter.IterDataPipe):\n",
    "    def __init__(self,\n",
    "            model:Module, # The base NN that we getting raw action values out of.\n",
    "            dls:List[DataLoader2], # The dataloaders to read data from for training\n",
    "            # LearnerBase will yield each dl individually by default. If `zipwise=True`\n",
    "            # next() will be called on `dls` and will `yield next(dl1),next(dl2),next(dl1)...`\n",
    "            zipwise:bool=False\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.iterable = dls\n",
    "        self.zipwise = zipwise\n",
    "        self.learner_base = self\n",
    "\n",
    "    def __iter__(self):\n",
    "        dls = [iter(dl) for dl in self.iterable]\n",
    "        exhausted = []\n",
    "        while True:\n",
    "            if self.zipwise:\n",
    "                yield [next(dl) for i,dl in enumerate(dls) if i not in exhausted]\n",
    "            else:\n",
    "                for i,dl in enumerate(dls): \n",
    "                    if i not in exhausted:\n",
    "                        try:\n",
    "                            yield next(dl)\n",
    "                        except StopIteration:\n",
    "                            exhausted.append(i)\n",
    "            if len(exhausted)==len(dls):\n",
    "                dls = [iter(dl) for dl in self.iterable]\n",
    "                exhausted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5d83e2f9-59d7-45bf-bf34-6f5ea27d864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_learner_base(pipe): return isinstance(pipe,LearnerBase)\n",
    "\n",
    "def find_learner_base(pipe):\n",
    "    \"Basically just find_pipes+is_learner_base with exception handling\"\n",
    "    learner_base = find_pipes(pipe,is_learner_base)\n",
    "    if not learner_base:\n",
    "        raise Exception('`LearnerBase` must be at the start of the pipeline, but it seems to be missing.')\n",
    "    return learner_base[0]\n",
    "\n",
    "class LearnerHead(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learner_base = find_learner_base(self.source_datapipe)\n",
    "\n",
    "    def __iter__(self): yield from self.source_datapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "31f18bb6-1e74-4a17-be8f-a1b36c4f2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "\n",
    "agent = AgentBase(model)\n",
    "agent = StepFieldSelector(agent,field='state')\n",
    "agent = BasicModelForwarder(agent)\n",
    "agent = ArgMaxer(agent)\n",
    "selector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100,ret_mask=True)\n",
    "agent = AgentHead(selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "97a3e6b7-e1fd-40c5-996d-9b8de93da06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent)\n",
    ")\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=10,bs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fd0f3282-c6f7-4157-a983-1e24f641b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = LearnerBase(model,dls)\n",
    "\n",
    "# learner = TrainingAugmentations(learner)\n",
    "\n",
    "learner = LearnerHead(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f69a6c52-7ba6-4a83-9cae-70896eadcf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleStep(state=tensor([[ 0.0887,  0.2735, -0.1989, -1.0469]]), action=tensor([[0.]]), next_state=tensor([[ 0.0941,  0.0815, -0.2199, -0.8227]]), terminated=tensor([[True]]), truncated=tensor([[False]]), reward=tensor([[1.]]), total_reward=tensor([[22.]]), env_id=tensor([[140235704488976]]), proc_id=tensor([[96]]), step_n=tensor([[22]]), episode_n=tensor([[118]]))]\n"
     ]
    }
   ],
   "source": [
    "for element in learner:\n",
    "    print(element)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import *\n",
    "    make_readme()\n",
    "    notebook2script(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e4591-4dbf-4772-92cb-a9dbdeaf2646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
