{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp test_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import importlib\n",
    "# Third party libs\n",
    "\n",
    "# Local modules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "liberal-permission",
   "metadata": {},
   "source": [
    "# Synth Agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "premium-protocol",
   "metadata": {},
   "source": [
    "# Test Utils\n",
    "> Tools for testing fastrl. fastai has a module with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4dfe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_env(name):\n",
    "    \"Return env var value if it's defined and not an empty string, or return Unknown\"\n",
    "    res = os.environ.get(name,'')\n",
    "    return res if len(res) else \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e440b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def try_import(module):\n",
    "    \"Try to import `module`. Returns module's object on success, None on failure\"\n",
    "    try: return importlib.import_module(module)\n",
    "    except: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dff6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def nvidia_mem():\n",
    "    from fastcore.all import run\n",
    "    try: mem = run(\"nvidia-smi --query-gpu=memory.total --format=csv,nounits,noheader\")\n",
    "    except: return None\n",
    "    return mem.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c763614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def nvidia_smi(cmd = \"nvidia-smi\"):\n",
    "    from fastcore.all import run\n",
    "    try: res = run(cmd)\n",
    "    except OSError as e: return None\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97014d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def initialize_notebook():\n",
    "    \"\"\"\n",
    "    Function to initialize the notebook environment considering whether it is in Colab or not.\n",
    "    It handles installation of necessary packages and setting up the environment variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Checking if the environment is Google Colab\n",
    "    if os.path.exists(\"/content\"):\n",
    "        # Installing necessary packages\n",
    "        os.system(\"pip install -Uqq fastrl['dev'] pyvirtualdisplay\")\n",
    "        os.system(\"apt-get install -y xvfb python-opengl > /dev/null 2>&1\")\n",
    "        \n",
    "        # Starting a virtual display\n",
    "        from pyvirtualdisplay import Display\n",
    "        display = Display(visible=0, size=(400, 300))\n",
    "        display.start()\n",
    "        \n",
    "    else:\n",
    "        # If not in Colab, importing necessary packages and checking environment variables\n",
    "        from nbdev.showdoc import show_doc\n",
    "        from nbdev.imports import IN_NOTEBOOK, IN_COLAB, IN_IPYTHON\n",
    "        \n",
    "        # Asserting the environment variables\n",
    "        if not os.environ.get(\"IN_TEST\", None):\n",
    "            assert IN_NOTEBOOK\n",
    "            assert not IN_COLAB\n",
    "            assert IN_IPYTHON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#|export\n",
    "def show_install(show_nvidia_smi:bool=False):\n",
    "    \"Print user's setup information\"\n",
    "\n",
    "    # import fastai\n",
    "    import platform \n",
    "    import fastprogress\n",
    "    import fastcore\n",
    "    import fastrl\n",
    "    import torch\n",
    "    from fastcore.all import ifnone\n",
    "\n",
    "\n",
    "    rep = []\n",
    "    opt_mods = []\n",
    "\n",
    "    rep.append([\"=== Software ===\", None])\n",
    "    rep.append([\"python\", platform.python_version()])\n",
    "    rep.append([\"fastrl\", fastrl.__version__])\n",
    "    # rep.append([\"fastai\", fastai.__version__])\n",
    "    rep.append([\"fastcore\", fastcore.__version__])\n",
    "    rep.append([\"fastprogress\", fastprogress.__version__])\n",
    "    rep.append([\"torch\",  torch.__version__])\n",
    "\n",
    "    # nvidia-smi\n",
    "    smi = nvidia_smi()\n",
    "    if smi:\n",
    "        match = re.findall(r'Driver Version: +(\\d+\\.\\d+)', smi)\n",
    "        if match: rep.append([\"nvidia driver\", match[0]])\n",
    "\n",
    "    available = \"available\" if torch.cuda.is_available() else \"**Not available** \"\n",
    "    rep.append([\"torch cuda\", f\"{torch.version.cuda} / is {available}\"])\n",
    "\n",
    "    # no point reporting on cudnn if cuda is not available, as it\n",
    "    # seems to be enabled at times even on cpu-only setups\n",
    "    if torch.cuda.is_available():\n",
    "        enabled = \"enabled\" if torch.backends.cudnn.enabled else \"**Not enabled** \"\n",
    "        rep.append([\"torch cudnn\", f\"{torch.backends.cudnn.version()} / is {enabled}\"])\n",
    "\n",
    "    rep.append([\"\\n=== Hardware ===\", None])\n",
    "\n",
    "    gpu_total_mem = []\n",
    "    nvidia_gpu_cnt = 0\n",
    "    if smi:\n",
    "        mem = nvidia_mem()\n",
    "        nvidia_gpu_cnt = len(ifnone(mem, []))\n",
    "\n",
    "    if nvidia_gpu_cnt: rep.append([\"nvidia gpus\", nvidia_gpu_cnt])\n",
    "\n",
    "    torch_gpu_cnt = torch.cuda.device_count()\n",
    "    if torch_gpu_cnt:\n",
    "        rep.append([\"torch devices\", torch_gpu_cnt])\n",
    "        # information for each gpu\n",
    "        for i in range(torch_gpu_cnt):\n",
    "            rep.append([f\"  - gpu{i}\", (f\"{gpu_total_mem[i]}MB | \" if gpu_total_mem else \"\") + torch.cuda.get_device_name(i)])\n",
    "    else:\n",
    "        if nvidia_gpu_cnt:\n",
    "            rep.append([f\"Have {nvidia_gpu_cnt} GPU(s), but torch can't use them (check nvidia driver)\", None])\n",
    "        else:\n",
    "            rep.append([f\"No GPUs available\", None])\n",
    "\n",
    "\n",
    "    rep.append([\"\\n=== Environment ===\", None])\n",
    "\n",
    "    rep.append([\"platform\", platform.platform()])\n",
    "\n",
    "    if platform.system() == 'Linux':\n",
    "        distro = try_import('distro')\n",
    "        if distro:\n",
    "            # full distro info\n",
    "            rep.append([\"distro\", ' '.join(distro.linux_distribution())])\n",
    "        else:\n",
    "            opt_mods.append('distro');\n",
    "            # partial distro info\n",
    "            rep.append([\"distro\", platform.uname().version])\n",
    "\n",
    "    rep.append([\"conda env\", get_env('CONDA_DEFAULT_ENV')])\n",
    "    rep.append([\"python\", sys.executable])\n",
    "    rep.append([\"sys.path\", \"\\n\".join(sys.path)])\n",
    "\n",
    "    print(\"\\n\\n```text\")\n",
    "\n",
    "    keylen = max([len(e[0]) for e in rep if e[1] is not None])\n",
    "    for e in rep:\n",
    "        print(f\"{e[0]:{keylen}}\", (f\": {e[1]}\" if e[1] is not None else \"\"))\n",
    "\n",
    "    if smi:\n",
    "        if show_nvidia_smi: print(f\"\\n{smi}\")\n",
    "    else:\n",
    "        if torch_gpu_cnt: print(\"no nvidia-smi is found\")\n",
    "        else: print(\"no supported gpus found on this system\")\n",
    "\n",
    "    print(\"```\\n\")\n",
    "\n",
    "    print(\"Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\\n\")\n",
    "\n",
    "    if opt_mods:\n",
    "        print(\"Optional package(s) to enhance the diagnostics can be installed with:\")\n",
    "        print(f\"pip install {' '.join(opt_mods)}\")\n",
    "        print(\"Once installed, re-run this utility to get the additional information\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "resistant-hebrew",
   "metadata": {},
   "source": [
    "This function is ripped directly from [97_test_utils](https://github.com/fastai/fastai/blob/master/nbs/97_test_utils.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "show_install(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
