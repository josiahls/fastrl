{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp learner.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "import torch\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "from torchdata.dataloader2 import DataLoader2\n",
    "from torchdata.dataloader2.graph import find_dps,traverse\n",
    "# Local modules\n",
    "from fastrl.core import *\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.loggers.core import *\n",
    "from fastrl.data.dataloader2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Learner Core\n",
    "> Core DataPipes for building Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "984a53f1-93ee-4540-8b8d-50071090280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LearnerBase(dp.iter.IterDataPipe):\n",
    "    def __init__(self,\n",
    "            model:Module, # The base NN that we getting raw action values out of.\n",
    "            dls:List[DataLoader2], # The dataloaders to read data from for training\n",
    "            device=None,\n",
    "            loss_func=None, # The loss function to use\n",
    "            opt=None, # The optimizer to use\n",
    "            # LearnerBase will yield each dl individually by default. If `zipwise=True`\n",
    "            # next() will be called on `dls` and will `yield next(dl1),next(dl2),next(dl1)...`\n",
    "            zipwise:bool=False,\n",
    "            # For reinforcement learning, the iterables/workers will live forever and so we dont want\n",
    "            # to shut them down. We still want a concept of \"batch\" and \"epoch\" so this param\n",
    "            # can handle that.\n",
    "            batches:int=None\n",
    "    ):\n",
    "        self.loss_func = loss_func\n",
    "        self.opt = opt\n",
    "        self.model = model\n",
    "        self.iterable = dls\n",
    "        self.zipwise = zipwise\n",
    "        self.learner_base = self\n",
    "        self.infinite_dls = False\n",
    "        self._dls = None\n",
    "        if batches is not None: \n",
    "            self.batches = batches\n",
    "            self.infinite_dls = True\n",
    "        else:                   \n",
    "            self.batches = find_dp(traverse(dls[0].datapipe,only_datapipe=True),dp.iter.Header).limit\n",
    "\n",
    "    def __getstate__(self):\n",
    "        state = super().__getstate__()\n",
    "        # TODO: Needs a better way to serialize / deserialize states.\n",
    "        # state['iterable'] = [d.state_dict() for d in state['iterable']]\n",
    "        return {k:v for k,v in state.items() if k not in ['_dls','opt','iterable']}\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        # state['iterable'] = [d.from_state_dict() for d in state['iterable']]\n",
    "        super().__setstate__(state)\n",
    "\n",
    "    def reset(self):\n",
    "        if not self.infinite_dls:\n",
    "            self._dls = [iter(dl) for dl in self.iterable]\n",
    "        elif self._dls is None:\n",
    "            self._dls = [iter(dl) for dl in self.iterable]\n",
    "            \n",
    "    def increment_batch(self,value):\n",
    "        # I dont make this inline, because there is a likihood we will have additional conditions\n",
    "        # and I want to actually be able to read and understand each one...\n",
    "        if type(value)==Record:               return False\n",
    "        if type(value)==GetInputItemResponse: return False\n",
    "        return True\n",
    "            \n",
    "    def __iter__(self):\n",
    "        self.reset()\n",
    "        exhausted = []\n",
    "        dl_batch_tracker = [0 for _ in self._dls]\n",
    "        if self.zipwise:\n",
    "            while len(exhausted)!=len(self._dls):\n",
    "                zip_list = []\n",
    "                for i,dl in self._dls:\n",
    "                    if i in exhausted: \n",
    "                        zip_list.append(None)\n",
    "                    else:              \n",
    "                        try: \n",
    "                            zip_list.append(next(dl))\n",
    "                            if self.increment_batch(zip_list[-1]): dl_batch_tracker[i]+=1\n",
    "                            if self.infinite_dls and dl_batch_tracker[i]>self.batches:\n",
    "                                raise StopIteration\n",
    "                        except StopIteration:\n",
    "                            exhausted.append(i)\n",
    "                            zip_list.append(None)\n",
    "        else:\n",
    "            while len(exhausted)!=len(self._dls):\n",
    "                for i,dl in enumerate(self._dls): \n",
    "                    while i not in exhausted:\n",
    "                        try:\n",
    "                            v = next(dl)\n",
    "                            if self.increment_batch(v): dl_batch_tracker[i]+=1\n",
    "                            yield v\n",
    "                            if self.infinite_dls and dl_batch_tracker[i]>self.batches:\n",
    "                                raise StopIteration\n",
    "                        except StopIteration:\n",
    "                            exhausted.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "742c9cc6-4be3-4606-b07d-12d30da2144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LearnerHead(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learner_base = find_dp(traverse(self.source_datapipe),LearnerBase)\n",
    "\n",
    "    def __iter__(self): yield from self.source_datapipe\n",
    "    \n",
    "    def fit(self,epochs):\n",
    "        epocher = find_dp(traverse(self),EpocherCollector)\n",
    "        epocher.epochs = epochs\n",
    "        \n",
    "        for iteration in self: \n",
    "            pass\n",
    "        \n",
    "add_docs(\n",
    "    LearnerHead,\n",
    "    \"\"\"\n",
    "    \"\"\",\n",
    "    fit=\"Runs the `LearnerHead` pipeline for `epochs`\"\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a51d58-04f6-454b-a783-ad667f4b2f17",
   "metadata": {},
   "source": [
    "> Warning: Pickling the LearnerBase will exclude the '_dls','opt','iterable' fields since\n",
    "these aren't easily picklable (yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef47785f-7041-4590-9a55-43bb50e986bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "from fastrl.agents.dqn.basic import *\n",
    "from fastrl.agents.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a48ec65-b385-4dea-87c8-f58c202d2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the agent\n",
    "agent = AgentBase(model,[])\n",
    "# All the things that make this agent unique and special\n",
    "# In this instance, all this module does is pass the action directly through to the model.\n",
    "agent = SimpleModelRunner(agent)\n",
    "# Bring everything together into the AgentHead where actions will be passed and then run through the pipeline\n",
    "agent = AgentHead(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bb26b-2ade-44d2-970c-7fff000d0ed6",
   "metadata": {},
   "source": [
    "If we pass a list of tensors, we will get a list of actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7422e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_datapipe': SimpleModelRunner, 'agent_base': AgentBase}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.__getstate__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "330318f5-4423-4174-b9fe-499bcbb9de85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for action in agent([tensor([1,2,3,4]).float()]):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "385e1141-4961-45dd-ad4e-2d8f049f5294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for action in agent([tensor([1,2,3,4]).float()]*3):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7496dbff-cda7-4826-8d2e-f4663d46430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.pipes.core import *\n",
    "from fastrl.pipes.map.transforms import *\n",
    "from fastrl.data.block import *\n",
    "from fastrl.envs.gym import *\n",
    "\n",
    "def baseline_test(envs,total_steps,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformer(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.header(limit=10)\n",
    "    pipe = GymStepper(pipe,seed=seed)\n",
    "\n",
    "    steps = [step for _,step in zip(*(range(total_steps),pipe))]\n",
    "    return steps, pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30e00ef9-f09d-475a-b28f-6878044feb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps, pipe = baseline_test(['CartPole-v1'],0)\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb00a29-9220-470d-9873-a609ea3ea7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
