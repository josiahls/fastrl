{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "%config Completer.use_jedi = False\n",
    "# upgrade fastrl on colab\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp agents.dqn.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Python native modules\n",
    "import os\n",
    "from collections import deque\n",
    "# Third party libs\n",
    "import torch\n",
    "from torch.nn import *\n",
    "from fastcore.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.callback.all import *\n",
    "# Local modules\n",
    "from fastrl.data.block import *\n",
    "from fastrl.agent import *\n",
    "from fastrl.core import *\n",
    "from fastrl.agents.dqn.core import *\n",
    "from fastrl.agents.dqn.targets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Double DQN\n",
    "> Using the target model to also evaluate the value of the actions taken by the current model\n",
    "given the next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf6eb01-5449-4d5a-afd5-cc422bcac62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DoubleDQNTrainer(DQNTargetTrainer):\n",
    "    def after_pred(self):\n",
    "        self.learn.yb=self.xb\n",
    "        self.learn.xb=self.xb[0]\n",
    "        \n",
    "        self._xb=({k:v.clone() for k,v in self.xb.items()},)\n",
    "        self.learn.done_mask=self.xb['done'].reshape(-1,)\n",
    "        chosen_actions=self.learn.next_q=self.model.model(self.xb['next_state']).argmax(dim=1).reshape(-1,1)\n",
    "        self.learn.next_q=self.target_model(self.xb['next_state']).gather(1,chosen_actions)\n",
    "        self.learn.next_q[self.done_mask]=0\n",
    "        self.learn.targets=self.xb['reward']+self.learn.next_q*(self.discount**self.n_steps)\n",
    "        self.learn.pred=self.learn.model.model(self.xb['state'])\n",
    "        t_q=self.pred.clone()\n",
    "        t_q.scatter_(1,self.xb['action'],self.targets)\n",
    "        self.learn.xb=(t_q,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d91aec-d20d-4e28-83b1-5492915350fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn=DQN(4,2)\n",
    "\n",
    "agent=Agent(dqn,cbs=[ArgMaxFeed,DiscreteEpsilonRandomSelect])\n",
    "source=Source(cbs=[GymLoop('CartPole-v1',agent,steps_count=3,seed=0,\n",
    "                           steps_delta=1),FirstLast])\n",
    "dls=SourceDataBlock().dataloaders([source],n=1000,bs=1,num_workers=0)\n",
    "\n",
    "learn=Learner(dls,agent,loss_func=MSELoss(),\n",
    "              cbs=[ExperienceReplay(bs=32,max_sz=100000,warmup_sz=32),DoubleDQNTrainer],\n",
    "              metrics=[Reward,Epsilon])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864bea5-39d1-498c-ba33-cf4cc756d391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_reward</th>\n",
       "      <th>train_epsilon</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_reward</th>\n",
       "      <th>valid_epsilon</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.987865</td>\n",
       "      <td>51.880000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.961967</td>\n",
       "      <td>55.730000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.178653</td>\n",
       "      <td>56.950000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full=False\n",
    "learn.fit(47 if full else 3,lr=0.0001,wd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n",
      "Converted 00_core.ipynb.\n",
      "Converted 00_nbdev_extension.ipynb.\n",
      "Converted 03_callback.core.ipynb.\n",
      "Converted 04_agent.ipynb.\n",
      "Converted 05_data.block.ipynb.\n",
      "Converted 05_data.test_async.ipynb.\n",
      "Converted 10a_agents.dqn.core.ipynb.\n",
      "Converted 10b_agents.dqn.targets.ipynb.\n",
      "Converted 10c_agents.dqn.double.ipynb.\n",
      "Converted 10d_agents.dqn.dueling.ipynb.\n",
      "Converted 20_test_utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted nbdev_template.ipynb.\n",
      "Converted tmp.ipynb.\n",
      "converting: /home/fastrl_user/fastrl/nbs/10c_agents.dqn.double.ipynb\n",
      "converting: /home/fastrl_user/fastrl/nbs/10d_agents.dqn.dueling.ipynb\n",
      "An error occurred while executing the following cell:\n",
      "------------------\n",
      "from nbdev.showdoc import show_doc\n",
      "from fastrl.agents.dqn.dueling import *\n",
      "------------------\n",
      "\n",
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\n",
      "  File \u001b[1;32m\"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3437\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c6549919bb7f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n",
      "\u001b[0;31m    from fastrl.agents.dqn.dueling import *\u001b[0m\n",
      "\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/fastrl_user/fastrl/fastrl/agents/dqn/dueling.py\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n",
      "\u001b[0;31m    def __init__(self,hidden=512,n_actions,lin_cls=nn.Linear):\u001b[0m\n",
      "\u001b[0m                 ^\u001b[0m\n",
      "\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n",
      "\n",
      "SyntaxError: non-default argument follows default argument (dueling.py, line 26)\n",
      "\n",
      "Conversion failed on the following:\n",
      "10d_agents.dqn.dueling.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.export import *\n",
    "    from nbdev.export2html import *\n",
    "    from nbdev.cli import make_readme\n",
    "    make_readme()\n",
    "    notebook2script()\n",
    "    notebook2html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2104d-1cd0-4e35-91c6-c49d7a85454c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
