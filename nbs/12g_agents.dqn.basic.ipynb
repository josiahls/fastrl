{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.dqn.basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "from collections import deque\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from torch.utils.data.datapipes._typing import _DataPipeMeta, _IterDataPipeMeta\n",
    "# Local modules\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "\n",
    "from fastrl.core import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.fastai.data.block import *\n",
    "from fastrl.memory.experience_replay import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.agents.discrete import *\n",
    "from fastrl.loggers.core import *\n",
    "from fastrl.loggers.jupyter_visualizers import *\n",
    "from fastrl.learner.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Basic\n",
    "> Core DQN modules, pipes, and tooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3fa6f0-079d-4834-a235-e1ca99654feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f18f79cf-4763-451d-92a2-817b532ba9d8",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6241ea68-611d-4cdf-abdb-4e2a58af23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cfe338-de27-4c61-a18d-d74ea33fde37",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480529a0-a23f-425a-a165-d4915c96c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DQNAgent(\n",
    "    model,\n",
    "    logger_bases=None,\n",
    "    min_epsilon=0.02,\n",
    "    max_epsilon=1,\n",
    "    max_steps=1000,\n",
    "    device='cpu'\n",
    ")->AgentHead:\n",
    "    agent = AgentBase(model)\n",
    "    agent = StepFieldSelector(agent,field='state')\n",
    "    agent = SimpleModelRunner(agent,device=device)\n",
    "    agent = ArgMaxer(agent)\n",
    "    selector = EpsilonSelector(agent,min_epsilon=min_epsilon,max_epsilon=max_epsilon,max_steps=max_steps,device=device)\n",
    "    if logger_bases is not None: agent = EpsilonCollector(selector,logger_bases)\n",
    "    agent = ArgMaxer(agent,only_idx=True)\n",
    "    agent = NumpyConverter(agent)\n",
    "    agent = PyPrimativeConverter(agent)\n",
    "    agent = AgentHead(agent)\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437f871a-64bb-42ac-868c-d37b0282c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "\n",
    "agent = DQNAgent(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "441c6eac-7851-4539-aa91-295479d05cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "input_tensor = tensor([1,2,3,4]).float()\n",
    "step = SimpleStep(state=input_tensor)\n",
    "\n",
    "for action in agent([step]):\n",
    "    print(action)\n",
    "    \n",
    "test_eq(input_tensor,tensor([1., 2., 3., 4.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47810afd-4430-4ba6-a840-3d8e5878aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.envs.gym import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ccbec06-fcc5-4be3-8b46-cd76c2a56b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "AgentHead.debug=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b61711f0-7a1d-4b0e-bd81-46ff7547179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SimpleStep(state=tensor([-0.0300,  0.0230, -0.0351,  0.0027]), action=tensor(1.), next_state=tensor([-0.0295,  0.2186, -0.0351, -0.3009]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(1.), env_id=tensor(139764479659536), proc_id=tensor(418), step_n=tensor(1), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([-0.0295,  0.2186, -0.0351, -0.3009]), action=tensor(0.), next_state=tensor([-0.0251,  0.0240, -0.0411, -0.0194]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(2.), env_id=tensor(139764479659536), proc_id=tensor(418), step_n=tensor(2), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([-0.0251,  0.0240, -0.0411, -0.0194]), action=tensor(1.), next_state=tensor([-0.0247,  0.2197, -0.0415, -0.3248]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(3.), env_id=tensor(139764479659536), proc_id=tensor(418), step_n=tensor(3), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([-0.0247,  0.2197, -0.0415, -0.3248]), action=tensor(0.), next_state=tensor([-0.0203,  0.0251, -0.0480, -0.0455]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(4.), env_id=tensor(139764479659536), proc_id=tensor(418), step_n=tensor(4), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([-0.0203,  0.0251, -0.0480, -0.0455]), action=tensor(1.), next_state=tensor([-0.0198,  0.2209, -0.0489, -0.3529]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(5.), env_id=tensor(139764479659536), proc_id=tensor(418), step_n=tensor(5), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([-0.0198,  0.2209, -0.0489, -0.3529]), action=tensor(0.), next_state=tensor([-0.0154,  0.0265, -0.0559, -0.0760]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(6.), env_id=tensor(139764479659536), proc_id=tensor(418), step_n=tensor(6), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([-0.0154,  0.0265, -0.0559, -0.0760]), action=tensor(1.), next_state=tensor([-0.0148,  0.2224, -0.0575, -0.3858]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(7.), env_id=tensor(139764479659536), proc_id=tensor(418), step_n=tensor(7), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([-0.0148,  0.2224, -0.0575, -0.3858]), action=tensor(0.), next_state=tensor([-0.0104,  0.0281, -0.0652, -0.1118]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(8.), env_id=tensor(139764479659536), proc_id=tensor(418), step_n=tensor(8), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([-0.0104,  0.0281, -0.0652, -0.1118]), action=tensor(0.), next_state=tensor([-0.0098, -0.1660, -0.0674,  0.1597]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(9.), env_id=tensor(139764479659536), proc_id=tensor(418), step_n=tensor(9), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([-0.0098, -0.1660, -0.0674,  0.1597]), action=tensor(0.), next_state=tensor([-0.0131, -0.3601, -0.0642,  0.4303]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(10.), env_id=tensor(139764479659536), proc_id=tensor(418), step_n=tensor(10), episode_n=tensor(1), image=tensor([0.]))]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Logger\n",
    "logger_base = ProgressBarLogger()\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "\n",
    "agent = DQNAgent(model,[logger_base])\n",
    "\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent)\n",
    ")\n",
    "# dls = L(block.dataloaders(['CartPole-v1']*1,n=10,bs=1))\n",
    "pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\n",
    "\n",
    "# list(dls[0])\n",
    "list(pipes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c98be0-6288-443a-b4ab-9390fbe3081c",
   "metadata": {},
   "source": [
    "## Training DataPipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eea139c-52c0-4005-9101-a45c25c2d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class QCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,discount=0.99,nsteps=1):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.discount = discount\n",
    "        self.nsteps = nsteps\n",
    "        self.learner = find_pipe_instance(self,LearnerBase)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            try:\n",
    "                self.learner.done_mask = batch.terminated.reshape(-1,)\n",
    "\n",
    "                self.learner.next_q = self.learner.model(batch.next_state)\n",
    "                # print(self.learner.next_q,self.learner.done_mask)\n",
    "                self.learner.next_q = self.learner.next_q.max(dim=1).values.reshape(-1,1)\n",
    "                self.learner.next_q[self.learner.done_mask] = 0 #xb[done_mask]['reward']\n",
    "                self.learner.targets = batch.reward+self.learner.next_q*(self.discount**self.nsteps)\n",
    "                self.learner.pred = self.learner.model(batch.state)\n",
    "\n",
    "                t_q=self.learner.pred.clone()\n",
    "                t_q.scatter_(1,batch.action.long(),self.learner.targets)\n",
    "\n",
    "                self.learner.loss_grad = self.learner.loss_func(self.learner.pred, t_q)\n",
    "                yield batch\n",
    "            except RuntimeError as e:\n",
    "                print(f'Failed on batch: {batch}')\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42ca2d01-a3c4-4f9e-8fef-186c9e1f1e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ModelLearnCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learner = find_pipe_instance(self,LearnerBase)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learner.loss_grad.backward()\n",
    "            self.learner.opt.step()\n",
    "            self.learner.opt.zero_grad()\n",
    "            self.learner.loss = self.learner.loss_grad.clone()\n",
    "            yield self.learner.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb1161a-26de-4f73-b052-dfefbb8bc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class StepBatcher(dp.iter.IterDataPipe):\n",
    "    def __init__(self,\n",
    "            source_datapipe,\n",
    "            device=None\n",
    "        ):\n",
    "        \"Converts multiple `StepType` into a single `StepType` with the fields concated.\"\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.device = device\n",
    "        \n",
    "    def vstack_by_fld(self,batch,fld):\n",
    "        try:\n",
    "            if self.device is None: return torch.vstack(tuple(getattr(step,fld) for step in batch))\n",
    "            return torch.vstack(tuple(getattr(step,fld) for step in batch)).to(torch.device(self.device))\n",
    "        except RuntimeError as e:\n",
    "            print(f'Failed to stack {fld} given batch: {batch}')\n",
    "            raise\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            cls = batch[0].__class__\n",
    "            yield cls(**{fld:self.vstack_by_fld(batch,fld) for fld in cls._fields})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a793dc72-c14a-48aa-bc7a-9bd8e865458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class EpisodeCollector(LogCollector):\n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('episode',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            if isinstance(steps,dp.DataChunk):\n",
    "                for step in steps:\n",
    "                    for q in self.main_queues: q.put(Record('episode',step.episode_n.cpu().detach().numpy()[0]))\n",
    "            else:\n",
    "                for q in self.main_queues: q.put(Record('episode',steps.episode_n.cpu().detach().numpy()[0]))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28aa721c-22fc-49e6-8bc4-fc01b20e6df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LossCollector(LogCollector):\n",
    "    def __init__(self,\n",
    "         source_datapipe, # The parent datapipe, likely the one to collect metrics from\n",
    "         logger_bases:List[LoggerBase] # `LoggerBase`s that we want to send metrics to\n",
    "        ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queues = [o.main_queue for o in logger_bases]\n",
    "        self.learner = find_pipe_instance(self,LearnerBase)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('loss',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            for q in self.main_queues: q.put(Record('loss',self.learner.loss.cpu().detach().numpy()))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "576be92f-0a44-459b-a3a4-3db191cca95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class RollingTerminatedRewardCollector(LogCollector):\n",
    "    def __init__(self,\n",
    "         source_datapipe, # The parent datapipe, likely the one to collect metrics from\n",
    "         logger_bases:List[LoggerBase], # `LoggerBase`s that we want to send metrics to\n",
    "         rolling_length:int=100\n",
    "        ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queues = [o.main_queue for o in logger_bases]\n",
    "        self.rolling_rewards = deque([],maxlen=rolling_length)\n",
    "        \n",
    "    def step2terminated(self,step): return bool(step.terminated)\n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('rolling_reward',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            if isinstance(steps,dp.DataChunk):\n",
    "                for step in steps:\n",
    "                    if self.step2terminated(step):\n",
    "                        self.rolling_rewards.append(step.total_reward.cpu().detach().numpy()[0])\n",
    "                        for q in self.main_queues: q.put(Record('rolling_reward',np.average(self.rolling_rewards)))\n",
    "            elif self.step2terminated(steps):\n",
    "                self.rolling_rewards.append(steps.total_reward.detach().numpy()[0])\n",
    "                for q in self.main_queues: q.put(Record('rolling_reward',np.average(self.rolling_rewards)))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c50c9dd-89fc-4a89-a6f0-ccd6126135d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DQNLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    logger_bases=None,\n",
    "    loss_func=MSELoss(),\n",
    "    opt=AdamW,\n",
    "    lr=0.005,\n",
    "    bs=128,\n",
    "    max_sz=10000,\n",
    "    nsteps=1,\n",
    "    device=None\n",
    ") -> LearnerHead:\n",
    "    learner = LearnerBase(model,dls,loss_func=MSELoss(),opt=opt(model.parameters(),lr=lr))\n",
    "    learner = BatchCollector(learner,logger_bases=logger_bases,batch_on_pipe=LearnerBase)\n",
    "    learner = EpocherCollector(learner,logger_bases=logger_bases)\n",
    "    for logger_base in L(logger_bases): learner = logger_base.connect_source_datapipe(learner)\n",
    "    if logger_bases: \n",
    "        learner = RollingTerminatedRewardCollector(learner,logger_bases)\n",
    "        learner = EpisodeCollector(learner,logger_bases)\n",
    "    learner = ExperienceReplay(learner,bs=bs,max_sz=max_sz,clone_detach=dls[0].num_workers>0)\n",
    "    learner = StepBatcher(learner,device=device)\n",
    "    learner = QCalc(learner,nsteps=nsteps)\n",
    "    learner = ModelLearnCalc(learner)\n",
    "    if logger_bases: \n",
    "        learner = LossCollector(learner,logger_bases)\n",
    "    learner = LearnerHead(learner)\n",
    "    return learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f9ed8-fb05-40a1-ac0d-d4cafee8fa07",
   "metadata": {},
   "source": [
    "Try training with basic defaults..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7cd7c546-8c01-4c8e-8eed-f7aba7366815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting external_run_scripts/agents_dqn_basic_35.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile external_run_scripts/agents_dqn_basic_35.py\n",
    "\n",
    "if __name__=='__main__':\n",
    "    from torch.multiprocessing import Pool, Process, set_start_method\n",
    "    \n",
    "    try:\n",
    "        set_start_method('spawn')\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    from fastcore.all import *\n",
    "    import torch\n",
    "    from torch.nn import *\n",
    "    import torch.nn.functional as F\n",
    "    from fastrl.loggers.core import *\n",
    "    from fastrl.loggers.jupyter_visualizers import *\n",
    "    from fastrl.learner.core import *\n",
    "    from fastrl.fastai.data.block import *\n",
    "    from fastrl.envs.gym import *\n",
    "    from fastrl.agents.core import *\n",
    "    from fastrl.agents.discrete import *\n",
    "    from fastrl.agents.dqn.basic import *\n",
    "    from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "\n",
    "    print('fitting')\n",
    "    # Setup Loggers\n",
    "    \n",
    "    def DQNAgent(\n",
    "        model,\n",
    "        logger_bases=None,\n",
    "        min_epsilon=0.02,\n",
    "        max_epsilon=1,\n",
    "        max_steps=1000,\n",
    "        device='cpu'\n",
    "    )->AgentHead:\n",
    "        agent = AgentBase(model)\n",
    "        agent = StepFieldSelector(agent,field='state')\n",
    "        agent = SimpleModelRunner(agent,device=device)\n",
    "        agent = ArgMaxer(agent)\n",
    "        agent = EpsilonSelector(agent,min_epsilon=min_epsilon,max_epsilon=max_epsilon,max_steps=max_steps,device=device)\n",
    "        if logger_bases is not None: agent = EpsilonCollector(agent,logger_bases)\n",
    "        agent = ArgMaxer(agent,only_idx=True)\n",
    "        agent = NumpyConverter(agent)\n",
    "        agent = PyPrimativeConverter(agent)\n",
    "        agent = AgentHead(agent)\n",
    "        return agent\n",
    "\n",
    "    \n",
    "    logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n",
    "                     batch_on_pipe=BatchCollector)\n",
    "\n",
    "    # Setup up the core NN\n",
    "    torch.manual_seed(0)\n",
    "    model = DQN(4,2).cuda()\n",
    "    model.share_memory()\n",
    "    # Setup the Agent\n",
    "    agent = DQNAgent(model,[logger_base],max_steps=4000,device='cuda')\n",
    "    # Setup the DataBlock\n",
    "    block = DataBlock(\n",
    "        blocks = GymTransformBlock(agent=agent,\n",
    "                                   nsteps=1,nskips=1,firstlast=False,\n",
    "                                   # dl_type=partial(DataLoader2,persistent_workers=True\n",
    "                                   #                )\n",
    "                                  )\n",
    "    )\n",
    "    # pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\n",
    "    dls = L(block.dataloaders(['CartPole-v1']*1,n=1000,bs=1,num_workers=0))\n",
    "    # # Setup the Learner\n",
    "    learner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=100_000,device='cuda')\n",
    "    learner.fit(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df20853-a286-4695-b3a4-8cf44f5bf70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n",
    "                 batch_on_pipe=BatchCollector)\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2).cuda()\n",
    "model.share_memory()\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,[logger_base],max_steps=4000,device='cuda')\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False,\n",
    "                               dl_type=partial(DataLoader2,persistent_workers=True))\n",
    ")\n",
    "# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=1000,bs=1,num_workers=1))\n",
    "# Setup the Learner\n",
    "learner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=100_000,device='cuda')\n",
    "# learner.fit(3)\n",
    "learner.fit(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0ed73-7bbf-415b-9ee7-9a95de31d638",
   "metadata": {},
   "source": [
    "If we try a regular DQN with nsteps/nskips it doesnt really converge after 130. We cant expect stability at all, and im pretty sure that nsteps (correctly) tries to reduce to number of duplicated states so that the agent can sample more unique state transitions. The problem with this is that the base dqn is not stable, so giving it lots of \"new\" stuff, im not sure helps. In otherwords, its going to forget the old stuff very quickly, and having duplicate states helps \"remind it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d510e-38c1-458c-9830-df5a68e6a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n",
    "                 batch_on_pipe=BatchCollector)\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,[logger_base],max_steps=10000)\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True) # We basically merge 2 steps into 1 and skip. \n",
    ")\n",
    "# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=1000,bs=1))\n",
    "# Setup the Learner\n",
    "learner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=20_000,nsteps=2,lr=0.001)\n",
    "# learner.fit(3)\n",
    "learner.fit(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de0f41e-2eda-4227-9fa8-f2e0b920754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.loggers.jupyter_visualizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15937f36-8efa-4163-bc67-20019d18c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482490a-475e-4c46-b1fa-193bf68b7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.envs.gym import GymTypeTransform,GymStepper\n",
    "\n",
    "def gym_pipe_base(envs,total_steps,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformLoop(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle(count=total_steps)\n",
    "    pipe = GymStepper(pipe,agent=agent,seed=seed,include_images=True)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc10e61-4f65-4a17-a5a9-489bb466af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8784650-6f5c-42b7-9a72-68a0d37d8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_logger = SimpleJupyterVideoPlayer()\n",
    "\n",
    "pipe = gym_pipe_base(['CartPole-v1'],100,seed=None)\n",
    "pipe = ImageCollector(pipe,[video_logger])\n",
    "\n",
    "pipe = video_logger.connect_source_datapipe(pipe)\n",
    "\n",
    "L(pipe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccaa785-605b-4e75-bff7-bae8c5603817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n",
    "                 batch_on_pipe=BatchCollector)\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(8,4)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,[logger_base])\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent)\n",
    ")\n",
    "dls = L(block.dataloaders(['LunarLander-v2']*1,n=1000,bs=1))\n",
    "# Setup the Learner\n",
    "learner = DQNLearner(model,dls,logger_bases=[logger_base])\n",
    "learner.fit(3)\n",
    "# learner.fit(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e84a7d-9583-485d-8e16-3958c72b526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.envs.gym import GymTypeTransform,GymStepper\n",
    "\n",
    "def gym_pipe_base(envs,total_steps,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformLoop(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle(count=total_steps)\n",
    "    pipe = GymStepper(pipe,agent=agent,seed=seed,include_images=True)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a8a98-5091-4e31-9cca-9220c64ecdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_logger = SimpleJupyterVideoPlayer()\n",
    "\n",
    "pipe = gym_pipe_base(['LunarLander-v2'],1000,seed=None)\n",
    "pipe = ImageCollector(pipe,[video_logger])\n",
    "\n",
    "pipe = video_logger.connect_source_datapipe(pipe)\n",
    "\n",
    "L(pipe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d3626-1702-4f22-ae15-bb93a75bec68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
