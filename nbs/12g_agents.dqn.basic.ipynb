{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp agents.dqn.basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os\n",
    "from collections import deque\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data.dataloader_experimental import DataLoader2\n",
    "from torch.utils.data.datapipes._typing import _DataPipeMeta, _IterDataPipeMeta\n",
    "# Local modules\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.torch_core import *\n",
    "\n",
    "from fastrl.core import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.fastai.data.block import *\n",
    "from fastrl.memory.experience_replay import *\n",
    "from fastrl.agents.core import *\n",
    "from fastrl.agents.discrete import *\n",
    "from fastrl.loggers.core import *\n",
    "from fastrl.loggers.jupyter_visualizers import *\n",
    "from fastrl.learner.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# DQN Basic\n",
    "> Core DQN modules, pipes, and tooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18f79cf-4763-451d-92a2-817b532ba9d8",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6241ea68-611d-4cdf-abdb-4e2a58af23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DQN(Module):\n",
    "    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n",
    "        self.layers=Sequential(\n",
    "            Linear(state_sz,hidden),\n",
    "            ReLU(),\n",
    "            Linear(hidden,action_sz),\n",
    "        )\n",
    "    def forward(self,x): return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cfe338-de27-4c61-a18d-d74ea33fde37",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "480529a0-a23f-425a-a165-d4915c96c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DQNAgent(\n",
    "    model,\n",
    "    logger_bases=None,\n",
    "    min_epsilon=0.02,\n",
    "    max_epsilon=1,\n",
    "    max_steps=1000\n",
    ")->AgentHead:\n",
    "    agent = AgentBase(model)\n",
    "    agent = StepFieldSelector(agent,field='state')\n",
    "    agent = SimpleModelRunner(agent)\n",
    "    agent = ArgMaxer(agent)\n",
    "    selector = EpsilonSelector(agent,min_epsilon=min_epsilon,max_epsilon=max_epsilon,max_steps=max_steps)\n",
    "    if logger_bases is not None: agent = EpsilonCollector(selector,logger_bases)\n",
    "    agent = ArgMaxer(agent,only_idx=True)\n",
    "    agent = NumpyConverter(agent)\n",
    "    agent = PyPrimativeConverter(agent)\n",
    "    agent = AgentHead(agent)\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437f871a-64bb-42ac-868c-d37b0282c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "\n",
    "agent = DQNAgent(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "441c6eac-7851-4539-aa91-295479d05cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "input_tensor = tensor([1,2,3,4]).float()\n",
    "step = SimpleStep(state=input_tensor)\n",
    "\n",
    "for action in agent([step]):\n",
    "    print(action)\n",
    "    \n",
    "test_eq(input_tensor,tensor([1., 2., 3., 4.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47810afd-4430-4ba6-a840-3d8e5878aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.envs.gym import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ccbec06-fcc5-4be3-8b46-cd76c2a56b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "AgentHead.debug=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b61711f0-7a1d-4b0e-bd81-46ff7547179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SimpleStep(state=tensor([0.0070, 0.0409, 0.0174, 0.0484]), action=tensor(1.), next_state=tensor([ 0.0078,  0.2358,  0.0184, -0.2387]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(1.), env_id=tensor(140566792998992), proc_id=tensor(1040), step_n=tensor(1), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([ 0.0078,  0.2358,  0.0184, -0.2387]), action=tensor(0.), next_state=tensor([0.0125, 0.0404, 0.0136, 0.0597]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(2.), env_id=tensor(140566792998992), proc_id=tensor(1040), step_n=tensor(2), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([0.0125, 0.0404, 0.0136, 0.0597]), action=tensor(1.), next_state=tensor([ 0.0133,  0.2353,  0.0148, -0.2286]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(3.), env_id=tensor(140566792998992), proc_id=tensor(1040), step_n=tensor(3), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([ 0.0133,  0.2353,  0.0148, -0.2286]), action=tensor(0.), next_state=tensor([0.0180, 0.0400, 0.0103, 0.0687]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(4.), env_id=tensor(140566792998992), proc_id=tensor(1040), step_n=tensor(4), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([0.0180, 0.0400, 0.0103, 0.0687]), action=tensor(1.), next_state=tensor([ 0.0188,  0.2350,  0.0116, -0.2207]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(5.), env_id=tensor(140566792998992), proc_id=tensor(1040), step_n=tensor(5), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([ 0.0188,  0.2350,  0.0116, -0.2207]), action=tensor(0.), next_state=tensor([0.0235, 0.0397, 0.0072, 0.0756]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(6.), env_id=tensor(140566792998992), proc_id=tensor(1040), step_n=tensor(6), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([0.0235, 0.0397, 0.0072, 0.0756]), action=tensor(1.), next_state=tensor([ 0.0243,  0.2347,  0.0087, -0.2148]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(7.), env_id=tensor(140566792998992), proc_id=tensor(1040), step_n=tensor(7), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([ 0.0243,  0.2347,  0.0087, -0.2148]), action=tensor(0.), next_state=tensor([0.0290, 0.0394, 0.0044, 0.0806]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(8.), env_id=tensor(140566792998992), proc_id=tensor(1040), step_n=tensor(8), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([0.0290, 0.0394, 0.0044, 0.0806]), action=tensor(0.), next_state=tensor([ 0.0298, -0.1557,  0.0061,  0.3747]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(9.), env_id=tensor(140566792998992), proc_id=tensor(1040), step_n=tensor(9), episode_n=tensor(1), image=tensor([0.]))],\n",
       " [SimpleStep(state=tensor([ 0.0298, -0.1557,  0.0061,  0.3747]), action=tensor(0.), next_state=tensor([ 0.0267, -0.3509,  0.0135,  0.6693]), terminated=tensor(False), truncated=tensor(False), reward=tensor(1.), total_reward=tensor(10.), env_id=tensor(140566792998992), proc_id=tensor(1040), step_n=tensor(10), episode_n=tensor(1), image=tensor([0.]))]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Logger\n",
    "logger_base = ProgressBarLogger()\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "\n",
    "agent = DQNAgent(model,[logger_base])\n",
    "\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent)\n",
    ")\n",
    "# dls = L(block.dataloaders(['CartPole-v1']*1,n=10,bs=1))\n",
    "pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\n",
    "\n",
    "# list(dls[0])\n",
    "list(pipes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c98be0-6288-443a-b4ab-9390fbe3081c",
   "metadata": {},
   "source": [
    "## Training DataPipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eea139c-52c0-4005-9101-a45c25c2d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class QCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,discount=0.99,nsteps=1):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.discount = discount\n",
    "        self.nsteps = nsteps\n",
    "        self.learner = find_pipe_instance(self,LearnerBase)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            try:\n",
    "                self.learner.done_mask = batch.terminated.reshape(-1,)\n",
    "\n",
    "                self.learner.next_q = self.learner.model(batch.next_state)\n",
    "                # print(self.learner.next_q,self.learner.done_mask)\n",
    "                self.learner.next_q = self.learner.next_q.max(dim=1).values.reshape(-1,1)\n",
    "                self.learner.next_q[self.learner.done_mask] = 0 #xb[done_mask]['reward']\n",
    "                self.learner.targets = batch.reward+self.learner.next_q*(self.discount**self.nsteps)\n",
    "                self.learner.pred = self.learner.model(batch.state)\n",
    "\n",
    "                t_q=self.learner.pred.clone()\n",
    "                t_q.scatter_(1,batch.action.long(),self.learner.targets)\n",
    "\n",
    "                self.learner.loss_grad = self.learner.loss_func(self.learner.pred, t_q)\n",
    "                yield batch\n",
    "            except RuntimeError as e:\n",
    "                print(f'Failed on batch: {batch}')\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42ca2d01-a3c4-4f9e-8fef-186c9e1f1e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ModelLearnCalc(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.learner = find_pipe_instance(self,LearnerBase)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            self.learner.loss_grad.backward()\n",
    "            self.learner.opt.step()\n",
    "            self.learner.opt.zero_grad()\n",
    "            self.learner.loss = self.learner.loss_grad.clone()\n",
    "            yield self.learner.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb1161a-26de-4f73-b052-dfefbb8bc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class StepBatcher(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe):\n",
    "        \"Converts multiple `StepType` into a single `StepType` with the fields concated.\"\n",
    "        self.source_datapipe = source_datapipe\n",
    "        \n",
    "    def vstack_by_fld(self,batch,fld):\n",
    "        try:\n",
    "            return torch.vstack(tuple(getattr(step,fld) for step in batch))\n",
    "        except RuntimeError as e:\n",
    "            print(f'Failed to stack {fld} given batch: {batch}')\n",
    "            raise\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.source_datapipe:\n",
    "            cls = batch[0].__class__\n",
    "            yield cls(**{fld:self.vstack_by_fld(batch,fld) for fld in cls._fields})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a793dc72-c14a-48aa-bc7a-9bd8e865458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class EpisodeCollector(LogCollector):\n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('episode',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            if isinstance(steps,dp.DataChunk):\n",
    "                for step in steps:\n",
    "                    for q in self.main_queues: q.put(Record('episode',step.episode_n.detach().numpy()[0]))\n",
    "            else:\n",
    "                for q in self.main_queues: q.put(Record('episode',steps.episode_n.detach().numpy()[0]))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28aa721c-22fc-49e6-8bc4-fc01b20e6df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LossCollector(LogCollector):\n",
    "    def __init__(self,\n",
    "         source_datapipe, # The parent datapipe, likely the one to collect metrics from\n",
    "         logger_bases:List[LoggerBase] # `LoggerBase`s that we want to send metrics to\n",
    "        ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queues = [o.main_queue for o in logger_bases]\n",
    "        self.learner = find_pipe_instance(self,LearnerBase)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('loss',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            for q in self.main_queues: q.put(Record('loss',self.learner.loss.detach().numpy()))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "576be92f-0a44-459b-a3a4-3db191cca95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class RollingTerminatedRewardCollector(LogCollector):\n",
    "    def __init__(self,\n",
    "         source_datapipe, # The parent datapipe, likely the one to collect metrics from\n",
    "         logger_bases:List[LoggerBase], # `LoggerBase`s that we want to send metrics to\n",
    "         rolling_length:int=100\n",
    "        ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queues = [o.main_queue for o in logger_bases]\n",
    "        self.rolling_rewards = deque([],maxlen=rolling_length)\n",
    "        \n",
    "    def step2terminated(self,step): return bool(step.terminated)\n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('rolling_reward',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            if isinstance(steps,dp.DataChunk):\n",
    "                for step in steps:\n",
    "                    if self.step2terminated(step):\n",
    "                        self.rolling_rewards.append(step.total_reward.detach().numpy()[0])\n",
    "                        for q in self.main_queues: q.put(Record('rolling_reward',np.average(self.rolling_rewards)))\n",
    "            elif self.step2terminated(steps):\n",
    "                self.rolling_rewards.append(steps.total_reward.detach().numpy()[0])\n",
    "                for q in self.main_queues: q.put(Record('rolling_reward',np.average(self.rolling_rewards)))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c50c9dd-89fc-4a89-a6f0-ccd6126135d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DQNLearner(\n",
    "    model,\n",
    "    dls,\n",
    "    logger_bases=None,\n",
    "    loss_func=MSELoss(),\n",
    "    opt=AdamW,\n",
    "    lr=0.005,\n",
    "    bs=128,\n",
    "    max_sz=10000,\n",
    "    nsteps=1\n",
    ") -> LearnerHead:\n",
    "    learner = LearnerBase(model,dls,loss_func=MSELoss(),opt=opt(model.parameters(),lr=lr))\n",
    "    learner = BatchCollector(learner,logger_bases=logger_bases,batch_on_pipe=LearnerBase)\n",
    "    learner = EpocherCollector(learner,logger_bases=logger_bases)\n",
    "    for logger_base in logger_bases: learner = logger_base.connect_source_datapipe(learner)\n",
    "    learner = RollingTerminatedRewardCollector(learner,logger_bases)\n",
    "    learner = EpisodeCollector(learner,logger_bases)\n",
    "    learner = ExperienceReplay(learner,bs=bs,max_sz=max_sz)\n",
    "    learner = StepBatcher(learner)\n",
    "    learner = QCalc(learner,nsteps=nsteps)\n",
    "    learner = ModelLearnCalc(learner)\n",
    "    learner = LossCollector(learner,logger_bases)\n",
    "    learner = LearnerHead(learner)\n",
    "    return learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f9ed8-fb05-40a1-ac0d-d4cafee8fa07",
   "metadata": {},
   "source": [
    "Try training with basic defaults..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63d9b481-5998-472a-a2df-18d79bf07ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>episode</th>\n",
       "      <th>rolling_reward</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.2087642</td>\n",
       "      <td>43</td>\n",
       "      <td>23.047619</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0.749500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.28469777</td>\n",
       "      <td>69</td>\n",
       "      <td>29.279411</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0.499250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.2914464</td>\n",
       "      <td>84</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.35165447</td>\n",
       "      <td>92</td>\n",
       "      <td>42.527473</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.32426468</td>\n",
       "      <td>100</td>\n",
       "      <td>49.747475</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.26075873</td>\n",
       "      <td>107</td>\n",
       "      <td>57.77</td>\n",
       "      <td>6</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.25057846</td>\n",
       "      <td>115</td>\n",
       "      <td>66.19</td>\n",
       "      <td>7</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.24011558</td>\n",
       "      <td>122</td>\n",
       "      <td>74.13</td>\n",
       "      <td>8</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.3424397</td>\n",
       "      <td>130</td>\n",
       "      <td>83.03</td>\n",
       "      <td>9</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.21306379</td>\n",
       "      <td>137</td>\n",
       "      <td>91.42</td>\n",
       "      <td>10</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.19652301</td>\n",
       "      <td>143</td>\n",
       "      <td>100.23</td>\n",
       "      <td>11</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.22279868</td>\n",
       "      <td>150</td>\n",
       "      <td>107.72</td>\n",
       "      <td>12</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.23521385</td>\n",
       "      <td>157</td>\n",
       "      <td>115.02</td>\n",
       "      <td>13</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.2638481</td>\n",
       "      <td>165</td>\n",
       "      <td>122.01</td>\n",
       "      <td>14</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.2520497</td>\n",
       "      <td>171</td>\n",
       "      <td>127.61</td>\n",
       "      <td>15</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.2064425</td>\n",
       "      <td>177</td>\n",
       "      <td>133.62</td>\n",
       "      <td>16</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.20902675</td>\n",
       "      <td>184</td>\n",
       "      <td>139.23</td>\n",
       "      <td>17</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.21909122</td>\n",
       "      <td>191</td>\n",
       "      <td>141.8</td>\n",
       "      <td>18</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.24537887</td>\n",
       "      <td>197</td>\n",
       "      <td>143.25</td>\n",
       "      <td>19</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.2499895</td>\n",
       "      <td>202</td>\n",
       "      <td>147.38</td>\n",
       "      <td>19</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n",
    "                 batch_on_pipe=BatchCollector)\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,[logger_base],max_steps=4000)\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False)\n",
    ")\n",
    "# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=1000,bs=1))\n",
    "# Setup the Learner\n",
    "learner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=100_000)\n",
    "# learner.fit(3)\n",
    "learner.fit(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0ed73-7bbf-415b-9ee7-9a95de31d638",
   "metadata": {},
   "source": [
    "The DQN learners, but I wonder if we can get it to learn faster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c95d510e-38c1-458c-9830-df5a68e6a53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>episode</th>\n",
       "      <th>rolling_reward</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.84105915</td>\n",
       "      <td>78</td>\n",
       "      <td>23.68</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0.810800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.67195046</td>\n",
       "      <td>139</td>\n",
       "      <td>33.08</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0.619100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.6794182</td>\n",
       "      <td>174</td>\n",
       "      <td>50.9</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0.424300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.63276404</td>\n",
       "      <td>198</td>\n",
       "      <td>67.22</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0.227600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.64580154</td>\n",
       "      <td>215</td>\n",
       "      <td>91.5</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5145112</td>\n",
       "      <td>226</td>\n",
       "      <td>113.68</td>\n",
       "      <td>6</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.37548837</td>\n",
       "      <td>239</td>\n",
       "      <td>136.56</td>\n",
       "      <td>7</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.4407295</td>\n",
       "      <td>256</td>\n",
       "      <td>137.68</td>\n",
       "      <td>8</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.3769788</td>\n",
       "      <td>276</td>\n",
       "      <td>118.74</td>\n",
       "      <td>9</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.31397462</td>\n",
       "      <td>300</td>\n",
       "      <td>90.7</td>\n",
       "      <td>10</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.36309677</td>\n",
       "      <td>319</td>\n",
       "      <td>88.84</td>\n",
       "      <td>11</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.40990824</td>\n",
       "      <td>348</td>\n",
       "      <td>78.88</td>\n",
       "      <td>12</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.22384205</td>\n",
       "      <td>375</td>\n",
       "      <td>71.42</td>\n",
       "      <td>13</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.30647063</td>\n",
       "      <td>411</td>\n",
       "      <td>60.72</td>\n",
       "      <td>14</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.32306856</td>\n",
       "      <td>438</td>\n",
       "      <td>62.98</td>\n",
       "      <td>15</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.19696616</td>\n",
       "      <td>468</td>\n",
       "      <td>69.76</td>\n",
       "      <td>16</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.23703837</td>\n",
       "      <td>500</td>\n",
       "      <td>62.94</td>\n",
       "      <td>17</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.15546267</td>\n",
       "      <td>529</td>\n",
       "      <td>65.56</td>\n",
       "      <td>18</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.15007436</td>\n",
       "      <td>568</td>\n",
       "      <td>54.18</td>\n",
       "      <td>19</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.19669779</td>\n",
       "      <td>608</td>\n",
       "      <td>46.86</td>\n",
       "      <td>19</td>\n",
       "      <td>999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n",
    "                 batch_on_pipe=BatchCollector)\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(4,2)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,[logger_base],max_steps=10000)\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True) # We basically merge 2 steps into 1 and skip. \n",
    ")\n",
    "# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\n",
    "dls = L(block.dataloaders(['CartPole-v1']*1,n=1000,bs=1))\n",
    "# Setup the Learner\n",
    "learner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=20_000,nsteps=2,lr=0.001)\n",
    "# learner.fit(3)\n",
    "learner.fit(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6de0f41e-2eda-4227-9fa8-f2e0b920754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrl.loggers.jupyter_visualizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15937f36-8efa-4163-bc67-20019d18c98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7482490a-475e-4c46-b1fa-193bf68b7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.envs.gym import GymTypeTransform,GymStepper\n",
    "\n",
    "def gym_pipe_base(envs,total_steps,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformLoop(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle(count=total_steps)\n",
    "    pipe = GymStepper(pipe,agent=agent,seed=seed,include_images=True)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7dc10e61-4f65-4a17-a5a9-489bb466af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8784650-6f5c-42b7-9a72-68a0d37d8983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "video_logger = SimpleJupyterVideoPlayer()\n",
    "\n",
    "pipe = gym_pipe_base(['CartPole-v1'],100,seed=None)\n",
    "pipe = ImageCollector(pipe,[video_logger])\n",
    "\n",
    "pipe = video_logger.connect_source_datapipe(pipe)\n",
    "\n",
    "L(pipe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccaa785-605b-4e75-bff7-bae8c5603817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loggers\n",
    "logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n",
    "                 batch_on_pipe=BatchCollector)\n",
    "\n",
    "# Setup up the core NN\n",
    "torch.manual_seed(0)\n",
    "model = DQN(8,4)\n",
    "# Setup the Agent\n",
    "agent = DQNAgent(model,[logger_base])\n",
    "# Setup the DataBlock\n",
    "block = DataBlock(\n",
    "    blocks = GymTransformBlock(agent=agent)\n",
    ")\n",
    "dls = L(block.dataloaders(['LunarLander-v2']*1,n=1000,bs=1))\n",
    "# Setup the Learner\n",
    "learner = DQNLearner(model,dls,logger_bases=[logger_base])\n",
    "learner.fit(3)\n",
    "# learner.fit(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e84a7d-9583-485d-8e16-3958c72b526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastrl.pipes.core import *\n",
    "from fastrl.envs.gym import GymTypeTransform,GymStepper\n",
    "\n",
    "def gym_pipe_base(envs,total_steps,seed=0):\n",
    "    pipe = dp.map.Mapper(envs)\n",
    "    pipe = TypeTransformLoop(pipe,[GymTypeTransform])\n",
    "    pipe = dp.iter.MapToIterConverter(pipe)\n",
    "    pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "    pipe = pipe.cycle(count=total_steps)\n",
    "    pipe = GymStepper(pipe,agent=agent,seed=seed,include_images=True)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a8a98-5091-4e31-9cca-9220c64ecdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_logger = SimpleJupyterVideoPlayer()\n",
    "\n",
    "pipe = gym_pipe_base(['LunarLander-v2'],1000,seed=None)\n",
    "pipe = ImageCollector(pipe,[video_logger])\n",
    "\n",
    "pipe = video_logger.connect_source_datapipe(pipe)\n",
    "\n",
    "L(pipe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d3626-1702-4f22-ae15-bb93a75bec68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
