{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "durable-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastrl['dev'] pyvirtualdisplay && \\\n",
    "                     apt-get install -y xvfb python-opengl > /dev/null 2>&1 \n",
    "# NOTE: IF YOU SEE VERSION ERRORS, IT IS SAFE TO IGNORE THEM. COLAB IS BEHIND IN SOME OF THE PACKAGE VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev.showdoc import *\n",
    "    from nbdev.imports import *\n",
    "    if not os.environ.get(\"IN_TEST\", None):\n",
    "        assert IN_NOTEBOOK\n",
    "        assert not IN_COLAB\n",
    "        assert IN_IPYTHON\n",
    "else:\n",
    "    # Virutual display is needed for colab\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 300))\n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp loggers.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Python native modules\n",
    "import os,typing\n",
    "# Third party libs\n",
    "from fastcore.all import *\n",
    "from torch.multiprocessing import Queue\n",
    "import torchdata.datapipes as dp\n",
    "from fastprogress.fastprogress import *\n",
    "# Local modules\n",
    "from fastrl.pipes.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-innocent",
   "metadata": {},
   "source": [
    "# Loggers Core\n",
    "> Core Utilties for logging in fastrl using Callbacks and DataPipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af94be53-536c-446d-8449-b415586a25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LoggerBase(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe=None):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queue = Queue()\n",
    "        \n",
    "    def connect_source_datapipe(self,pipe):\n",
    "        self.source_datapipe = pipe\n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1713a8-0c6d-4c72-953d-8edede20684b",
   "metadata": {},
   "source": [
    "The `LoggerBase` class outlines simply the `main_queue`. It works in combo with `LogCollector` datapipe which will add to the `main_queue` even across processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ea17189-d5bf-487a-a348-6cb9797ef548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LogCollector(dp.iter.IterDataPipe):\n",
    "    def __init__(self,\n",
    "         source_datapipe, # The parent datapipe, likely the one to collect metrics from\n",
    "         logger_bases:List[LoggerBase] # `LoggerBase`s that we want to send metrics to\n",
    "        ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queues = [o.main_queue for o in logger_bases]\n",
    "        \n",
    "    def __iter__(self): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac79f4c-7e2b-45bf-bba5-99f3abdf050c",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "User can init multiple different logger bases if they want\n",
    "\n",
    "We then can manually add Collectors, custom for certain pipes such as for collecting rewards. This can be put in \n",
    "full on pipelines even across workers.\n",
    "\n",
    "The manual process might not be desireable though, so I'm thinking of revising the `add_cbs_to_pipes` where\n",
    "the pipe itself literally says if it should go before, after, exclude from.\n",
    "\n",
    "This seems... easier than defining a callback, and keeps a level of flatness to the api.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e185243-5c23-4927-8896-c6a60cb5614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def is_pipe_instance(pipe,cls): return isinstance(pipe,cls) \n",
    "def find_pipe_instance(main_pipe,pipe_cls):\n",
    "    return find_pipes(main_pipe,partial(is_pipe_instance,cls=pipe_cls))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "317033b3-e2e5-43a3-89e8-fd474fbb5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Record(typing.NamedTuple):\n",
    "    name:str\n",
    "    value:typing.Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "562244df-e4e1-410e-bcb3-4487698effa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ProgressBarLogger(LoggerBase):\n",
    "    def __init__(self,\n",
    "                 # This does not need to be immediately set since we need the `LogCollectors` to \n",
    "                 # first be able to reference its queues.\n",
    "                 source_datapipe=None, \n",
    "                 # For this, and many LoggerBase objects, they likely will show their metrics\n",
    "                 # at the end of each epoch.\n",
    "                 epochs=None,\n",
    "                 # For this, and many LoggerBase objects, they likely will show progress of an epoch\n",
    "                 # at the end of each batch.\n",
    "                 batches=None,\n",
    "                 # For automatic pipe attaching, we can designate which pipe this should be\n",
    "                 # referneced for information on which epoch we are on\n",
    "                 epoch_on_pipe:dp.iter.IterDataPipe=None,\n",
    "                 # For automatic pipe attaching, we can designate which pipe this should be\n",
    "                 # referneced for information on which batch we are on\n",
    "                 batch_on_pipe:dp.iter.IterDataPipe=None\n",
    "                ):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.main_queue = Queue()\n",
    "        self.epochs = epochs\n",
    "        self.batches = batches\n",
    "        self.epoch_on_pipe = epoch_on_pipe\n",
    "        self.batch_on_pipe = batch_on_pipe\n",
    "    \n",
    "    def dequeue(self): \n",
    "        while not self.main_queue.empty(): yield self.main_queue.get()\n",
    "        \n",
    "    def __iter__(self):\n",
    "        epochs = find_pipe_instance(self,self.epoch_on_pipe).epochs if self.epochs is None else self.epochs\n",
    "        batches = find_pipe_instance(self,self.batch_on_pipe).batches if self.batches is None else self.batches\n",
    "        epoch_pipe = find_pipe_instance(self,self.epoch_on_pipe)\n",
    "        mbar = master_bar(list(range(epochs))) \n",
    "        pbar = progress_bar(list(range(batches)),parent=mbar,leave=False)\n",
    "        attached_collectors = {o.name:o.value for o in self.dequeue()}\n",
    "        mbar.write(attached_collectors, table=True)\n",
    "\n",
    "        source_datapipe_iter = iter(self.source_datapipe)\n",
    "        \n",
    "        for epoch in mbar:\n",
    "            for batch in pbar:\n",
    "                \n",
    "                batch_step = next(source_datapipe_iter)\n",
    "                \n",
    "                \n",
    "                yield batch_step\n",
    "                for o in self.dequeue(): attached_collectors[o.name] = o.value\n",
    "                \n",
    "                if epoch_pipe.epoch!=epoch:\n",
    "                    print('breaking',epoch_pipe.epoch,epoch)\n",
    "                    break\n",
    "                \n",
    "            mbar.write([f'{l:.6f}' if isinstance(l, float) else str(l)\n",
    "                        for l in attached_collectors.values()], table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49764c20-370d-431d-88ab-6ecabdaadfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class RewardCollector(LogCollector):\n",
    "    def __iter__(self):\n",
    "        for q in self.main_queues: q.put(Record('reward',None))\n",
    "        for steps in self.source_datapipe:\n",
    "            if isinstance(steps,dp.DataChunk):\n",
    "                for step in steps:\n",
    "                    for q in self.main_queues: q.put(Record('reward',step.reward.detach().numpy()))\n",
    "            else:\n",
    "                for q in self.main_queues: q.put(Record('reward',steps.reward.detach().numpy()))\n",
    "            yield steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12ba29b4-e434-4548-8aa1-2851a94dc75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_epocher(pipe): return isinstance(pipe,Epocher)\n",
    "\n",
    "class Epocher(dp.iter.IterDataPipe):\n",
    "    def __init__(self,source_datapipe,epochs=0):\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.epochs = epochs\n",
    "        self.epoch = 0\n",
    "\n",
    "    def __iter__(self): \n",
    "        print('Start epocher')\n",
    "        for i in range(self.epochs): \n",
    "            self.epoch = i\n",
    "            print(self.epoch,self.epochs)\n",
    "            yield from self.source_datapipe   \n",
    "            print('finished epochs')\n",
    "        print('End epocher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41455bda-ec57-4beb-9485-4295537ab7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epocher\n",
      "0 5\n",
      "finished epochs\n",
      "1 5\n",
      "finished epochs\n",
      "2 5\n",
      "finished epochs\n",
      "3 5\n",
      "finished epochs\n",
      "4 5\n",
      "finished epochs\n",
      "End epocher\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fastrl.envs.gym import *\n",
    "\n",
    "envs = ['CartPole-v1']*10\n",
    "\n",
    "logger_base = ProgressBarLogger(batches=18*len(envs),epoch_on_pipe=Epocher)\n",
    "\n",
    "pipe = dp.map.Mapper(envs)\n",
    "pipe = TypeTransformLoop(pipe,[GymTypeTransform])\n",
    "pipe = dp.iter.MapToIterConverter(pipe)\n",
    "pipe = dp.iter.InMemoryCacheHolder(pipe)\n",
    "pipe = pipe.cycle(count=(18*len(envs))) \n",
    "pipe = Epocher(pipe,epochs=5)\n",
    "# Turn off the seed so that some envs end before others...\n",
    "pipe = GymStepper(pipe,synchronized_reset=True)\n",
    "\n",
    "pipe = RewardCollector(pipe,[logger_base])\n",
    "\n",
    "# pipe = logger_base.connect_source_datapipe(pipe)\n",
    "# pipe = add_cbs_to_pipes(pipe,L(cb))\n",
    "# steps = list(pipe)\n",
    "steps = list(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "current-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting /home/fastrl_user/fastrl/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "from fastcore.imports import in_colab\n",
    "\n",
    "# Since colab still requires tornado<6, we don't want to import nbdev if we don't have to\n",
    "if not in_colab():\n",
    "    from nbdev import nbdev_export\n",
    "    nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8dae91-6f28-4256-975d-48783866322e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
