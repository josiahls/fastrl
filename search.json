[
  {
    "objectID": "03_Environment/envs.gym.html#iteration-examples",
    "href": "03_Environment/envs.gym.html#iteration-examples",
    "title": "Envs Gym",
    "section": "Iteration Examples",
    "text": "Iteration Examples\n\nimport pandas as pd\nfrom fastrl.agents.core import *\n\n\nclass ConstantRunner(dp.iter.IterDataPipe):\n    def __init__(self,source_datapipe,constant=1,array_nestings=0): \n        self.source_datapipe = source_datapipe\n        self.agent_base = find_dp(traverse(self.source_datapipe),AgentBase)\n        self.constant = constant\n        self.array_nestings = array_nestings\n    \n    def __iter__(self):\n        for o in self.source_datapipe: \n            try: \n                if self.array_nestings==0: yield self.constant\n                else:\n                    yield [self.constant]*self.array_nestings\n            except Exception:\n                print('Failed on ',o)\n                raise\n\nagent = AgentBase(None,[])\nagent = ConstantRunner(agent)\nagent = AgentHead(agent)\n\npipe = dp.map.Mapper(['CartPole-v1']*3)\npipe = TypeTransformer(pipe,[GymTypeTransform])\npipe = dp.iter.MapToIterConverter(pipe)\npipe = dp.iter.InMemoryCacheHolder(pipe)\npipe = pipe.cycle()\npipe = GymStepper(pipe,agent=agent,seed=0)\n\npd.DataFrame([step for step,_ in zip(*(pipe,range(10)))])[['state','next_state','action','terminated']]\n\n\n\n\n\n  \n    \n      \n      state\n      next_state\n      action\n      terminated\n    \n  \n  \n    \n      0\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      1\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      2\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      3\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      4\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      5\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      6\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      7\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      8\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      9\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      [tensor(0.0353), tensor(0.7603), tensor(-0.0866), tensor(-1.2844)]\n      tensor(1.)\n      tensor(False)\n    \n  \n\n\n\n\n\npipe = dp.map.Mapper(['CartPole-v1']*3)\npipe = TypeTransformer(pipe,[GymTypeTransform])\npipe = dp.iter.MapToIterConverter(pipe)\npipe = dp.iter.InMemoryCacheHolder(pipe)\npipe = pipe.cycle()\npipe = GymStepper(pipe,seed=0)\n\npd.DataFrame([step for step,_ in zip(*(pipe,range(10)))])[['state','next_state','action','terminated']]\n\n\n\n\n\n  \n    \n      \n      state\n      next_state\n      action\n      terminated\n    \n  \n  \n    \n      0\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      1\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      2\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      3\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      4\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      5\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      6\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      7\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      8\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      tensor(1.)\n      tensor(False)\n    \n    \n      9\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      [tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]\n      tensor(0.)\n      tensor(False)\n    \n  \n\n\n\n\n\nfrom torch.utils.data.dataloader_experimental import DataLoader2\n\n\ndef seed_worker(worker_id): torch.manual_seed(0)\n\ndl = DataLoader2(pipe,num_workers=2,worker_init_fn=seed_worker)\n\npd.DataFrame([step for step,_ in zip(*(dl,range(10)))])[['state','next_state','action','terminated']]\n\n\n\n\n\n  \n    \n      \n      state\n      next_state\n      action\n      terminated\n    \n  \n  \n    \n      0\n      [[tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]]\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      1\n      [[tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]]\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      2\n      [[tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]]\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      3\n      [[tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]]\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      4\n      [[tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]]\n      [[tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      5\n      [[tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]]\n      [[tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      6\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [[tensor(0.0463), tensor(-0.0172), tensor(-0.1094), tensor(-0.1771)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      7\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [[tensor(0.0463), tensor(-0.0172), tensor(-0.1094), tensor(-0.1771)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      8\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [[tensor(0.0463), tensor(-0.0172), tensor(-0.1094), tensor(-0.1771)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      9\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [[tensor(0.0463), tensor(-0.0172), tensor(-0.1094), tensor(-0.1771)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n  \n\n\n\n\n\npipe = dp.map.Mapper(['CartPole-v1']*3)\npipe = TypeTransformer(pipe,[GymTypeTransform])\npipe = dp.iter.MapToIterConverter(pipe)\npipe = dp.iter.InMemoryCacheHolder(pipe)\npipe = pipe.cycle()\npipe = GymStepper(pipe,synchronized_reset=True)\n\npd.DataFrame([step for step,_ in zip(*(dl,range(10)))])[['state','next_state','action','terminated']]\n\n\n\n\n\n  \n    \n      \n      state\n      next_state\n      action\n      terminated\n    \n  \n  \n    \n      0\n      [[tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]]\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      1\n      [[tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]]\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      2\n      [[tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]]\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      3\n      [[tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]]\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      4\n      [[tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]]\n      [[tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      5\n      [[tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]]\n      [[tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      6\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [[tensor(0.0463), tensor(-0.0172), tensor(-0.1094), tensor(-0.1771)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      7\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [[tensor(0.0463), tensor(-0.0172), tensor(-0.1094), tensor(-0.1771)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      8\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [[tensor(0.0463), tensor(-0.0172), tensor(-0.1094), tensor(-0.1771)]]\n      [tensor(0.)]\n      [tensor(False)]\n    \n    \n      9\n      [[tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]]\n      [[tensor(0.0463), tensor(-0.0172), tensor(-0.1094), tensor(-0.1771)]]\n      [tensor(0.)]\n      [tensor(False)]"
  },
  {
    "objectID": "03_Environment/envs.gym.html#tests",
    "href": "03_Environment/envs.gym.html#tests",
    "title": "Envs Gym",
    "section": "Tests",
    "text": "Tests\nWe create 3 envs and put a max iteration count at 180. Each env will run for 18 steps before ending, which means we expect there to be 10 total episodes.\n\nenvs = ['CartPole-v1']*3\nn_episodes = 3\n\npipe = dp.map.Mapper(envs)\npipe = TypeTransformer(pipe,[GymTypeTransform])\npipe = dp.iter.MapToIterConverter(pipe)\npipe = dp.iter.InMemoryCacheHolder(pipe)\n# We want to cycle through the envs enough times that their epsiode sum to 9, 3 episodes each\npipe = pipe.cycle(count=(18*len(envs))) \npipe = GymStepper(pipe,seed=0)\n\nAll the of the environments should reach max 18 steps given a seed of 0…\nThe total number of iterations should be ( 18 * n_envs) * n_episodes_per_env = 162…\n\nsteps = list(pipe)\ngsteps = groupby(steps,lambda o:int(o.step_n))\ntest_len(gsteps.keys(),18)\npd.DataFrame([step for step in steps])[['state','terminated','env_id','episode_n','step_n']][::10]\n\n\n\n\n\n  \n    \n      \n      state\n      terminated\n      env_id\n      episode_n\n      step_n\n    \n  \n  \n    \n      0\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      tensor(False)\n      tensor(140361096758800)\n      tensor(1)\n      tensor(1)\n    \n    \n      10\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      tensor(False)\n      tensor(140361096757392)\n      tensor(1)\n      tensor(4)\n    \n    \n      20\n      [tensor(0.0463), tensor(-0.0172), tensor(-0.1094), tensor(-0.1771)]\n      tensor(False)\n      tensor(140361096758352)\n      tensor(1)\n      tensor(7)\n    \n    \n      30\n      [tensor(0.0217), tensor(-0.4009), tensor(-0.0929), tensor(0.2661)]\n      tensor(False)\n      tensor(140361096758800)\n      tensor(1)\n      tensor(11)\n    \n    \n      40\n      [tensor(0.0094), tensor(0.1879), tensor(-0.0961), tensor(-0.6926)]\n      tensor(False)\n      tensor(140361096757392)\n      tensor(1)\n      tensor(14)\n    \n    \n      50\n      [tensor(0.0325), tensor(0.7771), tensor(-0.1570), tensor(-1.6694)]\n      tensor(False)\n      tensor(140361096758352)\n      tensor(1)\n      tensor(17)\n    \n    \n      60\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(False)\n      tensor(140361096758800)\n      tensor(2)\n      tensor(3)\n    \n    \n      70\n      [tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]\n      tensor(False)\n      tensor(140361096757392)\n      tensor(2)\n      tensor(6)\n    \n    \n      80\n      [tensor(0.0417), tensor(-0.4040), tensor(-0.1113), tensor(0.3342)]\n      tensor(False)\n      tensor(140361096758352)\n      tensor(2)\n      tensor(9)\n    \n    \n      90\n      [tensor(0.0096), tensor(-0.0083), tensor(-0.0886), tensor(-0.3733)]\n      tensor(False)\n      tensor(140361096758800)\n      tensor(2)\n      tensor(13)\n    \n    \n      100\n      [tensor(0.0209), tensor(0.5806), tensor(-0.1302), tensor(-1.3390)]\n      tensor(False)\n      tensor(140361096757392)\n      tensor(2)\n      tensor(16)\n    \n    \n      110\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      tensor(False)\n      tensor(140361096758352)\n      tensor(3)\n      tensor(1)\n    \n    \n      120\n      [tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]\n      tensor(False)\n      tensor(140361096758800)\n      tensor(3)\n      tensor(5)\n    \n    \n      130\n      [tensor(0.0459), tensor(-0.2106), tensor(-0.1129), tensor(0.0792)]\n      tensor(False)\n      tensor(140361096757392)\n      tensor(3)\n      tensor(8)\n    \n    \n      140\n      [tensor(0.0217), tensor(-0.4009), tensor(-0.0929), tensor(0.2661)]\n      tensor(False)\n      tensor(140361096758352)\n      tensor(3)\n      tensor(11)\n    \n    \n      150\n      [tensor(0.0132), tensor(0.3842), tensor(-0.1099), tensor(-1.0139)]\n      tensor(False)\n      tensor(140361096758800)\n      tensor(3)\n      tensor(15)\n    \n    \n      160\n      [tensor(0.0480), tensor(0.9737), tensor(-0.1904), tensor(-2.0066)]\n      tensor(True)\n      tensor(140361096757392)\n      tensor(3)\n      tensor(18)\n    \n  \n\n\n\n\nAll of the step groups should be the same length…\n\ngroup_sz = None\nfor name,group in gsteps.items():\n    if group_sz is None: group_sz = len(group)\n    else:                assert len(group)==group_sz,f' Got lengths {len(group)} and {group_sz} for {name}.\\n\\n{group}'\n\nEach step group’s state and next_states should match across envs…\n\ngroup_sz = None\nfor name,group in gsteps.items():\n    e1 = group[0]\n    for other in group[1:]: test_eq(e1.state,other.state)\n    for other in group[1:]: test_eq(e1.next_state,other.next_state)\n\nEach step group value should not show up/be duplicated in any other step groups…\n\ngroup_sz = None\nfor name,group in gsteps.items():\n    e1 = group[0]\n    for other_name,other_group in gsteps.items():\n        if other_name==name: continue\n        for other in other_group[1:]: test_ne(e1.state,other.state)\n        for other in other_group[1:]: test_ne(e1.next_state,other.next_state)\n\nGiven 3 envs, single steps, epsiodes of 18 steps in len, 3 episodes each, run for 162 iterations, we should expect there to be 9 dones.\n\ntest_eq(sum([o.terminated for o in steps]),tensor([9]))\n\nThe max episode numbers for each env should sum to 9 where for each env, it should reach and finish 3 episodes…\n\ngsteps = groupby(steps,lambda o:int(o.env_id))\ntest_len(gsteps.keys(),3)\nenv1,env2,env3 = L(gsteps.values()).map(L).map(Self.map(Self.episode_n()).map(int))\ntest_eq(max(env1)+max(env2)+max(env3),9)\n\n\nTest the synchronized_reset param…\n\nIn this case, we will have iterate through the 3 envs without producing a step on warmup.\n\n\nenvs = ['CartPole-v1']*3\nn_episodes = 3\n\npipe = dp.map.Mapper(envs)\npipe = TypeTransformer(pipe,[GymTypeTransform])\npipe = dp.iter.MapToIterConverter(pipe)\npipe = dp.iter.InMemoryCacheHolder(pipe)\n# We want to cycle through the envs enough times that their epsiode sum to 9, 3 episodes each\n# We add an additional +3 cycles since `synchronized_reset` cycles through the envs additional times\n# to make sure they are all reset prior to stepping\npipe = pipe.cycle(count=(18*len(envs))+3) \npipe = GymStepper(pipe,seed=0,synchronized_reset=True)\n\n\nsteps = list(pipe)\ngsteps = groupby(steps,lambda o:int(o.step_n))\ntest_len(gsteps.keys(),18)\npd.DataFrame([step for step in steps])[['state','terminated','env_id','episode_n','step_n']][::10]\n\n\n\n\n\n  \n    \n      \n      state\n      terminated\n      env_id\n      episode_n\n      step_n\n    \n  \n  \n    \n      0\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      tensor(False)\n      tensor(140361096587536)\n      tensor(1)\n      tensor(1)\n    \n    \n      10\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      tensor(False)\n      tensor(140361096587472)\n      tensor(1)\n      tensor(4)\n    \n    \n      20\n      [tensor(0.0463), tensor(-0.0172), tensor(-0.1094), tensor(-0.1771)]\n      tensor(False)\n      tensor(140361096587920)\n      tensor(1)\n      tensor(7)\n    \n    \n      30\n      [tensor(0.0217), tensor(-0.4009), tensor(-0.0929), tensor(0.2661)]\n      tensor(False)\n      tensor(140361096587536)\n      tensor(1)\n      tensor(11)\n    \n    \n      40\n      [tensor(0.0094), tensor(0.1879), tensor(-0.0961), tensor(-0.6926)]\n      tensor(False)\n      tensor(140361096587472)\n      tensor(1)\n      tensor(14)\n    \n    \n      50\n      [tensor(0.0325), tensor(0.7771), tensor(-0.1570), tensor(-1.6694)]\n      tensor(False)\n      tensor(140361096587920)\n      tensor(1)\n      tensor(17)\n    \n    \n      60\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(False)\n      tensor(140361096587536)\n      tensor(2)\n      tensor(3)\n    \n    \n      70\n      [tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]\n      tensor(False)\n      tensor(140361096587472)\n      tensor(2)\n      tensor(6)\n    \n    \n      80\n      [tensor(0.0417), tensor(-0.4040), tensor(-0.1113), tensor(0.3342)]\n      tensor(False)\n      tensor(140361096587920)\n      tensor(2)\n      tensor(9)\n    \n    \n      90\n      [tensor(0.0096), tensor(-0.0083), tensor(-0.0886), tensor(-0.3733)]\n      tensor(False)\n      tensor(140361096587536)\n      tensor(2)\n      tensor(13)\n    \n    \n      100\n      [tensor(0.0209), tensor(0.5806), tensor(-0.1302), tensor(-1.3390)]\n      tensor(False)\n      tensor(140361096587472)\n      tensor(2)\n      tensor(16)\n    \n    \n      110\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      tensor(False)\n      tensor(140361096587920)\n      tensor(3)\n      tensor(1)\n    \n    \n      120\n      [tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]\n      tensor(False)\n      tensor(140361096587536)\n      tensor(3)\n      tensor(5)\n    \n    \n      130\n      [tensor(0.0459), tensor(-0.2106), tensor(-0.1129), tensor(0.0792)]\n      tensor(False)\n      tensor(140361096587472)\n      tensor(3)\n      tensor(8)\n    \n    \n      140\n      [tensor(0.0217), tensor(-0.4009), tensor(-0.0929), tensor(0.2661)]\n      tensor(False)\n      tensor(140361096587920)\n      tensor(3)\n      tensor(11)\n    \n    \n      150\n      [tensor(0.0132), tensor(0.3842), tensor(-0.1099), tensor(-1.0139)]\n      tensor(False)\n      tensor(140361096587536)\n      tensor(3)\n      tensor(15)\n    \n    \n      160\n      [tensor(0.0480), tensor(0.9737), tensor(-0.1904), tensor(-2.0066)]\n      tensor(True)\n      tensor(140361096587472)\n      tensor(3)\n      tensor(18)\n    \n  \n\n\n\n\nAll of the step groups should be the same length…\n\ngroup_sz = None\nfor name,group in gsteps.items():\n    if group_sz is None: group_sz = len(group)\n    else:                assert len(group)==group_sz,f' Got lengths {len(group)} and {group_sz} for {name}.\\n\\n{group}'\n\nEach step group’s state and next_states should match across envs…\n\ngroup_sz = None\nfor name,group in gsteps.items():\n    e1 = group[0]\n    for other in group[1:]: test_eq(e1.state,other.state)\n    for other in group[1:]: test_eq(e1.next_state,other.next_state)\n\nEach step group value should not show up/be duplicated in any other step groups…\n\ngroup_sz = None\nfor name,group in gsteps.items():\n    e1 = group[0]\n    for other_name,other_group in gsteps.items():\n        if other_name==name: continue\n        for other in other_group[1:]: test_ne(e1.state,other.state)\n        for other in other_group[1:]: test_ne(e1.next_state,other.next_state)\n\nGiven 3 envs, single steps, epsiodes of 18 steps in len, 3 episodes each, run for 162 iterations, we should expect there to be 9 dones.\n\ntest_eq(sum([o.terminated for o in steps]),tensor([9]))\n\nThe max episode numbers for each env should sum to 9 where for each env, it should reach and finish 3 episodes…\n\ngsteps = groupby(steps,lambda o:int(o.env_id))\ntest_len(gsteps.keys(),3)\nenv1,env2,env3 = L(gsteps.values()).map(L).map(Self.map(Self.episode_n()).map(int))\ntest_eq(max(env1)+max(env2)+max(env3),9)\n\n\nenvs = ['CartPole-v1']*10\n\npipe = dp.map.Mapper(envs)\npipe = TypeTransformer(pipe,[GymTypeTransform])\npipe = dp.iter.MapToIterConverter(pipe)\npipe = dp.iter.InMemoryCacheHolder(pipe)\npipe = pipe.cycle(count=(18*len(envs))) \n# Turn off the seed so that some envs end before others...\npipe = GymStepper(pipe,synchronized_reset=True)\nsteps = list(pipe)\n\nSince the seed is turned off the only properties we are to expect are:\n- If an env finishes, no steps from that env should be seen until all 9 of the other envs finish\n\ndef synchronized_reset_checker(steps):\n    env_id_done_tracker = {}\n    did_syncs_happen = False\n    for d,env_id,idx in [(bool(o.terminated),int(o.env_id),i) for i,o in enumerate(steps)]:\n\n        if d: \n            env_id_done_tracker[env_id] = idx\n            continue\n\n        if env_id in env_id_done_tracker:\n            if len(env_id_done_tracker)!=len(envs):\n                raise Exception(f'env_id {env_id} was iterated through when it should not have been! idx: {idx}')\n        if len(env_id_done_tracker)==len(envs):\n            did_syncs_happen = True\n            env_id_done_tracker = {}\n\n    if not did_syncs_happen: \n        raise Exception('There should have at least been 1 time where all the envs had to reset, which did not happen.')\nsynchronized_reset_checker(steps)\n\nFor sanity, we should expect that without synchronized_reset envs will be reset and stepped through before other envs are reset, synchronized_reset_checker should fail.\n\npipe = dp.map.Mapper(envs)\npipe = TypeTransformer(pipe,[GymTypeTransform])\npipe = dp.iter.MapToIterConverter(pipe)\npipe = dp.iter.InMemoryCacheHolder(pipe)\npipe = pipe.cycle(count=(18*len(envs))) \n# Turn off the seed so that some envs end before others...\npipe = GymStepper(pipe)\nsteps = list(pipe)\n\n\nwith ExceptionExpected(regex='was iterated through when it should not have been'):\n    synchronized_reset_checker(steps)\n\n\n\n\nGymTransformBlock\n\n GymTransformBlock (agent:Union[torch.utils.data.datapipes.datapipe.IterDa\n                    taPipe,torch.utils.data.datapipes.datapipe.MapDataPipe\n                    ], seed:Union[int,NoneType]=None, nsteps:int=1,\n                    nskips:int=1, firstlast:bool=False,\n                    type_tfms:Union[List[Callable],NoneType]=None,\n                    item_tfms:Union[List[Callable],NoneType]=None,\n                    batch_tfms:Union[List[Callable],NoneType]=None,\n                    bs:int=1, n:Union[int,NoneType]=None,\n                    synchronized_reset:bool=False,\n                    include_images:bool=False,\n                    terminate_on_truncation:bool=True, dp_augmentation_fns\n                    :Tuple[fastrl.pipes.core.DataPipeAugmentationFn]=None)\n\nBasic OpenAi gym DataPipeGraph with first-last, nstep, and nskip capability\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nagent\ntyping.Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe]\n\nAn AgentHead\n\n\nseed\ntyping.Union[int, NoneType]\nNone\nThe seed for the gym to use\n\n\nnsteps\nint\n1\nUsed by NStepper, outputs tuples / chunks of assiciated steps\n\n\nnskips\nint\n1\nUsed by NSkipper to skip a certain number of steps (agent still gets called for each)\n\n\nfirstlast\nbool\nFalse\nWhether when nsteps>1 to merge it into a single StepType\n\n\ntype_tfms\ntyping.Union[typing.List[typing.Callable], NoneType]\nNone\nFunctions to run once, at the beginning of the pipeline\n\n\nitem_tfms\ntyping.Union[typing.List[typing.Callable], NoneType]\nNone\nFunctions to run over individual steps before batching\n\n\nbatch_tfms\ntyping.Union[typing.List[typing.Callable], NoneType]\nNone\nFunctions to run over batches (as specified by bs)\n\n\nbs\nint\n1\nThe batch size, which is different from nsteps in that firstlast will be run prior to batching, and a batch of steps might come from multiple envs,where nstep is associated with a single env\n\n\nn\ntyping.Union[int, NoneType]\nNone\nThe prefered default is for the pipeline to be infinate, and the learnerdecides how much to iter. If this is not None, then the pipeline will run for that number of n\n\n\nsynchronized_reset\nbool\nFalse\nWhether to reset all the envs at the same time as opposed to reseting them the moment an episode ends.\n\n\ninclude_images\nbool\nFalse\nShould be used only for validation / logging, will grab a render of the gymand assign to the StepType image field. This data should not be used for training.If it images are needed for training, then you should wrap the env instead.\n\n\nterminate_on_truncation\nbool\nTrue\nIf an environment truncates, terminate it.\n\n\ndp_augmentation_fns\ntyping.Tuple[fastrl.pipes.core.DataPipeAugmentationFn]\nNone\nAdditional pipelines to insert, replace, remove\n\n\nReturns\nNone\n\n\n\n\n\n\npd.set_option('display.max_rows', 50)\n\nenvs = ['CartPole-v1']*3\nblock = GymTransformBlock(None,nsteps=2,nskips=2,firstlast=True,bs=1,n=100)\npipes = block(envs)\npd.DataFrame([o[0] for o in pipes])[['state','action','terminated','reward']][:50]\n\n\n\n\n\n  \n    \n      \n      state\n      action\n      terminated\n      reward\n    \n  \n  \n    \n      0\n      [tensor(-0.0067), tensor(-0.0143), tensor(-0.0049), tensor(-0.0393)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      1\n      [tensor(-0.0420), tensor(0.0171), tensor(-0.0034), tensor(0.0493)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      2\n      [tensor(-0.0061), tensor(0.0313), tensor(-0.0255), tensor(-0.0405)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      3\n      [tensor(-0.0070), tensor(-0.2094), tensor(-0.0057), tensor(0.2518)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      4\n      [tensor(-0.0417), tensor(-0.1780), tensor(-0.0025), tensor(0.3409)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      5\n      [tensor(-0.0055), tensor(-0.1635), tensor(-0.0263), tensor(0.2440)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      6\n      [tensor(-0.0114), tensor(0.1810), tensor(-0.0015), tensor(-0.3355)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      7\n      [tensor(-0.0527), tensor(-0.5682), tensor(0.0170), tensor(0.9269)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      8\n      [tensor(-0.0159), tensor(-0.1628), tensor(-0.0109), tensor(0.2289)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      9\n      [tensor(-0.0003), tensor(0.5714), tensor(-0.0208), tensor(-0.9239)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      10\n      [tensor(-0.0794), tensor(-0.5689), tensor(0.0601), tensor(0.9435)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      11\n      [tensor(-0.0185), tensor(-0.1626), tensor(-0.0076), tensor(0.2235)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      12\n      [tensor(0.0187), tensor(0.1820), tensor(-0.0520), tensor(-0.3578)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      13\n      [tensor(-0.0982), tensor(-0.1807), tensor(0.0923), tensor(0.4035)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      14\n      [tensor(-0.0211), tensor(-0.1624), tensor(-0.0046), tensor(0.2201)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      15\n      [tensor(0.0299), tensor(0.5737), tensor(-0.0725), tensor(-0.9771)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      16\n      [tensor(-0.1016), tensor(0.2065), tensor(0.1032), tensor(-0.1181)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      17\n      [tensor(-0.0315), tensor(-0.1623), tensor(0.0101), tensor(0.2186)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      18\n      [tensor(0.0567), tensor(0.9659), tensor(-0.1179), tensor(-1.6117)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      19\n      [tensor(-0.0973), tensor(0.2036), tensor(0.1050), tensor(-0.0540)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      20\n      [tensor(-0.0341), tensor(-0.1627), tensor(0.0130), tensor(0.2263)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      21\n      [tensor(0.0915), tensor(0.5794), tensor(-0.1773), tensor(-1.1158)]\n      tensor(0.)\n      tensor(True)\n      tensor(1.9900)\n    \n    \n      22\n      [tensor(0.1031), tensor(0.3870), tensor(-0.1996), tensor(-0.8836)]\n      tensor(1.)\n      tensor(True)\n      tensor(1.)\n    \n    \n      23\n      [tensor(-0.0852), tensor(0.5906), tensor(0.0977), tensor(-0.5700)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      24\n      [tensor(-0.0445), tensor(-0.1631), tensor(0.0280), tensor(0.2360)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      25\n      [tensor(-0.0385), tensor(0.0387), tensor(0.0470), tensor(-0.0146)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      26\n      [tensor(-0.0655), tensor(0.5880), tensor(0.0813), tensor(-0.5125)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      27\n      [tensor(-0.0549), tensor(-0.1640), tensor(0.0435), tensor(0.2552)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      28\n      [tensor(-0.0330), tensor(0.4275), tensor(0.0409), tensor(-0.5697)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      29\n      [tensor(-0.0459), tensor(0.5859), tensor(0.0671), tensor(-0.4648)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      30\n      [tensor(-0.0576), tensor(-0.1653), tensor(0.0481), tensor(0.2841)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      31\n      [tensor(-0.0198), tensor(0.4266), tensor(0.0242), tensor(-0.5476)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      32\n      [tensor(-0.0264), tensor(0.1940), tensor(0.0548), tensor(0.1586)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      33\n      [tensor(-0.0681), tensor(-0.1667), tensor(0.0656), tensor(0.3163)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      34\n      [tensor(-0.0067), tensor(0.4260), tensor(0.0083), tensor(-0.5359)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      35\n      [tensor(-0.0226), tensor(0.1924), tensor(0.0673), tensor(0.1942)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      36\n      [tensor(-0.0787), tensor(-0.1687), tensor(0.0845), tensor(0.3598)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      37\n      [tensor(0.0143), tensor(0.8162), tensor(-0.0189), tensor(-1.1194)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      38\n      [tensor(-0.0110), tensor(0.1904), tensor(0.0697), tensor(0.2378)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      39\n      [tensor(-0.0894), tensor(-0.1712), tensor(0.1053), tensor(0.4154)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      40\n      [tensor(0.0430), tensor(0.8170), tensor(-0.0579), tensor(-1.1380)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      41\n      [tensor(-0.0073), tensor(0.1884), tensor(0.0855), tensor(0.2833)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      42\n      [tensor(-0.0924), tensor(0.2157), tensor(0.1167), tensor(-0.0971)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      43\n      [tensor(0.0718), tensor(0.4287), tensor(-0.0980), tensor(-0.5978)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      44\n      [tensor(0.0041), tensor(0.5759), tensor(0.0915), tensor(-0.2439)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      45\n      [tensor(-0.0877), tensor(0.2124), tensor(0.1194), tensor(-0.0244)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      46\n      [tensor(0.0851), tensor(0.4316), tensor(-0.1167), tensor(-0.6628)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      47\n      [tensor(0.0232), tensor(0.5734), tensor(0.0882), tensor(-0.1879)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      48\n      [tensor(-0.0831), tensor(-0.1808), tensor(0.1250), tensor(0.6311)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      49\n      [tensor(0.0985), tensor(0.4350), tensor(-0.1381), tensor(-0.7397)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n  \n\n\n\n\n\npd.set_option('display.max_rows', 50)\n\nenvs = ['CartPole-v1']*3\nblock = GymTransformBlock(None,nsteps=1,nskips=1,firstlast=True,bs=1,n=100)\npipes = block(envs)\n\npd.DataFrame([o[0] for o in pipes])[['state','action','terminated','reward']][:50]\n\n\n\n\n\n  \n    \n      \n      state\n      action\n      terminated\n      reward\n    \n  \n  \n    \n      0\n      [tensor(0.0350), tensor(-0.0038), tensor(0.0399), tensor(-0.0427)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      1\n      [tensor(0.0178), tensor(0.0382), tensor(0.0337), tensor(0.0479)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      2\n      [tensor(0.0076), tensor(-0.0453), tensor(-0.0180), tensor(0.0093)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      3\n      [tensor(0.0350), tensor(-0.1995), tensor(0.0391), tensor(0.2623)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      4\n      [tensor(0.0186), tensor(-0.1574), tensor(0.0346), tensor(0.3510)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      5\n      [tensor(0.0067), tensor(-0.2402), tensor(-0.0178), tensor(0.2963)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      6\n      [tensor(0.0310), tensor(-0.0050), tensor(0.0443), tensor(-0.0178)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      7\n      [tensor(0.0154), tensor(0.0372), tensor(0.0416), tensor(0.0694)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      8\n      [tensor(0.0019), tensor(-0.0448), tensor(-0.0119), tensor(-0.0020)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      9\n      [tensor(0.0309), tensor(-0.2007), tensor(0.0440), tensor(0.2885)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      10\n      [tensor(0.0162), tensor(-0.1585), tensor(0.0430), tensor(0.3749)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      11\n      [tensor(0.0010), tensor(0.1505), tensor(-0.0119), tensor(-0.2984)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      12\n      [tensor(0.0269), tensor(-0.3964), tensor(0.0498), tensor(0.5948)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      13\n      [tensor(0.0130), tensor(-0.3542), tensor(0.0505), tensor(0.6808)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      14\n      [tensor(0.0040), tensor(0.3458), tensor(-0.0179), tensor(-0.5948)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      15\n      [tensor(0.0189), tensor(-0.2020), tensor(0.0616), tensor(0.3182)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      16\n      [tensor(0.0059), tensor(-0.1598), tensor(0.0641), tensor(0.4045)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      17\n      [tensor(0.0109), tensor(0.1509), tensor(-0.0298), tensor(-0.3078)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      18\n      [tensor(0.0149), tensor(-0.3980), tensor(0.0680), tensor(0.6296)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      19\n      [tensor(0.0027), tensor(0.0343), tensor(0.0722), tensor(0.1327)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      20\n      [tensor(0.0139), tensor(-0.0438), tensor(-0.0360), tensor(-0.0247)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      21\n      [tensor(0.0069), tensor(-0.5940), tensor(0.0806), tensor(0.9429)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      22\n      [tensor(0.0034), tensor(0.2283), tensor(0.0749), tensor(-0.1364)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      23\n      [tensor(0.0131), tensor(-0.2384), tensor(-0.0365), tensor(0.2564)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      24\n      [tensor(-0.0049), tensor(-0.7901), tensor(0.0995), tensor(1.2598)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      25\n      [tensor(0.0080), tensor(0.0322), tensor(0.0721), tensor(0.1790)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      26\n      [tensor(0.0083), tensor(-0.0428), tensor(-0.0313), tensor(-0.0475)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      27\n      [tensor(-0.0207), tensor(-0.5964), tensor(0.1247), tensor(0.9999)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      28\n      [tensor(0.0086), tensor(-0.1638), tensor(0.0757), tensor(0.4935)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      29\n      [tensor(0.0074), tensor(-0.2374), tensor(-0.0323), tensor(0.2351)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      30\n      [tensor(-0.0327), tensor(-0.7929), tensor(0.1447), tensor(1.3290)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      31\n      [tensor(0.0053), tensor(0.0301), tensor(0.0856), tensor(0.2256)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      32\n      [tensor(0.0027), tensor(-0.4321), tensor(-0.0276), tensor(0.5174)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      33\n      [tensor(-0.0485), tensor(-0.5999), tensor(0.1712), tensor(1.0848)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      34\n      [tensor(0.0059), tensor(0.2239), tensor(0.0901), tensor(-0.0389)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      35\n      [tensor(-0.0060), tensor(-0.2366), tensor(-0.0172), tensor(0.2162)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      36\n      [tensor(-0.0605), tensor(-0.7968), tensor(0.1929), tensor(1.4260)]\n      tensor(1.)\n      tensor(True)\n      tensor(1.)\n    \n    \n      37\n      [tensor(0.0104), tensor(0.0276), tensor(0.0893), tensor(0.2808)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      38\n      [tensor(-0.0107), tensor(-0.4314), tensor(-0.0129), tensor(0.5034)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      39\n      [tensor(-0.0243), tensor(-0.0176), tensor(0.0349), tensor(-0.0015)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      40\n      [tensor(0.0110), tensor(-0.1686), tensor(0.0950), tensor(0.6003)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      41\n      [tensor(-0.0193), tensor(-0.6264), tensor(-0.0028), tensor(0.7920)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      42\n      [tensor(-0.0246), tensor(0.1771), tensor(0.0349), tensor(-0.2830)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      43\n      [tensor(0.0076), tensor(0.0250), tensor(0.1070), tensor(0.3390)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      44\n      [tensor(-0.0318), tensor(-0.8215), tensor(0.0130), tensor(1.0838)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      45\n      [tensor(-0.0211), tensor(-0.0185), tensor(0.0292), tensor(0.0205)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      46\n      [tensor(0.0081), tensor(0.2185), tensor(0.1137), tensor(0.0818)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      47\n      [tensor(-0.0483), tensor(-1.0168), tensor(0.0347), tensor(1.3805)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      48\n      [tensor(-0.0215), tensor(-0.2141), tensor(0.0296), tensor(0.3223)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.)\n    \n    \n      49\n      [tensor(0.0125), tensor(0.4118), tensor(0.1154), tensor(-0.1729)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.)\n    \n  \n\n\n\n\n\nenvs = ['CartPole-v1']*3\nblock = GymTransformBlock(None,nsteps=2,nskips=1,firstlast=True,bs=1,n=100)\npipes = block(envs)\npd.DataFrame([o[0] for o in pipes])[['state','action','terminated','reward']][:50]\n\n\n\n\n\n  \n    \n      \n      state\n      action\n      terminated\n      reward\n    \n  \n  \n    \n      0\n      [tensor(-0.0313), tensor(0.0204), tensor(-0.0340), tensor(-0.0372)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      1\n      [tensor(-0.0237), tensor(-0.0383), tensor(-0.0466), tensor(0.0060)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      2\n      [tensor(-0.0127), tensor(-0.0256), tensor(-0.0099), tensor(-0.0028)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      3\n      [tensor(-0.0309), tensor(0.2160), tensor(-0.0347), tensor(-0.3404)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      4\n      [tensor(-0.0245), tensor(0.1574), tensor(-0.0465), tensor(-0.3010)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      5\n      [tensor(-0.0132), tensor(-0.2206), tensor(-0.0100), tensor(0.2867)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      6\n      [tensor(-0.0266), tensor(0.0214), tensor(-0.0415), tensor(-0.0589)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      7\n      [tensor(-0.0213), tensor(-0.0370), tensor(-0.0525), tensor(-0.0234)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      8\n      [tensor(-0.0176), tensor(-0.4156), tensor(-0.0043), tensor(0.5762)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      9\n      [tensor(-0.0262), tensor(-0.1731), tensor(-0.0427), tensor(0.2204)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      10\n      [tensor(-0.0221), tensor(-0.2314), tensor(-0.0530), tensor(0.2523)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      11\n      [tensor(-0.0260), tensor(-0.6106), tensor(0.0073), tensor(0.8676)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      12\n      [tensor(-0.0296), tensor(-0.3676), tensor(-0.0383), tensor(0.4993)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      13\n      [tensor(-0.0267), tensor(-0.0355), tensor(-0.0479), tensor(-0.0566)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      14\n      [tensor(-0.0382), tensor(-0.8058), tensor(0.0246), tensor(1.1625)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      15\n      [tensor(-0.0370), tensor(-0.5622), tensor(-0.0283), tensor(0.7797)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      16\n      [tensor(-0.0274), tensor(-0.2299), tensor(-0.0491), tensor(0.2205)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      17\n      [tensor(-0.0543), tensor(-0.6111), tensor(0.0479), tensor(0.8777)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      18\n      [tensor(-0.0482), tensor(-0.7569), tensor(-0.0127), tensor(1.0633)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      19\n      [tensor(-0.0320), tensor(-0.4243), tensor(-0.0447), tensor(0.4973)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      20\n      [tensor(-0.0665), tensor(-0.8068), tensor(0.0654), tensor(1.1850)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      21\n      [tensor(-0.0634), tensor(-0.5616), tensor(0.0086), tensor(0.7667)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      22\n      [tensor(-0.0405), tensor(-0.2286), tensor(-0.0347), tensor(0.1909)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      23\n      [tensor(-0.0826), tensor(-1.0027), tensor(0.0891), tensor(1.4975)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      24\n      [tensor(-0.0746), tensor(-0.3666), tensor(0.0239), tensor(0.4767)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      25\n      [tensor(-0.0451), tensor(-0.0330), tensor(-0.0309), tensor(-0.1125)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      26\n      [tensor(-0.1027), tensor(-0.8088), tensor(0.1191), tensor(1.2339)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      27\n      [tensor(-0.0819), tensor(-0.1718), tensor(0.0334), tensor(0.1917)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      28\n      [tensor(-0.0457), tensor(0.1626), tensor(-0.0332), tensor(-0.4148)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      29\n      [tensor(-0.1189), tensor(-1.0052), tensor(0.1438), tensor(1.5614)]\n      tensor(0.)\n      tensor(True)\n      tensor(1.9900)\n    \n    \n      30\n      [tensor(-0.1390), tensor(-1.2017), tensor(0.1750), tensor(1.8952)]\n      tensor(1.)\n      tensor(True)\n      tensor(1.)\n    \n    \n      31\n      [tensor(-0.0854), tensor(0.0228), tensor(0.0373), tensor(-0.0903)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      32\n      [tensor(-0.0425), tensor(-0.0321), tensor(-0.0415), tensor(-0.1327)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      33\n      [tensor(-0.0849), tensor(0.2174), tensor(0.0355), tensor(-0.3710)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      34\n      [tensor(-0.0431), tensor(-0.2266), tensor(-0.0441), tensor(0.1466)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      35\n      [tensor(0.0108), tensor(0.0430), tensor(-0.0169), tensor(-0.0207)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      36\n      [tensor(-0.0806), tensor(0.0218), tensor(0.0280), tensor(-0.0674)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      37\n      [tensor(-0.0477), tensor(-0.4210), tensor(-0.0412), tensor(0.4250)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      38\n      [tensor(0.0116), tensor(0.2383), tensor(-0.0174), tensor(-0.3187)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      39\n      [tensor(-0.0801), tensor(0.2165), tensor(0.0267), tensor(-0.3511)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      40\n      [tensor(-0.0561), tensor(-0.2254), tensor(-0.0327), tensor(0.1197)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      41\n      [tensor(0.0164), tensor(0.0435), tensor(-0.0237), tensor(-0.0315)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      42\n      [tensor(-0.0758), tensor(0.0210), tensor(0.0197), tensor(-0.0501)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      43\n      [tensor(-0.0606), tensor(-0.4200), tensor(-0.0303), tensor(0.4019)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      44\n      [tensor(0.0173), tensor(0.2389), tensor(-0.0244), tensor(-0.3316)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      45\n      [tensor(-0.0754), tensor(-0.1744), tensor(0.0187), tensor(0.2487)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      46\n      [tensor(-0.0690), tensor(-0.2245), tensor(-0.0222), tensor(0.0998)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      47\n      [tensor(0.0220), tensor(0.0442), tensor(-0.0310), tensor(-0.0467)]\n      tensor(0.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      48\n      [tensor(-0.0789), tensor(-0.3698), tensor(0.0236), tensor(0.5472)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)\n    \n    \n      49\n      [tensor(-0.0735), tensor(-0.4193), tensor(-0.0202), tensor(0.3854)]\n      tensor(1.)\n      tensor(False)\n      tensor(1.9900)"
  },
  {
    "objectID": "03_Environment/envs.gym.html#multi-processing",
    "href": "03_Environment/envs.gym.html#multi-processing",
    "title": "Envs Gym",
    "section": "Multi Processing",
    "text": "Multi Processing\n\nimport torch\nimport torchdata.datapipes as dp\nfrom torch.utils.data.dataloader_experimental import DataLoader2\n       \nclass PointlessLoop(dp.iter.IterDataPipe):\n    def __init__(self,datapipe=None):\n        self.datapipe = datapipe\n    \n    def __iter__(self):\n        while True:\n            yield torch.LongTensor(4).detach().clone()\n            \n\nif __name__=='__main__':\n    from torch.multiprocessing import Pool, Process, set_start_method\n    try:\n         set_start_method('spawn')\n    except RuntimeError:\n        pass\n\n\n    pipe = PointlessLoop()\n    pipe = pipe.header(limit=10)\n    dls = [DataLoader2(pipe,num_workers=1)]\n    # Setup the Learner\n    print('type: ',type(dls[0]))\n    for o in dls[0]:\n        print(o)\n\nOverwriting ../external_run_scripts/spawn_multiproc.py\n\n\n\npass\n\ntype:  <class 'torch.utils.data.dataloader.DataLoader'>\ntensor([[139884568362288,  94350800652960, 139882444517456,   5896925594232]])\ntensor([[     139884568362656,       94350809486752, -2738188573198908631,\n          6879089491455928577]])\ntensor([[139882428343472, 139882428343504, 139882428343536, 139882428343568]])\ntensor([[139884568362144, 139884568362144,               0,               0]])\ntensor([[139884568362144, 139884568362144,               0,               0]])\ntensor([[    139884568362144,     139884568362144, 7575175955194277983,\n          737013014016696435]])\ntensor([[    139884568362304,     139884568362304, 8297992743086744941,\n         7022364571614997605]])\ntensor([[8247626271654158368, 7954879166212546670, 7957695015157983604,\n         2318341632102134867]])\ntensor([[             0,              0, 94350811801232, 94350790702720]])\ntensor([[1, 4, 0, 0]])"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "fastrl",
    "section": "Install",
    "text": "Install"
  },
  {
    "objectID": "index.html#pypi",
    "href": "index.html#pypi",
    "title": "fastrl",
    "section": "PyPI",
    "text": "PyPI\nBelow will install the alpha build of fastrl.\nCuda Install\npip install fastrl==0.0.* --pre --extra-index-url https://download.pytorch.org/whl/nightly/cu113\nCpu Install\npip install fastrl==0.0.* --pre --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
  },
  {
    "objectID": "index.html#docker-highly-recommend",
    "href": "index.html#docker-highly-recommend",
    "title": "fastrl",
    "section": "Docker (highly recommend)",
    "text": "Docker (highly recommend)\nInstall: Nvidia-Docker\nInstall: docker-compose\ndocker-compose pull && docker-compose up"
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "fastrl",
    "section": "Contributing",
    "text": "Contributing\nAfter you clone this repository, please run nbdev_install_hooks in your terminal. This sets up git hooks, which clean up the notebooks to remove the extraneous stuff stored in the notebooks (e.g. which cells you ran) which causes unnecessary merge conflicts.\nBefore submitting a PR, check that the local library and notebooks match. The script nbdev_clean can let you know if there is a difference between the local library and the notebooks. * If you made a change to the notebooks in one of the exported cells, you can export it to the library with nbdev_build_lib or make fastai2. * If you made a change to the library, you can export it back to the notebooks with nbdev_update_lib."
  },
  {
    "objectID": "nbdev_extension.html",
    "href": "nbdev_extension.html",
    "title": "Nbdev Extensions",
    "section": "",
    "text": "dependencies\n\n dependencies (dev:bool=False, cfg_name='settings.ini')\n\nGets a list of dependencies in a cfg_name for conda compatability.\n\ntest_eq(dependencies(cfg_name='test_settings.ini'),\n        ['python=3.6', 'pip', 'setuptools', 'fastai>=2.0.0', 'moviepy', \n         'jupyter', 'notebook', 'setuptools', \n         {'pip': ['pytest', 'nvidia-ml-py3', 'dataclasses', 'pandas', 'pyyaml']}])\ntest_eq(dependencies(dev=True,cfg_name='test_settings.ini'),\n        ['python=3.6', 'pip', 'setuptools', 'fastai>=2.0.0', 'moviepy', 'jupyter', \n         'notebook', 'setuptools', 'jupyterlab', 'nbdev', 'ipywidgets', 'moviepy', \n         'pygifsicle', 'aquirdturtle_collapsible_headings', \n         {'pip': ['pytest', 'nvidia-ml-py3', 'dataclasses', 'pandas', 'pyyaml']}])\n\n\n\n\ncreate_conda_yaml\n\n create_conda_yaml (channels:str='conda-forge,pytorch,fastai',\n                    cfg_name='settings.ini', dev:bool=False)\n\nCreates a conda dictionary of the format of an env file.\n\ntest_eq(create_conda_yaml(cfg_name='test_settings.ini'),\n       {'name': 'fastrl_test', 'channels': ['conda-forge', 'pytorch', 'fastai'], \n        'dependencies': ['python=3.6', 'pip', 'setuptools', 'fastai>=2.0.0', \n                         'moviepy', 'jupyter', 'notebook', 'setuptools', \n                         {'pip': ['pytest', 'nvidia-ml-py3', 'dataclasses', 'pandas', 'pyyaml']}]})\ntest_eq(create_conda_yaml(cfg_name='test_settings.ini',dev=True),\n       {'name': 'fastrl_test_dev', 'channels': ['conda-forge', 'pytorch', 'fastai'], \n        'dependencies': ['python=3.6', 'pip', 'setuptools', 'fastai>=2.0.0', \n                         'moviepy', 'jupyter', 'notebook', 'setuptools', 'jupyterlab', \n                         'nbdev', 'ipywidgets', 'moviepy', 'pygifsicle', 'aquirdturtle_collapsible_headings', \n                         {'pip': ['pytest', 'nvidia-ml-py3', 'dataclasses', 'pandas', 'pyyaml']}]})\n\n\n\n\ncreate_conda_yamls\n\n create_conda_yamls (also_dev:bool=True, cfg_name='settings.ini',\n                     sub_dir='')\n\nCreates conda env for normal and development environments.\n\ncreate_conda_yamls(cfg_name='test_settings.ini',sub_dir='testing')\n\n\n\n\nObject `testing/fastrl_test_env.yaml` not found.\n\n\n\nchannels:\n- conda-forge\n- pytorch\n- fastai\ndependencies:\n- python=3.6\n- pip\n- setuptools\n- fastai>=2.0.0\n- moviepy\n- jupyter\n- notebook\n- setuptools\n- pip:\n  - pytest\n  - nvidia-ml-py3\n  - dataclasses\n  - pandas\n  - pyyaml\nname: fastrl_test\n\n\n\n\n\ncreate_conda_yamls(sub_dir='extra')\n\n\nrm test_settings.ini"
  },
  {
    "objectID": "04_Memory/memory.experience_replay.html",
    "href": "04_Memory/memory.experience_replay.html",
    "title": "Experience Replay",
    "section": "",
    "text": "ExperienceReplay\n\n ExperienceReplay (*args, **kwds)\n\nSimplest form of memory. Takes steps from source_datapipe to stores them in memory. It outputs bs steps.\nlets generate some batches to test with…\n\nfrom fastrl.pipes.core import *\nfrom fastrl.data.block import *\nfrom fastrl.envs.gym import *\n\n\ndef baseline_test(envs,total_steps,seed=0):\n    pipe = GymTransformBlock(None,n=total_steps,seed=seed)(envs)\n    pipe = pipe.unbatch()\n    return list(pipe), pipe\n\n@delegates(ExperienceReplay)\ndef exp_replay_test(envs,total_steps,seed=0,**kwargs):\n    pipe = GymTransformBlock(None,n=total_steps,seed=seed)(envs)\n    pipe = pipe.unbatch()\n    pipe = ExperienceReplay(pipe,**kwargs)\n    if total_steps is None: return None,pipe\n    return list(pipe), pipe\n\n\nsteps, experience_replay = exp_replay_test(['CartPole-v1'],0,bs=1)\ntest_eq(len(experience_replay),0)\n\nwhat if we fill up ER? Lets add the batches, this process will happen inplace…\n\nsteps, experience_replay = exp_replay_test(['CartPole-v1'],10,max_sz=20)\ntest_eq(experience_replay._sz_tracker,10)\ntest_eq(experience_replay._idx_tracker,10)\ntest_eq(experience_replay._cycle_tracker,0)\ntest_len(experience_replay,10)\n\nIf we run 10 more times, the total size should be 20…\n\nsteps = [step for step,_ in zip(*(range(10),experience_replay))]\ntest_eq(experience_replay._sz_tracker,20)\ntest_eq(experience_replay._idx_tracker,20)\ntest_eq(experience_replay._cycle_tracker,0)\ntest_len(experience_replay,20)\n\nexperience_replay memory should contain identical steps to if we just run without it…\n\nsteps, pipe = baseline_test(['CartPole-v1'],20,seed=0)\n_, experience_replay = exp_replay_test(['CartPole-v1'],20,max_sz=20)\n\nfor i,(baseline_step,memory_step) in enumerate(zip(steps,experience_replay.memory)):\n    test_eq(baseline_step.state,memory_step.state)\n    test_eq(baseline_step.next_state,memory_step.next_state)\n    print('Step ',i)\n\nStep  0\nStep  1\nStep  2\nStep  3\nStep  4\nStep  5\nStep  6\nStep  7\nStep  8\nStep  9\nStep  10\nStep  11\nStep  12\nStep  13\nStep  14\nStep  15\nStep  16\nStep  17\nStep  18\nStep  19\n\n\nSince the max_sz is 20, and so far we have run a total of 20 steps, if we run another 10 steps, the _cycle_tracker should be 1 (since this is a new cycle),_idx_tracker should be 10 since it should have reset and stopped half way in the memory. The _sz_tracker should still be 20.\n\n_, experience_replay = exp_replay_test(['CartPole-v1'],None,max_sz=20)\nlist(experience_replay.header(19))\n\nsteps = [step for step,_ in zip(*(range(10),experience_replay))]\ntest_eq(experience_replay._sz_tracker,20)\ntest_eq(experience_replay._idx_tracker,10)\ntest_eq(experience_replay._cycle_tracker,1)\ntest_len(experience_replay,20)\n\n…and if we run the baseline, the last 10 steps in the baseline, should match the first 10 steps in memory since it is in the middle of re-writing the memory due to being at max size.\n\nsteps, pipe = baseline_test(['CartPole-v1'],30)\n\nfor baseline_step,memory_step in zip(steps[20:],experience_replay.memory[:10]):\n    test_eq(baseline_step.state,memory_step.state)\n    test_eq(baseline_step.next_state,memory_step.next_state)\n\nFinally we want to finish writing over the memory in its entirety.\n\nsteps = [step for step,_ in zip(*(range(10),experience_replay))]\ntest_eq(experience_replay._sz_tracker,20)\ntest_eq(experience_replay._idx_tracker,20)\ntest_eq(experience_replay._cycle_tracker,1)\ntest_len(experience_replay,20)\n\n\nsteps, pipe = baseline_test(['CartPole-v1'],40)\n\nfor baseline_step,memory_step in zip(steps[20:],experience_replay.memory):\n    test_eq(baseline_step.state,memory_step.state)\n    test_eq(baseline_step.next_state,memory_step.next_state)\n\nLet’s verify that the steps are what we expect…\nWhat if we sample the experience?\n\nsteps, experience_replay = exp_replay_test(['CartPole-v1'],1000,bs=300,max_sz=1000)\nmemory = None\nfor i,sample in enumerate(experience_replay):\n    for s in sample:\n        if memory is not None: test_ne(s,memory)\n        memory = copy(s)\n    if i>100:break\n\nWe should be able to sample enough times that we have sampled everything. So we test this by sampling, check if that sample has been seen before, and then record that.\n\nsteps, experience_replay = exp_replay_test(['CartPole-v1'],1000,bs=1,max_sz=30,return_idxs=True)\nmemory_hits = [False]*30\nfor i in range(150):\n    res,idxs = experience_replay.sample()\n    for idx in idxs: memory_hits[idx] = True\ntest_eq(all(memory_hits),True)"
  },
  {
    "objectID": "02_DataLoading/data.dataloader2.html",
    "href": "02_DataLoading/data.dataloader2.html",
    "title": "DataLoader2",
    "section": "",
    "text": "SpawnProcessForDataPipeline\n\n SpawnProcessForDataPipeline (multiprocessing_ctx, datapipe,\n                              call_locally_fn=None, protocol_type=None,\n                              pipe_type=None)\n\n\n\n\nDataPipeToQueuesLoop\n\n DataPipeToQueuesLoop (source_datapipe, req_queue, res_queue,\n                       call_locally_fn=None, protocol_type=None,\n                       pipe_type=None)\n\n\n\n\nGetInputItemRequest\n\n GetInputItemRequest (key, value)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\nGetInputItemResponse\n\n GetInputItemResponse (value)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\nInputItemIterDataPipeQueueProtocolServer\n\n InputItemIterDataPipeQueueProtocolServer (request_queue, response_queue)\n\nProtocolServer takes charge of getting requests from req_queue and fetching data from source datapipe.\n\n\n\nInputItemIterDataPipeQueueProtocolClient\n\n InputItemIterDataPipeQueueProtocolClient (request_queue, response_queue)\n\nProtocolClient takes charge of putting requests into req_queue and returning results from res_queue.\n\n\n\nAgentLoggerMerger\n\n AgentLoggerMerger (*args, **kwds)\n\nInserts values from input_jests into the current pipeline.\n\n\n\nPrototypeMultiProcessingReadingService\n\n PrototypeMultiProcessingReadingService (num_workers:int=0,\n                                         multiprocessing_context=None,\n                                         protocol_client_type=None,\n                                         protocol_server_type=None,\n                                         pipe_type=None, eventloop=None)\n\nHelper class that provides a standard way to create an ABC using inheritance.\n\n\n\nInputInjester\n\n InputInjester (*args, **kwds)\n\nInserts values from input_jests into the current pipeline.\n\n\n\nitem_input_pipe_type\n\n item_input_pipe_type ()\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\nDataPipeBehindQueues\n\n DataPipeBehindQueues (source_datapipe, protocol, full_stop=False,\n                       blocking_request_get=False)\n\nIndefinitely iterates over req_queue and passing values from source_datapipe to res_queue If raise_stop is true, raises exception when StopIteration received from the source_datapipe\n\nreading_service=PrototypeMultiProcessingReadingService(\n    num_workers = 1,\n    protocol_client_type = InputItemIterDataPipeQueueProtocolClient,\n    protocol_server_type = InputItemIterDataPipeQueueProtocolServer,\n    pipe_type = item_input_pipe_type,\n    eventloop = SpawnProcessForDataPipeline\n)"
  },
  {
    "objectID": "02_DataLoading/data.block.html",
    "href": "02_DataLoading/data.block.html",
    "title": "Data Block",
    "section": "",
    "text": "Loosely similar to the fastai==2.* TransformBlock, only this time, just like the fastrl Agent and Learner, is simply a DataPipe construction function with augmentation capabilities.\n\n\nDataPipeOrDataLoader = Union[DataPipe,DataLoader2]\nclass TransformBlock(Callable[[Union[Iterable,DataPipe]],DataPipeOrDataLoader]):...\n\n\n\n\n\n TransformBlock (*args, **kwds)\n\nAbstract base class for generic types.\nA generic type is typically declared by inheriting from this class parameterized with one or more type variables. For example, a generic mapping type might be defined as::\nclass Mapping(Generic[KT, VT]): def getitem(self, key: KT) -> VT: … # Etc.\nThis class can then be used as follows::\ndef lookup_name(mapping: Mapping[KT, VT], key: KT, default: VT) -> VT: try: return mapping[key] except KeyError: return default\nDataBlock as defined below expects single or tuples of TransformBlock callables. These functions need to have the above signatures.\nNote that a TransformBlock must take params source and as_dataloader at minimum. Additional params are up to the developer / user.\nThe simplest example would be:\n\ndef add(a,b): return a+b \ndef str_cast(a): return str(a)\nclass TestTransformBlock():\n\n    def __init__(self,\n        # Pipeline Parameters\n        a:int=1,\n        b:str='_test',\n        # Additional pipelines to insert, replace, remove\n        dp_augmentation_fns:Tuple[DataPipeAugmentationFn]=None\n    ) -> None:\n        \"This class returns a pipeline builder that either will return a DataPipe or a DataLoader\"\n        store_attr()\n\n    def __call__(\n        self,\n        # `source` likely will be an iterable that gets pushed into the pipeline when an \n        # experiment is actually being run.\n        source:Any,\n        # Any parameters needed for the dataloader\n        num_workers:int=0,\n        # This param must exist: as_dataloader for the datablock to create dataloaders\n        as_dataloader:bool=False\n    ) -> DataPipeOrDataLoader:\n        \"This is the function that is actually run by `DataBlock`\"\n        # This is where the template pipeline gets outlined. Notice that we\n        # are feeding source into the pipeline.\n        pipe = dp.iter.IterableWrapper(source) # In this example, probably a list of numbers\n        pipe = pipe.map(partial(add,b=self.a))          # Add `a` to them\n        pipe = pipe.map(str_cast)       # Convert the numbers to str\n        pipe = pipe.map(partial(add,b=self.b))          # Concat `b` into the str\n        # Once the base pipeline is constructed, we give the user the opportinuty to augment the \n        # pipeline however they like.\n        pipe = apply_dp_augmentation_fns(pipe,ifnone(self.dp_augmentation_fns,()))\n        # The transform block must be able to return a `DataLoader2` instance\n        if as_dataloader:\n            pipe = DataLoader2(\n                datapipe=pipe,\n                reading_service=PrototypeMultiProcessingReadingService(\n                    num_workers = num_workers,\n                    protocol_client_type = InputItemIterDataPipeQueueProtocolClient,\n                    protocol_server_type = InputItemIterDataPipeQueueProtocolServer,\n                    pipe_type = item_input_pipe_type,\n                    eventloop = SpawnProcessForDataPipeline\n                ) if num_workers>0 else None\n            )\n        return pipe \n    # return _TestTransformBlock\n\nCheck that we can return a DataPipe and that an iteration through it is what we expect…\n\ntfm_block = TestTransformBlock()\npipe = tfm_block([1,2,3])\ntest_eq(type(pipe),dp.iter.Mapper)\ntest_eq(list(pipe),['2_test', '3_test', '4_test'])\n\nCheck that we can return a DataLoader2 and that an iteration through it is what we expect…\n\ntfm_block = TestTransformBlock()\npipe = tfm_block([1,2,3],as_dataloader=True)\ntest_eq(type(pipe),DataLoader2)\ntest_eq(list(pipe),['2_test', '3_test', '4_test'])\n\n\n\n\n\n\n validate_transform_block (block:__main__.TransformBlock)\n\n\n\n\n\nCommon base class for all non-exit exceptions.\nCheck that TestTransformBlock is infact valid…\n\nvalidate_transform_block(tfm_block)\n\nAnd check that invalid TransformBlocks get caught…\n\ndef invalid_transform_block():\n    def _invalid_transform_block():pass\n    return _invalid_transform_block\n\ninvalid_tfm_block = invalid_transform_block()\nwith ExceptionExpected(InvalidTransformBlock):\n    try: validate_transform_block(invalid_tfm_block)\n    except InvalidTransformBlock as e:\n        print(str(e))\n        raise\n\nChecked <function invalid_transform_block.<locals>._invalid_transform_block>:\nGiven kwargs: {}\nGiven return: <class 'inspect._empty'>\n`source:Any` is missing from the arguments\n`as_dataloader:bool=False` is missing from the arguments\n`DataPipeOrDataLoader` missing from return signature\n\n\n\n\n\n\n\n DataPipeWrapperTransformBlock (dp_cls:Union[torch.utils.data.datapipes.da\n                                tapipe.IterDataPipe,torch.utils.data.datap\n                                ipes.datapipe.MapDataPipe], **dp_kwargs)\n\nUsed by DataBlock to support converting DataPipes to TransformBlocks on the fly.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndp_cls\ntyping.Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe]\nThe DataPipe to wrap into a TransformBlock,\n\n\ndp_kwargs\n\n\n\n\nReturns\nNone\n\n\n\n\nCheck that we can return a DataPipe and that an iteration through it is what we expect…\n\ntfm_block = TestTransformBlock()\npipe = tfm_block([1,2,3])\ntest_eq(type(pipe),dp.iter.Mapper)\ntest_eq(list(pipe),['2_test', '3_test', '4_test'])\n\nCheck that we can return a DataLoader2 and that an iteration through it is what we expect…\n\n\n\n\n\n DataBlock (*blocks:Tuple[Union[Tuple[__main__.TransformBlock],__main__.Tr\n            ansformBlock]], debug:bool=False)\n\nDataBlock is a single object for constructing datapipes and dataloaders from blocks. Below are examples on how blocks eventually get converted to dataloaders.\nExample 1: Simplest blocks = ( TestTransformBlock, TestTransformBlock ) -> ( DataLoader2(TestTransformBlock(as_dataloader=True)), DataLoader2(TestTransformBlock(as_dataloader=True)) )\nExample 2: Nested Blocks blocks = ( (TestTransformBlock,TestTransformBlock2), TestTransformBlock ) -> ( DataLoader2(TestTransformBlock -> TestTransformBlock2(as_dataloader=True)), DataLoader2(TestTransformBlock) )\nIn example 2, we can nest the blocks, thus chaining them together. The last one in the chain is used to create the dataloader that is required.\nIn the below example we want 2 dataloaders, so we the len(blocks) will be 2. However, for the second dataloader we want to change the output, and also cycle twice. We can easily do this by using a tuple instead of a single TestTransformBlock.\n\nblock = DataBlock(\n    TestTransformBlock(),\n    (TestTransformBlock(b='_test2'),DataPipeWrapperTransformBlock(dp.iter.Cycler,count=2)),\n    debug=True\n)\n\nInterpreting `blocks` input as ['datapipe', 'datapipe_group'], resulting in 2 dataloaders\n\n\nThe resulting datapipes are in the format that we expect…\n\npipes = block.datapipes([1,2,3])\ntraverse(pipes[0])\ntest_eq(type(pipes[0]),dp.iter.Mapper)\ntest_eq(list(pipes[0]),['2_test', '3_test', '4_test'])\n# Second pipe has _test2 as a postfix and cycles the dataset twice\ntest_eq(type(pipes[1]),dp.iter.Cycler)\ntest_eq(list(pipes[1]),['2_test2', '3_test2', '4_test2', '2_test2', '3_test2', '4_test2'])\n\nWe can easily do the same for the dataloaders…\n\nfrom shutil import ExecError\n\n\npipes = block.dataloaders([1,2,3])\ntest_eq(type(pipes[0]),DataLoader2)\ntest_eq(list(pipes[0]),['2_test', '3_test', '4_test'])\n# Second pipe has _test2 as a postfix and cycles the dataset twice\ntest_eq(type(pipes[1]),DataLoader2)\ntest_eq(list(pipes[1]),['2_test2', '3_test2', '4_test2', '2_test2', '3_test2', '4_test2'])\nwith ExceptionExpected(TypeError):\n    traverse(dp.iter.IterableWrapper(pipes))\n    print('torchdata dataloaders are not traverseable once started.')\n\n# TODO: Kind of what I was a afraid of for the transform blocks. In reality,\n# I think they should have their inner functions already returned before any\n# pickling happens, so this technically shouldn't be happening.\n# There are other issues with the dataloader itself though that can only be fixed \n# in torch data.\nfor k in pipes[0].__dict__:\n    try:\n        print(k)\n        pickle.dumps(pipes[0].__dict__[k])\n    except Exception as e:\n        print('Got pickle error: ',str(e),' for key ',k)\n\ndatapipe\n_adapted\n_datapipe_iter\nGot pickle error:  can't pickle generator objects  for key  _datapipe_iter\n_reset_iter\ndatapipe_adapter_fns\nreading_service\nreading_service_state\n_terminated\nvalid_iterator_id\n_datapipe_before_reading_service_adapt"
  },
  {
    "objectID": "05_Logging/loggers.core.html",
    "href": "05_Logging/loggers.core.html",
    "title": "Loggers Core",
    "section": "",
    "text": "LoggerBase\n\n LoggerBase (*args, **kwds)\n\nThe LoggerBase class outlines simply the buffer. It works in combo with LogCollector datapipe which will add to the buffer.\nLoggerBase also filters out the log records to as to not disrupt the training pipeline\n\n\n\nLoggerBasePassThrough\n\n LoggerBasePassThrough (*args, **kwds)\n\nAllows for collectors to find LoggerBases early in the pipeline without worrying about accidently iterating the logger bases at the incorrect time/frequency.\nThis is mainly used for collectors to call find_dps easily on the pipeline.\n\nlogger_base = LoggerBase()\n\n\ntraverse(logger_base)\n\n{140510339508112: (LoggerBase, {})}\n\n\n\n\n\nLogCollector\n\n LogCollector (*args, **kwds)\n\nLogCollector specifically manages finding and attaching itself to LoggerBases found earlier in the pipeline.\nNotes:\nUser can init multiple different logger bases if they want\nWe then can manually add Collectors, custom for certain pipes such as for collecting rewards.\n\n\n\nProgressBarLogger\n\n ProgressBarLogger (*args, **kwds)\n\nThe LoggerBase class outlines simply the buffer. It works in combo with LogCollector datapipe which will add to the buffer.\nLoggerBase also filters out the log records to as to not disrupt the training pipeline\n\n\n\nRewardCollector\n\n RewardCollector (*args, **kwds)\n\nLogCollector specifically manages finding and attaching itself to LoggerBases found earlier in the pipeline.\n\n\n\nEpocherCollector\n\n EpocherCollector (*args, **kwds)\n\nTracks the number of epochs that the pipeline is currently on.\n\n\n\nBatchCollector\n\n BatchCollector (*args, **kwds)\n\nTracks the number of batches that the pipeline is currently on.\n\n\n\nEpisodeCollector\n\n EpisodeCollector (*args, **kwds)\n\nCollects the episode_n field from steps.\n\n\n\nRollingTerminatedRewardCollector\n\n RollingTerminatedRewardCollector (*args, **kwds)\n\nCollects the total_reward field from steps if terminated is true and logs a rolling average of size rolling_length.\n\n\n\nTestSync\n\n TestSync (*args, **kwds)\n\nTests getting values from data loader requests.\n\nfrom torchdata.dataloader2.dataloader2 import DataLoader2\nfrom fastrl.data.dataloader2 import *\nimport pandas as pd\nfrom fastrl.envs.gym import *\nfrom fastrl.pipes.map.transforms import *\n\n\nenvs = ['CartPole-v1']*10\n\nlogger_base = ProgressBarLogger(batch_on_pipe=BatchCollector,epoch_on_pipe=EpocherCollector)\n\npipe = dp.map.Mapper(envs)\npipe = TypeTransformer(pipe,[GymTypeTransform])\npipe = dp.iter.MapToIterConverter(pipe)\npipe = LoggerBasePassThrough(pipe,[logger_base])\npipe = dp.iter.InMemoryCacheHolder(pipe)\npipe = pipe.cycle()\npipe = GymStepper(pipe,synchronized_reset=True)\npipe = RewardCollector(pipe)\npipe = InputInjester(pipe)\npipe = TestSync(pipe)\npipe = pipe.header(limit=10)\n\n\npipe = BatchCollector(pipe,batch_on_pipe=dp.iter.Header)\npipe = EpocherCollector(pipe,epochs=5)\npipe = logger_base.connect_source_datapipe(pipe)\n# Turn off the seed so that some envs end before others...\nsteps = list(pipe)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      batch\n      reward\n    \n  \n  \n    \n      1\n      10\n      1.0\n    \n    \n      2\n      10\n      1.0\n    \n    \n      3\n      10\n      1.0\n    \n    \n      4\n      10\n      1.0\n    \n    \n      4\n      10\n      1.0\n    \n  \n\n\n\n\ndl = DataLoader2(\n    pipe,\n    reading_service=PrototypeMultiProcessingReadingService(\n        num_workers = 1,\n        protocol_client_type = InputItemIterDataPipeQueueProtocolClient,\n        protocol_server_type = InputItemIterDataPipeQueueProtocolServer,\n        pipe_type = item_input_pipe_type,\n        eventloop = SpawnProcessForDataPipeline\n    )\n)\n\n# dl = logger_base.connect_source_datapipe(dl)\n\n\n\n\nActionPublish\n\n ActionPublish (*args, **kwds)\n\nPublishes an action augmentation to the dataloader.\n\n\n\nCacheLoggerBase\n\n CacheLoggerBase (*args, **kwds)\n\nShort lived logger base meant to dump logs"
  },
  {
    "objectID": "05_Logging/loggers.vscode_visualizers.html",
    "href": "05_Logging/loggers.vscode_visualizers.html",
    "title": "Visualizers - VS-Code",
    "section": "",
    "text": "SimpleVSCodeVideoPlayer\n\n SimpleVSCodeVideoPlayer (*args, **kwds)\n\nDisplays video from a source_datapipe that produces typing.NamedTuples that contain an image field. This only can handle 1 env input.\n\n\n\nVSCodeTransformBlock\n\n VSCodeTransformBlock (dp_augmentation_fns:Tuple[fastrl.pipes.core.DataPip\n                       eAugmentationFn]=None)\n\nBasic OpenAi gym DataPipeGraph with first-last, nstep, and nskip capability\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndp_augmentation_fns\ntyping.Tuple[fastrl.pipes.core.DataPipeAugmentationFn]\nNone\nAdditional pipelines to insert, replace, remove\n\n\nReturns\nNone\n\n\n\n\n\n\nimport pandas as pd\nfrom fastrl.pipes.core import *\nfrom fastrl.pipes.map.transforms import *\nfrom fastrl.envs.gym import GymTypeTransform,GymStepper,GymTransformBlock"
  },
  {
    "objectID": "05_Logging/loggers.jupyter_visualizers.html",
    "href": "05_Logging/loggers.jupyter_visualizers.html",
    "title": "Visualizers",
    "section": "",
    "text": "SimpleJupyterVideoPlayer\n\n SimpleJupyterVideoPlayer (*args, **kwds)\n\nDisplays video from a source_datapipe that produces typing.NamedTuples that contain an image field. This only can handle 1 env input.\n\n\n\nImageCollector\n\n ImageCollector (*args, **kwds)\n\nLogCollector specifically manages finding and attaching itself to LoggerBases found earlier in the pipeline.\n\nimport pandas as pd\nfrom fastrl.pipes.core import *\nfrom fastrl.pipes.map.transforms import *\nfrom fastrl.envs.gym import GymTypeTransform,GymStepper,GymTransformBlock\n\n\nvideo_logger = SimpleJupyterVideoPlayer()\npipe = GymTransformBlock(None,n=100,seed=0,include_images=True)(['CartPole-v1'])\npipe = LoggerBasePassThrough(pipe,[video_logger])\npipe = ImageCollector(pipe)\n\npipe = video_logger.connect_source_datapipe(pipe)\n\nL(pipe);"
  },
  {
    "objectID": "05_Logging/loggers.tensorboard.html",
    "href": "05_Logging/loggers.tensorboard.html",
    "title": "Tensorboard",
    "section": "",
    "text": "run_tensorboard\n\n run_tensorboard (port:int=6006, start_tag:str=None,\n                  samples_per_plugin:str=None, extra_args:str=None,\n                  rm_glob:bool=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nport\nint\n6006\nThe port to run tensorboard on/connect on\n\n\nstart_tag\nstr\nNone\nStarting regex e.g.: experience_replay/1\n\n\nsamples_per_plugin\nstr\nNone\nSampling freq such as images=0 (keep all)\n\n\nextra_args\nstr\nNone\nAny additional arguments in the --arg value format\n\n\nrm_glob\nbool\nNone\nRemove old logs via a parttern e.g.: ’’ will remove all files: runs/"
  },
  {
    "objectID": "test_utils.html",
    "href": "test_utils.html",
    "title": "Synth Agent",
    "section": "",
    "text": "Tools for testing fastrl. fastai has a module with the same name.\n\n\n\n\n\n get_env (name)\n\nReturn env var value if it’s defined and not an empty string, or return Unknown\n\n\n\n\n\n try_import (module)\n\nTry to import module. Returns module’s object on success, None on failure\n\n\n\n\n\n nvidia_mem ()\n\n\n\n\n\n\n nvidia_smi (cmd='nvidia-smi')\n\n\n\n\n\n\n show_install (show_nvidia_smi:bool=False)\n\nPrint user’s setup information\nThis function is ripped directly from 97_test_utils"
  },
  {
    "objectID": "06_Learning/learner.core.html",
    "href": "06_Learning/learner.core.html",
    "title": "Learner Core",
    "section": "",
    "text": "LearnerBase\n\n LearnerBase (*args, **kwds)\n\nCombines models,dataloaders, and optimizers together for running a training pipeline.\n\n\n\nLearnerHead\n\n LearnerHead (*args, **kwds)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nWarning: Pickling the LearnerBase will exclude the ’_dls’,‘opt’,‘iterable’ fields since these aren’t easily picklable (yet).\n\n\nfrom fastrl.torch_core import *\nfrom fastrl.agents.dqn.basic import *\nfrom fastrl.agents.core import *\nfrom fastrl.agents.discrete import *\nfrom fastrl.data.block import *\nfrom fastrl.envs.gym import *\nfrom fastrl.loggers.vscode_visualizers import *\n\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2)\n# Setup the agent\nagent = AgentBase(model,[])\nagent = StepFieldSelector(agent,field='state')\n# All the things that make this agent unique and special\n# In this instance, all this module does is pass the action directly through to the model.\nagent = SimpleModelRunner(agent)\nagent = ArgMaxer(agent,only_idx=True)\nagent = NumpyConverter(agent)\nagent = PyPrimativeConverter(agent)\n# Bring everything together into the AgentHead where actions will be passed and then run through the pipeline\nagent = AgentHead(agent)\n\n\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False,n=100,bs=1),\n    (GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False,n=100,bs=1,include_images=True),VSCodeTransformBlock())\n)\n\ndls = L(block.dataloaders(['CartPole-v1']*1,num_workers=0))\n\n\ndef TestLearner(model,dls):\n    learner = LearnerBase(model,dls)\n    learner = LearnerHead(learner)\n    return learner\n\n\nlearner = TestLearner(model,dls)\n\n\n\n\nStepBatcher\n\n StepBatcher (*args, **kwds)\n\nConverts multiple StepType into a single StepType with the fields concated."
  },
  {
    "objectID": "08_FAQ/99_notes.multi_proc.html",
    "href": "08_FAQ/99_notes.multi_proc.html",
    "title": "fastrl",
    "section": "",
    "text": "# Python native modules\nimport os\nfrom copy import deepcopy\n# Third party libs\nfrom fastcore.all import *\nimport numpy as np\n# Local modules"
  },
  {
    "objectID": "08_FAQ/99_notes.multi_proc.html#multiprocessing-notes",
    "href": "08_FAQ/99_notes.multi_proc.html#multiprocessing-notes",
    "title": "fastrl",
    "section": "MultiProcessing Notes",
    "text": "MultiProcessing Notes\n\nimport torchdata.datapipes as dp\n\n\nimport torchdata.datapipes as dp\nfrom torch.utils.data import IterableDataset\n\nclass AddABunch1(dp.iter.IterDataPipe):\n    def __init__(self,q):\n        super().__init__()\n        self.q = [q]\n\n    def __iter__(self):\n        for o in range(10): \n            self.q[0].put(o)\n            yield o\n            \nclass AddABunch2(dp.iter.IterDataPipe):\n    def __init__(self,source_datapipe,q):\n        super().__init__()\n        self.q = q\n        print(id(self.q))\n        self.source_datapipe = source_datapipe\n\n    def __iter__(self):\n        for o in self.source_datapipe: \n            print(id(self.q))\n            self.q.put(o)\n            yield o\n            \nclass AddABunch3(IterableDataset):\n    def __init__(self,q):\n        self.q = q\n\n    def __iter__(self):\n        for o in range(10): \n            print(id(self.q))\n            self.q.put(o)\n            yield o\n\nif __name__=='__main__':\n    from torch.multiprocessing import Pool,Process,set_start_method,Manager,get_start_method\n    import torch\n    \n    try: set_start_method('spawn')\n    except RuntimeError: pass\n    # from torch.utils.data.dataloader_experimental import DataLoader2\n    from torchdata.dataloader2 import DataLoader2\n    from torchdata.dataloader2.reading_service import MultiProcessingReadingService\n\n    m = Manager()\n    q = m.Queue()\n    \n    pipe = AddABunch2(list(range(10)),q)\n    print(type(pipe))\n    dl = DataLoader2(pipe,\n        reading_service=MultiProcessingReadingService(num_workers=1)\n    ) # Will fail if num_workers>0\n    \n    # dl = DataLoader2(AddABunch1(q),num_workers=1) # Will fail if num_workers>0\n    # dl = DataLoader2(AddABunch2(q),num_workers=1) # Will fail if num_workers>0\n    # dl = DataLoader2(AddABunch3(q),num_workers=1) # Will succeed if num_workers>0\n    list(dl)\n    \n    while not q.empty():\n        print(q.get())\n\nOverwriting external_run_scripts/notes_multi_proc_82.py\n\n\n\nfrom torch.multiprocessing import Pool,Process,set_start_method,Manager,get_start_method\n\n\nget_start_method()\n\n'fork'"
  },
  {
    "objectID": "08_FAQ/notes.pipe_insertion.html",
    "href": "08_FAQ/notes.pipe_insertion.html",
    "title": "TorchData DataPipe Notes",
    "section": "",
    "text": "Reference: https://github.com/pytorch/data/issues/750\n\nOriginal Graph: A -> B\nExpected New Graph: A -> C -> B\n\nfrom fastrl.pipes.core import *\nimport torchdata.datapipes as dp\n\n\nclass Template(dp.iter.IterDataPipe):\n    def __init__(self,source_datapipe=None): self.source_datapipe = source_datapipe\n    def __iter__(self): return (o for o in self.source_datapipe)\n\nclass A(Template):pass\nclass B(Template):pass\nclass C(Template):pass\nclass D(Template):pass\nclass E(Template):pass\n\nLet’s say that we have a graph: A -> B\n\npipe = A(range(10))\npipe = B(pipe)\n\ntest_eq(list(pipe),range(10))\ntraverse(pipe)\n\n{140342007547536: (B, {140342007547600: (A, {})})}\n\n\nLet’s say that we want a graph: A -> C -> B\n\nnew_dp = replace_dp(\n    traverse(pipe,only_datapipe=True),\n    find_dp(traverse(pipe,only_datapipe=True),A),\n    C(find_dp(traverse(pipe,only_datapipe=True),A))\n)\nnew_dp\n\n{140342007951312: (B, {140342007546576: (C, {140342007950928: (A, {})})})}\n\n\nWe have C to point to A and then we replace A with C\nNow, what if we want a graph A -> C -> D -> E -> B\n\npipe = A(range(10))\npipe = B(pipe)\n\ntest_eq(list(pipe),range(10))\ntraverse(pipe)\n\n{140342007227536: (B, {140342007227600: (A, {})})}\n\n\n\ndef sub_graph(pipe):\n    pipe = C(pipe)\n    pipe = D(pipe)\n    pipe = E(pipe)\n    return pipe\n\n\nnew_dp = replace_dp(\n    traverse(pipe,only_datapipe=True),\n    find_dp(traverse(pipe,only_datapipe=True),A),\n    sub_graph(find_dp(traverse(pipe,only_datapipe=True),A))\n)\nnew_dp\n\n{140342007227536: (B,\n  {140342007247376: (E,\n    {140342007247312: (D,\n      {140342007247120: (C, {140342007227600: (A, {})})})})})}\n\n\n\nlist(list(new_dp.values())[0][0])\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
  },
  {
    "objectID": "08_FAQ/notes.speed.html",
    "href": "08_FAQ/notes.speed.html",
    "title": "Speed",
    "section": "",
    "text": "# Python native modules\nimport os\nfrom copy import deepcopy\n# Third party libs\nfrom fastcore.all import *\nimport numpy as np\n# Local modules"
  },
  {
    "objectID": "08_FAQ/notes.speed.html#numpy-to-tensor-performance",
    "href": "08_FAQ/notes.speed.html#numpy-to-tensor-performance",
    "title": "Speed",
    "section": "Numpy to Tensor Performance",
    "text": "Numpy to Tensor Performance\n\nimg=np.random.randint(0,255,size=(240, 320, 3))\n\n\nimg=np.random.randint(0,255,size=(240, 320, 3))\n\n1.61 ms ± 23.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n\n\n\ndeepcopy(img)\n\n240 µs ± 4.64 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n\n\n\nTensor(img)\n\n79.2 µs ± 3.19 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n\n\n\nTensor([img])\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n  \n\n\n135 ms ± 3.56 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\nYou will notice that if you wrap a numpy in a list, it completely kills the performance. The solution is to just add a batch dim to the existing array and pass it directly.\n\nTensor(np.expand_dims(img,0))\n\n85.6 µs ± 4.48 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n\n\nIn fact we can just test this with python lists…\n\nTensor([[1]])\n\n6.75 µs ± 95.6 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n\n\n\ntest_arr=[[1]*270000]\n\n\nTensor(test_arr)\n\n9.55 ms ± 221 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\ntest_arr=np.array([[1]*270000])\n\n\nTensor(test_arr)\n\n88 µs ± 5.93 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n\n\nThis is horrifying just how made of a performance hit this causes… So we will be avoiding python list inputs to Tensors for now on…"
  },
  {
    "objectID": "08_FAQ/template.html",
    "href": "08_FAQ/template.html",
    "title": "Template",
    "section": "",
    "text": "# #|export\n# Python native modules\nimport os\n# Third party libs\nfrom fastcore.all import *\n# Local modules"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Core",
    "section": "",
    "text": "StepTypes are generated by environments and used by RL models for training / execution.\n\n\n\n\n\n add_namedtuple_doc (t:<class'NamedTuple'>, doc:str, **fields_docs:dict)\n\nAdd docs to t from doc along with individual doc fields fields_docs\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nt\nNamedTuple\nPrimary tuple to get docs from\n\n\ndoc\nstr\nPrimary doc for the overall tuple, where the docs for individual fields will be concated.\n\n\nfields_docs\ndict\n\n\n\n\n\n\n\n\n\n SimpleStep (state:torch.FloatTensor=tensor([0.]),\n             action:torch.FloatTensor=tensor([0.]),\n             next_state:torch.FloatTensor=tensor([0.]),\n             terminated:torch.BoolTensor=tensor([True]),\n             truncated:torch.BoolTensor=tensor([True]),\n             reward:torch.FloatTensor=tensor([0]),\n             total_reward:torch.FloatTensor=tensor([0.]),\n             env_id:torch.LongTensor=tensor([0]),\n             proc_id:torch.LongTensor=tensor([0]),\n             step_n:torch.LongTensor=tensor([0]),\n             episode_n:torch.LongTensor=tensor([0]),\n             image:torch.FloatTensor=tensor([0.]))\n\nRepresents a single step in an environment.\nParameters: - state:<class 'torch.FloatTensor'> = tensor([0.])Both the initial state of the environment and the previous state. - action:<class 'torch.FloatTensor'> = tensor([0.])The action that was taken to transition from state to next_state - next_state:<class 'torch.FloatTensor'> = tensor([0.])Both the next state, and the last state in the environment - terminated:<class 'torch.BoolTensor'> = tensor([True])Represents an ending condition for an environment such as reaching a goal or ‘living long enough’ as described by the MDP. Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155 - truncated:<class 'torch.BoolTensor'> = tensor([True])Represents an ending condition for an environment that can be seen as an out of bounds condition either literally going out of bounds, breaking rules, or exceeding the timelimit allowed by the MDP. Good reference is: https://github.com/openai/gym/blob/39b8661cb09f19cb8c8d2f59b57417517de89cb0/gym/core.py#L151-L155’ - reward:<class 'torch.FloatTensor'> = tensor([0])The single reward for this step. - total_reward:<class 'torch.FloatTensor'> = tensor([0.])The total accumulated reward for this episode up to this step. - env_id:<class 'torch.LongTensor'> = tensor([0])The environment this step came from (useful for debugging) - proc_id:<class 'torch.LongTensor'> = tensor([0])The process this step came from (useful for debugging) - step_n:<class 'torch.LongTensor'> = tensor([0])The step number in a given episode. - episode_n:<class 'torch.LongTensor'> = tensor([0])The episode this environment is currently running through. - image:<class 'torch.FloatTensor'> = tensor([0.])Intended for display and logging only. If the intention is to use images for training an agent, then use a env wrapper instead.\nNow we can generate a couple to send their a pytorch data loader.\n\ntorch.manual_seed(0)\nSimpleStep.random(state=torch.FloatTensor(2).fill_(0))\n\nSimpleStep(state=tensor([0., 0.]), action=tensor([39.]), next_state=tensor([33.]), terminated=tensor([False]), truncated=tensor([True]), reward=tensor([79.]), total_reward=tensor([27.]), env_id=tensor([3]), proc_id=tensor([97]), step_n=tensor([83]), episode_n=tensor([1]), image=tensor([66.]))\n\n\n\nSimpleStep.random(state=torch.FloatTensor(2).fill_(0)).clone()\n\nSimpleStep(state=tensor([0., 0.]), action=tensor([99.]), next_state=tensor([78.]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([68.]), total_reward=tensor([94.]), env_id=tensor([33]), proc_id=tensor([26]), step_n=tensor([19]), episode_n=tensor([91]), image=tensor([54.]))\n\n\n\nfrom torchdata.dataloader2.dataloader2 import DataLoader2\nfrom torchdata.dataloader2.reading_service import MultiProcessingReadingService\nfrom torchdata.dataloader2.graph import traverse\nimport torchdata.datapipes as dp\n\n\ndef seed_worker(worker_id): torch.manual_seed(0)\ndef random_step_generator(): \n    while True: yield SimpleStep.random()\n    \n\npipe = dp.iter.IterableWrapper(random_step_generator(),deepcopy=False)\npipe = pipe.batch(batch_size=3)\n\ng = torch.Generator()\ng.manual_seed(0)\ndl = DataLoader2(\n    pipe,\n    reading_service=MultiProcessingReadingService(num_workers=2,worker_init_fn=seed_worker)\n)\n\nfor o in dl:\n    print(o)\n    break\n\n/opt/conda/lib/python3.7/site-packages/torch/utils/data/datapipes/iter/utils.py:44: UserWarning: The input iterable can not be deepcopied, please be aware of in-place modification would affect source data.\n  \"The input iterable can not be deepcopied, \"\n\n\n[SimpleStep(state=tensor([44.]), action=tensor([39.]), next_state=tensor([33.]), terminated=tensor([False]), truncated=tensor([True]), reward=tensor([79.]), total_reward=tensor([27.]), env_id=tensor([3]), proc_id=tensor([97]), step_n=tensor([83]), episode_n=tensor([1]), image=tensor([66.])), SimpleStep(state=tensor([56.]), action=tensor([99.]), next_state=tensor([78.]), terminated=tensor([False]), truncated=tensor([False]), reward=tensor([68.]), total_reward=tensor([94.]), env_id=tensor([33]), proc_id=tensor([26]), step_n=tensor([19]), episode_n=tensor([91]), image=tensor([54.])), SimpleStep(state=tensor([24.]), action=tensor([41.]), next_state=tensor([69.]), terminated=tensor([True]), truncated=tensor([True]), reward=tensor([80.]), total_reward=tensor([81.]), env_id=tensor([12]), proc_id=tensor([63]), step_n=tensor([60]), episode_n=tensor([95]), image=tensor([85.]))]\n\n\n\n\n\n\n\n Record (name:str, value:Any)"
  },
  {
    "objectID": "core.html#testing",
    "href": "core.html#testing",
    "title": "Core",
    "section": "Testing",
    "text": "Testing\n\nAdditional utilities for testing anything\n\n\n\ntest_in\n\n test_in (a, b)\n\ntest that a in b\n\ntest_in('o','hello')\ntest_in(3,[1,2,3,4])\n\n\n\n\ntest_len\n\n test_len (a, b, meta_info='')\n\ntest that len(a) == int(b) or len(a) == len(b)\n\ntest_len([1,2,3],3)\ntest_len([1,2,3],[1,2,3])\ntest_len([1,2,3],'123')\ntest_fail(lambda:test_len([1,2,3],'1234'))\n\n\n\n\ntest_lt\n\n test_lt (a, b)\n\ntest that a < b\n\ntest_lt(4,5)\ntest_fail(lambda:test_lt(5,4))"
  },
  {
    "objectID": "01_DataPipes/pipes.map.mux.html",
    "href": "01_DataPipes/pipes.map.mux.html",
    "title": "Multiplexer",
    "section": "",
    "text": "MultiplexerMapDataPipe\n\n MultiplexerMapDataPipe (*args, **kwds)\n\nYields one element at a time from each of the input Iterable DataPipes (functional name: mux). As in, one element from the 1st input DataPipe, then one element from the 2nd DataPipe in the next iteration, and so on. It ends when the shortest input DataPipe is exhausted.\nFor example we can have a datapipe a that contains a list of numbers from 0->10, and b that is a map that maps letters to some integers.\ndp_index_map gives instructions for each additional datapipe (b) on the order to querying for values.\nThe result is that the letters a,b, etc get mapped to their respective integers.\n\na = dp.map.SequenceWrapper(range(10))\nb = dp.map.SequenceWrapper({'a': 100, 'b': 200, 'c': 300, 'd': 400})\ndatapipe = a.mux(b, dp_index_map={b: ['a', 'b', 'c', 'd']})\ntest_eq(list(datapipe),[0, 100, 1, 200, 2, 300, 3, 400, 4, 5, 6, 7, 8, 9])\nlist(datapipe)\n\n[0, 100, 1, 200, 2, 300, 3, 400, 4, 5, 6, 7, 8, 9]\n\n\nIn the second example we take a list of numbers 0->12 and split them equally into 3 datapipes…\n\nfrom fastrl.pipes.map.demux import DemultiplexerMapDataPipe\n\n\na = dp.map.SequenceWrapper(range(12))\n\ndef split_three_way(a):\n    return a%3\n\nk1,k2,k3 = a.demux(num_instances=3,classifier_fn=split_three_way)\nfor pipe in (k1,k2,k3): test_eq(len(pipe),4)\nlen(k1),len(k2),len(k3)\n\n(4, 4, 4)\n\n\nWe can then recombine them back into a single datapipe…\n\ncombined_pipes=MultiplexerMapDataPipe(k1,k2,k3)\ntest_eq(list(combined_pipes),range(12))\nlist(combined_pipes)\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
  },
  {
    "objectID": "01_DataPipes/pipes.map.demux.html",
    "href": "01_DataPipes/pipes.map.demux.html",
    "title": "DeMultiplexer",
    "section": "",
    "text": "DemultiplexerMapDataPipe\n\n DemultiplexerMapDataPipe\n                           (datapipe:torch.utils.data.datapipes.datapipe.M\n                           apDataPipe, num_instances:int,\n                           classifier_fn:Callable, drop_none:bool=False,\n                           source_index:Union[Iterable,NoneType]=None)\n\nSplits the input DataPipe into multiple child DataPipes, using the given classification function (functional name: demux). A list of the child DataPipes is returned from this operation.\nFor example we can have a function that splits a map of numbers into even and odd…\n\ndef odd_or_even(n):\n    return n % 2\nsource_dp = dp.map.SequenceWrapper(range(5))\ndp1, dp2 = source_dp.demux(num_instances=2, classifier_fn=odd_or_even)\nlist([dp1[i] for i in range(len(dp1))])\n\n[0, 2, 4]\n\n\n\nNote: The resulting datapipes from DemultiplexerMapDataPipe will be “re-indexed”.\n\n\nlist([dp2[i] for i in range(len(dp2))])\n\n[1, 3]\n\n\nIt can also filter out any element that gets None from the classifier_fn\n\ndef odd_or_even_no_zero(n):\n    return n % 2 if n != 0 else None\n\nsource_dp = dp.map.SequenceWrapper(range(5))\ndp1, dp2 = source_dp.demux(num_instances=2, classifier_fn=odd_or_even_no_zero, drop_none=True)\nlist([dp1[i] for i in range(len(dp1))])\n\n[2, 4]\n\n\n\nlist([dp2[i] for i in range(len(dp2))])\n\n[1, 3]"
  },
  {
    "objectID": "01_DataPipes/pipes.iter.nskip.html",
    "href": "01_DataPipes/pipes.iter.nskip.html",
    "title": "NSkip",
    "section": "",
    "text": "NSkipper\n\n NSkipper (*args, **kwds)\n\nAccepts a source_datapipe or iterable whose next() produces a StepType that skips N steps for individual environments while always producing 1st steps and terminated steps.\nBelow we skip every other step given 3 envs while always keeping the 1st and terminated steps.\n\nimport pandas as pd\nfrom fastrl.envs.gym import GymTypeTransform,GymStepper\nfrom fastrl.pipes.map.transforms import TypeTransformer\n\n\ndef n_skip_test(envs,total_steps,n=1,seed=0):\n    pipe = dp.map.Mapper(envs)\n    pipe = TypeTransformer(pipe,[GymTypeTransform])\n    pipe = dp.iter.MapToIterConverter(pipe)\n    pipe = dp.iter.InMemoryCacheHolder(pipe)\n    pipe = pipe.cycle()\n    pipe = GymStepper(pipe,seed=seed)\n    pipe = NSkipper(pipe,n=n)\n\n    steps = [step for step,_ in zip(*(pipe,range(total_steps)))]\n    return steps\n\nsteps = n_skip_test(['CartPole-v1']*3,200,2,0)\npd.DataFrame(steps)[['state','next_state','env_id','terminated']][:10]\n\n\n\n\n\n  \n    \n      \n      state\n      next_state\n      env_id\n      terminated\n    \n  \n  \n    \n      0\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      tensor(140527143417168)\n      tensor(False)\n    \n    \n      1\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      tensor(140527143418320)\n      tensor(False)\n    \n    \n      2\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      tensor(140527143418960)\n      tensor(False)\n    \n    \n      3\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(140527143417168)\n      tensor(False)\n    \n    \n      4\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(140527143418320)\n      tensor(False)\n    \n    \n      5\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(140527143418960)\n      tensor(False)\n    \n    \n      6\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      [tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]\n      tensor(140527143417168)\n      tensor(False)\n    \n    \n      7\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      [tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]\n      tensor(140527143418320)\n      tensor(False)\n    \n    \n      8\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      [tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]\n      tensor(140527143418960)\n      tensor(False)\n    \n    \n      9\n      [tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]\n      [tensor(0.0463), tensor(-0.0172), tensor(-0.1094), tensor(-0.1771)]\n      tensor(140527143417168)\n      tensor(False)\n    \n  \n\n\n\n\nHere is a simple 1-env result…\n\nsteps = n_skip_test(['CartPole-v1']*1,200,2,0)\npd.DataFrame(steps)[['state','next_state','step_n','terminated']][:10]\n\n\n\n\n\n  \n    \n      \n      state\n      next_state\n      step_n\n      terminated\n    \n  \n  \n    \n      0\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      tensor(1)\n      tensor(False)\n    \n    \n      1\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(2)\n      tensor(False)\n    \n    \n      2\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      [tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]\n      tensor(4)\n      tensor(False)\n    \n    \n      3\n      [tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]\n      [tensor(0.0463), tensor(-0.0172), tensor(-0.1094), tensor(-0.1771)]\n      tensor(6)\n      tensor(False)\n    \n    \n      4\n      [tensor(0.0459), tensor(-0.2106), tensor(-0.1129), tensor(0.0792)]\n      [tensor(0.0417), tensor(-0.4040), tensor(-0.1113), tensor(0.3342)]\n      tensor(8)\n      tensor(False)\n    \n    \n      5\n      [tensor(0.0336), tensor(-0.5973), tensor(-0.1047), tensor(0.5899)]\n      [tensor(0.0217), tensor(-0.4009), tensor(-0.0929), tensor(0.2661)]\n      tensor(10)\n      tensor(False)\n    \n    \n      6\n      [tensor(0.0137), tensor(-0.2046), tensor(-0.0875), tensor(-0.0543)]\n      [tensor(0.0096), tensor(-0.0083), tensor(-0.0886), tensor(-0.3733)]\n      tensor(12)\n      tensor(False)\n    \n    \n      7\n      [tensor(0.0094), tensor(0.1879), tensor(-0.0961), tensor(-0.6926)]\n      [tensor(0.0132), tensor(0.3842), tensor(-0.1099), tensor(-1.0139)]\n      tensor(14)\n      tensor(False)\n    \n    \n      8\n      [tensor(0.0209), tensor(0.5806), tensor(-0.1302), tensor(-1.3390)]\n      [tensor(0.0325), tensor(0.7771), tensor(-0.1570), tensor(-1.6694)]\n      tensor(16)\n      tensor(False)\n    \n    \n      9\n      [tensor(0.0480), tensor(0.9737), tensor(-0.1904), tensor(-2.0066)]\n      [tensor(0.0675), tensor(1.1702), tensor(-0.2305), tensor(-2.3517)]\n      tensor(18)\n      tensor(True)\n    \n  \n\n\n\n\n\n\n\nn_skips_expected\n\n n_skips_expected (default_steps:int, n:int)\n\nProduces the expected number of steps, assuming a fully deterministic episode based on default_steps and n.\nMainly used for testing.\nGiven n=2, given 1 envs, knowing that CartPole-v1 when seed=0 will always run 18 steps, the total steps will be:\n\\[\n18 // n + 1 (1st+last)\n\\]\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndefault_steps\nint\nThe number of steps the episode would run without n_skips\n\n\nn\nint\nThe n-skip value that we are planning to use"
  },
  {
    "objectID": "01_DataPipes/pipes.iter.transforms.html",
    "href": "01_DataPipes/pipes.iter.transforms.html",
    "title": "Item and Batch Transforms",
    "section": "",
    "text": "ItemTransformer\n\n ItemTransformer (*args, **kwds)\n\nConverts item_tfms into a Pipeline that is run over for every iter in source_datapipe\nItemTransformer can be used to do quick augmentations to an existing pipeline by passing simple functions into item_tfms. For example below given an input of 0->10 we add one to each element and then multiply that element by 2…\n\nadd_one = lambda o:o+1\nmultiple_by_two = lambda o:o*2\npipe = ItemTransformer(range(10),[add_one,multiple_by_two])\ntest_eq(list(pipe),[2, 4, 6, 8, 10, 12, 14, 16, 18, 20])\nlist(pipe)\n\n[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n\n\n\n\n\nBatchTransformer\n\n BatchTransformer (*args, **kwds)\n\nConverts batch_tfms into a Pipeline that is run over for every iter in source_datapipe\nBatchTransformer is identical to ItemTransformer but semantically the functions it runs should operate on an entire batch of elements…\n\nadd_one = lambda o:[element+1 for element in o]\nmultiple_by_two = lambda o:[element*2 for element in o]\n\npipe = dp.iter.IterableWrapper(range(10))\npipe = pipe.batch(2)\npipe = BatchTransformer(pipe,[add_one,multiple_by_two])\ntest_eq(list(pipe),[[2, 4], [6, 8], [10, 12], [14, 16], [18, 20]])\nlist(pipe)\n\n[[2, 4], [6, 8], [10, 12], [14, 16], [18, 20]]"
  },
  {
    "objectID": "01_DataPipes/pipes.core.html",
    "href": "01_DataPipes/pipes.core.html",
    "title": "Pipes Core",
    "section": "",
    "text": "find_dps\n\n find_dps (graph:Dict[int,Tuple[Union[torch.utils.data.datapipes.datapipe.\n           IterDataPipe,torch.utils.data.datapipes.datapipe.MapDataPipe],F\n           orwardRef('DataPipeGraph')]], dp_type:Type[Union[torch.utils.da\n           ta.datapipes.datapipe.IterDataPipe,torch.utils.data.datapipes.d\n           atapipe.MapDataPipe]], include_subclasses:bool=False)\n\nGiven the graph of DataPipe generated by traverse function, return DataPipe instances with the provided DataPipe type.\n\n\n\nfind_dp\n\n find_dp (graph:Dict[int,Tuple[Union[torch.utils.data.datapipes.datapipe.I\n          terDataPipe,torch.utils.data.datapipes.datapipe.MapDataPipe],For\n          wardRef('DataPipeGraph')]], dp_type:Type[Union[torch.utils.data.\n          datapipes.datapipe.IterDataPipe,torch.utils.data.datapipes.datap\n          ipe.MapDataPipe]], include_subclasses:bool=False)\n\nReturns a single DataPipe as opposed to find_dps.\nGiven the graph of DataPipe generated by traverse function, return DataPipe instances with the provided DataPipe type.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngraph\ntyping.Dict[int, typing.Tuple[typing.Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe], ForwardRef(‘DataPipeGraph’)]]\n\nA graph created from the traverse function\n\n\ndp_type\ntyping.Type[typing.Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe]]\n\n\n\n\ninclude_subclasses\nbool\nFalse\n\n\n\nReturns\ntyping.Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe]\n\n\n\n\n\nFor example if we have a pipeline such as:\n\nclass Template(dp.iter.IterDataPipe):\n    def __init__(self,source_datapipe=None): self.source_datapipe = source_datapipe\n    def __iter__(self): return (o for o in self.source_datapipe)\n\nclass A(Template):pass\nclass B(Template):pass\nclass C(Template):pass\nclass D(Template):pass\nclass E(Template):pass\nclass F(Template):pass\n\npipe = A(range(10))\npipe = B(pipe)\npipe = C(pipe)\npipe = D(pipe)\npipe = D(pipe)\npipe = E(pipe)\nlist(pipe)\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\nWe can grab the instance C in the middle of the graph via…\n\nfind_dp(traverse(pipe),C)\n\nC\n\n\nIf the pipe doesnt exist a LookupError gets raised…\n\nwith ExceptionExpected(LookupError):\n    find_dp(traverse(pipe),F)\n\nAnd if there are multiple instances of the same time, you will be warned to use find_dps instead…\n\nfind_dp(traverse(pipe),D)\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: There are 2 pipes of type <class '__main__.D'>. If this is intended, \n                     please use `find_dps` directly. Returning first instance.\n  from ipykernel import kernelapp as app\n\n\nD\n\n\nIf we try searching for all iterpipes we get nothing…\n\nfind_dps(traverse(pipe),dp.iter.IterDataPipe)\n\n[]\n\n\nHowever we can include subclasses in our search…\n\nfind_dps(traverse(pipe),dp.iter.IterDataPipe,include_subclasses=True)\n\n[E, D, D, C, B, A]\n\n\n\n\n\nDataPipeAugmentationFn\n\n DataPipeAugmentationFn (*args, **kwds)\n\nDataPipeAugmentationFn must take in a DataPipe and either output a DataPipe or None. This function should perform some operation on the graph such as replacing, removing, inserting DataPipe’s and DataGraphs. Below is an example that replaces a dp.iter.Batcher datapipe with a dp.iter.Filter\n\ndef iseven(i): return i%2==0\ndef test_replace(pipe:DataPipe) -> DataPipe:\n    graph = replace_dp(\n        traverse(pipe),\n        find_dp(traverse(pipe),dp.iter.Batcher),\n        dp.iter.Filter(find_dp(traverse(pipe),dp.iter.IterableWrapper),filter_fn=iseven)\n    )\n    return list(graph.values())[0][0]\n\n\n\n\napply_dp_augmentation_fns\n\n apply_dp_augmentation_fns (pipe:Union[torch.utils.data.datapipes.datapipe\n                            .IterDataPipe,torch.utils.data.datapipes.datap\n                            ipe.MapDataPipe], dp_augmentation_fns:Union[Tu\n                            ple[__main__.DataPipeAugmentationFn],NoneType]\n                            , debug:bool=False)\n\nGiven a pipe, run dp_augmentation_fns other the pipeline\nGiven a simple pipeline below…\n\npipe = dp.iter.IterableWrapper(range(10))\npipe = pipe.batch(2)\npipe = pipe.cycle(2)\npipe = pipe.header(limit=10)\ntraverse(pipe)\n\n{139934820824464: (HeaderIterDataPipe,\n  {139934820824400: (CyclerIterDataPipe,\n    {139934820824144: (BatcherIterDataPipe,\n      {139934820824080: (IterableWrapperIterDataPipe, {})})})})}\n\n\nWe want to run test_replace over the pipeline which will replace the pipe.batch with a dp.iter.Filter…\n\nnew_dp = apply_dp_augmentation_fns(pipe,(test_replace,))\ntest_eq(list(new_dp),[0, 2, 4, 6, 8, 0, 2, 4, 6, 8])\ntraverse(new_dp)\n\n/opt/conda/lib/python3.7/site-packages/torchdata/datapipes/iter/util/header.py:60: UserWarning: The length of this HeaderIterDataPipe is inferred to be equal to its limit.The actual value may be smaller if the actual length of source_datapipe is smaller than the limit.\n  \"The length of this HeaderIterDataPipe is inferred to be equal to its limit.\"\n\n\n{139934820824464: (HeaderIterDataPipe,\n  {139934820824400: (CyclerIterDataPipe,\n    {139934820825104: (FilterIterDataPipe,\n      {139934820824080: (IterableWrapperIterDataPipe, {})})})})}"
  },
  {
    "objectID": "01_DataPipes/pipes.iter.firstlast.html",
    "href": "01_DataPipes/pipes.iter.firstlast.html",
    "title": "FirstLast",
    "section": "",
    "text": "FirstLastMerger\n\n FirstLastMerger (*args, **kwds)\n\nTakes multiple steps and converts them into a single step consisting of properties from the first and last steps. Reward is recalculated to factor in the multiple steps.\nBelow we see an example where we collect 2 steps for each env, then yield them. This is useful for training models of larger chunks of env step output.\n\nimport pandas as pd\nfrom fastrl.envs.gym import GymTypeTransform,GymStepper\nfrom fastrl.pipes.iter.nstep import *\nfrom fastrl.pipes.map.transforms import *\n\n\ndef first_last_test(envs,total_steps,n=1,seed=0):\n    pipe = dp.map.Mapper(envs)\n    pipe = TypeTransformer(pipe,[GymTypeTransform])\n    pipe = dp.iter.MapToIterConverter(pipe)\n    pipe = dp.iter.InMemoryCacheHolder(pipe)\n    pipe = pipe.cycle()\n    pipe = GymStepper(pipe,seed=seed)\n    pipe = NStepper(pipe,n=n)\n    pipe = FirstLastMerger(pipe)\n    pipe = pipe.header(total_steps)\n    return list(pipe)\n\nsteps = first_last_test(['CartPole-v1']*3,200,2,0)\npd.DataFrame(steps)[['state','next_state','env_id','terminated']][:10]\n\n/opt/conda/lib/python3.7/site-packages/torchdata/datapipes/iter/util/header.py:60: UserWarning: The length of this HeaderIterDataPipe is inferred to be equal to its limit.The actual value may be smaller if the actual length of source_datapipe is smaller than the limit.\n  \"The length of this HeaderIterDataPipe is inferred to be equal to its limit.\"\n\n\n\n\n\n\n  \n    \n      \n      state\n      next_state\n      env_id\n      terminated\n    \n  \n  \n    \n      0\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(139621059434512)\n      tensor(False)\n    \n    \n      1\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(139621060390992)\n      tensor(False)\n    \n    \n      2\n      [tensor(0.0137), tensor(-0.0230), tensor(-0.0459), tensor(-0.0483)]\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      tensor(139621060250832)\n      tensor(False)\n    \n    \n      3\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      tensor(139621059434512)\n      tensor(False)\n    \n    \n      4\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      tensor(139621060390992)\n      tensor(False)\n    \n    \n      5\n      [tensor(0.0132), tensor(0.1727), tensor(-0.0469), tensor(-0.3552)]\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      tensor(139621060250832)\n      tensor(False)\n    \n    \n      6\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      [tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]\n      tensor(139621059434512)\n      tensor(False)\n    \n    \n      7\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      [tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]\n      tensor(139621060390992)\n      tensor(False)\n    \n    \n      8\n      [tensor(0.0167), tensor(0.3685), tensor(-0.0540), tensor(-0.6622)]\n      [tensor(0.0353), tensor(0.3702), tensor(-0.0866), tensor(-0.7006)]\n      tensor(139621060250832)\n      tensor(False)\n    \n    \n      9\n      [tensor(0.0241), tensor(0.5643), tensor(-0.0672), tensor(-0.9714)]\n      [tensor(0.0427), tensor(0.1763), tensor(-0.1007), tensor(-0.4364)]\n      tensor(139621059434512)\n      tensor(False)\n    \n  \n\n\n\n\nFirst, NStepper(pipe,n=1) with FirstLastMerger should be identical to a pipelines that never used it.\n\nimport pandas as pd\nfrom fastrl.envs.gym import GymTypeTransform,GymStepper\n\n\npipe = dp.map.Mapper(['CartPole-v1']*3)\npipe = TypeTransformer(pipe,[GymTypeTransform])\npipe = dp.iter.MapToIterConverter(pipe)\npipe = dp.iter.InMemoryCacheHolder(pipe)\npipe = pipe.cycle()\npipe = GymStepper(pipe,seed=0)\npipe = pipe.header(10)\n\nno_n_steps = list(pipe)\nsteps = first_last_test(['CartPole-v1']*3,10,1,0)\n\n/opt/conda/lib/python3.7/site-packages/torchdata/datapipes/iter/util/header.py:60: UserWarning: The length of this HeaderIterDataPipe is inferred to be equal to its limit.The actual value may be smaller if the actual length of source_datapipe is smaller than the limit.\n  \"The length of this HeaderIterDataPipe is inferred to be equal to its limit.\"\n\n\nIf n=1 we should expect that regardless of the number of envs, both n-step and simple environment pipelines should be identical.\n\ntest_len(steps,no_n_steps)\nfor field in ['next_state','state','terminated']:\n    for i,(step,no_n_step) in enumerate(zip(steps,no_n_steps)): \n        test_eq(getattr(step,field),getattr(no_n_step,field))\n\n\n\n\nn_first_last_steps_expected\n\n n_first_last_steps_expected (default_steps:int)\n\nThis function doesnt do much for now. FirstLastMerger pretty much undoes the number of steps nsteps does.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndefault_steps\nint\nThe number of steps the episode would run without n_steps\n\n\n\n\nexpected_n_steps = n_first_last_steps_expected(default_steps=18)\nprint('Given the above values, we expect a single episode to be ',expected_n_steps,' steps long')\nsteps = first_last_test(['CartPole-v1']*1,expected_n_steps+1,2,0)\n# The first episode should have ended on row 34, beign 35 steps long. The 36th row should be a new episode\ntest_eq(steps[-2].terminated,tensor([True]))\ntest_eq(steps[-2].episode_n,tensor([1]))\ntest_eq(steps[-2].step_n,tensor([18]))\ntest_eq(steps[-1].terminated,tensor([False]))\ntest_eq(steps[-1].episode_n,tensor([2]))\ntest_eq(steps[-1].step_n,tensor([2])) # Main difference, the \"step\" for the new episode will be 2 instead of 1\n\nGiven the above values, we expect a single episode to be  18  steps long\n\n\n\nexpected_n_steps = n_first_last_steps_expected(default_steps=18)\nprint('Given the above values, we expect a single episode to be ',expected_n_steps,' steps long')\nsteps = first_last_test(['CartPole-v1']*1,expected_n_steps+1,4,0)\n# The first episode should have ended on row 34, beign 35 steps long. The 36th row should be a new episode\ntest_eq(steps[-2].terminated,tensor([True]))\ntest_eq(steps[-2].episode_n,tensor([1]))\ntest_eq(steps[-2].step_n,tensor([18]))\ntest_eq(steps[-1].terminated,tensor([False]))\ntest_eq(steps[-1].episode_n,tensor([2]))\ntest_eq(steps[-1].step_n,tensor([4]))\n\nGiven the above values, we expect a single episode to be  18  steps long\n\n\n\nexpected_n_steps = n_first_last_steps_expected(default_steps=18)\nprint('Given the above values, we expect a single episode to be ',expected_n_steps,' steps long')\nsteps = first_last_test(['CartPole-v1']*3,expected_n_steps*3+1,2,0)\n# The first episode should have ended on row 34, beign 35 steps long. The 36th row should be a new episode\ntest_eq(steps[-2].terminated,tensor([True]))\ntest_eq(steps[-2].episode_n,tensor([1]))\ntest_eq(steps[-2].step_n,tensor([18]))\ntest_eq(steps[-1].terminated,tensor([False]))\ntest_eq(steps[-1].episode_n,tensor([2]))\ntest_eq(steps[-1].step_n,tensor([2]))\n\nGiven the above values, we expect a single episode to be  18  steps long"
  },
  {
    "objectID": "01_DataPipes/pipes.map.transforms.html",
    "href": "01_DataPipes/pipes.map.transforms.html",
    "title": "Type Transforms",
    "section": "",
    "text": "TypeTransformer\n\n TypeTransformer (*args, **kwds)\n\nOn __getitem__ functions in self.type_tfms get called over each element. Generally TypeTransformer as the name suggests is intended to convert elements from one type to another. reference documentation on how to combine this with InMemoryCacheHolder.\nSimilar to the fastrl.pipes.iter.transforms, TypeTransformer can be used to convert elements into different values…\n\nadd_one = lambda o:o+1\nmultiple_by_two = lambda o:o*2\npipe = TypeTransformer(range(10),[add_one,multiple_by_two])\n\nresults = [pipe[i] for i in range(10)] \ntest_eq(results,[2, 4, 6, 8, 10, 12, 14, 16, 18, 20])\n\nHowever if we want to convert types and keep them, we can combine TypeTransformer with InMemoryCacheHolder…\n\nnum2str = lambda o:str(o)\nadd_str_postfix = lambda o:o+'_postfix'\npipe = TypeTransformer(range(10),[num2str,add_str_postfix])\npipe = dp.map.InMemoryCacheHolder(pipe)\n\nresults = [pipe[i] for i in range(10)] \ntest_eq(results,['0_postfix', '1_postfix', '2_postfix', '3_postfix', \n                 '4_postfix', '5_postfix', '6_postfix', '7_postfix', '8_postfix', '9_postfix'])"
  },
  {
    "objectID": "01_DataPipes/pipes.iter.nstep.html#nstepper-tests",
    "href": "01_DataPipes/pipes.iter.nstep.html#nstepper-tests",
    "title": "NStep",
    "section": "NStepper Tests",
    "text": "NStepper Tests\nThere are a couple properties that we expect from n-step output: - tuples should be n size at max, however can be smaller. - done n-steps unravel into multiple tuples yielded individually.\n- In other words if `n=3`, meaning we want to yield 3 blocks of steps per env, then if we have\n  [step5,step6,step7] where step7 is `done` we will get individual tuples in the order:\n  \n      1. [step5,step6,step7]\n      2. [step6,step7]\n      3. [step7]\nFirst, NStepper(pipe,n=1) when falttened should be identical to a pipelines that never used it.\n\nimport pandas as pd\nfrom fastrl.envs.gym import GymTypeTransform,GymStepper\n\n\npipe = dp.map.Mapper(['CartPole-v1']*3)\npipe = TypeTransformer(pipe,[GymTypeTransform])\npipe = dp.iter.MapToIterConverter(pipe)\npipe = dp.iter.InMemoryCacheHolder(pipe)\npipe = pipe.cycle()\npipe = GymStepper(pipe,seed=0)\npipe = pipe.header(10)\n\nno_n_steps = list(pipe)\nsteps = n_step_test(['CartPole-v1']*3,10,1,0)\n\nIf n=1 we should expect that regardless of the number of envs, both n-step and simple environment pipelines should be identical.\n\ntest_len(steps,no_n_steps)\nfor field in ['next_state','state','terminated']:\n    for i,(step,no_n_step) in enumerate(zip(steps,no_n_steps)): \n        test_eq(getattr(step,field),getattr(no_n_step,field))\n\nWe should expect n=1 -> 3 to have the same basic shape…\n\nsteps1 = n_step_test(['CartPole-v1']*1,30,1,0)\nsteps2 = n_step_test(['CartPole-v1']*1,30,2,0)\nsteps3 = n_step_test(['CartPole-v1']*1,30,3,0)\n\n\nfor o in itertools.chain(steps1,steps2,steps3):\n    test_eq(len(o),12)\n    test_eq(isinstance(o,SimpleStep),True)\n\n\n\nn_steps_expected\n\n n_steps_expected (default_steps:int, n:int)\n\nProduces the expected number of steps, assuming a fully deterministic episode based on default_steps and n\nGiven n=2, given 1 envs, knowing that CartPole-v1 when seed=0 will always run 18 steps, the total steps will be:\n\\[\n18 * n - \\sum_{0}^{n - 1}(i)\n\\]\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndefault_steps\nint\nThe number of steps the episode would run without n_steps\n\n\nn\nint\nThe n-step value that we are planning ot use\n\n\n\n\nexpected_n_steps = n_steps_expected(default_steps=18,n=2)\nprint('Given the above values, we expect a single episode to be ',expected_n_steps,' steps long')\nsteps = n_step_test(['CartPole-v1']*1,expected_n_steps+1,2,0)\n# The first episode should have ended on row 34, beign 35 steps long. The 36th row should be a new episode\ntest_eq(steps[-2].terminated,tensor([True]))\ntest_eq(steps[-2].episode_n,tensor([1]))\ntest_eq(steps[-2].step_n,tensor([18]))\ntest_eq(steps[-1].terminated,tensor([False]))\ntest_eq(steps[-1].episode_n,tensor([2]))\ntest_eq(steps[-1].step_n,tensor([1]))\n\nGiven the above values, we expect a single episode to be  35  steps long\n\n\n\nexpected_n_steps = n_steps_expected(default_steps=18,n=4)\nprint('Given the above values, we expect a single episode to be ',expected_n_steps,' steps long')\nsteps = n_step_test(['CartPole-v1']*1,expected_n_steps+1,4,0)\n# The first episode should have ended on row 34, beign 35 steps long. The 36th row should be a new episode\ntest_eq(steps[-2].terminated,tensor([True]))\ntest_eq(steps[-2].episode_n,tensor([1]))\ntest_eq(steps[-2].step_n,tensor([18]))\ntest_eq(steps[-1].terminated,tensor([False]))\ntest_eq(steps[-1].episode_n,tensor([2]))\ntest_eq(steps[-1].step_n,tensor([1]))\n\nGiven the above values, we expect a single episode to be  66  steps long\n\n\n\nexpected_n_steps = n_steps_expected(default_steps=18,n=2)\nprint('Given the above values, we expect a single episode to be ',expected_n_steps,' steps long')\nsteps = n_step_test(['CartPole-v1']*3,expected_n_steps*3+1,2,0)\n# The first episode should have ended on row 34, beign 35 steps long. The 36th row should be a new episode\ntest_eq(steps[-2].terminated,tensor([True]))\ntest_eq(steps[-2].episode_n,tensor([1]))\ntest_eq(steps[-2].step_n,tensor([18]))\ntest_eq(steps[-1].terminated,tensor([False]))\ntest_eq(steps[-1].episode_n,tensor([2]))\ntest_eq(steps[-1].step_n,tensor([1]))\n\nGiven the above values, we expect a single episode to be  35  steps long"
  },
  {
    "objectID": "00_Fastai/torch_core.html",
    "href": "00_Fastai/torch_core.html",
    "title": "Torch Core",
    "section": "",
    "text": "Important: Fastai is not a direct dependency, but we want the ability to use some of the torch utilites offered by fastai, we have this notebook, which has been copied from: fastai. At some point having fastai as a direct dep would be good, however for know we are keeping the number of deps as low as we can."
  },
  {
    "objectID": "00_Fastai/torch_core.html#arrays-and-show",
    "href": "00_Fastai/torch_core.html#arrays-and-show",
    "title": "Torch Core",
    "section": "Arrays and show",
    "text": "Arrays and show\n\n\nsubplots\n\n subplots (nrows:int=1, ncols:int=1, figsize:tuple=None, imsize:int=3,\n           suptitle:str=None, sharex=False, sharey=False, squeeze=True,\n           subplot_kw=None, gridspec_kw=None, **kwargs)\n\nReturns a figure and set of subplots to display images of imsize inches\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnrows\nint\n1\nNumber of rows in returned axes grid\n\n\nncols\nint\n1\nNumber of columns in returned axes grid\n\n\nfigsize\ntuple\nNone\nWidth, height in inches of the returned figure\n\n\nimsize\nint\n3\nSize (in inches) of images that will be displayed in the returned figure\n\n\nsuptitle\nstr\nNone\nTitle to be set to returned figure\n\n\nsharex\nbool\nFalse\n\n\n\nsharey\nbool\nFalse\n\n\n\nsqueeze\nbool\nTrue\n\n\n\nsubplot_kw\nNoneType\nNone\n\n\n\ngridspec_kw\nNoneType\nNone\n\n\n\nkwargs\n\n\n\n\n\nReturns\n(<class ‘matplotlib.figure.Figure’>, <class ‘matplotlib.axes._axes.Axes’>)\n\nReturns both fig and ax as a tuple\n\n\n\nThis is used in get_grid. suptitle, sharex, sharey, squeeze, subplot_kw and gridspec_kw are all passed down to plt.subplots.\n\n\n\nshow_image\n\n show_image (im, ax=None, figsize=None, title=None, ctx=None, cmap=None,\n             norm=None, aspect=None, interpolation=None, alpha=None,\n             vmin=None, vmax=None, origin=None, extent=None,\n             interpolation_stage=None, filternorm=True, filterrad=4.0,\n             resample=None, url=None, data=None, **kwargs)\n\nShow a PIL or PyTorch image on ax.\nshow_image can show PIL images…\n\nim = Image.open(TEST_IMAGE_BW)\nax = show_image(im, cmap=\"Greys\")\n\n\n\n\n…and color images with standard CHW dim order…\n\nim2 = np.array(Image.open(TEST_IMAGE))\nax = show_image(im2, figsize=(2,2))\n\n\n\n\n…and color images with HWC dim order…\n\nim3 = torch.as_tensor(im2).permute(2,0,1)\nax = show_image(im3, figsize=(2,2))\n\n\n\n\n\n\n\nshow_titled_image\n\n show_titled_image (o, ax=None, figsize=None, title=None, ctx=None,\n                    cmap=None, norm=None, aspect=None, interpolation=None,\n                    alpha=None, vmin=None, vmax=None, origin=None,\n                    extent=None, interpolation_stage=None,\n                    filternorm=True, filterrad=4.0, resample=None,\n                    url=None, data=None, **kwargs)\n\nCall show_image destructuring o to (img,title)\n\nshow_titled_image((im3,'A puppy'), figsize=(2,2))\n\n\n\n\nShow all images ims as subplots with rows using titles. suptitle provides a way to create a figure title for all images. If you use suptitle, constrained_layout is used unless you set constrained_layout to False.\n\n\n\nshow_images\n\n show_images (ims, nrows=1, ncols=None, titles=None, figsize:tuple=None,\n              imsize:int=3, suptitle:str=None, sharex=False, sharey=False,\n              squeeze=True, subplot_kw=None, gridspec_kw=None)\n\nShow all images ims as subplots with rows using titles.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nims\n\n\n\n\n\nnrows\nint\n1\nNumber of rows in returned axes grid\n\n\nncols\nint\n1\nNumber of columns in returned axes grid\n\n\ntitles\nNoneType\nNone\n\n\n\nfigsize\ntuple\nNone\nWidth, height in inches of the returned figure\n\n\nimsize\nint\n3\nSize (in inches) of images that will be displayed in the returned figure\n\n\nsuptitle\nstr\nNone\nTitle to be set to returned figure\n\n\nsharex\nbool\nFalse\n\n\n\nsharey\nbool\nFalse\n\n\n\nsqueeze\nbool\nTrue\n\n\n\nsubplot_kw\nNoneType\nNone\n\n\n\ngridspec_kw\nNoneType\nNone\n\n\n\nReturns\n(<class ‘matplotlib.figure.Figure’>, <class ‘matplotlib.axes._axes.Axes’>)\n\nReturns both fig and ax as a tuple\n\n\n\n\nshow_images((im,im3),titles=('number','puppy'),suptitle='Number Puppy',  imsize=3)\n\n\n\n\nArrayImage, ArrayImageBW and ArrayMask are subclasses of ndarray that know how to show themselves.\n\n\n\nArrayBase\nAn ndarray that can modify casting behavior\n\n\n\nArrayImageBase\nBase class for arrays representing images\n\n\n\nArrayImage\nAn array representing an image\n\n\n\nArrayImageBW\nAn array representing an image\n\n\n\nArrayMask\nAn array representing an image mask\n\nim = Image.open(TEST_IMAGE)\n\n\nim_t = cast(im, ArrayImage)\ntest_eq(type(im_t), ArrayImage)\n\n\nax = im_t.show(figsize=(2,2))\n\n\n\n\n\ntest_fig_exists(ax)"
  },
  {
    "objectID": "00_Fastai/torch_core.html#basics",
    "href": "00_Fastai/torch_core.html#basics",
    "title": "Torch Core",
    "section": "Basics",
    "text": "Basics\n\n\nevaluating\n\n evaluating (model)\n\nTemporarily switch to evaluation mode.\n\n\n\ntensor\n\n tensor (x, *rest, dtype=None, device=None, requires_grad=False,\n         pin_memory=False)\n\nLike torch.as_tensor, but handle lists too, and can pass multiple vector elements directly.\n\ntest_eq(tensor(torch.tensor([1,2,3])), torch.tensor([1,2,3]))\ntest_eq(tensor(array([1,2,3])), torch.tensor([1,2,3]))\ntest_eq(tensor(1,2,3), torch.tensor([1,2,3]))\ntest_eq_type(tensor(1.0), torch.tensor(1.0))\n\nset_seed is useful for reproducibility between runs. It is important to remember that certain classes such as Dataloaders have internal random number generators that is not effected by this function, so this must be run before such objects are created in order to guarantee reproducibility.\n\n\n\nset_seed\n\n set_seed (s, reproducible=False)\n\nSet random seed for random, torch, and numpy (where available)\nHere is an example of how set_seed can be used to reset the state of random number generators.\n\nset_seed(2*33)\na1 = np.random.random()\na2 = torch.rand(())\na3 = random.random()\nset_seed(2*33)\nb1 = np.random.random()\nb2 = torch.rand(())\nb3 = random.random()\nprint('a\\'s: {0:3.3f} {1:3.3f} {2:3.3f}'.format(a1,a2,a3))\nprint('b\\'s: {0:3.3f} {1:3.3f} {2:3.3f}'.format(b1,b2,a3))\n\na's: 0.154 0.498 0.071\nb's: 0.154 0.498 0.071\n\n\n\ntest_eq(a1,b1)\ntest_eq(a2,b2)\ntest_eq(a3,b3)\n\nget_random_states and set_random_states are useful for storing a state so you can go back to it later.\n\n\n\nget_random_states\n\n get_random_states ()\n\nGets states for random, torch, and numpy random number generators\n\n\n\nset_random_states\n\n set_random_states (random_state, numpy_state, torch_state,\n                    torch_cuda_state, torch_deterministic,\n                    torch_benchmark)\n\nSet states for random, torch, and numpy random number generators\nBelow notice that the old values and rewinded values are the same because we were able to return to the previous state.\n\nold_states = get_random_states()\nolds = (random.random(),np.random.random(),torch.rand(()))\nnews = (random.random(),np.random.random(),torch.rand(()))\nset_random_states(**old_states)\nrewinds = (random.random(),np.random.random(),torch.rand(()))\n\nprint('olds:    {0:3.3f} {1:3.3f} {2:3.3f}'.format(*olds))\nprint('news:    {0:3.3f} {1:3.3f} {2:3.3f}'.format(*news))\nprint('rewinds: {0:3.3f} {1:3.3f} {2:3.3f}'.format(*rewinds))\n\nolds:    0.435 0.134 0.023\nnews:    0.246 0.363 0.227\nrewinds: 0.435 0.134 0.023\n\n\n\ntest_ne(olds,news)\ntest_eq(olds,rewinds)\n\nIn no_random we combine the ideas of rewinding state with get_random_states and set_random_states with the ability to set_seed and create a context manager that can allow us to control randomness in a portion of our code.\nNote: Similar to torch.random.fork_rng, but also with numpy and random\n\n\n\nno_random\n\n no_random (seed=42, reproducible=True)\n\nStores and retrieves state of random number generators. Sets random seed for random, torch, and numpy.\nHere are some examples on how we can use no_random to control the randomness within a block of code.\n\nstates=get_random_states()\nolds = (random.random(),np.random.random(),torch.rand(()))\nset_random_states(**states) #rewinding above random calls\n\nwith no_random():\n    new1 = (random.random(),np.random.random(),torch.rand(()))\nwith no_random():\n    new2 = (random.random(),np.random.random(),torch.rand(()))\nwith no_random(seed=100):\n    seeded1 = (random.random(),np.random.random(),torch.rand(()))\nwith no_random(seed=100):\n    seeded2 = (random.random(),np.random.random(),torch.rand(()))\n        \nrewinds = (random.random(),np.random.random(),torch.rand(()))\n\nprint('olds:    {0:3.3f} {1:3.3f} {2:3.3f}'.format(*olds))\nprint('new1:    {0:3.3f} {1:3.3f} {2:3.3f}'.format(*new1))\nprint('new2:    {0:3.3f} {1:3.3f} {2:3.3f}'.format(*new2))\nprint('seeded1: {0:3.3f} {1:3.3f} {2:3.3f}'.format(*seeded1))\nprint('seeded2: {0:3.3f} {1:3.3f} {2:3.3f}'.format(*seeded2))\nprint('rewinds: {0:3.3f} {1:3.3f} {2:3.3f}'.format(*rewinds))\n\nolds:    0.246 0.363 0.227\nnew1:    0.639 0.375 0.882\nnew2:    0.639 0.375 0.882\nseeded1: 0.146 0.543 0.112\nseeded2: 0.146 0.543 0.112\nrewinds: 0.246 0.363 0.227\n\n\nNotice that olds, and rewinds are alos both equal to each other. From this we can see that everything in the with blocks did not update the state outside of the block. Inside of the block, the state is reset for any particular seed, so for the same seed you should get the same random number generator results.\nNote: It is important to remember that classes like Dataloader have internal random number generators, and no_random will have no effect on those random number generators.\n\ntest_ne(olds,new1)\ntest_eq(new1,new2)\ntest_ne(new1,seeded1)\ntest_eq(seeded1,seeded2)\ntest_eq(olds,rewinds)\n\n\n\n\nunsqueeze\n\n unsqueeze (x, dim=-1, n=1)\n\nSame as torch.unsqueeze but can add n dims\n\nt = tensor([1])\nt2 = unsqueeze(t, n=2)\ntest_eq(t2,t[:,None,None])\n\n\n\n\nunsqueeze_\n\n unsqueeze_ (x, dim=-1, n=1)\n\nSame as torch.unsqueeze_ but can add n dims\n\nt = tensor([1])\nunsqueeze_(t, n=2)\ntest_eq(t, tensor([1]).view(1,1,1))\n\n\n\n\napply\n\n apply (func, x, *args, **kwargs)\n\nApply func recursively to x, passing on args\n\n\n\nmaybe_gather\n\n maybe_gather (x, axis=0)\n\nGather copies of x on axis (if training is distributed)\n\n\n\nto_detach\n\n to_detach (b, cpu=True, gather=True)\n\nRecursively detach lists of tensors in b; put them on the CPU if cpu=True.\ngather only applies during distributed training and the result tensor will be the one gathered across processes if gather=True (as a result, the batch size will be multiplied by the number of processes).\n\n\n\nto_half\n\n to_half (b)\n\nRecursively map lists of tensors in b to FP16.\n\n\n\nto_float\n\n to_float (b)\n\nRecursively map lists of int tensors in b to float.\n\n\n\ndefault_device\n\n default_device (use_cuda=-1)\n\nReturn or set default device; use_cuda: None - CUDA if available; True - error if not available; False - CPU\n\n\n\ndefault_device\n\n default_device (use=-1)\n\nReturn or set default device; use_cuda: -1 - CUDA/mps if available; True - error if not available; False - CPU\n\nif torch.cuda.is_available():\n    _td = torch.device(torch.cuda.current_device())\n    test_eq(default_device(-1), _td)\n    test_eq(default_device(True), _td)\nelse:\n    test_eq(default_device(False), torch.device('cpu'))\ndefault_device(-1);\n\n\n\n\nto_device\n\n to_device (b, device=None, non_blocking=False)\n\nRecursively put b on device.\n\nt = to_device((3,(tensor(3),tensor(2))))\nt1,(t2,t3) = t\n\n\nif torch.cuda.is_available():\n    test_eq_type(t,(3,(tensor(3).cuda(),tensor(2).cuda())))\n    test_eq(t2.type(), \"torch.cuda.LongTensor\")\n    test_eq(t3.type(), \"torch.cuda.LongTensor\")\n\n\n\n\nto_cpu\n\n to_cpu (b)\n\nRecursively map lists of tensors in b to the cpu.\n\nt3 = to_cpu(t3)\ntest_eq(t3.type(), \"torch.LongTensor\")\ntest_eq(t3, 2)\n\n\n\n\nto_np\n\n to_np (x)\n\nConvert a tensor to a numpy array.\n\nt3 = to_np(t3)\ntest_eq(type(t3), np.ndarray)\ntest_eq(t3, 2)\n\n\n\n\nto_concat\n\n to_concat (xs, dim=0)\n\nConcat the element in xs (recursively if they are tuples/lists of tensors)\n\ntest_eq(to_concat([tensor([1,2]), tensor([3,4])]), tensor([1,2,3,4]))\ntest_eq(to_concat([tensor([[1,2]]), tensor([[3,4]])], dim=1), tensor([[1,2,3,4]]))\ntest_eq_type(to_concat([(tensor([1,2]), tensor([3,4])), (tensor([3,4]), tensor([5,6]))]), (tensor([1,2,3,4]), tensor([3,4,5,6])))\ntest_eq_type(to_concat([[tensor([1,2]), tensor([3,4])], [tensor([3,4]), tensor([5,6])]]), [tensor([1,2,3,4]), tensor([3,4,5,6])])\ntest_eq_type(to_concat([(tensor([1,2]),), (tensor([3,4]),)]), (tensor([1,2,3,4]),))\n\ntest_eq(to_concat([tensor([[1,2]]), tensor([[3,4], [5,6]])], dim=1), [tensor([1]),tensor([3, 5]),tensor([4, 6])])\n\n\ntest_eq(type(to_concat([dict(foo=tensor([1,2]), bar=tensor(3,4))])), dict)"
  },
  {
    "objectID": "00_Fastai/torch_core.html#tensor-subtypes",
    "href": "00_Fastai/torch_core.html#tensor-subtypes",
    "title": "Torch Core",
    "section": "Tensor subtypes",
    "text": "Tensor subtypes\n\n\nTensor.set_meta\n\n Tensor.set_meta (x, as_copy=False)\n\nSet all metadata in __dict__\n\n\n\nTensor.as_subclass\n\n Tensor.as_subclass (typ)\n\nCast to typ and include __dict__ and meta\nTensor.set_meta and Tensor.as_subclass work together to maintain __dict__ after casting.\n\nclass _T(Tensor): pass\nt = tensor(1.).requires_grad_()\nt.img_size = 1\nt2 = t.as_subclass(_T)\ntest_eq(t.img_size, t2.img_size)\ntest_eq(t2.img_size, 1)\nassert(t2.requires_grad_)\n\n\n\n\nTensorBase\n\n TensorBase (x, **kwargs)\n\nA Tensor which support subclass pickling, and maintains metadata when casting or after methods\nTensorBase hooks into __torch_function__ to ensure metadata is not lost. To see all functions being called, set debug.\n\na = TensorBase(1)\na.debug=True\n1/(a+1)\n\nTensorBase(0.5000)\n\n\nTensorBase and its subclasses also allow for passing through metadata size as img_size…\n\nfrom torch.utils.data._utils.collate import default_collate\n\n\na = TensorBase(1,img_size=(128,128))\ntest_eq(a.img_size,(128,128))\nb = cast(a,TensorBase)\ntest_eq(b.img_size,(128,128))\ntest_eq(torch.stack([a,b],0).img_size,(128,128))\n\ntest_eq(default_collate([a,b]).img_size,(128,128))\n\n\nclass _TImage(TensorBase): pass\nclass _TImage2(_TImage): pass\nt1 = _TImage([1.])\nt2 = _TImage2([1.])\nt2+t1\n\n_TImage2([2.])\n\n\n\nclass _T(TensorBase): pass\n\nt = _T(range(5))\ntest_eq(t[0], 0)\ntest_eq_type(t+1, _T(range(1,6)))\ntest_eq(repr(t), '_T([0, 1, 2, 3, 4])')\ntest_eq_type(t[_T([False,False,True,True,True])], _T([2,3,4]))\ntest_eq_type(t[_T([2,3,4])], _T([2,3,4]))\ntest_eq(type(pickle.loads(pickle.dumps(t))), _T)\ntest_eq_type(t.new_ones(1), _T([1]))\ntest_eq_type(t.new_tensor([1,2]), _T([1,2]))\n\n\nt = tensor([1,2,3])\nm = TensorBase([False,True,True])\ntest_eq(t[m], tensor([2,3]))\nt = tensor([[1,2,3],[1,2,3]])\nm = cast(tensor([[False,True,True],\n                 [False,True,True]]), TensorBase)\ntest_eq(t[m], tensor([2,3,2,3]))\n\n\nt = tensor([[1,2,3],[1,2,3]])\nt.img_size = 1\nt2 = cast(t, TensorBase)\ntest_eq(t2.img_size, t.img_size)\nx = retain_type(tensor([4,5,6]), t2)\ntest_eq(x.img_size, t.img_size)\nt3 = TensorBase([[1,2,3],[1,2,3]], img_size=1)\ntest_eq(t3.img_size, t.img_size)\nt4 = t2+1\nt4.img_size = 2\ntest_eq(t2.img_size, 1)\ntest_eq(t4.img_size, 2)\n# this will fail with `Tensor` but works with `TensorBase`\ntest_eq(pickle.loads(pickle.dumps(t2)).img_size, t2.img_size)\n\n\n\n\nTensorImageBase\n\n TensorImageBase (x, **kwargs)\n\nA Tensor which support subclass pickling, and maintains metadata when casting or after methods\n\n\n\nTensorImage\n\n TensorImage (x, **kwargs)\n\nA Tensor which support subclass pickling, and maintains metadata when casting or after methods\n\n\n\nTensorImageBW\n\n TensorImageBW (x, **kwargs)\n\nA Tensor which support subclass pickling, and maintains metadata when casting or after methods\n\n\n\nTensorMask\n\n TensorMask (x, **kwargs)\n\nA Tensor which support subclass pickling, and maintains metadata when casting or after methods\n\nim = Image.open(TEST_IMAGE)\nim_t = cast(array(im), TensorImage)\ntest_eq(type(im_t), TensorImage)\n\n\nim_t2 = cast(tensor(1), TensorMask)\ntest_eq(type(im_t2), TensorMask)\ntest_eq(im_t2, tensor(1))\nax = im_t.show(figsize=(2,2))\n_ =(im_t == im_t2)\n\n\n\n\n\ntest_fig_exists(ax)\n\nOperations between TensorMask and TensorImageBase objects return the type of the TensorImageBase object:\n\na = TensorMask([1,2])\ntest_eq_type(TensorImage(1)+a, TensorImage([2,3]))\ntest_eq_type(1-a, TensorMask([0,-1]))\n\n\n\n\nTensorFlowField\n\n TensorFlowField (x, **kwargs)\n\nA Tensor which support subclass pickling, and maintains metadata when casting or after methods\n\nt1 = TensorImage([1.]).view(1,1,1,1)\nt2 = TensorFlowField([1.,1.]).view(1,1,1,2)\ntest_eq_type(F.grid_sample(t1, t2), TensorImage([[[[0.25]]]]))\n\n\n\n\nTensorCategory\n\n TensorCategory (x, **kwargs)\n\nA Tensor which support subclass pickling, and maintains metadata when casting or after methods\n\ntc = TensorCategory([1,2,3])\nmask_t = TensorMask([0,2,4,5])\nim_t = TensorImage([0,2,4,5])\ntest_eq(mask_t[tc], tensor([2,4,5]))\ntest_eq(im_t[tc], tensor([2,4,5]))\n\n\n\n\nTensorMultiCategory\n\n TensorMultiCategory (x, **kwargs)\n\nA Tensor which support subclass pickling, and maintains metadata when casting or after methods\n\n\n\nTitledTensorScalar\n\n TitledTensorScalar (x, **kwargs)\n\nA tensor containing a scalar that has a show method\n\n\n\nL.cat\n\n L.cat (dim=0)\n\nSame as torch.cat\n\n\n\nL.stack\n\n L.stack (dim=0)\n\nSame as torch.stack\n\n\n\nL.tensored\n\n L.tensored ()\n\nmapped(tensor)\n\n\n\nL.tensored\n\n L.tensored ()\n\nmapped(tensor)\nThere are shortcuts for torch.stack and torch.cat if your L contains tensors or something convertible. You can manually convert with tensored.\n\nt = L(([1,2],[3,4]))\ntest_eq(t.tensored(), [tensor(1,2),tensor(3,4)])\n\n\n\n\nL.stack\n\n L.stack (dim=0)\n\nSame as torch.stack\n\ntest_eq(t.stack(), tensor([[1,2],[3,4]]))\n\n\n\n\nL.cat\n\n L.cat (dim=0)\n\nSame as torch.cat\n\ntest_eq(t.cat(), tensor([1,2,3,4]))"
  },
  {
    "objectID": "00_Fastai/torch_core.html#chunks",
    "href": "00_Fastai/torch_core.html#chunks",
    "title": "Torch Core",
    "section": "Chunks",
    "text": "Chunks\n\n\nconcat\n\n concat (*ls)\n\nConcatenate tensors, arrays, lists, or tuples\n\na,b,c = [1],[1,2],[1,1,2]\ntest_eq(concat(a,b), c)\ntest_eq_type(concat(tuple (a),tuple (b)), tuple (c))\ntest_eq_type(concat(array (a),array (b)), array (c))\ntest_eq_type(concat(tensor(a),tensor(b)), tensor(c))\ntest_eq_type(concat(TensorBase(a),TensorBase(b)), TensorBase(c))\ntest_eq_type(concat([1,1],1), [1,1,1])\ntest_eq_type(concat(1,1,1), L(1,1,1))\ntest_eq_type(concat(L(1,2),1), L(1,2,1))\n\n\n\n\nChunks\n\n Chunks (chunks, lens=None)\n\nSlice and int indexing into a list of lists\n\ndocs = L(list(string.ascii_lowercase[a:b]) for a,b in ((0,3),(3,7),(7,8),(8,16),(16,24),(24,26)))\n\nb = Chunks(docs)\ntest_eq([b[ o] for o in range(0,5)], ['a','b','c','d','e'])\ntest_eq([b[-o] for o in range(1,6)], ['z','y','x','w','v'])\ntest_eq(b[6:13], 'g,h,i,j,k,l,m'.split(','))\ntest_eq(b[20:77], 'u,v,w,x,y,z'.split(','))\ntest_eq(b[:5], 'a,b,c,d,e'.split(','))\ntest_eq(b[:2], 'a,b'.split(','))\n\n\nt = torch.arange(26)\ndocs = L(t[a:b] for a,b in ((0,3),(3,7),(7,8),(8,16),(16,24),(24,26)))\nb = Chunks(docs)\ntest_eq([b[ o] for o in range(0,5)], range(0,5))\ntest_eq([b[-o] for o in range(1,6)], [25,24,23,22,21])\ntest_eq(b[6:13], torch.arange(6,13))\ntest_eq(b[20:77], torch.arange(20,26))\ntest_eq(b[:5], torch.arange(5))\ntest_eq(b[:2], torch.arange(2))\n\n\ndocs = L(TensorBase(t[a:b]) for a,b in ((0,3),(3,7),(7,8),(8,16),(16,24),(24,26)))\nb = Chunks(docs)\ntest_eq_type(b[:2], TensorBase(range(2)))\ntest_eq_type(b[:5], TensorBase(range(5)))\ntest_eq_type(b[9:13], TensorBase(range(9,13)))"
  },
  {
    "objectID": "00_Fastai/torch_core.html#simple-types",
    "href": "00_Fastai/torch_core.html#simple-types",
    "title": "Torch Core",
    "section": "Simple types",
    "text": "Simple types\n\n\nshow_title\n\n show_title (o, ax=None, ctx=None, label=None, color='black', **kwargs)\n\nSet title of ax to o, or print o if ax is None\n\ntest_stdout(lambda: show_title(\"title\"), \"title\")\n# ensure that col names are unique when showing to a pandas series\nassert show_title(\"title\", ctx=pd.Series(dict(a=1)), label='a').equals(pd.Series(dict(a=1,a_='title')))\n\n\n\n\nShowTitle\n\n ShowTitle ()\n\nBase class that adds a simple show\n\n\n\nTitledInt\nAn int with show\n\n\n\nTitledStr\nAn str with show\n\n\n\nTitledFloat\n\n TitledFloat (x=0)\n\nA float with show\n\ntest_stdout(lambda: TitledStr('s').show(), 's')\ntest_stdout(lambda: TitledInt(1).show(), '1')\n\n\n\n\nTitledTuple\n\n TitledTuple (x=None, *rest)\n\nA fastuple with show\n\n\n\nTitledStr.truncate\n\n TitledStr.truncate (n)\n\nTruncate self to n"
  },
  {
    "objectID": "00_Fastai/torch_core.html#other-functions",
    "href": "00_Fastai/torch_core.html#other-functions",
    "title": "Torch Core",
    "section": "Other functions",
    "text": "Other functions\n\n\nget_empty_df\n\n get_empty_df (n)\n\nReturn n empty rows of a dataframe\n\n\n\ndisplay_df\n\n display_df (df)\n\nDisplay df in a notebook or defaults to print\n\n\n\nget_first\n\n get_first (c)\n\nGet the first element of c, even if c is a dataframe\n\n\n\none_param\n\n one_param (m)\n\nFirst parameter in m\n\n\n\nitem_find\n\n item_find (x, idx=0)\n\nRecursively takes the idx-th element of x\n\n\n\nfind_device\n\n find_device (b)\n\nRecursively search the device of b.\n\nt2 = to_device(tensor(0))\ndev = default_device()\ntest_eq(find_device(t2), dev)\ntest_eq(find_device([t2,t2]), dev)\ntest_eq(find_device({'a':t2,'b':t2}), dev)\ntest_eq(find_device({'a':[[t2],[t2]],'b':t2}), dev)\n\n\n\n\nfind_bs\n\n find_bs (b)\n\nRecursively search the batch size of b.\n\nx = torch.randn(4,5)\nx1 = [1,2,3]\ntest_eq(find_bs(x1), 3)\ntest_eq(find_bs(x), 4)\ntest_eq(find_bs((x,x)), 4)\ntest_eq(find_bs([x, x]), 4)\ntest_eq(find_bs({'a':x,'b':x}), 4)\ntest_eq(find_bs({'a':[[x],[x]],'b':x}), 4)\n\n\n\n\nnp_func\n\n np_func (f)\n\nConvert a function taking and returning numpy arrays to one taking and returning tensors\nThis decorator is particularly useful for using numpy functions as fastai metrics, for instance:\n\nfrom sklearn.metrics import f1_score\n\n\n@np_func\ndef f1(inp,targ): return f1_score(targ, inp)\n\na1,a2 = array([0,1,1]),array([1,0,1])\nt = f1(tensor(a1),tensor(a2))\ntest_eq(f1_score(a1,a2), t)\nassert isinstance(t,Tensor)\n\n\n\n\nModule\n\n Module ()\n\nSame as nn.Module, but no need for subclasses to call super().__init__\n\nclass _T(Module):\n    def __init__(self): self.f = nn.Linear(1,1)\n    def forward(self,x): return self.f(x)\n\nt = _T()\nt(tensor([1.]))\n\ntensor([-0.0832], grad_fn=<AddBackward0>)\n\n\n\n\n\nget_model\n\n get_model (model)\n\nReturn the model maybe wrapped inside model.\n\n\n\none_hot\n\n one_hot (x, c)\n\nOne-hot encode x with c classes.\n\ntest_eq(one_hot([1,4], 5), tensor(0,1,0,0,1).byte())\ntest_eq(one_hot(torch.tensor([]), 5), tensor(0,0,0,0,0).byte())\ntest_eq(one_hot(2, 5), tensor(0,0,1,0,0).byte())\n\n\n\n\none_hot_decode\n\n one_hot_decode (x, vocab=None)\n\n\ntest_eq(one_hot_decode(tensor(0,1,0,0,1)), [1,4])\ntest_eq(one_hot_decode(tensor(0,0,0,0,0)), [   ])\ntest_eq(one_hot_decode(tensor(0,0,1,0,0)), [2  ])\n\n\n\n\nparams\n\n params (m)\n\nReturn all parameters of m\n\n\n\ntrainable_params\n\n trainable_params (m)\n\nReturn all trainable parameters of m\n\nm = nn.Linear(4,5)\ntest_eq(trainable_params(m), [m.weight, m.bias])\nm.weight.requires_grad_(False)\ntest_eq(trainable_params(m), [m.bias])\n\n\n\n\nnorm_bias_params\n\n norm_bias_params (m, with_bias=True)\n\nReturn all bias and BatchNorm parameters\n\nfor norm_func in [nn.BatchNorm1d, partial(nn.InstanceNorm1d, affine=True)]:\n    model = nn.Sequential(nn.Linear(10,20), norm_func(20), nn.Conv1d(3,4, 3))\n    test_eq(norm_bias_params(model), [model[0].bias, model[1].weight, model[1].bias, model[2].bias])\n    model = nn.ModuleList([nn.Linear(10,20, bias=False), nn.Sequential(norm_func(20), nn.Conv1d(3,4,3))])\n    test_eq(norm_bias_params(model), [model[1][0].weight, model[1][0].bias, model[1][1].bias])\n    model = nn.ModuleList([nn.Linear(10,20), nn.Sequential(norm_func(20), nn.Conv1d(3,4,3))])\n    test_eq(norm_bias_params(model, with_bias=False), [model[1][0].weight, model[1][0].bias])\n\n\n\n\nbatch_to_samples\n\n batch_to_samples (b, max_n=10)\n\n‘Transposes’ a batch to (at most max_n) samples\n\nt = tensor([1,2,3])\ntest_eq(batch_to_samples([t,t+1], max_n=2), ([1,2],[2,3]))\ntest_eq(batch_to_samples(tensor([1,2,3]), 10), [1, 2, 3])\ntest_eq(batch_to_samples([tensor([1,2,3]), tensor([4,5,6])], 10), [(1, 4), (2, 5), (3, 6)])\ntest_eq(batch_to_samples([tensor([1,2,3]), tensor([4,5,6])], 2), [(1, 4), (2, 5)])\ntest_eq(batch_to_samples([tensor([1,2,3]), [tensor([4,5,6]),tensor([7,8,9])]], 10), \n        [(1, (4, 7)), (2, (5, 8)), (3, (6, 9))])\ntest_eq(batch_to_samples([tensor([1,2,3]), [tensor([4,5,6]),tensor([7,8,9])]], 2), [(1, (4, 7)), (2, (5, 8))])\n\nt = fastuple(tensor([1,2,3]),TensorBase([2,3,4]))\ntest_eq_type(batch_to_samples(t)[0][1], TensorBase(2))\ntest_eq(batch_to_samples(t).map(type), [fastuple]*3)\n\n\n\n\nTensor.interp_1d\n\n Tensor.interp_1d (x:torch.Tensor, xp, fp)\n\nSame as np.interp\n\nbrks = tensor(0,1,2,4,8,64).float()\nys = tensor(range_of(brks)).float()\nys /= ys[-1].item()\npts = tensor(0.2,0.5,0.8,3,5,63)\n\npreds = pts.interp_1d(brks, ys)\ntest_close(preds.numpy(), np.interp(pts.numpy(), brks.numpy(), ys.numpy()))\n\nplt.scatter(brks,ys)\nplt.scatter(pts,preds)\nplt.legend(['breaks','preds']);\n\n\n\n\n\n\n\nTensor.pca\n\n Tensor.pca (x:torch.Tensor, k=2)\n\nCompute PCA of x with k dimensions.\n\n\n\nlogit\n\n logit (x)\n\nLogit of x, clamped to avoid inf.\n\n\n\nnum_distrib\n\n num_distrib ()\n\nReturn the number of processes in distributed training (if applicable).\n\n\n\nrank_distrib\n\n rank_distrib ()\n\nReturn the distributed rank of this process (if applicable).\n\n\n\ndistrib_barrier\n\n distrib_barrier ()\n\nPlace a synchronization barrier in distributed training\nAfter calling this, ALL sub-processes in the pytorch process group must arrive here before proceeding.\n\n\n\nPath.save_array\n\n Path.save_array (p:pathlib.Path, o, complib='lz4', lvl=3)\n\nSave numpy array to a compressed pytables file, using compression level lvl\nCompression lib can be any of: blosclz, lz4, lz4hc, snappy, zlib or zstd.\n\n\n\nPath.load_array\n\n Path.load_array (p:pathlib.Path)\n\nSave numpy array to a pytables file\n\n\n\nbase_doc\n\n base_doc (elt)\n\nPrint a base documentation of elt\n\n\n\ndoc\n\n doc (elt)\n\nTry to use doc form nbdev and fall back to base_doc\n\n\n\nnested_reorder\n\n nested_reorder (t, idxs)\n\nReorder all tensors in t using idxs\n\nx = tensor([0,1,2,3,4,5])\nidxs = tensor([2,5,1,0,3,4])\ntest_eq_type(nested_reorder(([x], x), idxs), ([idxs], idxs))\n\ny = L(0,1,2,3,4,5)\nz = L(i.item() for i in idxs)\ntest_eq_type(nested_reorder((y, x), idxs), (z,idxs))\n\n\n\n\nflatten_check\n\n flatten_check (inp, targ)\n\nCheck that out and targ have the same number of elements and flatten them.\n\nx1,x2 = torch.randn(5,4),torch.randn(20)\nx1,x2 = flatten_check(x1,x2)\ntest_eq(x1.shape, [20])\ntest_eq(x2.shape, [20])\nx1,x2 = torch.randn(5,4),torch.randn(21)\ntest_fail(lambda: flatten_check(x1,x2))"
  },
  {
    "objectID": "00_Fastai/torch_core.html#image-helpers",
    "href": "00_Fastai/torch_core.html#image-helpers",
    "title": "Torch Core",
    "section": "Image helpers",
    "text": "Image helpers\n\n\nmake_cross_image\n\n make_cross_image (bw=True)\n\nCreate a tensor containing a cross image, either bw (True) or color\n\nplt.imshow(make_cross_image(), cmap=\"Greys\");\n\n\n\n\n\nplt.imshow(make_cross_image(False).permute(1,2,0));\n\n\n\n\n\n\n\nshow_image_batch\n\n show_image_batch (b, show=<function show_titled_image>, items=9, cols=3,\n                   figsize=None, **kwargs)\n\nDisplay batch b in a grid of size items with cols width\n\nshow_image_batch(([Image.open(TEST_IMAGE_BW),Image.open(TEST_IMAGE)],['bw','color']), items=2)"
  },
  {
    "objectID": "00_Fastai/torch_core.html#model-init",
    "href": "00_Fastai/torch_core.html#model-init",
    "title": "Torch Core",
    "section": "Model init",
    "text": "Model init\n\n\nrequires_grad\n\n requires_grad (m)\n\nCheck if the first parameter of m requires grad or not\n\ntst = nn.Linear(4,5)\nassert requires_grad(tst)\nfor p in tst.parameters(): p.requires_grad_(False)\nassert not requires_grad(tst)\n\n\n\n\ninit_default\n\n init_default (m, func=<function kaiming_normal_>)\n\nInitialize m weights with func and set bias to 0.\n\ntst = nn.Linear(4,5)\ntst.weight.data.uniform_(-1,1)\ntst.bias.data.uniform_(-1,1)\ntst = init_default(tst, func = lambda x: x.data.fill_(1.))\ntest_eq(tst.weight, torch.ones(5,4))\ntest_eq(tst.bias, torch.zeros(5))\n\n\n\n\ncond_init\n\n cond_init (m, func)\n\nApply init_default to m unless it’s a batchnorm module\n\ntst = nn.Linear(4,5)\ntst.weight.data.uniform_(-1,1)\ntst.bias.data.uniform_(-1,1)\ncond_init(tst, func = lambda x: x.data.fill_(1.))\ntest_eq(tst.weight, torch.ones(5,4))\ntest_eq(tst.bias, torch.zeros(5))\n\ntst = nn.BatchNorm2d(5)\ninit = [tst.weight.clone(), tst.bias.clone()]\ncond_init(tst, func = lambda x: x.data.fill_(1.))\ntest_eq(tst.weight, init[0])\ntest_eq(tst.bias, init[1])\n\n\n\n\napply_leaf\n\n apply_leaf (m, f)\n\nApply f to children of m.\n\ntst = nn.Sequential(nn.Linear(4,5), nn.Sequential(nn.Linear(4,5), nn.Linear(4,5)))\napply_leaf(tst, partial(init_default, func=lambda x: x.data.fill_(1.)))\nfor l in [tst[0], *tst[1]]: test_eq(l.weight, torch.ones(5,4))\nfor l in [tst[0], *tst[1]]: test_eq(l.bias,   torch.zeros(5))\n\n\n\n\napply_init\n\n apply_init (m, func=<function kaiming_normal_>)\n\nInitialize all non-batchnorm layers of m with func.\n\ntst = nn.Sequential(nn.Linear(4,5), nn.Sequential(nn.Linear(4,5), nn.BatchNorm1d(5)))\ninit = [tst[1][1].weight.clone(), tst[1][1].bias.clone()]\napply_init(tst, func=lambda x: x.data.fill_(1.))\nfor l in [tst[0], tst[1][0]]: test_eq(l.weight, torch.ones(5,4))\nfor l in [tst[0], tst[1][0]]: test_eq(l.bias,   torch.zeros(5))\ntest_eq(tst[1][1].weight, init[0])\ntest_eq(tst[1][1].bias,   init[1])"
  },
  {
    "objectID": "00_Fastai/torch_core.html#autograd-jit-functions",
    "href": "00_Fastai/torch_core.html#autograd-jit-functions",
    "title": "Torch Core",
    "section": "autograd jit functions",
    "text": "autograd jit functions\n\n\nscript_use_ctx\n\n script_use_ctx (f)\n\nDecorator: create jit script and pass everything in ctx.saved_variables tof, after*args`\n\n\n\nscript_save_ctx\n\n script_save_ctx (static, *argidx)\n\nDecorator: create jit script and save args with indices argidx using ctx.save_for_backward\n\n\n\nscript_fwd\n\n script_fwd (*argidx)\n\nDecorator: create static jit script and save args with indices argidx using ctx.save_for_backward\n\n\n\nscript_bwd\n\n script_bwd (f)\n\nDecorator: create static jit script and pass everything in ctx.saved_variables tof, after*args`\n\n\n\ngrad_module\n\n grad_module (cls)\n\nDecorator: convert cls into an autograd function\n\n\n\nismin_torch\n\n ismin_torch (min_version)\n\nCheck if torch.__version__ >= min_version using packaging.version\n\n\n\nnotmax_torch\n\n notmax_torch (max_version)\n\nCheck if torch.__version__ < max_version using packaging.version"
  },
  {
    "objectID": "07_Agents/02_Continuous/agents.ddpg.html",
    "href": "07_Agents/02_Continuous/agents.ddpg.html",
    "title": "DDPG",
    "section": "",
    "text": "(Lillicrap et al., 2016) [DDPG] Continuous Control with Deep Reinforcement Learning based on the DPG algorithm in (Silver et al., 2014) [DPG] Deterministic Policy Gradient Algorithms.\nDDPG uses an actor-critic architecture and has a similar training / learning paradym to DQNs.\nBelow is (Lillicrap et al., 2016) Algorithm 1 that summarizes DDPG."
  },
  {
    "objectID": "07_Agents/02_Continuous/agents.ddpg.html#model",
    "href": "07_Agents/02_Continuous/agents.ddpg.html#model",
    "title": "DDPG",
    "section": "Model",
    "text": "Model\n\n\ninit_xavier_uniform_weights\n\n init_xavier_uniform_weights (m:fastrl.torch_core.Module, bias=0.01)\n\nInitializes weights for linear layers using torch.nn.init.xavier_uniform_\n\n\n\ninit_uniform_weights\n\n init_uniform_weights (m:fastrl.torch_core.Module, bound)\n\nInitializes weights for linear layers using torch.nn.init.uniform_\n\n\n\ninit_kaiming_normal_weights\n\n init_kaiming_normal_weights (m:fastrl.torch_core.Module, bias=0.01)\n\nInitializes weights for linear layers using torch.nn.init.kaiming_normal_\nLilicrap et al., 2016 pg 11 notes: “The other layers were initialized from uniform distributions \\([ \\frac{-1}{\\sqrt{f}},\\frac{1}{\\sqrt{f}}]\\) where f is the fan-in of the layer.”\ninit_kaiming_normal_weights is the most similar to this strategy. Other implimentations of DDPGs have also used init_xavier_uniform_weights\n\nNote: There does not appear to be a major difference between performance of using either.\n\nThe same page notes: “final layer weights and biases of both the actor and critic were initialized from a uniform distribution \\([−3 * 10^{−3}, 3 * 10^{−3}]\\) and \\([3 * 10^{−4}, 3 * 10^{−4}]\\) for the low dimensional and pixel cases respectively.”, so the default value for final_layer_init_fn uses init_uniform_weights with a bound of 1e-4 for low dim, and if pixels, needs to be changed to 1e-5.\nThe same page notes: “The low-dimensional networks had 2 hidden layers with 400 and 300 units respectively … When learning from pixels we used 3 convolutional layers (no pooling) with 32 filters at each layer. This was followed by two fully connected layers with 200 units”\nWe default to expect low-dimensions, and for images we will augment this.\n\n\n\nddpg_conv2d_block\n\n ddpg_conv2d_block (state_sz:Tuple[int,int,int], filters=32,\n                    activation_fn=<class\n                    'torch.nn.modules.activation.ReLU'>,\n                    ignore_warning:bool=False)\n\nCreates a 3 layer conv block from state_sz along with expected n_feature output shape.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nstate_sz\ntyping.Tuple[int, int, int]\n\nA tuple of state sizes generally representing an image of format: [channel,width,height]\n\n\nfilters\nint\n32\nNumber of filters to use for each conv layer\n\n\nactivation_fn\ntype\nReLU\nActivation function between each layer.\n\n\nignore_warning\nbool\nFalse\nWe assume the channels dim should be size 3 max. If it is morewe assume the width/height are in the location of channel and need tobe transposed.\n\n\nReturns\ntyping.Tuple[torch.nn.modules.container.Sequential, int]\n\n(Convolutional block,n_features_out)\n\n\n\n\nddpg_conv2d_block((3,100,100))\n\n(Sequential(\n   (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n   (1): Conv2d(3, 3, kernel_size=(32, 32), stride=(1, 1))\n   (2): ReLU()\n   (3): Conv2d(3, 3, kernel_size=(32, 32), stride=(1, 1))\n   (4): ReLU()\n   (5): Conv2d(3, 3, kernel_size=(32, 32), stride=(1, 1))\n   (6): Flatten(start_dim=1, end_dim=-1)\n ),\n 147)\n\n\n\n\n\nCritic\n\n Critic (state_sz:int, action_sz:int, hidden1:int=400, hidden2:int=300,\n         head_layer:fastrl.torch_core.Module=<class\n         'torch.nn.modules.linear.Linear'>,\n         activation_fn:fastrl.torch_core.Module=<class\n         'torch.nn.modules.activation.ReLU'>,\n         weight_init_fn:Callable=<function init_kaiming_normal_weights>,\n         final_layer_init_fn:Callable=functools.partial(<function\n         init_uniform_weights at 0x7f75db31ef80>, bound=0.0001), conv_bloc\n         k:Union[torch.nn.modules.container.Sequential,NoneType]=None,\n         batch_norm:bool=False)\n\nTakes a 2 tensors of size [B,state_sz], [B,action_sz] -> [B,1] outputs a 1d tensor representing the Q value\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nstate_sz\nint\n\nThe input dim of the state / flattened conv output\n\n\naction_sz\nint\n\nThe input dim of the actions\n\n\nhidden1\nint\n400\nNumber of neurons connected between the 2 input/output layers\n\n\nhidden2\nint\n300\nNumber of neurons connected between the 2 input/output layers\n\n\nhead_layer\nModule\nLinear\nOutput layer\n\n\nactivation_fn\nModule\nReLU\nThe activation function\n\n\nweight_init_fn\ntyping.Callable\ninit_kaiming_normal_weights\nThe weight initialization strategy\n\n\nfinal_layer_init_fn\ntyping.Callable\nfunctools.partial(<function init_uniform_weights at 0x7f75db31ef80>, bound=0.0001)\nFinal layer initialization strategy\n\n\nconv_block\ntyping.Union[torch.nn.modules.container.Sequential, NoneType]\nNone\nFor pixel inputs, we can plug in a nn.Sequential block from ddpg_conv2d_block.This means that actions will be feed into the second linear layer instead of the first.\n\n\nbatch_norm\nbool\nFalse\nWhether to do batch norm.\n\n\n\nThe Critic is used by DDPG to estimate the Q value of state-action pairs and is updated using the the Bellman-Equation similarly to DQN/Q-Learning and is represeted by \\(Q(s,a)\\)\nCheck that low dim input works…\n\ntorch.manual_seed(0)\ncritic = Critic(4,2)\n\nstate = torch.randn(1,4)\naction = torch.randn(1,2)\n\nwith torch.no_grad(),evaluating(critic):\n    test_eq(\n        str(critic(state,action)),\n        str(tensor([[0.0083]]))\n    )\n\nCheck that image input works…\n\ntorch.manual_seed(0)\n\nimage_shape = (3,100,100)\n\nconv_block,feature_out = ddpg_conv2d_block(image_shape)\ncritic = Critic(feature_out,2,conv_block=conv_block)\n\nstate = torch.randn(1,*image_shape)\naction = torch.randn(1,2)\n\nwith torch.no_grad(),evaluating(critic):\n    test_eq(\n        str(critic(state,action)),\n        str(tensor([[0.0102]]))\n    )\n\n\n\n\nActor\n\n Actor (state_sz:int, action_sz:int, hidden1:int=400, hidden2:int=300,\n        head_layer:fastrl.torch_core.Module=<class\n        'torch.nn.modules.linear.Linear'>,\n        activation_fn:fastrl.torch_core.Module=<class\n        'torch.nn.modules.activation.ReLU'>,\n        weight_init_fn:Callable=<function init_kaiming_normal_weights>,\n        final_layer_init_fn:Callable=functools.partial(<function\n        init_uniform_weights at 0x7f75db31ef80>, bound=0.0001), conv_block\n        :Union[torch.nn.modules.container.Sequential,NoneType]=None,\n        batch_norm:bool=False)\n\nTakes a single tensor of size [B,state_sz] -> [B,action_sz] and outputs a tensor of actions.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nstate_sz\nint\n\nThe input dim of the state\n\n\naction_sz\nint\n\nThe output dim of the actions\n\n\nhidden1\nint\n400\nNumber of neurons connected between the 2 input/output layers\n\n\nhidden2\nint\n300\nNumber of neurons connected between the 2 input/output layers\n\n\nhead_layer\nModule\nLinear\nOutput layer\n\n\nactivation_fn\nModule\nReLU\nThe activiation function\n\n\nweight_init_fn\ntyping.Callable\ninit_kaiming_normal_weights\nThe weight initialization strategy\n\n\nfinal_layer_init_fn\ntyping.Callable\nfunctools.partial(<function init_uniform_weights at 0x7f75db31ef80>, bound=0.0001)\nFinal layer initialization strategy\n\n\nconv_block\ntyping.Union[torch.nn.modules.container.Sequential, NoneType]\nNone\nFor pixel inputs, we can plug in a nn.Sequential block from ddpg_conv2d_block.\n\n\nbatch_norm\nbool\nFalse\nWhether to do batch norm.\n\n\n\nThe Actor is used by DDPG to predict actions based on state inputs and is represeted by \\(\\mu(s|\\theta^\\mu)\\)\nCheck that low dim input works…\n\ntorch.manual_seed(0)\nactor = Actor(4,2)\n\nstate = torch.randn(1,4)\n\nwith torch.no_grad(),evaluating(actor):\n    test_eq(\n        str(actor(state)),\n        str(tensor([[0.0101, 0.0083]]))\n    )\n\nCheck that image input works…\n\ntorch.manual_seed(0)\n\nimage_shape = (3,100,100)\n\nconv_block,feature_out = ddpg_conv2d_block(image_shape)\nactor = Actor(feature_out,2,conv_block=conv_block)\n\nstate = torch.randn(1,*image_shape)\naction = torch.randn(1,2)\n\nwith torch.no_grad(),evaluating(actor):\n    test_eq(\n        str(actor(state)),\n        str(tensor([[0.0100, 0.0100]]))\n    )\n\n\n\n\npipe_to_device\n\n pipe_to_device (pipe, device, debug=False)\n\nAttempt to move an entire pipe and its pipeline to device"
  },
  {
    "objectID": "07_Agents/02_Continuous/agents.ddpg.html#ornstein-uhlenbeck-exploration",
    "href": "07_Agents/02_Continuous/agents.ddpg.html#ornstein-uhlenbeck-exploration",
    "title": "DDPG",
    "section": "Ornstein-Uhlenbeck Exploration",
    "text": "Ornstein-Uhlenbeck Exploration\n\n\nOrnsteinUhlenbeck\n\n OrnsteinUhlenbeck (*args, **kwds)\n\nUsed for exploration in continuous action domains via temporaly correlated noise.\n[1] From https://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n[2] Cumulatively based on Uhlenbeck et al., 1930\nThe OrnsteinUhlenbeck for DDPG has natation:\n\\(\\mu'(s_t)=\\mu(s_t|\\theta_{t}^{\\mu}) + N\\)\n\nNote: (Lilicrap et al., 2016) pg 4 says “generate temporally correlated exploration for exploration efficiency in physical control problems with inertia”. This might be important to consider when training on environments that don’t require inertia.\n\n\n\n\nExplorationComparisonLogger\n\n ExplorationComparisonLogger (*args, **kwds)\n\nAllows for quickly doing a “what if” on exploration methods by comparing the actions selected via exploration with the ones chosen by the model.\nBelow we demonstrate that the exploration works. As the number of steps increase, epsilon will decrease to zero, and so the actions slowly become more deterministic.\n\ntorch.manual_seed(0)\n\nactions = dp.iter.IterableWrapper(\n    # Batch of 4 actions with dimensions 2\n    torch.randn(4,2).to(device=default_device())\n)\n\nactions = OrnsteinUhlenbeck(\n    actions,\n    min_epsilon=0,\n    max_steps=200,\n    action_sz=2,\n    decrement_on_val=True,\n    explore_on_val=True,\n    ret_original=True\n)\nactions.to(device=default_device())\nactions = actions.cycle(count=50)\nactions = ExplorationComparisonLogger(actions)\nlist(actions)\nactions.show()"
  },
  {
    "objectID": "07_Agents/02_Continuous/agents.ddpg.html#agent",
    "href": "07_Agents/02_Continuous/agents.ddpg.html#agent",
    "title": "DDPG",
    "section": "Agent",
    "text": "Agent\n\n\nActionUnbatcher\n\n ActionUnbatcher (*args, **kwds)\n\nRemoves the batch dim from an action.\n\n\n\nActionClip\n\n ActionClip (*args, **kwds)\n\nRestricts actions from source_datapipe between clip_min and clip_max\nInterally calls torch.clip\n\n\n\nDDPGAgent\n\n DDPGAgent (model:__main__.Actor,\n            logger_bases:Union[fastrl.loggers.core.LoggerBase,NoneType]=No\n            ne, min_epsilon:float=0.2, max_epsilon:float=1,\n            max_steps:int=100, dp_augmentation_fns:Union[List[fastrl.pipes\n            .core.DataPipeAugmentationFn],NoneType]=None)\n\nProduces continuous action outputs.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodel\nActor\n\nThe actor to use for mapping states to actions\n\n\nlogger_bases\ntyping.Union[fastrl.loggers.core.LoggerBase, NoneType]\nNone\nLoggerBases push logs to. If None, logs will be collected and outputby the dataloader.\n\n\nmin_epsilon\nfloat\n0.2\nThe minimum epsilon to drop to\n\n\nmax_epsilon\nfloat\n1\nThe max/starting epsilon if epsilon is None and used for calculating epislon decrease speed.\n\n\nmax_steps\nint\n100\nDetermines how fast the episilon should drop to min_epsilon. This should be the numberof steps that the agent was run through.\n\n\ndp_augmentation_fns\ntyping.Union[typing.List[fastrl.pipes.core.DataPipeAugmentationFn], NoneType]\nNone\nAny augmentations to the DDPG agent.\n\n\nReturns\nAgentHead\n\n\n\n\n\nCheck that given a step, we can get actions from the DDPGAgent…\n\ntorch.manual_seed(0)\n\nactor = Actor(4,2)\n\nagent = DDPGAgent(actor)\n\ninput_tensor = tensor([1,2,3,4]).float()\nstep = SimpleStep(state=input_tensor)\n\nfor _ in range(10):\n    for action in agent([step]):\n        print(action)\n\n[0.91868794 0.7928086 ]\n[0.89038295 1.        ]\n[0.59973884 0.5640401 ]\n[0.8244315 0.6234891]\n[0.6276505  0.41781008]\n[0.59242374 0.68170094]\n[0.339647   0.42176256]\n[0.5469213  0.11551299]\n[ 0.34022635 -0.23093009]\n[ 0.33037645 -0.13671152]\n\n\n\nfrom fastrl.envs.gym import GymTransformBlock\nfrom fastrl.loggers.vscode_visualizers import VSCodeTransformBlock"
  },
  {
    "objectID": "07_Agents/02_Continuous/agents.ddpg.html#learner",
    "href": "07_Agents/02_Continuous/agents.ddpg.html#learner",
    "title": "DDPG",
    "section": "Learner",
    "text": "Learner\n\n\nBasicOptStepper\n\n BasicOptStepper (*args, **kwds)\n\nOptimizes model using opt. source_datapipe must produce a dictionary of format: {\"loss\":...}, otherwise all non-dicts will be passed through.\n\n\n\nLossCollector\n\n LossCollector (*args, **kwds)\n\nItercepts dictionary results generated from source_datapipe that are in the format: {'loss':tensor(...)}. All other elements will be ignored and passed through.\nIf filter=true, then intercepted dictionaries will filtered out by this pipe, and will not be propagated to the rest of the pipeline.\n\n\n\nSoftTargetUpdater\n\n SoftTargetUpdater (*args, **kwds)\n\nSoft-Copies model to a target_model (internal) every target_sync batches.\nWe use SoftTargetUpdater to update the target Critic and Actor. This is characterized by the notation:\n\\[\n\\theta^{Q'} \\leftarrow \\tau \\theta^Q + (1 - \\tau)\\theta^{Q'}\n\\] \\[\n\\theta^{\\mu'} \\leftarrow \\tau \\theta^\\mu + (1 - \\tau)\\theta^{\\mu'}\n\\]\nFor both the Critic(Q) and Actor(\\(\\mu\\)) are slowly copied to their targets based on the value \\(\\tau\\)\n\n\n\nget_target_model\n\n get_target_model (model:Union[torch.nn.modules.module.Module,NoneType], p\n                   ipe:Union[torch.utils.data.datapipes.datapipe.IterDataP\n                   ipe,torch.utils.data.datapipes.datapipe.MapDataPipe],\n                   model_cls:torch.nn.modules.module.Module, target_update\n                   r_cls:Tuple[Union[torch.utils.data.datapipes.datapipe.I\n                   terDataPipe,torch.utils.data.datapipes.datapipe.MapData\n                   Pipe]]=(<class '__main__.SoftTargetUpdater'>,),\n                   debug:bool=False)\n\nBasic utility for getting the ‘target’ version of model_cls in pipe\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodel\ntyping.Union[torch.nn.modules.module.Module, NoneType]\n\nIf model is not none, then we assume it to be the target modeland simply return it, otherwise we search for a target_model\n\n\npipe\ntyping.Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe]\n\nThe pipe to start search along\n\n\nmodel_cls\nModule\n\nThe class of the model we are looking for\n\n\ntarget_updater_cls\ntyping.Tuple[typing.Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe]]\n(<class ‘main.SoftTargetUpdater’>,)\nA tuple of datapipes that have a field called target_model.get_target_model will look for these in pipe\n\n\ndebug\nbool\nFalse\nVerbose output\n\n\n\n\n\n\nCriticLossProcessor\n\n CriticLossProcessor (*args, **kwds)\n\nProduces a critic loss based on critic,t_actor,t_critic and batch StepTypes from source_datapipe where the targets and predictions are fed into loss.\nThis datapipe produces either Dict[Literal[‘loss’],torch.Tensor] or SimpleStep.\nFrom (Lilicrap et al., 2016), we expect to get N transitions from \\(R\\) where \\(R\\) is source_datapipe.\n\\(N\\) transitions \\((s_i, a_i, r_i, s_{i+1})\\) from \\(R\\) where \\((s_i, a_i, r_i, s_{i+1})\\) are StepType\nThe targets are similar to DQN since we are estimating the \\(Q\\) value:\n\\(y_i = r_i + \\gamma Q' (s_{i+1}, \\mu'(s_{i+1} | \\theta^{\\mu'})|\\theta^{Q'})\\)\nWhere \\(y_i\\) is the targets, \\(\\gamma\\) is the discount**nsteps, \\(Q'\\) is the t_critic, \\(\\mu'\\) is the t_actor.\n\\(\\mu'(s_{i+1} | \\theta^{\\mu'})\\) is the t_actors predicted actions of s_{i+1}\nUpdate critic by minimizing the loss: \\(L = \\frac{1}{N}\\sum_i{y_i - Q(s_i,a_i|\\theta^Q))^2}\\)\nWhere \\(Q(s_i,a_i|\\theta^Q)\\) is critic(batch.state,batch.action) and anything with \\(\\frac{1}{N}\\sum_i{(...)}^2\\) is just nn.MSELoss\n\ntorch.manual_seed(0)\npipe = GymTransformBlock(agent=None,n=1000,bs=64,seed=0)(['Pendulum-v1'])\npipe = StepBatcher(pipe)\n\nactor = Actor(3,1)\ncritic = Critic(3,1)\n\npipe = SoftTargetUpdater(pipe,critic)\npipe = CriticLossProcessor(pipe,critic,actor)\n\npipe_loss = LossCollector(pipe,main_buffers=[[]])\npipe = BasicOptStepper(pipe_loss,critic,1e-3)\nlist(pipe)\npipe_loss.show(title='Critic Loss over N-Steps')\n\n\n                                                \n\n\n\n\n\nActorLossProcessor\n\n ActorLossProcessor (*args, **kwds)\n\nProduces a critic loss based on critic,actor and batch StepTypes from source_datapipe where the targets and predictions are fed into loss.\n(Lilicrap et al., 2016) notes: “The actor is updated by following the applying the chain rule to the expected return from the start distribution J with respect to the actor parameters”\nThe loss is defined as the “policy gradient” below:\n\\[\n\\nabla_{\\theta^{\\mu}} J \\approx \\frac{1}{N} \\sum_i{\\nabla_aQ(s,a|\\theta^Q)|_{s={s_i},a={\\mu(s_i)}}\\nabla_{\\theta^{\\mu}\\mu(s|\\theta^Q)|_{s_i}}}\n\\]\nWhere:\n\\(\\frac{1}{N} \\sum_i\\) is the mean.\n\\(\\nabla_{\\theta^{\\mu}\\mu(s|\\theta^Q)|_{s_i}}\\) is the actor output.\n\\(\\nabla_aQ(s,a|\\theta^Q)|_{s={s_i},a={\\mu(s_i)}}\\) is the critic output, using actions from the actor.\n\nImportant: A little confusing point, \\(\\nabla\\) is the gradient/derivative of both. The point of the loss is that we want to select actions that have critic output higher values. We can do this by first calling CriticLossProcessor to load critic with gradients, then run it again but with the actor inputs. We want the actor to have the critic produce more positive gradients, than negative i.e: Have actions that maximize the critic outputs. The confusing thing is since pytorch has autograd, the actual code is not going to match the math above, for good and bad.\n\nTODO: It would be helpful if this documentation can be better explained.\n\nNote: We actually multiply J by -1 since the optimizer is trying to make the value as “small” as possible, but the actual value we want to be as big as possible. So if we have a J of 100 (high reward), it becomes -100, letting the optimizer know that it is moving is the correct direction (the more negative, the better).\n\n\nactor = Actor(3,1)\ncritic = Critic(3,1)\n\nagent = DDPGAgent(actor,max_steps=10000)\n\npipe = GymTransformBlock(agent=agent,n=1000,bs=10)(['Pendulum-v1'])\npipe = StepBatcher(pipe)\n\npipe = ActorLossProcessor(pipe,critic,actor)\n\npipe_loss = LossCollector(pipe,main_buffers=[[]])\npipe = BasicOptStepper(pipe_loss,actor,1e-3)\nlist(pipe)\npipe_loss.show()\n\n\n                                                \n\n\n\n\n\nDDPGLearner\n\n DDPGLearner (actor:__main__.Actor, critic:__main__.Critic, dls:List[Union\n              [torch.utils.data.datapipes.datapipe.IterDataPipe,torch.util\n              s.data.datapipes.datapipe.MapDataPipe,torchdata.dataloader2.\n              dataloader2.DataLoader2]], logger_bases:Union[List[fastrl.lo\n              ggers.core.LoggerBase],NoneType]=None, actor_lr:float=0.001,\n              actor_opt:torch.optim.optimizer.Optimizer=<class\n              'torch.optim.adam.Adam'>, critic_lr:float=0.01,\n              critic_opt:torch.optim.optimizer.Optimizer=<class\n              'torch.optim.adam.Adam'>, critic_target_copy_freq:int=1,\n              actor_target_copy_freq:int=1, tau:float=0.001, bs:int=128,\n              max_sz:int=10000, nsteps:int=1, device:torch.device=None,\n              batches:int=None, dp_augmentation_fns:Union[List[fastrl.pipe\n              s.core.DataPipeAugmentationFn],NoneType]=None,\n              debug:bool=False)\n\nDDPG is a continuous action, actor-critic model, first created in (Lilicrap et al., 2016). The critic estimates a Q value estimate, and the actor attempts to maximize that Q value.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nactor\nActor\n\nThe actor model to use\n\n\ncritic\nCritic\n\nThe critic model to use\n\n\ndls\ntyping.List[typing.Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe, torchdata.dataloader2.dataloader2.DataLoader2]]\n\nA list of dls, where index=0 is the training dl.\n\n\nlogger_bases\ntyping.Union[typing.List[fastrl.loggers.core.LoggerBase], NoneType]\nNone\nOptional logger bases to log training/validation data to.\n\n\nactor_lr\nfloat\n0.001\nThe learning rate for the actor. Expected to learn slower than the critic\n\n\nactor_opt\nOptimizer\nAdam\nThe optimizer for the actor\n\n\ncritic_lr\nfloat\n0.01\nThe learning rate for the critic. Expected to learn faster than the actor\n\n\ncritic_opt\nOptimizer\nAdam\nThe optimizer for the criticNote that weight decay doesnt seem to be great for Pendulum, so we use regular Adam, which has the decay rateset to 0. (Lilicrap et al., 2016) would instead use AdamW\n\n\ncritic_target_copy_freq\nint\n1\nReference: SoftTargetUpdater docs\n\n\nactor_target_copy_freq\nint\n1\nReference: SoftTargetUpdater docs\n\n\ntau\nfloat\n0.001\nReference: SoftTargetUpdater docs\n\n\nbs\nint\n128\nReference: ExperienceReplay docs\n\n\nmax_sz\nint\n10000\nReference: ExperienceReplay docs\n\n\nnsteps\nint\n1\nReference: GymStepper docs\n\n\ndevice\ndevice\nNone\nThe device for the entire pipeline to use. Will move the agent, dls, and learner to that device.\n\n\nbatches\nint\nNone\nNumber of batches per epoch\n\n\ndp_augmentation_fns\ntyping.Union[typing.List[fastrl.pipes.core.DataPipeAugmentationFn], NoneType]\nNone\nAny augmentations to the learner\n\n\ndebug\nbool\nFalse\nDebug mode will output device moves\n\n\nReturns\nLearnerHead\n\n\n\n\n\n\n# Setup Loggers\nlogger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                 batch_on_pipe=BatchCollector)\n\n# Setup up the core NN\ntorch.manual_seed(0)\nactor = Actor(3,1)\ncritic = Critic(3,1)\n\n# Setup the Agent\nagent = DDPGAgent(actor,[logger_base],max_steps=5000,min_epsilon=0.1)\n\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True), \n    (GymTransformBlock(agent=agent,n=400,nsteps=2,nskips=2,firstlast=True,include_images=True),VSCodeTransformBlock())\n)\ndls = L(block.dataloaders(['Pendulum-v1']*1))\n# Setup the Learner\nlearner = DDPGLearner(actor,critic,dls,logger_bases=[logger_base],\n                      bs=128,max_sz=20_000,nsteps=2,\n                      batches=1000)\n# learner.fit(1)\nlearner.fit(15)\n\n\n\n\n\n\n\n  \n    \n      actor-loss\n      critic-loss\n      episode\n      rolling_reward\n      epoch\n      batch\n    \n  \n  \n    \n      23.484377\n      2.7217586\n      10\n      -1606.006924\n      1\n      1001\n    \n    \n      31.69706\n      12.016734\n      20\n      -1542.288166\n      2\n      1001\n    \n    \n      40.06336\n      25.084415\n      30\n      -1472.712552\n      3\n      1001\n    \n    \n      50.46943\n      7.714135\n      40\n      -1450.873017\n      4\n      1001\n    \n    \n      59.180523\n      17.604204\n      50\n      -1406.556492\n      5\n      1001\n    \n    \n      67.14108\n      46.2947\n      60\n      -1338.766411\n      6\n      1001\n    \n    \n      68.84964\n      16.201414\n      70\n      -1135.972938\n      7\n      1001\n    \n    \n      69.09436\n      143.93195\n      80\n      -993.549349\n      8\n      1001\n    \n    \n      69.35192\n      25.970486\n      90\n      -817.256042\n      9\n      1001\n    \n    \n      73.09758\n      171.4342\n      100\n      -673.698936\n      10\n      1001\n    \n    \n      74.067116\n      261.42377\n      110\n      -546.182211\n      11\n      1001\n    \n    \n      71.98171\n      119.34804\n      119\n      -492.149361\n      12\n      1001\n    \n    \n      72.43381\n      239.37431\n      129\n      -445.763457\n      13\n      1001\n    \n    \n      74.57726\n      23.358807\n      139\n      -408.875556\n      14\n      1001\n    \n    \n      61.790493\n      230.8901\n      149\n      -369.512350\n      14\n      1001"
  },
  {
    "objectID": "07_Agents/01_Discrete/agents.dqn.asynchronous.html",
    "href": "07_Agents/01_Discrete/agents.dqn.asynchronous.html",
    "title": "DQN Async",
    "section": "",
    "text": "There is a little weirdness using cuda with spawn. pytorch has a bug: https://github.com/pytorch/pytorch/issues/30401 so queue usage isnt so simple"
  },
  {
    "objectID": "07_Agents/01_Discrete/agents.dqn.asynchronous.html#training-datapipes",
    "href": "07_Agents/01_Discrete/agents.dqn.asynchronous.html#training-datapipes",
    "title": "DQN Async",
    "section": "Training DataPipes",
    "text": "Training DataPipes\n\n\nModelSubscriber\n\n ModelSubscriber (*args, **kwds)\n\nIf an agent is passed to another process and ‘spawn’ start method is used, then this module is needed.\n\n\n\nModelPublisher\n\n ModelPublisher (*args, **kwds)\n\nIterable-style DataPipe.\nAll DataPipes that represent an iterable of data samples should subclass this. This style of DataPipes is particularly useful when data come from a stream, or when the number of samples is too large to fit them all in memory. IterDataPipe is lazily initialized and its elements are computed only when next() is called on the iterator of an IterDataPipe.\nAll subclasses should overwrite :meth:__iter__, which would return an iterator of samples in this DataPipe. Calling __iter__ of an IterDataPipe automatically invokes its method reset(), which by default performs no operation. When writing a custom IterDataPipe, users should override reset() if necessary. The common usages include resetting buffers, pointers, and various state variables within the custom IterDataPipe.\nNote: Only one iterator can be valid for each IterDataPipe at a time, and the creation a second iterator will invalidate the first one. This constraint is necessary because some IterDataPipe have internal buffers, whose states can become invalid if there are multiple iterators. The code example below presents details on how this constraint looks in practice. If you have any feedback related to this constraint, please see GitHub IterDataPipe Single Iterator Issue_.\nThese DataPipes can be invoked in two ways, using the class constructor or applying their functional form onto an existing IterDataPipe (recommended, available to most but not all DataPipes). You can chain multiple IterDataPipe together to form a pipeline that will perform multiple operations in succession.\n.. _GitHub IterDataPipe Single Iterator Issue: https://github.com/pytorch/data/issues/45\nNote: When a subclass is used with :class:~torch.utils.data.DataLoader, each item in the DataPipe will be yielded from the :class:~torch.utils.data.DataLoader iterator. When :attr:num_workers > 0, each worker process will have a different copy of the DataPipe object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. :func:~torch.utils.data.get_worker_info, when called in a worker process, returns information about the worker. It can be used in either the dataset’s :meth:__iter__ method or the :class:~torch.utils.data.DataLoader ’s :attr:worker_init_fn option to modify each copy’s behavior.\nExamples: General Usage: >>> # xdoctest: +SKIP >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> map_dp_1 = Mapper(dp, lambda x: x + 1) # Using class constructor >>> map_dp_2 = dp.map(lambda x: x + 1) # Using functional form (recommended) >>> list(map_dp_1) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> list(map_dp_2) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> filter_dp = map_dp_1.filter(lambda x: x % 2 == 0) >>> list(filter_dp) [2, 4, 6, 8, 10] Single Iterator Constraint Example: >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> it1 = iter(source_dp) >>> list(it1) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> it1 = iter(source_dp) >>> it2 = iter(source_dp) # The creation of a new iterator invalidates it1 >>> next(it2) 0 >>> next(it1) # Further usage of it1 will raise a RunTimeError\nTry training with basic defaults…\n\nimport torch\nfrom torch.nn import *\nimport torch.nn.functional as F\nfrom fastrl.loggers.core import *\nfrom fastrl.loggers.jupyter_visualizers import *\nfrom fastrl.learner.core import *\nfrom fastrl.data.block import *\nfrom fastrl.envs.gym import *\nfrom fastrl.agents.core import *\nfrom fastrl.agents.discrete import *\nfrom fastrl.agents.dqn.basic import *\n\nlogger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                 batch_on_pipe=BatchCollector)\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2).cuda()\n# model.share_memory() # This will not work in spawn\n# Setup the Agent\nagent = DQNAgent(model,max_steps=4000,device='cuda',\n                 dp_augmentation_fns=[ModelSubscriber.insert_dp()])\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False),\n    GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False,include_images=True)\n)\ndls = L(block.dataloaders(['CartPole-v1']*1,num_workers=1))\n# # Setup the Learner\nlearner = DQNLearner(model,dls,batches=1000,logger_bases=[logger_base],bs=128,max_sz=100_000,device='cuda',\n                     dp_augmentation_fns=[ModelPublisher.insert_dp()]\n                     )\n# learner.fit(2)\n\n\n# %%python\n\nif __name__=='__main__':\n    from torch.multiprocessing import Pool, Process, set_start_method\n    \n    try:\n        set_start_method('spawn')\n    except RuntimeError:\n        pass\n    \n    from fastcore.all import *\n    import torch\n    from torch.nn import *\n    import torch.nn.functional as F\n    from fastrl.loggers.core import *\n    from fastrl.loggers.jupyter_visualizers import *\n    from fastrl.learner.core import *\n    from fastrl.data.block import *\n    from fastrl.envs.gym import *\n    from fastrl.agents.core import *\n    from fastrl.agents.discrete import *\n    from fastrl.agents.dqn.basic import *\n    from fastrl.agents.dqn.asynchronous import *\n    \n    from torchdata.dataloader2 import DataLoader2\n    from torchdata.dataloader2.graph import traverse\n    from fastrl.data.dataloader2 import *\n    \n    logger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                    batch_on_pipe=BatchCollector)\n\n    # Setup up the core NN\n    torch.manual_seed(0)\n    model = DQN(4,2).cuda()\n    # model.share_memory() # This will not work in spawn\n    # Setup the Agent\n    agent = DQNAgent(model,max_steps=4000,device='cuda',\n                    dp_augmentation_fns=[ModelSubscriber.insert_dp()])\n    # Setup the DataBlock\n    block = DataBlock(\n        GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False),\n        GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False,include_images=True)\n    )\n    dls = L(block.dataloaders(['CartPole-v1']*1,num_workers=1))\n    # # Setup the Learner\n    learner = DQNLearner(model,dls,batches=1000,logger_bases=[logger_base],bs=128,max_sz=100_000,device='cuda',\n                        dp_augmentation_fns=[ModelPublisher.insert_dp(publish_freq=10)])\n    # print(traverse(learner))\n    learner.fit(20)\n\nOverwriting ../../external_run_scripts/agents_dqn_async_35.py"
  },
  {
    "objectID": "07_Agents/01_Discrete/agents.discrete.html",
    "href": "07_Agents/01_Discrete/agents.discrete.html",
    "title": "Agent Discrete",
    "section": "",
    "text": "ArgMaxer\n\n ArgMaxer (*args, **kwds)\n\nIterable-style DataPipe.\nAll DataPipes that represent an iterable of data samples should subclass this. This style of DataPipes is particularly useful when data come from a stream, or when the number of samples is too large to fit them all in memory. IterDataPipe is lazily initialized and its elements are computed only when next() is called on the iterator of an IterDataPipe.\nAll subclasses should overwrite :meth:__iter__, which would return an iterator of samples in this DataPipe. Calling __iter__ of an IterDataPipe automatically invokes its method reset(), which by default performs no operation. When writing a custom IterDataPipe, users should override reset() if necessary. The common usages include resetting buffers, pointers, and various state variables within the custom IterDataPipe.\nNote: Only one iterator can be valid for each IterDataPipe at a time, and the creation a second iterator will invalidate the first one. This constraint is necessary because some IterDataPipe have internal buffers, whose states can become invalid if there are multiple iterators. The code example below presents details on how this constraint looks in practice. If you have any feedback related to this constraint, please see GitHub IterDataPipe Single Iterator Issue_.\nThese DataPipes can be invoked in two ways, using the class constructor or applying their functional form onto an existing IterDataPipe (recommended, available to most but not all DataPipes). You can chain multiple IterDataPipe together to form a pipeline that will perform multiple operations in succession.\n.. _GitHub IterDataPipe Single Iterator Issue: https://github.com/pytorch/data/issues/45\nNote: When a subclass is used with :class:~torch.utils.data.DataLoader, each item in the DataPipe will be yielded from the :class:~torch.utils.data.DataLoader iterator. When :attr:num_workers > 0, each worker process will have a different copy of the DataPipe object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. :func:~torch.utils.data.get_worker_info, when called in a worker process, returns information about the worker. It can be used in either the dataset’s :meth:__iter__ method or the :class:~torch.utils.data.DataLoader ’s :attr:worker_init_fn option to modify each copy’s behavior.\nExamples: General Usage: >>> # xdoctest: +SKIP >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> map_dp_1 = Mapper(dp, lambda x: x + 1) # Using class constructor >>> map_dp_2 = dp.map(lambda x: x + 1) # Using functional form (recommended) >>> list(map_dp_1) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> list(map_dp_2) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> filter_dp = map_dp_1.filter(lambda x: x % 2 == 0) >>> list(filter_dp) [2, 4, 6, 8, 10] Single Iterator Constraint Example: >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> it1 = iter(source_dp) >>> list(it1) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> it1 = iter(source_dp) >>> it2 = iter(source_dp) # The creation of a new iterator invalidates it1 >>> next(it2) 0 >>> next(it1) # Further usage of it1 will raise a RunTimeError\n\n# class DQN(Module):\n#     def __init__(self,state_sz:int,action_sz:int,hidden=512):\n#         self.layers=Sequential(\n#             Linear(state_sz,hidden),\n#             ReLU(),\n#             Linear(hidden,action_sz),\n#         )\n#     def forward(self,x): return self.layers(x)\n\n\nfrom fastrl.agents.dqn.basic import DQN\n\n\n# from fastrl.agents.dqn.basic import DQN\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2)\n# Setup the agent\nagent = AgentBase(model)\nagent = StepFieldSelector(agent,field='state')\nagent = SimpleModelRunner(agent)\nagent = ArgMaxer(agent)\nagent = AgentHead(agent)\n\nfor action in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n    print(action)\n\ntraverse(agent)\n\ntensor([[1, 0]])\n\n\n{140047797327504: (AgentHead,\n  {140047624286480: (ArgMaxer,\n    {140047623235216: (SimpleModelRunner,\n      {140047623536912: (StepFieldSelector,\n        {140047623234960: (AgentBase, {})}),\n       140047623234960: (AgentBase, {})})}),\n   140047623234960: (AgentBase, {})})}\n\n\n\n\n\nEpsilonSelector\n\n EpsilonSelector (*args, **kwds)\n\nIterable-style DataPipe.\nAll DataPipes that represent an iterable of data samples should subclass this. This style of DataPipes is particularly useful when data come from a stream, or when the number of samples is too large to fit them all in memory. IterDataPipe is lazily initialized and its elements are computed only when next() is called on the iterator of an IterDataPipe.\nAll subclasses should overwrite :meth:__iter__, which would return an iterator of samples in this DataPipe. Calling __iter__ of an IterDataPipe automatically invokes its method reset(), which by default performs no operation. When writing a custom IterDataPipe, users should override reset() if necessary. The common usages include resetting buffers, pointers, and various state variables within the custom IterDataPipe.\nNote: Only one iterator can be valid for each IterDataPipe at a time, and the creation a second iterator will invalidate the first one. This constraint is necessary because some IterDataPipe have internal buffers, whose states can become invalid if there are multiple iterators. The code example below presents details on how this constraint looks in practice. If you have any feedback related to this constraint, please see GitHub IterDataPipe Single Iterator Issue_.\nThese DataPipes can be invoked in two ways, using the class constructor or applying their functional form onto an existing IterDataPipe (recommended, available to most but not all DataPipes). You can chain multiple IterDataPipe together to form a pipeline that will perform multiple operations in succession.\n.. _GitHub IterDataPipe Single Iterator Issue: https://github.com/pytorch/data/issues/45\nNote: When a subclass is used with :class:~torch.utils.data.DataLoader, each item in the DataPipe will be yielded from the :class:~torch.utils.data.DataLoader iterator. When :attr:num_workers > 0, each worker process will have a different copy of the DataPipe object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. :func:~torch.utils.data.get_worker_info, when called in a worker process, returns information about the worker. It can be used in either the dataset’s :meth:__iter__ method or the :class:~torch.utils.data.DataLoader ’s :attr:worker_init_fn option to modify each copy’s behavior.\nExamples: General Usage: >>> # xdoctest: +SKIP >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> map_dp_1 = Mapper(dp, lambda x: x + 1) # Using class constructor >>> map_dp_2 = dp.map(lambda x: x + 1) # Using functional form (recommended) >>> list(map_dp_1) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> list(map_dp_2) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> filter_dp = map_dp_1.filter(lambda x: x % 2 == 0) >>> list(filter_dp) [2, 4, 6, 8, 10] Single Iterator Constraint Example: >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> it1 = iter(source_dp) >>> list(it1) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> it1 = iter(source_dp) >>> it2 = iter(source_dp) # The creation of a new iterator invalidates it1 >>> next(it2) 0 >>> next(it1) # Further usage of it1 will raise a RunTimeError\nCheck that when min_epsilon=1, that the actions have 100% likihood of randomness applied (even though some might not change due to the random action matching the chosen action). Check that this works on a large batch of 200 steps…\n\nagent = AgentBase(model)\nagent = StepFieldSelector(agent,field='state')\nagent = SimpleModelRunner(agent)\nagent = ArgMaxer(agent)\nselector = EpsilonSelector(agent,min_epsilon=1,ret_mask=True)\nagent = AgentHead(selector)\n\nfor action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n    test_eq(mask.sum(),200)\n    test_ne(action.sum(0)[0],200) # Only some of the actions should 1\n    test_ne(action.sum(0)[1],0) # Only some of the actions should be 0\n    test_eq(selector.epsilon,1)\n    test_eq(selector.step,1)\n\ntraverse(agent)\n\n{140047623236880: (AgentHead,\n  {140047623235856: (EpsilonSelector,\n    {140047623234448: (ArgMaxer,\n      {140047623234512: (SimpleModelRunner,\n        {140047623234704: (StepFieldSelector,\n          {140047623237328: (AgentBase, {})}),\n         140047623237328: (AgentBase, {})})}),\n     140047623237328: (AgentBase, {})}),\n   140047623237328: (AgentBase, {})})}\n\n\nCheck that when min_epsilon=1, that the actions have 100% likihood of randomness applied (even though some might not change due to the random action matching the chosen action). Check that this works on single batches over 200 steps…\n\nArgMaxer.debug=False\n\n\nagent = AgentBase(model)\nagent = StepFieldSelector(agent,field='state')\nagent = SimpleModelRunner(agent)\nagent = ArgMaxer(agent,axis=1)\nselector = EpsilonSelector(agent,min_epsilon=1,ret_mask=True)\nagent = AgentHead(selector)\n\nactions = None\nfor i in range(200):\n    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n        test_eq(mask.sum(),1)\n        if actions is None: actions = action\n        else:               actions = torch.vstack((actions,action))\ntest_ne(actions.sum(0)[0],200) # Only some of the actions should 1\ntest_ne(actions.sum(0)[1],0) # Only some of the actions should be 0\ntest_eq(selector.epsilon,1)\ntest_eq(selector.step,200)\ntraverse(agent)\n\n{140047623595664: (AgentHead,\n  {140047623595216: (EpsilonSelector,\n    {140047623594704: (ArgMaxer,\n      {140047623595728: (SimpleModelRunner,\n        {140047623597712: (StepFieldSelector,\n          {140047623594896: (AgentBase, {})}),\n         140047623594896: (AgentBase, {})})}),\n     140047623594896: (AgentBase, {})}),\n   140047623594896: (AgentBase, {})})}\n\n\nCheck that when min_epsilon=0 and max_epsilon=0, that the actions have 0% likihood of randomness applied. Check that this works on a large batch of 200 steps…\n\nagent = AgentBase(model)\nagent = StepFieldSelector(agent,field='state')\nagent = SimpleModelRunner(agent)\nagent = ArgMaxer(agent)\nselector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=0,ret_mask=True)\nagent = AgentHead(selector)\n\nfor action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n    test_eq(mask.sum(),0)\n    test_eq(action.sum(0)[0],200) # All the \"left\" actions should be 1\n    test_eq(action.sum(0)[1],0) # All the \"right\" actions should be 0\n    test_eq(selector.epsilon,0)\n    test_eq(selector.step,1)\ntraverse(agent)\n\n{140047796955600: (AgentHead,\n  {140047796956048: (EpsilonSelector,\n    {140047796954256: (ArgMaxer,\n      {140047796956688: (SimpleModelRunner,\n        {140047796956496: (StepFieldSelector,\n          {140047796954896: (AgentBase, {})}),\n         140047796954896: (AgentBase, {})})}),\n     140047796954896: (AgentBase, {})}),\n   140047796954896: (AgentBase, {})})}\n\n\nCheck that when min_epsilon=0 and max_epsilon=0, that the actions have 0% likihood of randomness applied. Check that this works on single batches over 200 steps…\n\nagent = AgentBase(model)\nagent = StepFieldSelector(agent,field='state')\nagent = SimpleModelRunner(agent)\nagent = ArgMaxer(agent)\nselector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=0,ret_mask=True)\nagent = AgentHead(selector)\n\nactions = None\nfor i in range(200):\n    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n        test_eq(mask.sum(),0)\n        if actions is None: actions = action\n        else:               actions = torch.vstack((actions,action))\ntest_eq(actions.sum(0)[0],200) # All the \"left\" actions should be 1\ntest_eq(actions.sum(0)[1],0) # All the \"right\" actions should be 0\ntest_eq(selector.epsilon,0)\ntest_eq(selector.step,200)\ntraverse(agent)\n\n{140047799059920: (AgentHead,\n  {140047623596816: (EpsilonSelector,\n    {140047623597008: (ArgMaxer,\n      {140047623595024: (SimpleModelRunner,\n        {140047623594320: (StepFieldSelector,\n          {140047623597328: (AgentBase, {})}),\n         140047623597328: (AgentBase, {})})}),\n     140047623597328: (AgentBase, {})}),\n   140047623597328: (AgentBase, {})})}\n\n\nCheck that when min_epsilon=0 and max_epsilon=1, the actions should become less random as the steps go on. Check that this works on a large batch of 200 steps…\nepislon should be 0 at the end of this…\n\nagent = AgentBase(model)\nagent = StepFieldSelector(agent,field='state')\nagent = SimpleModelRunner(agent)\nagent = ArgMaxer(agent)\nselector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100,ret_mask=True)\nagent = AgentHead(selector)\n\nactions = None\nmasks = None\nepsilons = None\nfor i in range(200):\n    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]*200))]):\n        if actions is None: actions = action\n        else:               actions = torch.vstack((actions,action))\n        if masks is None: masks = mask\n        else:             masks = torch.hstack((masks,mask))\n        if epsilons is None: epsilons = tensor([selector.epsilon])\n        else:                epsilons = torch.hstack((epsilons,tensor([selector.epsilon])))\n        \ntest_ne(masks[:((200*200)//2)].sum(),200) # We do not expect this to equal a perfect 200...\ntest_ne(masks[:((200*200)//2)].sum(),0)   # ... but we also dont expect it to be 0\nassert 1000<masks[:((200*200)//2)].sum()<10_000,\\\n        \"\"\"We expect this to be somewhere between 1000 and 10,000, generally in the 9000 range since \n           for 200 steps, we are running 200 inputs\"\"\"\ntest_eq(masks[((200*200)//2):].sum(),0) # We fully expect this to be 0 after the half way point\ntest_ne(actions.sum(0)[0],200) # All the \"left\" generally shouldnt be 1\ntest_ne(actions.sum(0)[1],0) # All the \"right\"  generally shouldnt be 0\ntest_eq(selector.epsilon,0)\ntest_eq(selector.step,200)\n# Since the max steps are 100, and we go for 200 steps, the first 100 epislon entries shouldnt be 0\ntest_ne(epsilons[:100].sum(),0) \n# In fact the first 100 should sum up to somewhere between 40 and 50. (expected 49.5)\ntest_eq(40<epsilons[:100].sum()<50,True) \n# Everything after 100 should be 0\ntest_eq(epsilons[100:].sum(),0)\ntraverse(agent)\n\n{140047622145488: (AgentHead,\n  {140047622147472: (EpsilonSelector,\n    {140047622146256: (ArgMaxer,\n      {140047622146128: (SimpleModelRunner,\n        {140047622147600: (StepFieldSelector,\n          {140047622146192: (AgentBase, {})}),\n         140047622146192: (AgentBase, {})})}),\n     140047622146192: (AgentBase, {})}),\n   140047622146192: (AgentBase, {})})}\n\n\nCheck that when min_epsilon=0 and max_epsilon=0, that the actions have 0% likihood of randomness applied. Check that this works on single batches over 200 steps…\n\nagent = AgentBase(model)\nagent = StepFieldSelector(agent,field='state')\nagent = SimpleModelRunner(agent)\nagent = ArgMaxer(agent)\nselector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100,ret_mask=True)\nagent = AgentHead(selector)\n\nactions = None\nmasks = None\nepsilons = None\nfor i in range(200):\n    for action,mask in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]):\n        if actions is None: actions = action\n        else:               actions = torch.vstack((actions,action))\n        if masks is None: masks = mask\n        else:             masks = torch.hstack((masks,mask))\n        if epsilons is None: epsilons = tensor([selector.epsilon])\n        else:                epsilons = torch.hstack((epsilons,tensor([selector.epsilon])))\n        \ntest_ne(masks[:(200//2)].sum(),200) # We do not expect this to equal a perfect 200...\ntest_ne(masks[:(200//2)].sum(),0)   # ... but we also dont expect it to be 0\nassert 40<masks[:(200//2)].sum()<60,'We expect this to be somewhere between 60, generally in the ~50 range'\ntest_eq(masks[(200//2):].sum(),0) # We fully expect this to be 0 after the half way point\ntest_ne(actions.sum(0)[0],200) # All the \"left\" generally shouldnt be 1\ntest_ne(actions.sum(0)[1],0) # All the \"right\"  generally shouldnt be 0\ntest_eq(selector.epsilon,0)\ntest_eq(selector.step,200)\n# Since the max steps are 100, and we go for 200 steps, the first 100 epislon entries shouldnt be 0\ntest_ne(epsilons[:100].sum(),0) \n# In fact the first 100 should sum up to somewhere between 40 and 50. (expected 49.5)\ntest_eq(40<epsilons[:100].sum()<50,True) \n# Everything after 100 should be 0\ntest_eq(epsilons[100:].sum(),0)\n\ntraverse(agent)\n\n{140047623236112: (AgentHead,\n  {140047623236496: (EpsilonSelector,\n    {140047623237136: (ArgMaxer,\n      {140047623236944: (SimpleModelRunner,\n        {140047623234128: (StepFieldSelector,\n          {140047623233616: (AgentBase, {})}),\n         140047623233616: (AgentBase, {})})}),\n     140047623233616: (AgentBase, {})}),\n   140047623233616: (AgentBase, {})})}\n\n\n\n\n\nEpsilonCollector\n\n EpsilonCollector (*args, **kwds)\n\nLogCollector specifically manages finding and attaching itself to LoggerBases found earlier in the pipeline.\n\n\n\nPyPrimativeConverter\n\n PyPrimativeConverter (*args, **kwds)\n\nIterable-style DataPipe.\nAll DataPipes that represent an iterable of data samples should subclass this. This style of DataPipes is particularly useful when data come from a stream, or when the number of samples is too large to fit them all in memory. IterDataPipe is lazily initialized and its elements are computed only when next() is called on the iterator of an IterDataPipe.\nAll subclasses should overwrite :meth:__iter__, which would return an iterator of samples in this DataPipe. Calling __iter__ of an IterDataPipe automatically invokes its method reset(), which by default performs no operation. When writing a custom IterDataPipe, users should override reset() if necessary. The common usages include resetting buffers, pointers, and various state variables within the custom IterDataPipe.\nNote: Only one iterator can be valid for each IterDataPipe at a time, and the creation a second iterator will invalidate the first one. This constraint is necessary because some IterDataPipe have internal buffers, whose states can become invalid if there are multiple iterators. The code example below presents details on how this constraint looks in practice. If you have any feedback related to this constraint, please see GitHub IterDataPipe Single Iterator Issue_.\nThese DataPipes can be invoked in two ways, using the class constructor or applying their functional form onto an existing IterDataPipe (recommended, available to most but not all DataPipes). You can chain multiple IterDataPipe together to form a pipeline that will perform multiple operations in succession.\n.. _GitHub IterDataPipe Single Iterator Issue: https://github.com/pytorch/data/issues/45\nNote: When a subclass is used with :class:~torch.utils.data.DataLoader, each item in the DataPipe will be yielded from the :class:~torch.utils.data.DataLoader iterator. When :attr:num_workers > 0, each worker process will have a different copy of the DataPipe object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. :func:~torch.utils.data.get_worker_info, when called in a worker process, returns information about the worker. It can be used in either the dataset’s :meth:__iter__ method or the :class:~torch.utils.data.DataLoader ’s :attr:worker_init_fn option to modify each copy’s behavior.\nExamples: General Usage: >>> # xdoctest: +SKIP >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> map_dp_1 = Mapper(dp, lambda x: x + 1) # Using class constructor >>> map_dp_2 = dp.map(lambda x: x + 1) # Using functional form (recommended) >>> list(map_dp_1) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> list(map_dp_2) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> filter_dp = map_dp_1.filter(lambda x: x % 2 == 0) >>> list(filter_dp) [2, 4, 6, 8, 10] Single Iterator Constraint Example: >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> it1 = iter(source_dp) >>> list(it1) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> it1 = iter(source_dp) >>> it2 = iter(source_dp) # The creation of a new iterator invalidates it1 >>> next(it2) 0 >>> next(it1) # Further usage of it1 will raise a RunTimeError\n\npipe = PyPrimativeConverter([np.array([0.5])])\nL(pipe)\n\n(#1) [0.5]\n\n\n\npipe = PyPrimativeConverter([np.array([1])])\nL(pipe)\n\n(#1) [1]\n\n\n\npipe = PyPrimativeConverter([np.array([True])])\nL(pipe)\n\n(#1) [True]\n\n\n\nfrom multiprocessing import get_start_method\n\n\nget_start_method()\n\n'fork'\n\n\n\nlogger_base = ProgressBarLogger()\n\n\ntraverse(logger_base)\n\n{140047796619344: (ProgressBarLogger, {})}\n\n\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2)\n\nagent = AgentBase(model)\nagent = LoggerBasePassThrough(agent,[logger_base])\nagent = StepFieldSelector(agent,field='state')\nagent = SimpleModelRunner(agent)\nagent = ArgMaxer(agent)\nselector = EpsilonSelector(agent,min_epsilon=0,max_epsilon=1,max_steps=100)\nagent = EpsilonCollector(selector)\nagent = ArgMaxer(agent,only_idx=True)\nagent = NumpyConverter(agent)\nagent = PyPrimativeConverter(agent)\nagent = AgentHead(agent)\n\ntraverse(agent)\n\n{140047622144464: (AgentHead,\n  {140047622144656: (PyPrimativeConverter,\n    {140047622145360: (NumpyConverter,\n      {140047622144208: (ArgMaxer,\n        {140047622147152: (EpsilonCollector,\n          {140047622147088: (EpsilonSelector,\n            {140047622147728: (ArgMaxer,\n              {140047622811472: (SimpleModelRunner,\n                {140047796723664: (StepFieldSelector,\n                  {140047796643280: (LoggerBasePassThrough,\n                    {140047624034640: (AgentBase, {}),\n                     140047796619344: (ProgressBarLogger, {})})}),\n                 140047624034640: (AgentBase, {})})}),\n             140047624034640: (AgentBase, {})})})})})}),\n   140047624034640: (AgentBase, {})})}\n\n\n\nfor action in agent([SimpleStep.random(state=tensor([[1.,2.,3.,4.]]))]*800):\n    pass # print(action)\n\nepsilon_logs = list(logger_base.dequeue())\ntest_eq(len(epsilon_logs),801)"
  },
  {
    "objectID": "07_Agents/01_Discrete/agents.dqn.rainbow.html",
    "href": "07_Agents/01_Discrete/agents.dqn.rainbow.html",
    "title": "DQN Rainbow",
    "section": "",
    "text": "# Setup Loggers\nlogger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                 batch_on_pipe=BatchCollector)\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = CategoricalDQN( # CategoricalDQN\n    4,2,\n    head_layer=DuelingHead # DuelingDQN\n).to(device='cuda')\n# Setup the Agent\nagent = DQNAgent(model,[logger_base],max_steps=4000,device='cuda',\n                dp_augmentation_fns=[\n                    MultiModelRunner.replace_dp(device='cuda') # CategoricalDQN\n])\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True), # We basically merge 2 steps into 1 and skip. \n    (GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True,n=100,include_images=True),VSCodeTransformBlock())\n)\ndls = L(block.dataloaders(['CartPole-v1']*1))\n# Setup the Learner\nlearner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,\n                     batches=1000,\n                     loss_func = PartialCrossEntropy, # CategoricalDQN\n                     device='cuda',\n                     max_sz=100_000,\n                     lr=0.001,\n                     dp_augmentation_fns=[\n                         TargetModelUpdater.insert_dp(),# TargetDQN\n                         CategoricalTargetQCalc.replace_remove_dp( # CategoricalDQN\n                             device='cuda',\n                             nsteps=2,\n                             double_dqn_strategy=True # DoubleDQN\n                         )\n                     ])\nlearner.fit(1)\n# learner.fit(7)\n\n\n\n\n\n\n\n  \n    \n      loss\n      episode\n      rolling_reward\n      epoch\n      batch\n      epsilon\n    \n  \n  \n    \n      2.784912\n      77\n      27.920000\n      0\n      1001\n      0.528000"
  },
  {
    "objectID": "07_Agents/01_Discrete/agents.dqn.target.html",
    "href": "07_Agents/01_Discrete/agents.dqn.target.html",
    "title": "DQN Target",
    "section": "",
    "text": "TargetModelUpdater (*args, **kwds)\n\nIterable-style DataPipe.\nAll DataPipes that represent an iterable of data samples should subclass this. This style of DataPipes is particularly useful when data come from a stream, or when the number of samples is too large to fit them all in memory. IterDataPipe is lazily initialized and its elements are computed only when next() is called on the iterator of an IterDataPipe.\nAll subclasses should overwrite :meth:__iter__, which would return an iterator of samples in this DataPipe. Calling __iter__ of an IterDataPipe automatically invokes its method reset(), which by default performs no operation. When writing a custom IterDataPipe, users should override reset() if necessary. The common usages include resetting buffers, pointers, and various state variables within the custom IterDataPipe.\nNote: Only one iterator can be valid for each IterDataPipe at a time, and the creation a second iterator will invalidate the first one. This constraint is necessary because some IterDataPipe have internal buffers, whose states can become invalid if there are multiple iterators. The code example below presents details on how this constraint looks in practice. If you have any feedback related to this constraint, please see GitHub IterDataPipe Single Iterator Issue_.\nThese DataPipes can be invoked in two ways, using the class constructor or applying their functional form onto an existing IterDataPipe (recommended, available to most but not all DataPipes). You can chain multiple IterDataPipe together to form a pipeline that will perform multiple operations in succession.\n.. _GitHub IterDataPipe Single Iterator Issue: https://github.com/pytorch/data/issues/45\nNote: When a subclass is used with :class:~torch.utils.data.DataLoader, each item in the DataPipe will be yielded from the :class:~torch.utils.data.DataLoader iterator. When :attr:num_workers > 0, each worker process will have a different copy of the DataPipe object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. :func:~torch.utils.data.get_worker_info, when called in a worker process, returns information about the worker. It can be used in either the dataset’s :meth:__iter__ method or the :class:~torch.utils.data.DataLoader ’s :attr:worker_init_fn option to modify each copy’s behavior.\nExamples: General Usage: >>> # xdoctest: +SKIP >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> map_dp_1 = Mapper(dp, lambda x: x + 1) # Using class constructor >>> map_dp_2 = dp.map(lambda x: x + 1) # Using functional form (recommended) >>> list(map_dp_1) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> list(map_dp_2) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> filter_dp = map_dp_1.filter(lambda x: x % 2 == 0) >>> list(filter_dp) [2, 4, 6, 8, 10] Single Iterator Constraint Example: >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> it1 = iter(source_dp) >>> list(it1) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> it1 = iter(source_dp) >>> it2 = iter(source_dp) # The creation of a new iterator invalidates it1 >>> next(it2) 0 >>> next(it1) # Further usage of it1 will raise a RunTimeError\n\n\n\n\n\n TargetModelQCalc (*args, **kwds)\n\nIterable-style DataPipe.\nAll DataPipes that represent an iterable of data samples should subclass this. This style of DataPipes is particularly useful when data come from a stream, or when the number of samples is too large to fit them all in memory. IterDataPipe is lazily initialized and its elements are computed only when next() is called on the iterator of an IterDataPipe.\nAll subclasses should overwrite :meth:__iter__, which would return an iterator of samples in this DataPipe. Calling __iter__ of an IterDataPipe automatically invokes its method reset(), which by default performs no operation. When writing a custom IterDataPipe, users should override reset() if necessary. The common usages include resetting buffers, pointers, and various state variables within the custom IterDataPipe.\nNote: Only one iterator can be valid for each IterDataPipe at a time, and the creation a second iterator will invalidate the first one. This constraint is necessary because some IterDataPipe have internal buffers, whose states can become invalid if there are multiple iterators. The code example below presents details on how this constraint looks in practice. If you have any feedback related to this constraint, please see GitHub IterDataPipe Single Iterator Issue_.\nThese DataPipes can be invoked in two ways, using the class constructor or applying their functional form onto an existing IterDataPipe (recommended, available to most but not all DataPipes). You can chain multiple IterDataPipe together to form a pipeline that will perform multiple operations in succession.\n.. _GitHub IterDataPipe Single Iterator Issue: https://github.com/pytorch/data/issues/45\nNote: When a subclass is used with :class:~torch.utils.data.DataLoader, each item in the DataPipe will be yielded from the :class:~torch.utils.data.DataLoader iterator. When :attr:num_workers > 0, each worker process will have a different copy of the DataPipe object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. :func:~torch.utils.data.get_worker_info, when called in a worker process, returns information about the worker. It can be used in either the dataset’s :meth:__iter__ method or the :class:~torch.utils.data.DataLoader ’s :attr:worker_init_fn option to modify each copy’s behavior.\nExamples: General Usage: >>> # xdoctest: +SKIP >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> map_dp_1 = Mapper(dp, lambda x: x + 1) # Using class constructor >>> map_dp_2 = dp.map(lambda x: x + 1) # Using functional form (recommended) >>> list(map_dp_1) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> list(map_dp_2) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> filter_dp = map_dp_1.filter(lambda x: x % 2 == 0) >>> list(filter_dp) [2, 4, 6, 8, 10] Single Iterator Constraint Example: >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> it1 = iter(source_dp) >>> list(it1) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> it1 = iter(source_dp) >>> it2 = iter(source_dp) # The creation of a new iterator invalidates it1 >>> next(it2) 0 >>> next(it1) # Further usage of it1 will raise a RunTimeError\nTry training with basic defaults…\n\nfrom fastrl.envs.gym import *\n\n\n# Setup Loggers\nlogger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                 batch_on_pipe=BatchCollector)\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2)\n# Setup the Agent\nagent = DQNAgent(model,[logger_base],max_steps=4000)\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False)\n)\ndls = L(block.dataloaders(['CartPole-v1']*1))\n# Setup the Learner\nlearner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=100_000,\n                     batches=1000,\n                    dp_augmentation_fns=[\n                        TargetModelUpdater.insert_dp(),\n                        TargetModelQCalc.replace_dp()\n                    ]\n)\nlearner.fit(3)\n# learner.fit(25)\n\n\n\n\n\n\n\n  \n    \n      loss\n      episode\n      rolling_reward\n      epoch\n      batch\n      epsilon\n    \n  \n  \n    \n      0.013058196\n      52\n      19.588235\n      1\n      1001\n      0.749500\n    \n    \n      0.0881805\n      96\n      20.936842\n      2\n      1001\n      0.499250\n    \n    \n      0.26291308\n      116\n      25.860000\n      2\n      1001\n      0.249250\n    \n  \n\n\n\nThe DQN learners, but I wonder if we can get it to learn faster…\n\n# Setup Loggers\nlogger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                 batch_on_pipe=BatchCollector)\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2)\n# Setup the Agent\nagent = DQNAgent(model,[logger_base],max_steps=10000)\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True), # We basically merge 2 steps into 1 and skip. \n    (GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True,n=100,include_images=True),VSCodeTransformBlock())\n)\ndls = L(block.dataloaders(['CartPole-v1']*1))\n# Setup the Learner\nlearner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=20_000,nsteps=2,lr=0.001,\n                     batches=1000,\n                    dp_augmentation_fns=[\n                        TargetModelUpdater.insert_dp(),\n                        TargetModelQCalc.replace_dp()\n                    ])\nlearner.fit(3)\n# learner.fit(10)\n\n\n\n\n\n\n\n  \n    \n      loss\n      episode\n      rolling_reward\n      epoch\n      batch\n      epsilon\n    \n  \n  \n    \n      0.0866633\n      70\n      29.300000\n      1\n      1001\n      0.810300\n    \n    \n      1.1521769\n      114\n      44.820000\n      2\n      1001\n      0.616700\n    \n    \n      1.852667\n      134\n      67.080000\n      2\n      1001\n      0.419800"
  },
  {
    "objectID": "07_Agents/01_Discrete/agents.dqn.dueling.html",
    "href": "07_Agents/01_Discrete/agents.dqn.dueling.html",
    "title": "DQN Dueling",
    "section": "",
    "text": "DuelingHead (hidden:int, n_actions:int, lin_cls=<class\n              'torch.nn.modules.linear.Linear'>)\n\nSame as nn.Module, but no need for subclasses to call super().__init__\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhidden\nint\n\nInput into the DuelingHead, likely a hidden layer input\n\n\nn_actions\nint\n\nNumber/dim of actions to output\n\n\nlin_cls\ntype\nLinear\n\n\n\n\nTry training with basic defaults…\n\nfrom fastrl.envs.gym import *\nfrom fastrl.agents.dqn.target import *\n\n\n# Setup Loggers\nlogger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                 batch_on_pipe=BatchCollector)\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2,head_layer=DuelingHead) #.cuda()\n# Setup the Agent\nagent = DQNAgent(model,[logger_base],max_steps=4000)#,device='cuda')\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False,n=1000,bs=1)\n)\n# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\ndls = L(block.dataloaders(['CartPole-v1']*1))\n# Setup the Learner\nlearner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=100_000,\n                    dp_augmentation_fns=[\n                        TargetModelUpdater.insert_dp(),\n                        TargetModelQCalc.replace_dp()\n                    ])\nlearner.fit(3)\n# learner.fit(25)\n\n\n\n\n\n\n\n  \n    \n      loss\n      episode\n      rolling_reward\n      epoch\n      batch\n      epsilon\n    \n  \n  \n    \n      0.010209812\n      53\n      18.826923\n      1\n      1000\n      0.749500\n    \n    \n      0.032916732\n      92\n      21.406593\n      2\n      1000\n      0.499250\n    \n    \n      0.041681465\n      105\n      28.240000\n      2\n      1000\n      0.249250\n    \n  \n\n\n\nThe DQN learners, but I wonder if we can get it to learn faster…\n\n# Setup Loggers\nlogger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                 batch_on_pipe=BatchCollector)\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2,head_layer=DuelingHead)\n# Setup the Agent\nagent = DQNAgent(model,[logger_base],max_steps=10000)\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True,n=1000,bs=1), # We basically merge 2 steps into 1 and skip. \n    (GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True,n=100,include_images=True),VSCodeTransformBlock())\n)\ndls = L(block.dataloaders(['CartPole-v1']*1))\n# Setup the Learner\nlearner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=20_000,nsteps=2,lr=0.001,\n                    dp_augmentation_fns=[\n                        TargetModelUpdater.insert_dp(),\n                        TargetModelQCalc.replace_dp()\n                    ])\nlearner.fit(3)\n# learner.fit(10)\n\n\n\n\n\n\n\n  \n    \n      loss\n      episode\n      rolling_reward\n      epoch\n      batch\n      epsilon\n    \n  \n  \n    \n      0.24247332\n      72\n      28.780000\n      1\n      1000\n      0.810000\n    \n    \n      2.1317954\n      110\n      45.080000\n      2\n      1000\n      0.615800\n    \n    \n      3.3318765\n      133\n      71.960000\n      2\n      1000\n      0.419400"
  },
  {
    "objectID": "07_Agents/01_Discrete/agents.dqn.categorical.html",
    "href": "07_Agents/01_Discrete/agents.dqn.categorical.html",
    "title": "Categorical DQN",
    "section": "",
    "text": "Instead of action outputs being single Q values, they are instead distributions of `N` size.\nWe start off with the idea of atoms and supports. A support acts as a mask over the output action distributions. This is illistrated by the equations and the corresponding functions.\nWe start with the equation…\n\\[\n{\\large\nZ_{\\theta}(z,a) = z_i \\quad w.p. \\: p_i(x,a):= \\frac{ e^{\\theta_i(x,a)}} {\\sum_j{e^{\\theta_j(x,a)}}}\n}\n\\]\n… which shows that the end of our neural net model needs to be squished to be a proper probability. It also defines \\(z_i\\) which is a support we will define very soon. Below is the implimentation of the right side equation for \\(p_i(x,a)\\)\nAn important note is that $ {_j{e^{_j(x,a)}}} $ is just:\n\nSoftmax\n\ntorch.nn.modules.activation.Softmax\n\n\nWe pretend that the output of the neural net is of shape (batch_sz,n_actions,n_atoms). In this instance, there is only one action. This implies that \\(Z_{\\theta}\\) is just \\(z_0\\).\n\nout=Softmax(dim=1)(torch.randn(1,51,1))[0] # Action 0\nplt.plot(out.numpy())\n\n\n\n\nThe next function describes how propabilities are calculated from the neural net output. The equation describes a \\(z_i\\) which is explained by: \\[\n\\{z_i = V_{min} + i\\Delta z : 0 \\leq i < N \\}, \\: \\Delta z := \\frac{V_{max} - V_{min}}{N - 1}\n\\]\nWhere \\(V_{max}\\), \\(V_{min}\\), and \\(N\\) are constants that we define. Note that \\(N\\) is the number of atoms. So what does a \\(z_i\\) look like? We will define this in code below…\n\n\ncreate_support\n\n create_support (v_min=-10, v_max=10, n_atoms=51)\n\nCreates the support and returns the z_delta that was used.\n\nsupport_dist,z_delta=create_support()\nprint('z_delta: ',z_delta)\nplt.plot(support_dist.numpy())\n\nz_delta:  0.4\n\n\n\n\n\nThis is a single \\(z_i\\) in \\(Z_{\\theta}\\). The number of \\(z_i\\)s is equal to the number of actions that the DQN is operating with.\n\nNote: Josiah: Is this always the case? Could there be only \\(z_0\\) and multiple actions?\n\nOk! Hopefully this wasn’t too bad to go through. We basically normalized the neural net output to be nicer to deal with, and created/initialized a (bunch) of increasing arrays that we are calling discrete distributions i.e. output from create_support.\nNow for the fun part! We have this giant ass update equation:\n\\[\n{\\large\n(\\Phi\\hat{\\mathcal{T}}Z_{\\theta}(x,a))_i = \\sum_{j=0}^{N-1} \\left[ 1 - \\frac{ | \\mathcal{T}z_j |_{V_{min}}^{V_{max}} - z_i }{ \\Delta z } \\right]_0^1 p_j(x^{\\prime},\\pi(x^{\\prime}))\n}\n\\] Good god… and we also have\n\\[\n\\hat{\\mathcal{T}}z_j := r + \\gamma z_j\n\\]\nwhere, to quote the paper:\n\n“for each atom \\(z_j\\), [and] then distribute its probability $ p_j(x{},(x{})) $ to the immediate neighbors of $ z_j $”\n\n\nI highly recommend reading pg6 in the paper for a fuller explaination. I was originally wondering what the difference was between \\(\\pi\\) and simple \\(\\theta\\), which the main difference is that \\(\\pi\\) is a greedy action selection i.e. we run argmax to get the action.\nThis was a lot! Luckily they have a re-formalation in algorithmic form:\n\ndef categorical_update(v_min,v_max,n_atoms,support,delta_z,model,reward,gamma,action,next_state):\n    t_q=(support*Softmax(model(next_state).gather(action))).sum()\n    a_star=torch.argmax(t_q)\n    \n    m=torch.zeros((N,)) # m_i = 0 where i in 1,...,N-1\n    \n    for j in range(n_atoms):\n        # Compute the projection of $ \\hat{\\mathcal{T}}z_j $ onto support $ z_j $\n        target_z=torch.clamp(reward+gamma*support[:,j],v_min,v_max)\n        b_j=(target_z-v_min)/delta_z # b_j in [0,N-1]\n        l=torch.floor(b_j)\n        u=torch.ceil(b_j)\n        # Distribute probability of $ \\hat{\\mathcal{T}}z_j $\n        m[:,l]=m[:,l]+a_star*(u-b)\n        m[:,u]=m[:,u]+a_star*(b-l)\n    return # Some cross entropy loss\n\nThere is a small problem with the above equation. This was a (fairly) literal convertion from Algorithm 1 in the paper to Python. There are some problems here: - The current setup doesnt handle batches - Some of the variables are a little vague - Does not handle terminal states\nLets rename these! We will instead have: \\[\nm\\_i    \\rightarrow projection\\\\\na\\_star \\rightarrow next\\_action\\\\\nb\\_j    \\rightarrow support\\_value\\\\\nl      \\rightarrow support\\_left\\\\\nu      \\rightarrow support\\_right\\\\\n\\]\nSo lets revise the problem and pretend that we have a 2 action model, batch size of 8, where the last element has a reward of 0, and where left actions are -1, while right actions are 1.\n\nfrom torch.distributions.normal import Normal\n\nSo for a single action we would have a distribution like this…\n\nplt.plot(Normal(0,1).sample((51,)).numpy())\n\n\n\n\nSo since our model has 2 actions that it can pick, we create some distributions for them…\n\ndist_left=torch.vstack([Normal(0.5,1).sample((1,51)),Normal(0.5,0.1).sample((1,51))]).unsqueeze(0)\ndist_right=torch.vstack([Normal(0.5,0.1).sample((1,51)),Normal(0.5,1).sample((1,51))]).unsqueeze(0)\n(dist_left.shape,dist_right.shape)\n\n(torch.Size([1, 2, 51]), torch.Size([1, 2, 51]))\n\n\n…where the \\([1, 2, 51]\\) is \\([batch, action, n\\_atoms]\\)\n\nmodel_out=torch.vstack([copy([dist_left,dist_right][i%2==0]) for i in range(1,9)]).to(device=default_device())\n(model_out.shape)\n\ntorch.Size([8, 2, 51])\n\n\n\nsummed_model_out=model_out.sum(dim=2);summed_model_out=Softmax(dim=1)(summed_model_out).to(device=default_device())\n(summed_model_out.shape,summed_model_out)\n\n(torch.Size([8, 2]),\n tensor([[0.1954, 0.8046],\n         [0.0060, 0.9940],\n         [0.1954, 0.8046],\n         [0.0060, 0.9940],\n         [0.1954, 0.8046],\n         [0.0060, 0.9940],\n         [0.1954, 0.8046],\n         [0.0060, 0.9940]], device='cuda:0'))\n\n\nSo when we sum/normalize the distrubtions per batch, per action, we get an output that looks like your typical dqn output…\nWe can also treat this like a regular DQN and do an argmax to get actions like usual…\n\nactions=torch.argmax(summed_model_out,dim=1).reshape(-1,1).to(device=default_device());actions\n\ntensor([[1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1]], device='cuda:0')\n\n\n\nrewards=actions;rewards\n\ntensor([[1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1]], device='cuda:0')\n\n\n\ndones=torch.Tensor().new_zeros((8,1)).bool().to(device=default_device());dones[-1][0]=1;dones\n\ntensor([[False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [False],\n        [ True]], device='cuda:0')\n\n\nSo lets decompose the categorical_update above into something easier to read. First we will note the author’s original algorithm:\n\nWe can break this into 3 different functions: - getting the Q - calculating the update - calculating the loss\nWe will start with the \\(Q(x_{t+1},a):=\\sum_iz_ip_i(x_{t_1},a))\\)\n\n\n\nCategoricalDQN\n\n CategoricalDQN (state_sz:int, action_sz:int, n_atoms:int=51, hidden=512,\n                 v_min=-10, v_max=10, head_layer=<class\n                 'torch.nn.modules.linear.Linear'>, activation_fn=<class\n                 'torch.nn.modules.activation.ReLU'>)\n\nSame as nn.Module, but no need for subclasses to call super().__init__\nThe CategoricalDQN.q function gets us 90% of the way to the equation above. However, you will notice that that equation is for a specific action. We will handle this in the actual update function.\n\ndqn=CategoricalDQN(4,2).to(device=default_device())\ndqn(torch.randn(8,4).to(device=default_device())).shape\n\ntorch.Size([8, 2, 51])\n\n\n\ndqn.q(torch.randn(8,4).to(device=default_device()))\n\ntensor([[ 0.3418, -0.2006],\n        [ 0.1096, -0.0358],\n        [-0.2790,  0.0382],\n        [ 0.1743,  0.0024],\n        [-0.5164,  0.0867],\n        [-0.0825, -0.0634],\n        [-0.5792,  0.2759],\n        [-0.0598, -0.0087]], device='cuda:0', grad_fn=<SumBackward1>)\n\n\n\ndqn.policy(torch.randn(8,4).to(device=default_device()))\n\ntensor([[-0.0020,  0.0022],\n        [-0.0043, -0.0014],\n        [-0.0063,  0.0037],\n        [-0.0079,  0.0028],\n        [-0.0001,  0.0039],\n        [-0.0001, -0.0017],\n        [-0.0008,  0.0004],\n        [-0.0108,  0.0052]], device='cuda:0', grad_fn=<MeanBackward1>)\n\n\n\n\n\nfinal_distribute\n\n final_distribute (projection, left, right, support_value, p_a, atom,\n                   done)\n\nDoes: m_l <- m_l + p_j(x_{t+1},a*)(u - b_j) operation for final states.\n\n\n\ndistribute\n\n distribute (projection, left, right, support_value, p_a, atom, done)\n\nDoes: m_l <- m_l + p_j(x_{t+1},a*)(u - b_j) operation for non-final states.\n\n\n\ncategorical_update\n\n categorical_update (support, delta_z, q, p, actions, rewards, dones,\n                     v_min=-10, v_max=10, n_atoms=51, gamma=0.99,\n                     passes=None, nsteps=1, debug=False)\n\n\n\n\nshow_q_distribution\n\n show_q_distribution (cat_dist, title='Update Distributions')\n\ncat_dist being shape: (bs,n_atoms)\n\noutput=categorical_update(dqn.supports,dqn.z_delta,summed_model_out,\n                          Softmax(dim=2)(model_out),actions,rewards,dones,passes=None)\nshow_q_distribution(output)\n\n\n                                                \n\n\n\nq=dqn.q(torch.randn(8,4).to(device=default_device()))\np=dqn.p(torch.randn(8,4).to(device=default_device()))\n\noutput=categorical_update(dqn.supports,dqn.z_delta,q,p,actions,rewards,dones)\nshow_q_distribution(output,title='Real Model Update Distributions')\n\n\n                                                \n\n\n\n\n\nPartialCrossEntropy\n\n PartialCrossEntropy (p, q)\n\n\n\n\nCategoricalTargetQCalc\n\n CategoricalTargetQCalc (*args, **kwds)\n\nIterable-style DataPipe.\nAll DataPipes that represent an iterable of data samples should subclass this. This style of DataPipes is particularly useful when data come from a stream, or when the number of samples is too large to fit them all in memory. IterDataPipe is lazily initialized and its elements are computed only when next() is called on the iterator of an IterDataPipe.\nAll subclasses should overwrite :meth:__iter__, which would return an iterator of samples in this DataPipe. Calling __iter__ of an IterDataPipe automatically invokes its method reset(), which by default performs no operation. When writing a custom IterDataPipe, users should override reset() if necessary. The common usages include resetting buffers, pointers, and various state variables within the custom IterDataPipe.\nNote: Only one iterator can be valid for each IterDataPipe at a time, and the creation a second iterator will invalidate the first one. This constraint is necessary because some IterDataPipe have internal buffers, whose states can become invalid if there are multiple iterators. The code example below presents details on how this constraint looks in practice. If you have any feedback related to this constraint, please see GitHub IterDataPipe Single Iterator Issue_.\nThese DataPipes can be invoked in two ways, using the class constructor or applying their functional form onto an existing IterDataPipe (recommended, available to most but not all DataPipes). You can chain multiple IterDataPipe together to form a pipeline that will perform multiple operations in succession.\n.. _GitHub IterDataPipe Single Iterator Issue: https://github.com/pytorch/data/issues/45\nNote: When a subclass is used with :class:~torch.utils.data.DataLoader, each item in the DataPipe will be yielded from the :class:~torch.utils.data.DataLoader iterator. When :attr:num_workers > 0, each worker process will have a different copy of the DataPipe object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. :func:~torch.utils.data.get_worker_info, when called in a worker process, returns information about the worker. It can be used in either the dataset’s :meth:__iter__ method or the :class:~torch.utils.data.DataLoader ’s :attr:worker_init_fn option to modify each copy’s behavior.\nExamples: General Usage: >>> # xdoctest: +SKIP >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> map_dp_1 = Mapper(dp, lambda x: x + 1) # Using class constructor >>> map_dp_2 = dp.map(lambda x: x + 1) # Using functional form (recommended) >>> list(map_dp_1) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> list(map_dp_2) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> filter_dp = map_dp_1.filter(lambda x: x % 2 == 0) >>> list(filter_dp) [2, 4, 6, 8, 10] Single Iterator Constraint Example: >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> it1 = iter(source_dp) >>> list(it1) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> it1 = iter(source_dp) >>> it2 = iter(source_dp) # The creation of a new iterator invalidates it1 >>> next(it2) 0 >>> next(it1) # Further usage of it1 will raise a RunTimeError\n\n\n\nMultiModelRunner\n\n MultiModelRunner (*args, **kwds)\n\nIf a model contains multiple models, then we support selecting a sub model.\n\nfrom torchdata.datapipes.utils import to_graph\nfrom fastrl.envs.gym import *\nfrom fastrl.agents.dqn.target import *\n\n\n# Setup Loggers\nlogger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                 batch_on_pipe=BatchCollector)\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = CategoricalDQN(4,2).to(device='cuda')\n# Setup the Agent\nagent = DQNAgent(model,[logger_base],max_steps=4000,device='cuda',\n                dp_augmentation_fns=[\n                    MultiModelRunner.replace_dp(device='cuda')\n])\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True), # We basically merge 2 steps into 1 and skip. \n    (GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True,n=100,include_images=True),VSCodeTransformBlock())\n)\n# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\ndls = L(block.dataloaders(['CartPole-v1']*1))\n# Setup the Learner\nlearner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,\n                     batches=1000,\n                     loss_func = PartialCrossEntropy,\n                     device='cuda',\n                     max_sz=100_000,\n                     lr=0.001,\n                     dp_augmentation_fns=[\n                         TargetModelUpdater.insert_dp(),\n                         CategoricalTargetQCalc.replace_remove_dp(device='cuda',nsteps=2,double_dqn_strategy=True)\n                     ])\nlearner.fit(1)\n# learner.fit(7)\n\n\n\n\n\n\n\n  \n    \n      loss\n      episode\n      rolling_reward\n      epoch\n      batch\n      epsilon\n    \n  \n  \n    \n      2.8483639\n      65\n      30.870000\n      0\n      1001\n      0.523000\n    \n  \n\n\n\n\nfrom IPython.display import HTML\nimport plotly.express as px\nfrom torchdata.dataloader2.graph import find_dps,traverse\n\n\n\n\nshow_q\n\n show_q (cat_dist, title='Update Distributions')\n\ncat_dist being shape: (bs,n_atoms)"
  },
  {
    "objectID": "07_Agents/01_Discrete/agents.dqn.double.html",
    "href": "07_Agents/01_Discrete/agents.dqn.double.html",
    "title": "DQN Double",
    "section": "",
    "text": "DoubleQCalc (*args, **kwds)\n\nIterable-style DataPipe.\nAll DataPipes that represent an iterable of data samples should subclass this. This style of DataPipes is particularly useful when data come from a stream, or when the number of samples is too large to fit them all in memory. IterDataPipe is lazily initialized and its elements are computed only when next() is called on the iterator of an IterDataPipe.\nAll subclasses should overwrite :meth:__iter__, which would return an iterator of samples in this DataPipe. Calling __iter__ of an IterDataPipe automatically invokes its method reset(), which by default performs no operation. When writing a custom IterDataPipe, users should override reset() if necessary. The common usages include resetting buffers, pointers, and various state variables within the custom IterDataPipe.\nNote: Only one iterator can be valid for each IterDataPipe at a time, and the creation a second iterator will invalidate the first one. This constraint is necessary because some IterDataPipe have internal buffers, whose states can become invalid if there are multiple iterators. The code example below presents details on how this constraint looks in practice. If you have any feedback related to this constraint, please see GitHub IterDataPipe Single Iterator Issue_.\nThese DataPipes can be invoked in two ways, using the class constructor or applying their functional form onto an existing IterDataPipe (recommended, available to most but not all DataPipes). You can chain multiple IterDataPipe together to form a pipeline that will perform multiple operations in succession.\n.. _GitHub IterDataPipe Single Iterator Issue: https://github.com/pytorch/data/issues/45\nNote: When a subclass is used with :class:~torch.utils.data.DataLoader, each item in the DataPipe will be yielded from the :class:~torch.utils.data.DataLoader iterator. When :attr:num_workers > 0, each worker process will have a different copy of the DataPipe object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. :func:~torch.utils.data.get_worker_info, when called in a worker process, returns information about the worker. It can be used in either the dataset’s :meth:__iter__ method or the :class:~torch.utils.data.DataLoader ’s :attr:worker_init_fn option to modify each copy’s behavior.\nExamples: General Usage: >>> # xdoctest: +SKIP >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> map_dp_1 = Mapper(dp, lambda x: x + 1) # Using class constructor >>> map_dp_2 = dp.map(lambda x: x + 1) # Using functional form (recommended) >>> list(map_dp_1) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> list(map_dp_2) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> filter_dp = map_dp_1.filter(lambda x: x % 2 == 0) >>> list(filter_dp) [2, 4, 6, 8, 10] Single Iterator Constraint Example: >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> it1 = iter(source_dp) >>> list(it1) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> it1 = iter(source_dp) >>> it2 = iter(source_dp) # The creation of a new iterator invalidates it1 >>> next(it2) 0 >>> next(it1) # Further usage of it1 will raise a RunTimeError\nTry training with basic defaults…\n\nfrom fastrl.envs.gym import *\nfrom fastrl.loggers.vscode_visualizers import *\n\n\n# Setup Loggers\nlogger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                 batch_on_pipe=BatchCollector)\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2)\n# Setup the Agent\nagent = DQNAgent(model,[logger_base],max_steps=4000)\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False,n=1000,bs=1)\n)\ndls = L(block.dataloaders(['CartPole-v1']*1))\n# Setup the Learner\nlearner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=100_000,\n                    dp_augmentation_fns=[\n                        TargetModelUpdater.insert_dp(),\n                        DoubleQCalc.replace_dp()\n                    ])\nlearner.fit(3)\n# learner.fit(25)\n\n\n\n\n\n\n\n  \n    \n      loss\n      episode\n      rolling_reward\n      epoch\n      batch\n      epsilon\n    \n  \n  \n    \n      0.017258495\n      46\n      21.644444\n      1\n      1000\n      0.749500\n    \n    \n      0.0485615\n      75\n      26.837838\n      2\n      1000\n      0.499250\n    \n    \n      0.03659891\n      94\n      31.946237\n      2\n      1000\n      0.249250\n    \n  \n\n\n\nThe DQN learners, but I wonder if we can get it to learn faster…\n\n# Setup Loggers\nlogger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                 batch_on_pipe=BatchCollector)\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2)\n# Setup the Agent\nagent = DQNAgent(model,[logger_base],max_steps=10000)\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True,n=1000,bs=1), # We basically merge 2 steps into 1 and skip. \n    (GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True,n=100,include_images=True),VSCodeTransformBlock())\n)\n# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\ndls = L(block.dataloaders(['CartPole-v1']*1))\n# Setup the Learner\nlearner = DQNLearner(model,dls,logger_bases=[logger_base],bs=128,max_sz=20_000,nsteps=2,lr=0.001,\n                    dp_augmentation_fns=[\n                        TargetModelUpdater.insert_dp(),\n                        DoubleQCalc.replace_dp()\n                    ])\nlearner.fit(3)\n# learner.fit(10)\n\n\n\n\n\n\n\n  \n    \n      loss\n      episode\n      rolling_reward\n      epoch\n      batch\n      epsilon\n    \n  \n  \n    \n      0.12804106\n      71\n      29.120000\n      1\n      1000\n      0.809700\n    \n    \n      0.9983938\n      118\n      41.120000\n      2\n      1000\n      0.615900\n    \n    \n      1.8011488\n      135\n      66.460000\n      2\n      1000\n      0.418300"
  },
  {
    "objectID": "07_Agents/01_Discrete/agents.dqn.basic.html",
    "href": "07_Agents/01_Discrete/agents.dqn.basic.html",
    "title": "DQN Basic",
    "section": "",
    "text": "DQN (state_sz:int, action_sz:int, hidden=512,\n      head_layer:fastrl.torch_core.Module=<class\n      'torch.nn.modules.linear.Linear'>,\n      activition_fn:fastrl.torch_core.Module=<class\n      'torch.nn.modules.activation.ReLU'>)\n\nSame as nn.Module, but no need for subclasses to call super().__init__\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nstate_sz\nint\n\nThe input dim of the state\n\n\naction_sz\nint\n\nThe output dim of the actions\n\n\nhidden\nint\n512\nNumber of neurons connected between the 2 input/output layers\n\n\nhead_layer\nModule\nLinear\nDQN extensions such as Dueling DQNs have custom heads\n\n\nactivition_fn\nModule\nReLU\nThe activiation fn used by DQN"
  },
  {
    "objectID": "07_Agents/01_Discrete/agents.dqn.basic.html#agent",
    "href": "07_Agents/01_Discrete/agents.dqn.basic.html#agent",
    "title": "DQN Basic",
    "section": "Agent",
    "text": "Agent\n\n\nDQNAgent\n\n DQNAgent (model, logger_bases=None, min_epsilon=0.02, max_epsilon=1,\n           max_steps=1000, device='cpu', dp_augmentation_fns:Union[List[Ca\n           llable[[Union[torch.utils.data.datapipes.datapipe.IterDataPipe,\n           torch.utils.data.datapipes.datapipe.MapDataPipe]],Union[torch.u\n           tils.data.datapipes.datapipe.IterDataPipe,torch.utils.data.data\n           pipes.datapipe.MapDataPipe,NoneType]]],NoneType]=None)\n\n\ntorch.manual_seed(0)\nmodel = DQN(4,2)\n\nagent = DQNAgent(model)\n\n\ninput_tensor = tensor([1,2,3,4]).float()\nstep = SimpleStep(state=input_tensor)\n\nfor action in agent([step]):\n    print(action)\n    \ntest_eq(input_tensor,tensor([1., 2., 3., 4.]))\n\n1\n\n\n\nfrom fastrl.envs.gym import *\n\n\nAgentHead.debug=True\n\n\n# Setup Logger\nlogger_base = ProgressBarLogger()\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2)\n\nagent = DQNAgent(model,[logger_base])\n\nblock = DataBlock(\n    GymTransformBlock(agent,n=10)\n)\n# dls = L(block.dataloaders(['CartPole-v1']*1,n=10,bs=1))\npipes = L(block.datapipes(['CartPole-v1']*1))\n\n# list(dls[0])\nlist(pipes[0])\ntraverse(agent)\n\n{139835997488656: (AgentHead,\n  {139835997488848: (PyPrimativeConverter,\n    {139835997489168: (NumpyConverter,\n      {139835997490512: (ArgMaxer,\n        {139835997489104: (EpsilonCollector,\n          {139835791724432: (EpsilonSelector,\n            {139835791724368: (ArgMaxer,\n              {139835791808976: (SimpleModelRunner,\n                {139835791808912: (InputInjester,\n                  {139835791808784: (StepFieldSelector,\n                    {139837965380880: (AgentBase,\n                      {139835791808400: (ProgressBarLogger, {})})})}),\n                 139837965380880: (AgentBase,\n                  {139835791808400: (ProgressBarLogger, {})})})}),\n             139837965380880: (AgentBase,\n              {139835791808400: (ProgressBarLogger, {})})})})})})}),\n   139837965380880: (AgentBase, {139835791808400: (ProgressBarLogger, {})})})}"
  },
  {
    "objectID": "07_Agents/01_Discrete/agents.dqn.basic.html#training-datapipes",
    "href": "07_Agents/01_Discrete/agents.dqn.basic.html#training-datapipes",
    "title": "DQN Basic",
    "section": "Training DataPipes",
    "text": "Training DataPipes\n\n\nQCalc\n\n QCalc (*args, **kwds)\n\nIterable-style DataPipe.\nAll DataPipes that represent an iterable of data samples should subclass this. This style of DataPipes is particularly useful when data come from a stream, or when the number of samples is too large to fit them all in memory. IterDataPipe is lazily initialized and its elements are computed only when next() is called on the iterator of an IterDataPipe.\nAll subclasses should overwrite :meth:__iter__, which would return an iterator of samples in this DataPipe. Calling __iter__ of an IterDataPipe automatically invokes its method reset(), which by default performs no operation. When writing a custom IterDataPipe, users should override reset() if necessary. The common usages include resetting buffers, pointers, and various state variables within the custom IterDataPipe.\nNote: Only one iterator can be valid for each IterDataPipe at a time, and the creation a second iterator will invalidate the first one. This constraint is necessary because some IterDataPipe have internal buffers, whose states can become invalid if there are multiple iterators. The code example below presents details on how this constraint looks in practice. If you have any feedback related to this constraint, please see GitHub IterDataPipe Single Iterator Issue_.\nThese DataPipes can be invoked in two ways, using the class constructor or applying their functional form onto an existing IterDataPipe (recommended, available to most but not all DataPipes). You can chain multiple IterDataPipe together to form a pipeline that will perform multiple operations in succession.\n.. _GitHub IterDataPipe Single Iterator Issue: https://github.com/pytorch/data/issues/45\nNote: When a subclass is used with :class:~torch.utils.data.DataLoader, each item in the DataPipe will be yielded from the :class:~torch.utils.data.DataLoader iterator. When :attr:num_workers > 0, each worker process will have a different copy of the DataPipe object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. :func:~torch.utils.data.get_worker_info, when called in a worker process, returns information about the worker. It can be used in either the dataset’s :meth:__iter__ method or the :class:~torch.utils.data.DataLoader ’s :attr:worker_init_fn option to modify each copy’s behavior.\nExamples: General Usage: >>> # xdoctest: +SKIP >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> map_dp_1 = Mapper(dp, lambda x: x + 1) # Using class constructor >>> map_dp_2 = dp.map(lambda x: x + 1) # Using functional form (recommended) >>> list(map_dp_1) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> list(map_dp_2) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> filter_dp = map_dp_1.filter(lambda x: x % 2 == 0) >>> list(filter_dp) [2, 4, 6, 8, 10] Single Iterator Constraint Example: >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> it1 = iter(source_dp) >>> list(it1) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> it1 = iter(source_dp) >>> it2 = iter(source_dp) # The creation of a new iterator invalidates it1 >>> next(it2) 0 >>> next(it1) # Further usage of it1 will raise a RunTimeError\n\n\n\nTargetCalc\n\n TargetCalc (*args, **kwds)\n\nIterable-style DataPipe.\nAll DataPipes that represent an iterable of data samples should subclass this. This style of DataPipes is particularly useful when data come from a stream, or when the number of samples is too large to fit them all in memory. IterDataPipe is lazily initialized and its elements are computed only when next() is called on the iterator of an IterDataPipe.\nAll subclasses should overwrite :meth:__iter__, which would return an iterator of samples in this DataPipe. Calling __iter__ of an IterDataPipe automatically invokes its method reset(), which by default performs no operation. When writing a custom IterDataPipe, users should override reset() if necessary. The common usages include resetting buffers, pointers, and various state variables within the custom IterDataPipe.\nNote: Only one iterator can be valid for each IterDataPipe at a time, and the creation a second iterator will invalidate the first one. This constraint is necessary because some IterDataPipe have internal buffers, whose states can become invalid if there are multiple iterators. The code example below presents details on how this constraint looks in practice. If you have any feedback related to this constraint, please see GitHub IterDataPipe Single Iterator Issue_.\nThese DataPipes can be invoked in two ways, using the class constructor or applying their functional form onto an existing IterDataPipe (recommended, available to most but not all DataPipes). You can chain multiple IterDataPipe together to form a pipeline that will perform multiple operations in succession.\n.. _GitHub IterDataPipe Single Iterator Issue: https://github.com/pytorch/data/issues/45\nNote: When a subclass is used with :class:~torch.utils.data.DataLoader, each item in the DataPipe will be yielded from the :class:~torch.utils.data.DataLoader iterator. When :attr:num_workers > 0, each worker process will have a different copy of the DataPipe object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. :func:~torch.utils.data.get_worker_info, when called in a worker process, returns information about the worker. It can be used in either the dataset’s :meth:__iter__ method or the :class:~torch.utils.data.DataLoader ’s :attr:worker_init_fn option to modify each copy’s behavior.\nExamples: General Usage: >>> # xdoctest: +SKIP >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> map_dp_1 = Mapper(dp, lambda x: x + 1) # Using class constructor >>> map_dp_2 = dp.map(lambda x: x + 1) # Using functional form (recommended) >>> list(map_dp_1) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> list(map_dp_2) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> filter_dp = map_dp_1.filter(lambda x: x % 2 == 0) >>> list(filter_dp) [2, 4, 6, 8, 10] Single Iterator Constraint Example: >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> it1 = iter(source_dp) >>> list(it1) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> it1 = iter(source_dp) >>> it2 = iter(source_dp) # The creation of a new iterator invalidates it1 >>> next(it2) 0 >>> next(it1) # Further usage of it1 will raise a RunTimeError\n\n\n\nLossCalc\n\n LossCalc (*args, **kwds)\n\nIterable-style DataPipe.\nAll DataPipes that represent an iterable of data samples should subclass this. This style of DataPipes is particularly useful when data come from a stream, or when the number of samples is too large to fit them all in memory. IterDataPipe is lazily initialized and its elements are computed only when next() is called on the iterator of an IterDataPipe.\nAll subclasses should overwrite :meth:__iter__, which would return an iterator of samples in this DataPipe. Calling __iter__ of an IterDataPipe automatically invokes its method reset(), which by default performs no operation. When writing a custom IterDataPipe, users should override reset() if necessary. The common usages include resetting buffers, pointers, and various state variables within the custom IterDataPipe.\nNote: Only one iterator can be valid for each IterDataPipe at a time, and the creation a second iterator will invalidate the first one. This constraint is necessary because some IterDataPipe have internal buffers, whose states can become invalid if there are multiple iterators. The code example below presents details on how this constraint looks in practice. If you have any feedback related to this constraint, please see GitHub IterDataPipe Single Iterator Issue_.\nThese DataPipes can be invoked in two ways, using the class constructor or applying their functional form onto an existing IterDataPipe (recommended, available to most but not all DataPipes). You can chain multiple IterDataPipe together to form a pipeline that will perform multiple operations in succession.\n.. _GitHub IterDataPipe Single Iterator Issue: https://github.com/pytorch/data/issues/45\nNote: When a subclass is used with :class:~torch.utils.data.DataLoader, each item in the DataPipe will be yielded from the :class:~torch.utils.data.DataLoader iterator. When :attr:num_workers > 0, each worker process will have a different copy of the DataPipe object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. :func:~torch.utils.data.get_worker_info, when called in a worker process, returns information about the worker. It can be used in either the dataset’s :meth:__iter__ method or the :class:~torch.utils.data.DataLoader ’s :attr:worker_init_fn option to modify each copy’s behavior.\nExamples: General Usage: >>> # xdoctest: +SKIP >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> map_dp_1 = Mapper(dp, lambda x: x + 1) # Using class constructor >>> map_dp_2 = dp.map(lambda x: x + 1) # Using functional form (recommended) >>> list(map_dp_1) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> list(map_dp_2) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> filter_dp = map_dp_1.filter(lambda x: x % 2 == 0) >>> list(filter_dp) [2, 4, 6, 8, 10] Single Iterator Constraint Example: >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> it1 = iter(source_dp) >>> list(it1) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> it1 = iter(source_dp) >>> it2 = iter(source_dp) # The creation of a new iterator invalidates it1 >>> next(it2) 0 >>> next(it1) # Further usage of it1 will raise a RunTimeError\n\n\n\nModelLearnCalc\n\n ModelLearnCalc (*args, **kwds)\n\nIterable-style DataPipe.\nAll DataPipes that represent an iterable of data samples should subclass this. This style of DataPipes is particularly useful when data come from a stream, or when the number of samples is too large to fit them all in memory. IterDataPipe is lazily initialized and its elements are computed only when next() is called on the iterator of an IterDataPipe.\nAll subclasses should overwrite :meth:__iter__, which would return an iterator of samples in this DataPipe. Calling __iter__ of an IterDataPipe automatically invokes its method reset(), which by default performs no operation. When writing a custom IterDataPipe, users should override reset() if necessary. The common usages include resetting buffers, pointers, and various state variables within the custom IterDataPipe.\nNote: Only one iterator can be valid for each IterDataPipe at a time, and the creation a second iterator will invalidate the first one. This constraint is necessary because some IterDataPipe have internal buffers, whose states can become invalid if there are multiple iterators. The code example below presents details on how this constraint looks in practice. If you have any feedback related to this constraint, please see GitHub IterDataPipe Single Iterator Issue_.\nThese DataPipes can be invoked in two ways, using the class constructor or applying their functional form onto an existing IterDataPipe (recommended, available to most but not all DataPipes). You can chain multiple IterDataPipe together to form a pipeline that will perform multiple operations in succession.\n.. _GitHub IterDataPipe Single Iterator Issue: https://github.com/pytorch/data/issues/45\nNote: When a subclass is used with :class:~torch.utils.data.DataLoader, each item in the DataPipe will be yielded from the :class:~torch.utils.data.DataLoader iterator. When :attr:num_workers > 0, each worker process will have a different copy of the DataPipe object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. :func:~torch.utils.data.get_worker_info, when called in a worker process, returns information about the worker. It can be used in either the dataset’s :meth:__iter__ method or the :class:~torch.utils.data.DataLoader ’s :attr:worker_init_fn option to modify each copy’s behavior.\nExamples: General Usage: >>> # xdoctest: +SKIP >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> map_dp_1 = Mapper(dp, lambda x: x + 1) # Using class constructor >>> map_dp_2 = dp.map(lambda x: x + 1) # Using functional form (recommended) >>> list(map_dp_1) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> list(map_dp_2) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] >>> filter_dp = map_dp_1.filter(lambda x: x % 2 == 0) >>> list(filter_dp) [2, 4, 6, 8, 10] Single Iterator Constraint Example: >>> from torchdata.datapipes.iter import IterableWrapper, Mapper >>> dp = IterableWrapper(range(10)) >>> it1 = iter(source_dp) >>> list(it1) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> it1 = iter(source_dp) >>> it2 = iter(source_dp) # The creation of a new iterator invalidates it1 >>> next(it2) 0 >>> next(it1) # Further usage of it1 will raise a RunTimeError\n\n\n\nLossCollector\n\n LossCollector (*args, **kwds)\n\nLogCollector specifically manages finding and attaching itself to LoggerBases found earlier in the pipeline.\n\n\n\nDQNLearner\n\n DQNLearner (model, dls, logger_bases=None, loss_func=MSELoss(),\n             opt=<class 'torch.optim.adamw.AdamW'>, lr=0.005, bs=128,\n             max_sz=10000, nsteps=1, device=None, batches=None, dp_augment\n             ation_fns:Union[List[Callable[[Union[torch.utils.data.datapip\n             es.datapipe.IterDataPipe,torch.utils.data.datapipes.datapipe.\n             MapDataPipe]],Union[torch.utils.data.datapipes.datapipe.IterD\n             ataPipe,torch.utils.data.datapipes.datapipe.MapDataPipe,NoneT\n             ype]]],NoneType]=None)\n\nTry training with basic defaults…\n\n# Setup Loggers\nlogger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                 batch_on_pipe=BatchCollector)\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2).cuda()\n# Setup the Agent\nagent = DQNAgent(model,[logger_base],max_steps=4000,device='cuda')\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,nsteps=1,nskips=1,firstlast=False,bs=1)\n)\n\ndls = L(block.dataloaders(['CartPole-v1']*1,num_workers=0))\n\n# Setup the Learner\nlearner = DQNLearner(model,dls,batches=4,#1000,\n                     logger_bases=[logger_base],\n                      bs=2,#128,\n                      max_sz=100_000,device='cuda')\n# learner.fit(3)\nlearner.fit(2)\n\n\n\n\n\n\n\n  \n    \n      loss\n      episode\n      rolling_reward\n      epoch\n      batch\n      epsilon\n    \n  \n  \n    \n      0.44844115\n      1\n      None\n      1\n      5\n      0.998500\n    \n    \n      0.41163164\n      1\n      None\n      1\n      5\n      0.997500\n    \n  \n\n\n\nIf we try a regular DQN with nsteps/nskips it doesnt really converge after 130. We cant expect stability at all, and im pretty sure that nsteps (correctly) tries to reduce to number of duplicated states so that the agent can sample more unique state transitions. The problem with this is that the base dqn is not stable, so giving it lots of “new” stuff, im not sure helps. In otherwords, its going to forget the old stuff very quickly, and having duplicate states helps “remind it”\n\nlogger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                 batch_on_pipe=BatchCollector)\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2)\n# Setup the Agent\nagent = DQNAgent(model,[logger_base],max_steps=10000)\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,nsteps=2,nskips=2,firstlast=True) # We basically merge 2 steps into 1 and skip. \n)\n# pipes = L(block.datapipes(['CartPole-v1']*1,n=10))\ndls = L(block.dataloaders(['CartPole-v1']*1))\n# Setup the Learner\nlearner = DQNLearner(model,dls,batches=1000,logger_bases=[logger_base],bs=128,max_sz=20_000,nsteps=2,lr=0.001)\n# learner.fit(3)\n# learner.fit(20)\n\n\nimport pandas as pd\nfrom fastrl.pipes.core import *\nfrom fastrl.pipes.map.transforms import *\nfrom fastrl.envs.gym import GymTypeTransform,GymStepper\nfrom fastrl.loggers.core import *\nfrom fastrl.loggers.jupyter_visualizers import *\nfrom fastrl.loggers.vscode_visualizers import *\n\n\n# Setup Loggers\nlogger_base = ProgressBarLogger(epoch_on_pipe=EpocherCollector,\n                 batch_on_pipe=BatchCollector)\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(8,4)\n# Setup the Agent\nagent = DQNAgent(model,[logger_base])\n# Setup the DataBlock\nblock = DataBlock(\n    GymTransformBlock(agent=agent,bs=1,n=1000)\n)\ndls = L(block.dataloaders(['LunarLander-v2']*1))\n# Setup the Learner\nlearner = DQNLearner(model,dls,logger_bases=[logger_base])\nlearner.fit(3)\n# learner.fit(30)\n\n\n\n\n\n\n\n  \n    \n      loss\n      episode\n      rolling_reward\n      epoch\n      batch\n      epsilon\n    \n  \n  \n    \n      0.44493392\n      9\n      -174.366881\n      1\n      1000\n      0.020000\n    \n    \n      0.57215977\n      11\n      -149.441252\n      2\n      1000\n      0.020000\n    \n    \n      0.37252918\n      11\n      -149.441252\n      2\n      1000\n      0.020000\n    \n  \n\n\n\n\nimport pandas as pd\nfrom fastrl.pipes.core import *\nfrom fastrl.pipes.map.transforms import *\nfrom fastrl.envs.gym import GymTypeTransform,GymStepper\nfrom fastrl.loggers.vscode_visualizers import VSCodeTransformBlock"
  },
  {
    "objectID": "07_Agents/agents.core.html",
    "href": "07_Agents/agents.core.html",
    "title": "Agent Core",
    "section": "",
    "text": "AgentBase\n\n AgentBase (*args, **kwds)\n\nActs as the footer of the Agent pipeline. Maintains important state such as the model being used for get actions from. Also optionally allows passing a reference list of action_iterator which is a persistent list of actions for the entire agent pipeline to process through.\n\nImportant: Must be at the start of the pipeline, and be used with AgentHead at the end.\n\n\nImportant: action_iterator is stored in the iterable field. However the recommended way of passing actions to the pipeline is to call an AgentHead instance.\n\n\n\n\nAgentHead\n\n AgentHead (*args, **kwds)\n\nActs as the head of the Agent pipeline. Used for conveniently adding actions to the pipeline to process.\n\nImportant: Must be paired with AgentBase\n\n\n\n\nSimpleModelRunner\n\n SimpleModelRunner (*args, **kwds)\n\nTakes input from source_datapipe and pushes through the agent bases model assuming there is only one model field.\nCheck that the 1x4 tensor assuccessfully pushes through the model can get expected outputs…\n\ntorch.manual_seed(0)\n\nclass DQN(Module):\n    def __init__(self,state_sz:int,action_sz:int,hidden=512):\n        self.layers=Sequential(\n            Linear(state_sz,hidden),\n            ReLU(),\n            Linear(hidden,action_sz),\n        )\n    def forward(self,x): return self.layers(x)\n\n\n# from fastrl.agents.dqn.basic import DQN\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2)\n# Setup the agent\nagent = AgentBase(model)\nagent = SimpleModelRunner(agent)\nagent = AgentHead(agent)\n\n\ninput_tensor = tensor([1,2,3,4]).float()\n\nfor action in agent([input_tensor]):\n    print(action)\n    \ntest_eq(input_tensor,tensor([1., 2., 3., 4.]))\n\ntensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n\n\n\n\n\nStepFieldSelector\n\n StepFieldSelector (*args, **kwds)\n\nGrabs field from source_datapipe to push to the rest of the pipeline.\nCheck that using StepFieldSelector, we can grab the state field from the Simplestep to push through the model…\n\nagent = AgentBase(model)\nagent = StepFieldSelector(agent,field='state')\nagent = SimpleModelRunner(agent)\nagent = AgentHead(agent)\n\nfor action in agent([SimpleStep.random(state=tensor([1.,2.,3.,4.]))]):\n    print(action)\n\ntensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n\n\n\n# Setup up the core NN\ntorch.manual_seed(0)\nmodel = DQN(4,2)\n# Setup the agent\nagent = AgentBase(model,[])\n# All the things that make this agent unique and special\n# In this instance, all this module does is pass the action directly through to the model.\nagent = SimpleModelRunner(agent)\n# Bring everything together into the AgentHead where actions will be passed and then run through the pipeline\nagent = AgentHead(agent)\n\nIf we pass a list of tensors, we will get a list of actions:\n\nfor action in agent([tensor([1,2,3,4]).float()]):\n    print(action)\n\ntensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n\n\n\nfor action in agent([tensor([1,2,3,4]).float()]*3):\n    print(action)\ntraverse(agent); # Check that we can traverse it\n\ntensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\ntensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\ntensor([[-0.2909, -1.0357]], grad_fn=<AddmmBackward0>)\n\n\n\nfrom fastrl.pipes.core import *\nfrom fastrl.pipes.map.transforms import *\nfrom fastrl.data.block import *\nfrom fastrl.envs.gym import *\n\n\n# def baseline_test(envs,total_steps,seed=0):\n#     pipe = dp.map.Mapper(envs)\n#     pipe = TypeTransformer(pipe,[GymTypeTransform])\n#     pipe = dp.iter.MapToIterConverter(pipe)\n#     pipe = dp.iter.InMemoryCacheHolder(pipe)\n#     pipe = pipe.cycle()\n#     pipe = GymStepper(pipe,seed=seed)\n\n#     steps = [step for _,step in zip(*(range(total_steps),pipe))]\n#     return steps, pipe\n\n\n# steps, pipe = baseline_test(['CartPole-v1'],0)\n\n\n\n\nStepModelFeeder\n\n StepModelFeeder (*args, **kwds)\n\nConverts StepTypes into unified tensors using keys and feeds them into self.agent_base.model\n\n\n\nNumpyConverter\n\n NumpyConverter (*args, **kwds)\n\nGiven input Tensor from source_datapipe returns a numpy array of same shape with argmax set to 1.\n\ntensors = [tensor([4]) for _ in range(10)]\npipe = NumpyConverter(tensors)\nlist(pipe);\n\n\ntensors = [tensor([4]).to(device='cuda') for _ in range(10)]\npipe = NumpyConverter(tensors)\nlist(pipe);"
  },
  {
    "objectID": "cli.html",
    "href": "cli.html",
    "title": "CLI",
    "section": "",
    "text": "fastrl_make_requirements\n\n fastrl_make_requirements (path:pathlib.Path=None,\n                           project_file:str='settings.ini',\n                           out_path:pathlib.Path=None, verbose:bool=False)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nPath\nNone\nThe path to a dir with the settings.ini, if none, cwd.\n\n\nproject_file\nstr\nsettings.ini\nThe file to load for reading the requirements\n\n\nout_path\nPath\nNone\nThe output path (can be relative to path)\n\n\nverbose\nbool\nFalse\nOutput to stdout\n\n\n\n\n\n\nfastrl_nbdev_docs\n\n fastrl_nbdev_docs (path:str=None, n_workers:int=2, verbose:bool=False,\n                    one2one:bool=True, file_glob:str=None,\n                    file_re:str='\\\\.(?:ipynb|qmd|html)$',\n                    symlinks:bool=False, folder_re:str=None,\n                    skip_file_glob:str=None, skip_file_re:str='^[_.]',\n                    skip_folder_re:str='^[_.]')\n\nCreate Quarto docs and README.md\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\nn_workers\nint\n2\nNumber of workers\n\n\nverbose\nbool\nFalse\nverbose outputs\n\n\none2one\nbool\nTrue\nRun 1 notebook per process instance.\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\n.(?:ipynb|qmd|html)$\nOnly include files matching regex\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex\n\n\n\n\n\n\nproc_nbs\n\n proc_nbs (path:str='', n_workers:int=2, force:bool=False,\n           file_glob:str='', verbose:bool=False, one2one:bool=True,\n           symlinks:bool=False, file_re:str=None, folder_re:str=None,\n           skip_file_glob:str=None, skip_file_re:str='^[_.]',\n           skip_folder_re:str='^[_.]')\n\nProcess notebooks in path for docs rendering\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\n\nPath to notebooks\n\n\nn_workers\nint\n2\nNumber of workers\n\n\nforce\nbool\nFalse\nIgnore cache and build all\n\n\nfile_glob\nstr\n\nOnly include files matching glob\n\n\nverbose\nbool\nFalse\nverbose outputs\n\n\none2one\nbool\nTrue\nRun 1 notebook per process instance.\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex\n\n\n\n\n\n\nfastrl_nbdev_test\n\n fastrl_nbdev_test (path:str=None, flags:str='', n_workers:int=None,\n                    timing:bool=False, do_print:bool=False,\n                    pause:float=0.01, ignore_fname:str='.notest',\n                    one2one:bool=True, symlinks:bool=False,\n                    file_glob:str='*.ipynb', file_re:str=None,\n                    folder_re:str=None, skip_file_glob:str=None,\n                    skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]')\n\nTest in parallel notebooks matching path, passing along flags\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nA notebook name or glob to test\n\n\nflags\nstr\n\nSpace separated list of test flags to run that are normally ignored\n\n\nn_workers\nint\nNone\nNumber of workers\n\n\ntiming\nbool\nFalse\nTime each notebook to see which are slow\n\n\ndo_print\nbool\nFalse\nPrint start and end of each notebook\n\n\npause\nfloat\n0.01\nPause time (in seconds) between notebooks to avoid race conditions\n\n\nignore_fname\nstr\n.notest\nFilename that will result in siblings being ignored\n\n\none2one\nbool\nTrue\nRun 1 notebook per process instance.\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfile_glob\nstr\n*.ipynb\nOnly include files matching glob\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex\n\n\n\n\n# fastrl_nbdev_test(n_workers=1)"
  }
]